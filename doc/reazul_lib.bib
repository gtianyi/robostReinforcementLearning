@article{Csaba2010,
	author = {Szepesvari, Csaba},
	doi = {10.2200/S00268ED1V01Y201005AIM009},
	file = {:home/reazul/Books/RLAlgsInMDPs-lecture.pdf:pdf},
	isbn = {9781608454921},
	issn = {1939-4608},
	pages = {1--98},
	journal = {Morgan and Claypool Publisher},
	title = {{Algorithms for reinforcement learning}},
	year = {2010}
}
@article{Wiesemann2013,
author = {Wiesemann, Wolfram},
file = {:C$\backslash$:/Users/Reazul Hasan Russel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiesemann - 2013 - Robust Markov decision processes.pdf:pdf},
journal = {Mathematics of Operations Research},
keywords = {markov decision processes,robust optimization,semidefinite programming},
volume = {38(1)},
pages={153-183},
title = {{Robust Markov decision processes}},
url = {http://mor.journal.informs.org/content/38/1/153.short},
year = {2013}
}
@article{Taleghan2015,
abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
file = {:C$\backslash$:/Users/Reazul Hasan Russel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Taleghan et al. - 2015 - PAC Optimal MDP Planning with Application to Invasive Species Management.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Good- Turing estimate,MDP planning,Markov decision processes,invasive species management,reinforcement learning},
pages = {3877--3903},
title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
url = {http://jmlr.org/papers/v16/taleghan15a.html},
volume = {16},
year = {2015}
}
@article{Pattanaik2017,
abstract = {This paper proposes adversarial attacks for Reinforcement Learning (RL) and then improves the robustness of Deep Reinforcement Learning algorithms (DRL) to parameter uncertainties with the help of these attacks. We show that even a naively engineered attack successfully degrades the performance of DRL algorithm. We further improve the attack using gradient information of an engineered loss function which leads to further degradation in performance. These attacks are then leveraged during training to improve the robustness of RL within robust control framework. We show that this adversarial training of DRL algorithms like Deep Double Q learning and Deep Deterministic Policy Gradients leads to significant increase in robustness to parameter variations for RL benchmarks such as Cart-pole, Mountain Car, Hopper and Half Cheetah environment.},
archivePrefix = {arXiv},
arxivId = {1712.03632},
author = {Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
eprint = {1712.03632},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/1712.03632.pdf:pdf},
title = {{Robust Deep Reinforcement Learning with Adversarial Attacks}},
url = {http://arxiv.org/abs/1712.03632},
year = {2017}
}
@article{Fu2017,
abstract = {Reinforcement learning provides a powerful and general framework for decision making and control, but its application in practice is often hindered by the need for extensive feature and reward engineering. Deep reinforcement learning methods can remove the need for explicit engineering of policy or value features, but still require a manually specified reward function. Inverse reinforcement learning holds the promise of automatic reward acquisition, but has proven exceptionally difficult to apply to large, high-dimensional problems with unknown dynamics. In this work, we propose adverserial inverse reinforcement learning (AIRL), a practical and scalable inverse reinforcement learning algorithm based on an adversarial reward learning formulation. We demonstrate that AIRL is able to recover reward functions that are robust to changes in dynamics, enabling us to learn policies even under significant variation in the environment seen during training. Our experiments show that AIRL greatly outperforms prior methods in these transfer settings.},
archivePrefix = {arXiv},
arxivId = {1710.11248},
author = {Fu, Justin and Luo, Katie and Levine, Sergey},
eprint = {1710.11248},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/1710.11248.pdf:pdf},
pages = {1--13},
title = {{Learning Robust Rewards with Adversarial Inverse Reinforcement Learning}},
url = {http://arxiv.org/abs/1710.11248},
year = {2017}
}
@article{Roy2017,
abstract = {We study reinforcement learning under model misspecification, where we do not have access to the true environment but only to a reasonably close approximation to it. We address this problem by extending the framework of robust MDPs to the model-free Reinforcement Learning setting, where we do not have access to the model parameters, but can only sample states from it. We define robust versions of Q-learning, SARSA, and TD-learning and prove convergence to an approximately optimal robust policy and approximate value function respectively. We scale up the robust algorithms to large MDPs via function approximation and prove convergence under two different settings. We prove convergence of robust approximate policy iteration and robust approximate value iteration for linear architectures (under mild assumptions). We also define a robust loss function, the mean squared robust projected Bellman error and give stochastic gradient descent algorithms that are guaranteed to converge to a local minimum.},
archivePrefix = {arXiv},
arxivId = {1706.04711},
author = {Roy, Aurko and Xu, Huan and Pokutta, Sebastian},
eprint = {1706.04711},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/6897-reinforcement-learning-under-model-mismatch.pdf:pdf},
number = {Nips},
pages = {1--10},
title = {{Reinforcement Learning under Model Mismatch}},
url = {http://arxiv.org/abs/1706.04711},
year = {2017}
}
@article{Everitt2017,
abstract = {No real-world reward function is perfect. Sensory errors and software bugs may result in RL agents observing higher (or lower) rewards than they should. For example, a reinforcement learning agent may prefer states where a sensory error gives it the maximum reward, but where the true reward is actually small. We formalise this problem as a generalised Markov Decision Problem called Corrupt Reward MDP. Traditional RL methods fare poorly in CRMDPs, even under strong simplifying assumptions and when trying to compensate for the possibly corrupt rewards. Two ways around the problem are investigated. First, by giving the agent richer data, such as in inverse reinforcement learning and semi-supervised reinforcement learning, reward corruption stemming from systematic sensory errors may sometimes be completely managed. Second, by using randomisation to blunt the agent's optimisation, reward corruption can be partially managed under some assumptions.},
archivePrefix = {arXiv},
arxivId = {1705.08417},
author = {Everitt, Tom and Krakovna, Victoria and Orseau, Laurent and Legg, Shane},
doi = {10.24963/ijcai.2017/656},
eprint = {1705.08417},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/0656.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Philosophical: Other,Social: Security {\&} Privacy,Technical: Models,Technical: Techniques},
pages = {4705--4713},
title = {{Reinforcement learning with a corrupted reward channel}},
year = {2017}
}
@article{Pinto2017,
abstract = {Deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning (RL). However, most current RL-based approaches fail to generalize since: (a) the gap between simulation and real world is so large that policy-learning approaches fail to transfer; (b) even if policy learning is done in real world, the data scarcity leads to failed generalization from training to test scenarios (e.g., due to different friction or object masses). Inspired from H-infinity control methods, we note that both modeling errors and differences in training and test scenarios can be viewed as extra forces/disturbances in the system. This paper proposes the idea of robust adversarial reinforcement learning (RARL), where we train an agent to operate in the presence of a destabilizing adversary that applies disturbance forces to the system. The jointly trained adversary is reinforced -- that is, it learns an optimal destabilization policy. We formulate the policy learning as a zero-sum, minimax objective function. Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah, Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a) improves training stability; (b) is robust to differences in training/test conditions; and c) outperform the baseline even in the absence of the adversary.},
archivePrefix = {arXiv},
arxivId = {1703.02702},
author = {Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
eprint = {1703.02702},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/1703.02702.pdf:pdf},
isbn = {9781538626818},
issn = {1938-7228},
title = {{Robust Adversarial Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.02702},
year = {2017}
}
@book{Ghavamzadeh2015,
abstract = {Bayesian Reinforcement Learning: A Survey},
archivePrefix = {arXiv},
arxivId = {1405.4980},
author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
booktitle = {Foundations and Trends{\textregistered} in Machine Learning},
doi = {10.1561/2200000049},
eprint = {1405.4980},
file = {:C$\backslash$:/Users/Reazul Hasan Russel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghavamzadeh et al. - 2015 - Convex Optimization Algorithms and Complexity.pdf:pdf},
isbn = {2200000049},
issn = {1935-8237},
number = {5-6},
pages = {359--483},
pmid = {18255791},
title = {{Convex Optimization: Algorithms and Complexity}},
url = {http://www.nowpublishers.com/article/Details/MAL-049},
volume = {8},
year = {2015}
}
@article{SuvritSraandStephenJ.Wright2012,
author = {{Suvrit Sra  and Stephen J. Wright}, Sebastian Nowozin},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/RobustMLchapter.pdf:pdf},
journal = {Mit},
title = {{Optimization for Machine Learning}},
year = {2012}
}
@article{Xu2012,
abstract = {We consider Markov decision processes where the values of the parameters are uncertain. This uncertainty is described by a sequence of nested sets (that is, each set contains the previous one), each of which corresponds to a probabilistic guarantee for a different confidence level. Consequently, a set of admissible probability distributions of the unknown parameters is specified. This formulation models the case where the decision maker is aware of and wants to exploit some (yet imprecise) a priori information of the distribution of parameters, and it arises naturally in practice where methods for estimating the confidence region of parameters abound. We propose a decision criterion based on distributional robustness: the optimal strategy maximizes the expected total reward under the most adversarial admissible probability distributions. We show that finding the optimal distributionally robust strategy can be reduced to the standard robust MDP where parameters are known to belong to a single uncertainty set; hence, it can be computed in polynomial time under mild technical conditions.},
author = {Xu, Huan and Mannor, Shie},
doi = {10.1287/moor.1120.0540},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/3927-distributionally-robust-markov-decision-processes.pdf:pdf},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {2},
pages = {288--300},
title = {{Distributionally Robust Markov Decision Processes}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1120.0540},
volume = {37},
year = {2012}
}
@article{Chen2018,
abstract = {The distributionally robust Markov Decision Process approach has been proposed in the literature, where the goal is to seek a distributionally robust policy that achieves the maximal expected total reward under the most adversarial joint distribution of uncertain parameters. In this paper, we study distributionally robust MDP where ambiguity sets for uncertain parameters are of a format that can easily incorporate in its description the uncertainty's statistical information estimated from historical data. In this way, we generalize existing works on distributionally robust Markov Decision Process with generalized-moment-based ambiguity sets and statistical-distance-based ambiguity sets to incorporate information from the former class such as moments and dispersions to the latter class that critically depend on samples. We show that, under this format of ambiguity sets, the resulting distributionally robust Markov Decision Process remains tractable under mild technical conditions. To be more specific, a distributionally robust policy can be constructed by solving a collection of one-stage convex optimization subproblems.},
archivePrefix = {arXiv},
arxivId = {1801.04745},
author = {Chen, Zhi and Yu, Pengqian and Haskell, William B.},
eprint = {1801.04745},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/1801.04745.pdf:pdf},
pages = {1--29},
title = {{Distributionally Robust Optimization for Sequential Decision Making}},
url = {http://arxiv.org/abs/1801.04745},
year = {2018}
}
@article{Ho2018,
author = {Ho, Chin Pang and Petrik, Marek and Wiesemann, Wolfram},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/ho18a.pdf:pdf},
issn = {1938-7228},
journal = {International Conference on Machine Learning (ICML)},
title = {{Fast Bellman Updates for Robust MDPs}},
url = {http://proceedings.mlr.press/v80/ho18a.html},
year = {2018}
}
@article{Yang2017,
abstract = {—We consider the problem of constructing con-trol policies that are robust against distribution errors in the model parameters of Markov decision processes. The Wasserstein metric is used to model the ambiguity set of admissible distributions. We prove the existence and optimality of Markov policies and develop convex optimization-based tools to compute and analyze the poli-cies. Our methods, which are based on the Kantorovich convex relaxation and duality principle, have the follow-ing advantages. First, the proposed dual formulation of an associated Bellman equation resolves the infinite dimen-sionality issue that is inherent in its original formula-tion when the nominal distribution has a finite support. Second, our duality analysis identifies the structure of a worst-case distribution and provides a simple decen-tralized method for its construction. Third, a sensitivity analysis tool is developed to quantify the effect of ambi-guity set parameters on the performance of distributionally robust policies. The effectiveness of our proposed tools is demonstrated through a human-centered air conditioning problem.},
author = {Yang, Insoon},
doi = {10.1109/LCSYS.2017.2711553},
file = {:E$\backslash$:/PhD Depth/Relevant Papers/07938642.pdf:pdf},
isbn = {9781509028726},
journal = {IEEE control systems letters},
number = {1},
pages = {164--169},
title = {{A convex optimization approach to distributionally robust Markov decision processes with Wasserstein distance}},
volume = {1},
year = {2017}
}
@article{Petrik2016,
author = {Petrik, Marek},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2016 - Safe Policy Improvement by Minimizing Robust Baseline Regret.pdf:pdf},
number = {Nips},
title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
year = {2016}
}
@book{RobustOptimization,
author = {Ben-Tal, Aharon and El Ghaoui, Laurent and Nemirovski, Arkadi},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Optimization - Unknown - Robust Optimization.pdf:pdf},
isbn = {9780691143682},
title = {{Robust Optimization}}
year = {2009}
}
@article{Brown2017,
author = {Brown, David B and Brown, David B and Caramanis, Constantine},
file = {:home/reazul/PhD{\_}Research/robust{\_}papers/RobustOptyimization{\_}Bertsimas.pdf:pdf},
title = {{Theory and Applications of Robust Optimization The MIT Faculty has made this article openly available . Please share Citation Accessed Citable Link Robust Optimization ∗}},
year = {2017}
}
@article{Dann2015,
abstract = {Recently, there has been significant progress in understanding reinforcement learning in discounted infinite-horizon Markov decision processes (MDPs) by deriving tight sample complexity bounds. However, in many real-world applications, an interactive learning agent operates for a fixed or bounded period of time, for example tutoring students for exams or handling customer service requests. Such scenarios can often be better treated as episodic fixed-horizon MDPs, for which only looser bounds on the sample complexity exist. A natural notion of sample complexity in this setting is the number of episodes required to guarantee a certain performance with high probability (PAC guarantee). In this paper, we derive an upper PAC bound {\$}\backslashtilde O(\backslashfrac{\{}|\backslashmathcal S|{\^{}}2 |\backslashmathcal A| H{\^{}}2{\}}{\{}\backslashepsilon{\^{}}2{\}} \backslashln\backslashfrac 1 \backslashdelta){\$} and a lower PAC bound {\$}\backslashtilde \backslashOmega(\backslashfrac{\{}|\backslashmathcal S| |\backslashmathcal A| H{\^{}}2{\}}{\{}\backslashepsilon{\^{}}2{\}} \backslashln \backslashfrac 1 {\{}\backslashdelta + c{\}}){\$} that match up to log-terms and an additional linear dependency on the number of states {\$}|\backslashmathcal S|{\$}. The lower bound is the first of its kind for this setting. Our upper bound leverages Bernstein's inequality to improve on previous bounds for episodic finite-horizon MDPs which have a time-horizon dependency of at least {\$}H{\^{}}3{\$}.},
archivePrefix = {arXiv},
arxivId = {1510.08906},
author = {Dann, Christoph and Brunskill, Emma},
doi = {10.1128/IAI.70.4.2245-2248.2002},
eprint = {1510.08906},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/b644549f02f84a8780e17d8c40e3caa37be0.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
title = {{Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning}},
url = {http://arxiv.org/abs/1510.08906},
year = {2015}
}
@article{Lai1985,
abstract = {The authors consider multiarmed bandit problems with switching cost, define uniformly good allocation rules, and restrict attention to such rules. They present a lower bound on the asymptotic performance of uniformly good allocation rules and construct an allocation scheme that achieves the bound. It is found that despite the inclusion of a switching cost the proposed allocation scheme achieves the same asymptotic performance as the optimal rule for the bandit problem without switching cost. This is made possible by grouping together samples into blocks of increasing sizes, thereby reducing the number of switches to O(log {\textless}e1{\textgreater}n{\textless}/e1{\textgreater}). Finally, an optimal allocation scheme for a large class of distributions which includes members of the exponential family is illustrated},
author = {Lai, T. L. and Robbins, Herbert},
doi = {10.1016/0196-8858(85)90002-8},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Lai{\_}robbins85.pdf:pdf},
isbn = {0196-8858},
issn = {10902074},
journal = {Advances in Applied Mathematics},
number = {1},
pages = {4--22},
title = {{Asymptotically efficient adaptive allocation rules}},
volume = {6},
year = {1985}
}
@article{Brafman2001,
abstract = {R-max is a very simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-max, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on the optimal policy derived from this model. The model is initialized in an optimistic fashion: all actions in all states return the maximal possible reward (hence the name). During execution, it is updated based on the agent's observations. R-max improves upon several previous algo-rithms: (1) It is simpler and more general than Kearns and Singh's E 3 algorithm, covering zero-sum stochastic games. (2) It has a built-in mechanism for resolving the exploration vs. exploitation dilemma. (3) It formally justifies the " optimism under uncertainty " bias used in many RL algorithms. (4) It is simpler, more general, and more efficient than Brafman and Tennenholtz's LSG algorithm for learning in single controller stochastic games. (5) It generalizes the algorithm by Monderer and Tennenholtz for learning in repeated games. (6) It is the only algorithm for learning in repeated games, to date, which is provably efficient, considerably improving and simplifying previous algorithms by Banos and by Megiddo.},
author = {Brafman, Ronen I. and Tennenholtz, Moshe},
doi = {10.1162/153244303765208377},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/brafman02a.pdf:pdf},
isbn = {1532-4435},
issn = {10450823},
journal = {International Joint Conference on Artificial Intelligence (IJCAI)},
keywords = {decision processes,learning in games,markov,provably efficient learning,reinforcement learning,stochastic games},
title = {{R-MAX - A general polynomial time algorithm for near-optimal reinforcement learning}},
year = {2001}
}
@article{,
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/reinforcement.pdf:pdf},
title = {{Kearn98}}
}
@article{Zukerman2007,
abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we showthat the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.6028v1},
author = {Zukerman, I and Zukerman, I and Albrecht, D W and Albrecht, D W and Zhou, Li and White, John Myles and Voigtlaender, Paul and Shao, Xuhui and Li, Lexin and Said, Dormouse and Mitchell, T M and Mahajan, Aditya and Li, Wei and Wang, Xuerui and Zhang, Ruofei and Cui, Ying and Mao, Jianchang and Jin, Rong and Li, Cheng and Bendersky, Michael and Garg, Vijay and Ravi, Sujith and Kuleshov, Volodymyr and Precup, D and Kalos, Malvin H. and Whitlock, Paula a. and Jr, Joe F. Hair and Hoffman, Md and Gelman, Andrew and Granville, Vincent and Goul, Michael and Balkan, Sule and Dolk, Daniel and Gentle, James E and Frank, Eibe and Fernandes, Ricardo Felipe and Teixeira, Costa Magalhaes and Dietterich, Tg and Cao, F. and Ester, M. and Qian, W. and Zhou, A. and Cabras, S and Morales, J and Bucklin, Randolph E and Lattin, James M and Ansari, Asim and Gupta, Sunil and Bell, David and Little, John D C and Mela, Carl and Montgomery, Alan and Steckel, Joel and Berman, Ron and Auer, P and Cesa-bianchi, N and Fischer, P and Airlines, American},
doi = {10.1145/1552303.1552307},
eprint = {arXiv:1402.6028v1},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Zukerman et al. - 2007 - Monte Carlo Methods.pdf:pdf},
isbn = {089871611X | 9780898716115},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Campaign management support systems,Data handling,Data mining algorithms,Density based clustering,Evolving data streams,Multivariate anal,Predictive analytics,Predictive process,adaptive allocation rules,adaptive monte carlo,all or part of,back,bagged,bandit problems,bayesian inference,bayesian networks,c{\_}and{\_}e,cation,classi,click feed-,click-through-rate,collaborative learning,content-based learning,digital advertising,dual averaging,event discovery,event retrieval,exploitation and exploration,finite horizon regret,generalized pareto distribution,hamiltonian monte carlo,linear models,linear regression,locally weighted regression,markov chain monte carlo,markov models,model trees,models,monte carlo,multi-touch attribution model,naive bayes,neural networks,online advertising,or hard copies of,org entities,partial posterior predictive distribution,permission to make digital,regression,rule induction,schema,student{\_}modeling,tfidf-based,this work for,threshold selection,web events},
number = {1},
pages = {1--123},
pmid = {18292226},
title = {{Monte Carlo Methods}},
url = {http://link.springer.com/article/10.1023/A:1020231107662{\%}5Cnhttp://link.springer.com/chapter/10.1007/3-540-70659-3{\_}2{\%}5Cnhttp://www.datashaping.com/ABbook5.pdf{\%}5Cnhttp://phyusdb.files.wordpress.com/2013/03/monte-carlo-methods-second-revised-and-enlarged-ed},
volume = {1},
year = {2007}
}
@article{Houthooft2016,
abstract = {Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.},
archivePrefix = {arXiv},
arxivId = {1605.09674},
author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and {De Turck}, Filip and Abbeel, Pieter},
eprint = {1605.09674},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/1605.09674.pdf:pdf},
issn = {10495258},
title = {{VIME: Variational Information Maximizing Exploration}},
url = {http://arxiv.org/abs/1605.09674},
year = {2016}
}
@article{Auer2006,
abstract = {We present a learning algorithm for undiscounted reinforcement learning. $\backslash$r$\backslash$nOur interest lies in bounds for the algorithm's online performance after$\backslash$r$\backslash$nsome finite number of steps. In the spirit of similar methods already successfully applied for the exploration-exploitation tradeoff in multi-armed bandit problems, we use upper confidence bounds to show that our UCRL algorithm achieves logarithmic online regret in the number of steps taken with respect to an optimal policy.},
author = {Auer, Peter},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/UCRL.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Logarithmic Online Regret Bounds for Undiscounted Reinforcement Learning}},
year = {2006}
}
@article{Osband2017,
abstract = {We study the use of randomized value functions to guide deep exploration in reinforcement learning. This offers an elegant means for synthesizing statistically and computationally efficient exploration with common practical approaches to value function learning. We present several reinforcement learning algorithms that leverage randomized value functions and demonstrate their efficacy through computational studies. We also prove a regret bound that establishes statistical efficiency with a tabular representation.},
archivePrefix = {arXiv},
arxivId = {1703.07608},
author = {Osband, Ian and {Van Roy}, Benjamin and Russo, Daniel and Wen, Zheng},
eprint = {1703.07608},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Generalization and Exploration via Randomized Value Functions.pdf:pdf},
isbn = {9781510829008},
journal = {PhD thesis},
title = {{Deep Exploration via Randomized Value Functions}},
url = {http://arxiv.org/abs/1703.07608},
year = {2017}
}
@article{Kaufmann2018,
abstract = {This paper is about index policies for minimizing (frequentist) regret in a stochastic multi-armed bandit model, inspired by a Bayesian view on the problem. Our main contribution is to prove that the Bayes-UCB algorithm, which relies on quantiles of posterior distributions, is asymptotically optimal when the reward distributions belong to a one-dimensional exponential family, for a large class of prior distributions. We also show that the Bayesian literature gives new insight on what kind of exploration rates could be used in frequentist, UCB-type algorithms. Indeed, approximations of the Bayesian optimal solution or the Finite Horizon Gittins indices provide a justification for the kl-UCB+ and kl-UCB-H+ algorithms, whose asymptotic optimality is also established.},
archivePrefix = {arXiv},
arxivId = {1601.01190},
author = {Kaufmann, Emilie},
doi = {10.1214/17-AOS1569},
eprint = {1601.01190},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Bayes{\_}UCB.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bayesian methods,Gittins indices,Multi-armed bandit problems,Upper-confidence bounds},
number = {2},
pages = {842--865},
title = {{On Bayesian index policies for sequential resource allocation}},
volume = {46},
year = {2018}
}
@article{Jaksch2010,
abstract = {For undiscounted reinforcement learning in Markov decision processes (MDPs) we consider the total regret of a learning algorithm with respect to an optimal policy. In order to describe the transition structure of an MDP we propose a new parameter: An MDP has diameter D if for any pair of states s,s' there is a policy which moves from s to s' in at most D steps (on average). We present a reinforcement learning algorithm with total regret {\~{O}}(DS√AT) after T steps for any unknown MDP with S states, A actions per state, and diameter D. A corresponding lower bound of $\Omega$(√DSAT) on the total regret of any learning algorithm is given as well.$\backslash$r$\backslash$nThese results are complemented by a sample complexity bound on the number of suboptimal steps taken by our algorithm. This bound can be used to achieve a (gap-dependent) regret bound that is logarithmic in T.$\backslash$r$\backslash$nFinally, we also consider a setting where the MDP is allowed to change a fixed number of l times. We present a modification of our algorithm that is able to deal with this setting and show a regret bound of {\~{O}}(l1/3T2/3DS√A).},
archivePrefix = {arXiv},
arxivId = {1403.3741},
author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
eprint = {1403.3741},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Near-optimal Regret Bounds for Reinforcement Learning.pdf:pdf},
isbn = {Technical Report No. CIT-2009-01},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Computational,Information-Theoretic Learning with,Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
number = {1},
pages = {1563--1600},
title = {{Near-optimal Regret Bounds for Reinforcement Learning}},
url = {http://eprints.pascal-network.org/archive/00007081/},
volume = {11},
year = {2010}
}
@article{Lattimore2018,
author = {Lattimore, Tor and Szepesv, Csaba},
file = {:home/reazul/Books/Bandits{\_}book{\_}by{\_}Tor.pdf:pdf},
title = {{Bandits Book}},
year = {2018}
}
@article{Kaufmann2012,
author = {Kaufmann, Emilie and Capp, Olivier},
file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/On Bayesian Upper Confidence Bounds for Bandit Problems.pdf:pdf},
title = {{On Bayesian Upper Confidence Bounds for Bandit Problems}},
year = {2012}
}
@article{Thrun1992,
abstract = {Introduction Whenever an intelligent agent learns to control an unknown environment, two opposing objectives have to be combined. On the one hand, the environment must be sufficiently explored in order to identify a (sub-) optimal controller. For instance, a robot facing an unknown environment has to spend time moving around and acquiring knowledge. On the other hand, the environment must also be exploited during learning, i.e., experience made during learning must also be considered for action selection, if one is interested in minimizing costs of learning. For example, although a robot has to explore its environment, it should avoid collisions with obstacles once it has received some negative reward for collisions. For efficient learning, actions should thus be generated in such a way that the environment is explored and pain is avoided. This fundamental trade-off between exploration and exploitation demands efficient exploration capabilities, maximizing the effect of learni},
author = {Thrun, Sebastian},
doi = {10.1.1.17.4252},
file = {:home/reazul/PhD{\_}Research/Depth/7bbd8ba95e134089621e2674a7ac753fa4f5.pdf:pdf},
journal = {Handbook of Intelligent Control: Neural, Fuzzy and Adaptive Approaches},
keywords = {learning control},
title = {{The role of exploration in learning control}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.4252},
year = {1992}
}
@article{Tokic2010,
	abstract = {This paper presents “Value-Difference Based Exploration” (VDBE), a method for balancing the exploration/exploitation dilemma inherent to reinforcement learning. The proposed method adapts the ex- ploration parameter of $\epsilon$-greedy in dependence of the temporal-difference error observed from value-function backups, which is considered as a measure of the agent's uncertainty about the environment. VDBE is evaluated on a multi-armed bandit task, which allows for insight into the behavior of the method. Preliminary results indicate that VDBE seems to be more parameter robust than commonly used ad hoc approaches such as $\epsilon$-greedy or softmax.},
	author = {Tokic, Michel},
	doi = {10.1007/978-3-642-16111-7_23},
	file = {:home/reazul/PhD{\_}Research/Depth/AdaptiveEpsilonGreedyExploration.pdf:pdf},
	journal = {Annual German Conference on Advances in Artificial Intelligence},
	title = {{Adaptive $\epsilon$-greedy exploration in reinforcement learning based on value differences}},
	year = {2010}
}
@article{Thrun1992b,
	abstract = {Exploration plays a fundamental role in any active learning system. This study evaluates the role of exploration in active learning and describes several local techniques for exploration in finite, discrete domains, embedded in a reinforcement learning framework (delayed reinforcement). This paper distinguishes between two families of exploration schemes: undirected and directed exploration. While the former family is closely related to random walk exploration, directed exploration techniques memorize exploration-specific knowledge which is used for guiding the exploration search. In many finite deterministic domains, any learning technique based on undirected exploration is inefficient in terms of learning time, i.e., learning time is expected to scale exponentially with the size of the state space. We prove that for all these domains, reinforcement learning using a directed technique can always be performed in polynomial time, demonstrating the important role of exploration in reinforcement learning. (The proof is given for one specific directed exploration technique named counter-based exploration.) Subsequently, several exploration techniques found in recent reinforcement learning and connectionist adaptive control literature are described. In order to trade off efficiently between exploration and exploitation a trade-off which characterizes many real-world active learning tasks combination methods are described which explore and avoid costs simultaneously. This includes a selective attention mechanism, which allows smooth switching between exploration and exploitation. All techniques are evaluated and compared on a discrete reinforcement learning task (robot navigation). The empirical evaluation is followed by an extensive discussion of benefits and limitations of this work.},
	author = {Thrun, Sebastian B.},
	doi = {10.1109/IJCNN.2001.939497},
	file = {:home/reazul/PhD{\_}Research/Depth/10.1.1.45.2894.pdf:pdf},
	journal = {Technical Report},
	title = {{Efficient Exploration In Reinforcement Learning}},
	year = {1992}
}
@article{Sutton1991,
	abstract = {Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Sutton, Richard S.},
	doi = {10.1145/122344.122377},
	eprint = {arXiv:1011.1669v3},
	file = {:home/reazul/PhD{\_}Research/Depth/10.1.1.48.6005.pdf:pdf},
	isbn = {1-55860-141-4},
	issn = {01635719},
	journal = {ACM SIGART Bulletin},
	number = {4},
	pages = {160--163},
	pmid = {15003161},
	title = {{Dyna, an integrated architecture for learning, planning, and reacting}},
	url = {http://portal.acm.org/citation.cfm?doid=122344.122377},
	volume = {2},
	year = {1991}
}
@article{Tang2017,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1611.04717v3},
	author = {Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, Xi},
	eprint = {arXiv:1611.04717v3},
	file = {:home/reazul/PhD{\_}Research/Depth/1611.04717.pdf:pdf},
	journal = {Advances in Neural Information Processing Systems (NIPS)},
	title = {{Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning}},
	year = {2017}
}
@article{Gelly2007,
	author = {Gelly, Sylvain and Silver, David},
	file = {:home/reazul/PhD{\_}Research/Depth/GellySilverICML2007.pdf:pdf},
	journal = {International Conference on Machine Learning (ICML)},
	title = {{Combining Online and Offline Knowledge in UCT}},
	year = {2007}
}
@article{Kocsis2006,
	author = {Kocsis, Levente and Szepesvári, Csaba},
	file = {:home/reazul/PhD{\_}Research/Depth/uct.pdf:pdf},
	journal = {European Conference on Machine Learning (ECML)},
	title = {{Bandit based Monte-Carlo Planning}},
	year = {2006}
}
@article{Watkins1992,
	author = {Watkins, Christopher J C H},
	file = {:home/reazul/PhD{\_}Research/Depth/Watkins-Dayan1992{\_}Article{\_}Q-learning.pdf:pdf},
	keywords = {-learning,0,asynchronous dynamic programming,reinforcement learning,temporal differences},
	journal = {Machine Learning},
	title = {{Q-Learning}},
	year = {1992}
}
@article{Strehl2007,
	author = {Strehl, Alexander L},
	file = {:home/reazul/PhD{\_}Research/Depth/strehl.pdf:pdf},
	title = {{PROBABLY APPROXIMATELY CORRECT ( PAC ) EXPLORATION IN REINFORCEMENT LEARNING BY}},
	year = {2007}
}
@article{Kakade2003,
	author = {Kakade, Sham Machandranath},
	file = {:home/reazul/PhD{\_}Research/Depth/kakade{\_}thesis.pdf:pdf},
	title = {{On the Sample Complexity of Reinforcement Learning}},
	journal = {PhD thesis},
	year = {2003}
}
@article{Strehl2009,
	author = {Strehl, Alexander L and Littman, Michael L},
	file = {:home/reazul/PhD{\_}Research/Depth/strehl09a.pdf:pdf},
	keywords = {exploration,markov decision processes,pac-mdp,reinforcement learning,sample},
	pages = {2413--2444},
	journal = {Journal of Machine Learning Research (JMLR)},
	title = {{Reinforcement Learning in Finite MDPs: PAC Analysis}},
	volume = {10},
	year = {2009}
}
@article{Gittins1979,
	author = {Gittins, J. C.},
	file = {:home/reazul/PhD{\_}Research/Depth/10.1.1.295.4422.pdf:pdf},
	keywords = {bandit processes,dynamic allocation},
	number = {2},
	volume = {41},
	pages = {148--177},
	journal = {Journal of the Royal Statistical Society},
	title = {{Bandit Processes and Dynamic Allocation Indices}},
	volume = {41},
	year = {1979}
}
@article{Brafman2001,
	abstract = {R-max is a very simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-max, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on the optimal policy derived from this model. The model is initialized in an optimistic fashion: all actions in all states return the maximal possible reward (hence the name). During execution, it is updated based on the agent's observations. R-max improves upon several previous algo-rithms: (1) It is simpler and more general than Kearns and Singh's E 3 algorithm, covering zero-sum stochastic games. (2) It has a built-in mechanism for resolving the exploration vs. exploitation dilemma. (3) It formally justifies the " optimism under uncertainty " bias used in many RL algorithms. (4) It is simpler, more general, and more efficient than Brafman and Tennenholtz's LSG algorithm for learning in single controller stochastic games. (5) It generalizes the algorithm by Monderer and Tennenholtz for learning in repeated games. (6) It is the only algorithm for learning in repeated games, to date, which is provably efficient, considerably improving and simplifying previous algorithms by Banos and by Megiddo.},
	author = {Brafman, Ronen I. and Tennenholtz, Moshe},
	doi = {10.1162/153244303765208377},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/brafman02a.pdf:pdf},
	isbn = {1532-4435},
	issn = {10450823},
	journal = {International Joint Conference on Artificial Intelligence (IJCAI)},
	keywords = {decision processes,learning in games,markov,provably efficient learning,reinforcement learning,stochastic games},
	pages = {953--958},
	title = {{R-MAX - A general polynomial time algorithm for near-optimal reinforcement learning}},
	volume = {3},
	year = {2001}
}
@article{Li2011,
	author = {Li, Lihong and Littman, Michael L and Walsh, Thomas J and Strehl, Alexander L},
	doi = {10.1007/s10994-010-5225-4},
	file = {:home/reazul/PhD{\_}Research/Depth/kwik{\_}journal.pdf:pdf},
	keywords = {active learning,approximately correct,computational learning theory,exploration,knows what it knows,kwik,mistake bound,pac,probably,reinforcement learning},
	volume={82},
	pages = {399--443},
	journal = {Machine Learning},
	title = {{Knows what it knows: a framework for self-aware learning}},
	year = {2011}
}
@article{Cserna2017,
	abstract = {Multi-armed bandits are a quintessential machine learning problem requiring the balancing of exploration and exploitation. While there has been progress in developing algorithms with strong theoretical guarantees, there has been less focus on practical near-optimal finite-time performance. In this paper, we propose an algorithm for Bayesian multi-armed bandits that utilizes value-function-driven online planning techniques. Building on previous work on UCB and Gittins index, we introduce linearly-separable value functions that take both the expected return and the benefit of exploration into consideration to perform n-step lookahead. The algorithm enjoys a sub-linear performance guarantee and we present simulation results that confirm its strength in problems with structured priors. The simplicity and generality of our approach makes it a strong candidate for analyzing more complex multi-armed bandit problems.},
	archivePrefix = {arXiv},
	arxivId = {1704.03926},
	author = {Cserna, Bence and Petrik, Marek and Russel, Reazul Hasan and Ruml, Wheeler},
	eprint = {1704.03926},
	journal = {Uncertainty in Artificial Intelligence (UAI)},
	file = {:home/reazul/PhD{\_}Research/Depth/1704.03926.pdf:pdf},
	title = {{Value Directed Exploration in Multi-Armed Bandits with Structured Priors}},
	url = {http://arxiv.org/abs/1704.03926},
	year = {2017}
}
@article{Strens2002,
	author = {Strens, Malcolm},
	file = {:home/reazul/PhD{\_}Research/Depth/10.1.1.140.1701.pdf:pdf},
	isbn = {1-55860-707-2},
	journal = {International Conference on Machine Learning (ICML)},
	title = {{A Bayesian Framework for Reinforcement Learning}},
	year = {2000}
}
@article{Osband2013,
	abstract = {Most provably-efficient learning algorithms introduce optimism about poorly-understood states and actions to encourage exploration. We study an alternative approach for efficient exploration, posterior sampling for reinforcement learning (PSRL). This algorithm proceeds in repeated episodes of known duration. At the start of each episode, PSRL updates a prior distribution over Markov decision processes and takes one sample from this posterior. PSRL then follows the policy that is optimal for this sample during the episode. The algorithm is conceptually simple, computationally efficient and allows an agent to encode prior knowledge in a natural way. We establish an {\$}\backslashtilde{\{}O{\}}(\backslashtau S \backslashsqrt{\{}AT{\}}){\$} bound on the expected regret, where {\$}T{\$} is time, {\$}\backslashtau{\$} is the episode length and {\$}S{\$} and {\$}A{\$} are the cardinalities of the state and action spaces. This bound is one of the first for an algorithm not based on optimism, and close to the state of the art for any reinforcement learning algorithm. We show through simulation that PSRL significantly outperforms existing algorithms with similar regret bounds.},
	author = {Osband, Ian and Russo, Daniel and {Van Roy}, Benjamin},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/1306.0940.pdf:pdf},
	journal = {Advances in Neural Information Processing Systems (NIPS)},
	title = {{(More) Efficient Reinforcement Learning via Posterior Sampling?}},
	year = {2013}
}
@article{Osband2016,
	abstract = {Computational results demonstrate that posterior sampling for reinforcement learning (PSRL) dramatically outperforms algorithms driven by optimism, such as UCRL2. We provide insight into the extent of this performance boost and the phenomenon that drives it. We leverage this insight to establish an {\$}\backslashtilde{\{}O{\}}(H\backslashsqrt{\{}SAT{\}}){\$} Bayesian expected regret bound for PSRL in finite-horizon episodic Markov decision processes, where {\$}H{\$} is the horizon, {\$}S{\$} is the number of states, {\$}A{\$} is the number of actions and {\$}T{\$} is the time elapsed. This improves upon the best previous bound of {\$}\backslashtilde{\{}O{\}}(H S \backslashsqrt{\{}AT{\}}){\$} for any reinforcement learning algorithm.},
	author = {Osband, Ian and {Van Roy}, Benjamin},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/1607.00215.pdf:pdf},
	isbn = {9781510855144},
	journal = {International Conference on Machine Learning (ICML)},
	title = {{Why is Posterior Sampling Better than Optimism for Reinforcement Learning?}},
	year = {2017}
}
@article{Thompson1933,
	author = {Thompson, W.R.},
	file = {:home/reazul/PhD{\_}Research/Depth/2332286.pdf:pdf},
	number = {3},
	pages = {285--294},
	journal = { Oxford University Press},
	title = {{On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples}},
	volume = {25},
	year = {1933}
}
@article{Garc2018,
	abstract = {Safe Reinforcement Learning can be defined as the process of learning policies that maxi-mize the expectation of the return in problems in which it is important to ensure reasonable system performance and/or respect safety constraints during the learning and/or deploy-ment processes. We categorize and analyze two approaches of Safe Reinforcement Learning. The first is based on the modification of the optimality criterion, the classic discounted fi-nite/infinite horizon, with a safety factor. The second is based on the modification of the exploration process through the incorporation of external knowledge or the guidance of a risk metric. We use the proposed classification to survey the existing literature, as well as suggesting future directions for Safe Reinforcement Learning.},
	author = {Garc´, Javier and Andez, ıa Fernando Fern´},
	doi = {10.1109/TNNLS.2017.2654539},
	file = {:home/reazul/PhD{\_}Research/Depth/garcia15a.pdf:pdf},
	issn = {15337928},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	keywords = {reinforcement learning,risk sensitivity,safe exploration,teacher advice},
	number = {4},
	pages = {1069--1081},
	title = {{A Comprehensive Survey on Safe Reinforcement Learning}},
	url = {http://ieeexplore.ieee.org/document/7842559/},
	volume = {29},
	year = {2018}
}
@article{Russel2018,
	author = {Russel, Reazul Hasan and Petrik, Marek},
	file = {:home/reazul/PhD{\_}Research/Beyond{\_}CI/Infer2Control{\_}writeup/Optimizing{\_}ambiguity{\_}set{\_}workshop{\_}version.pdf:pdf},
	journal = {Infer to Control, Workshop on Probabilistic Reinforcement Learning and Structured Control, Advances in Neural Information Processing Systems (NIPS)},
	title = {{Tight Bayesian Ambiguity Sets for Robust MDPs}},
	year = {2018}
}
@article{Ahmed2017,
	abstract = {{\textless}p{\textgreater}Markov Decision Processes (MDPs) are an effective model to represent decision processes in the presence of transitional uncertainty and reward tradeoffs. However, due to the difficulty in exactly specifying the transition and reward functions in MDPs, researchers have proposed uncertain MDP models and robustness objectives in solving those models. Most approaches for computing robust policies have focused on the computation of maximin policies which maximize the value in the worst case amongst all realisations of uncertainty. Given the overly conservative nature of maximin policies, recent work has proposed minimax regret as an ideal alternative to the maximin objective for robust optimization. However, existing algorithms for handling minimax regret are restricted to models with uncertainty over rewards only and they are also limited in their scalability. Therefore, we provide a general model of uncertain MDPs that considers uncertainty over both transition and reward functions. Furthermore, we also consider dependence of the uncertainty across different states and decision epochs. We also provide a mixed integer linear program formulation for minimizing regret given a set of samples of the transition and reward functions in the uncertain MDP. In addition, we provide two myopic variants of regret, namely Cumulative Expected Myopic Regret (CEMR) and One Step Regret (OSR) that can be optimized in a scalable manner. Specifically, we provide dynamic programming and policy iteration based algorithms to optimize CEMR and OSR respectively. Finally, to demonstrate the effectiveness of our approaches, we provide comparisons on two benchmark problems from literature. We observe that optimizing the myopic variants of regret, OSR and CEMR are better than directly optimizing the regret.{\textless}/p{\textgreater}},
	author = {Ahmed, Asrar and Varakantham, Pradeep and Lowalekar, Meghna and Adulyasak, Yossiri and Jaillet, Patrick},
	doi = {10.1613/jair.5242},
	file = {:home/reazul/PhD{\_}Research/Depth/Sampling based approaches for minimizing regret in uncertain Mark.pdf:pdf},
	issn = {1076-9757},
	journal = {Journal of Artificial Intelligence Research},
	pages = {229--264},
	title = {{Sampling Based Approaches for Minimizing Regret in Uncertain Markov Decision Processes (MDPs)}},
	url = {https://jair.org/index.php/jair/article/view/11066},
	volume = {59},
	year = {2017}
}
@article{Schlecht2014,
	abstract = {Choice models are today ubiquitous across a range of applications in operations and marketing. Real world implementations of many of these models face the formidable stumbling block of simply identifying the 'right' model of choice to use. Since models of choice are inherently high dimensional objects, the typical approach to dealing with this problem is positing, a-priori, a parametric model that one believes adequately captures choice behavior. This approach can be substantially sub-optimal in scenarios where one cares about using the choice model learned to make fine-grained predictions; one must contend with the risks of mis-specification and over/under-fitting. Thus motivated, we visit the following problem: For a 'generic' model of consumer choice (namely, dis-tributions over preference lists) and a limited amount of data on how consumers actually make decisions (such as marginal information about these distributions), how may one predict revenues from offering a particular assortment of choices? An outcome of our investigation is a non-parametric approach in which the data automatically selects the 'right' choice model for revenue predictions. The approach is practical. Using a data set consisting of automobile sales transaction data from a major US automaker, our method demonstrates a 20{\%} improvement in prediction accuracy over state-of-the art benchmark models, which can result in a 10{\%} increase in revenues from optimizing the offer set. We also address a number of theoretical issues, among them a qualitative examination of the choice models implicitly learned by the approach. We believe that this paper takes a step towards 'automating' the crucial task of choice model selection.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1301.2609v5},
	author = {Schlecht, Volker},
	doi = {10.1287/xxxx.0000.0000},
	eprint = {arXiv:1301.2609v5},
	file = {:home/reazul/PhD{\_}Research/Depth/10.1.1.362.2568.pdf:pdf},
	isbn = {0025-1909},
	issn = {18129358},
	journal = {Investment Management and Financial Innovations},
	keywords = {Applied econometrics,Bayesian statistics,CRM,Customer centricity,Customer insights,Hierarchical Bayes approach,Online-marketing,Predictive modeling,Recommender-systems,Strategic marketing,Targeting,Two-mode segmentation},
	number = {4},
	pages = {7--24},
	pmid = {28028460},
	title = {{How to predict preferences for new items}},
	volume = {5},
	year = {2014}
}
@article{Xu2009,
	abstract = {We consider decision making in a Markovian setup where the reward parameters are not known in advance. Our performance criterion is the gap between the performance of the best strategy that is chosen after the true parameter realization is revealed and the performance of the strategy that is chosen before the parameter realization is revealed. We call this gap the parametric regret. We consider two related problems: minimax regret and mean-variance tradeoff of the regret. The minimax regret strategy minimizes the worst-case regret under the most adversarial possible realization. We show that the problem of computing a minimax regret strategy is NP-hard and propose algorithms to efficiently finding it under favorable conditions. The mean-variance tradeoff formulation requires a probabilistic model of the uncertain parameters and looks for a strategy that minimizes a convex combination of the mean and the variance of the regret. We prove that computing such a strategy can be done numerically in an efficient way.},
	author = {Xu, Huan and Mannor, Shie},
	doi = {10.1109/CDC.2009.5400796},
	file = {:home/reazul/PhD{\_}Research/Depth/05400796.pdf:pdf},
	isbn = {9781424438716},
	issn = {01912216},
	journal = {IEEE Conference on Decision and Control},
	keywords = {Markov processes,Stochastic optimal control,Uncertain systems},
	title = {{Parametric regret in uncertain Markov decision processes}},
	year = {2009}
}
@article{Wang2005,
	author = {Wang, Tao and Bowling, Michael and Cs, Dale and Ca, Ualberta},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/icml05a.pdf:pdf},
	journal = {International Conference on Machine Learning (ICML)},
	title = {{Bayesian Sparse Sampling for On-line Reward Optimization}},
	year = {2005}
}
@article{Strehl2008,
	author = {Strehl, Alexander L and Littman, Michael L},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/10.1.1.118.1174.pdf:pdf},
	keywords = {learning theory,markov decision processes,reinforcement learning},
	year = {2008},
	journal={Journal of Computer and System Sciences},
	volume={74},
	pages={1309-1331}
	title = {{An Analysis of Model-Based Interval Estimation for Markov Decision Processes}}
}
@article{Strehl2004,
	author = {Strehl, Alexander L and Littman, Michael L},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/4946d51e1f9dd0aefbc4f078c3ff4dd94358.pdf:pdf},
	year={2004}
	journal = {International Conference on Machine Learning (ICML)},
	title = {{Exploration via Model-based Interval Estimation}}
}
@article{Wiering1998,
	author = {Wiering, Marco and Schmidhuber, Jurgen},
	file = {:home/reazul/PhD{\_}Research/Bayesian{\_}Exploration/Wiering{\_}98{\_}efficientmodelbased.pdf:pdf},
	year = {1998},
	pages = {223--228},
	journal={ International Conference on Simulation of Adaptive Behavior (SAB)}
	title = {{Efficient Model-Based Exploration}}
}

















@article{Russo2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1403.5556v4},
author = {Russo, Daniel and Roy, Benjamin Van},
eprint = {arXiv:1403.5556v4},
file = {::},
pages = {1--34},
title = {{Learning to Optimize Via Information-Directed Sampling}},
year = {2014}
}
@article{Dudik2011,
abstract = {We address the problem of learning in an online setting where the learner repeatedly observes features, selects among a set of actions, and receives reward for the action taken. We provide the first efficient algorithm with an optimal regret. Our algorithm uses a cost sensitive classification learner as an oracle and has a running time {\$}\backslashmathrm{\{}polylog{\}}(N){\$}, where {\$}N{\$} is the number of classification rules among which the oracle might choose. This is exponentially faster than all previous algorithms that achieve optimal regret in this setting. Our formulation also enables us to create an algorithm with regret that is additive rather than multiplicative in feedback delay as in all previous work.},
archivePrefix = {arXiv},
arxivId = {1106.2369},
author = {Dudik, Miroslav and Hsu, Daniel and Kale, Satyen},
eprint = {1106.2369},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dudik, Hsu, Kale - 2011 - Efficient optimal learning for contextual bandits.pdf:pdf},
journal = {arXiv preprint arXiv: {\ldots}},
month = {jun},
title = {{Efficient optimal learning for contextual bandits}},
url = {http://arxiv.org/abs/1106.2369},
year = {2011}
}
@article{Zhao2014,
abstract = {We consider information filtering, in which we face a stream of items too voluminous to process by hand (e.g., scientific articles, blog posts, emails), and must rely on a computer system to automatically filter out irrelevant items. Such systems face the exploration vs. exploitation tradeoff, in which it may be beneficial to present an item despite a low probability of relevance, just to learn about future items with similar content. We present a Bayesian sequential decision-making model of this problem, show how it may be solved to optimality using dynamic programming and a decomposition that exploits problem structure, and show structural results for the optimal policy. We show that the resulting method is especially useful when facing the cold start problem, i.e., when filtering items for new users without a long history of past interactions. We then present an application of this information filtering method to a historical dataset from the arXiv.org repository of scientific articles.},
archivePrefix = {arXiv},
arxivId = {1407.8186},
author = {Zhao, Xiaoting and Frazier, Peter I.},
eprint = {1407.8186},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Frazier - 2014 - Exploration vs. Exploitation in the Information Filtering Problem.pdf:pdf},
month = {jul},
number = {2012},
pages = {32},
title = {{Exploration vs. Exploitation in the Information Filtering Problem}},
url = {http://arxiv.org/abs/1407.8186},
year = {2014}
}
@article{Filippi2010,
author = {Filippi, Sarah and Cappe, O and Garivier, a and Szepesv{\'{a}}ri, C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippi et al. - 2010 - Parametric Bandits The Generalized Linear Case(2).pdf:pdf},
isbn = {9781617823800},
journal = {Nips},
keywords = {generalized linear models,multi-armed bandit,parametric bandits,regret minimization,ucb},
pages = {1--9},
title = {{Parametric Bandits: The Generalized Linear Case.}},
url = {https://papers.nips.cc/paper/4166-parametric-bandits-the-generalized-linear-case.pdf},
year = {2010}
}
@article{Tsitsiklis1994,
author = {Tsitsiklis, JN},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis - 1994 - A short proof of the Gittins index theorem.pdf:pdf},
journal = {The Annals of Applied Probability},
number = {1},
pages = {194--199},
title = {{A short proof of the Gittins index theorem}},
url = {http://www.jstor.org/stable/2245051},
volume = {4},
year = {1994}
}
@article{Brafman2002a,
author = {Brafman, Ronen I and Tennenholtz, Moshe},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brafman, Tennenholtz - 2002 - R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {213--231},
title = {{R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning}},
volume = {3},
year = {2002}
}
@article{Anantharam1987,
abstract = {At each instant of time we are required to sample a fixed number{\textless}tex{\textgreater}m geq 1{\textless}/tex{\textgreater}out of{\textless}tex{\textgreater}N{\textless}/tex{\textgreater}Markov chains whose stationary transition probability matrices belong to a family suitably parameterized by a real number{\textless}tex{\textgreater}theta{\textless}/tex{\textgreater}. The objective is to maximize the long run expected value of the samples. The learning loss of a sampling scheme corresponding to a parameters configuration{\textless}tex{\textgreater}C = (theta{\_}{\{}1{\}}, ..., theta{\_}{\{}N{\}}){\textless}/tex{\textgreater}is quantified by the regret{\textless}tex{\textgreater}R{\_}{\{}n{\}}(C){\textless}/tex{\textgreater}. This is the difference between the maximum expected reward that could be achieved if{\textless}tex{\textgreater}C{\textless}/tex{\textgreater}were known and the expected reward actually achieved. We provide a lower bound for the regret associated with any uniformly good scheme, and construct a sampling scheme which attains the lower bound for every{\textless}tex{\textgreater}C{\textless}/tex{\textgreater}. The lower bound is given explicitly in terms of the Kullback-Liebler number between pairs of transition probabilities.},
author = {Anantharam, V. and Varaiya, P. and Walrand, J.},
doi = {10.1109/TAC.1987.1104491},
file = {::},
isbn = {0018-9286},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
pages = {968--976},
title = {{Asymptotically efficient allocation rules for the multiarmed bandit problem with multiple plays-Part I: I.I.D. rewards}},
volume = {32},
year = {1987}
}
@article{Kearns1998a,
author = {Kearns, Michael and Singh, Satinder},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kearns, Singh - 1998 - Near-optimal reinforcement learning in polynomial time.pdf:pdf},
journal = {International Conference on Machine Learning (ICML)},
title = {{Near-optimal reinforcement learning in polynomial time}},
year = {1998}
}
@article{Xie2013,
author = {Xie, Jing and Frazier, PI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Frazier - 2013 - Sequential Bayes-Optimal Policies for Multiple Comparisons with a Known Standard.pdf:pdf},
journal = {Operations Research},
keywords = {bayesian statistics,control,dynamic programming,multiple comparisons with a,sequential experimental design,value of information},
title = {{Sequential Bayes-Optimal Policies for Multiple Comparisons with a Known Standard}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.2013.1207},
year = {2013}
}
@article{Bubeck2012a,
abstract = {Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the Thirties, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this survey, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.},
archivePrefix = {arXiv},
arxivId = {1204.5721},
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
doi = {10.1561/2200000024},
eprint = {1204.5721},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems(3).pdf:pdf},
isbn = {9781601986269},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000024},
volume = {5},
year = {2012}
}
@inproceedings{Gentile2014a,
author = {Gentile, Claudio and Li, Shuai and Zappella, Giovanni and Com, Zappella Amazon},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gentile, Zappella, Com - 2014 - Online Clustering of Bandits.pdf:pdf},
keywords = {()},
title = {{Online Clustering of Bandits}},
year = {2014}
}
@article{Li2010a,
author = {Li, Lihong and Littman, Michael L. and Walsh, Thomas J. and Strehl, Alexander L.},
doi = {10.1007/s10994-010-5225-4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2010 - Knows what it knows a framework for self-aware learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {nov},
number = {3},
pages = {399--443},
title = {{Knows what it knows: a framework for self-aware learning}},
volume = {82},
year = {2010}
}
@article{Rusmevichientong2010b,
abstract = {We consider an assortment optimization problem where a retailer chooses$\backslash$nan assortment of products that maximizes the profit subject to a$\backslash$ncapacity constraint. The demand is represented by a multinomial logit$\backslash$nchoice model. We consider both the static and dynamic optimization$\backslash$nproblems. In the static problem, we assume that the parameters of$\backslash$nthe logit model are known in advance; we then develop a simple algorithm$\backslash$nfor computing a profit-maximizing assortment based on the geometry$\backslash$nof lines in the plane and derive structural properties of the optimal$\backslash$nassortment. For the dynamic problem, the parameters of the logit$\backslash$nmodel are unknown and must be estimated from data. By exploiting$\backslash$nthe structural properties found for the static problem, we develop$\backslash$nan adaptive policy that learns the unknown parameters from past data$\backslash$nand at the same time optimizes the profit. Numerical experiments$\backslash$nbased on sales data from an online retailer indicate that our policy$\backslash$nperforms well.},
author = {Rusmevichientong, P. and Shen, Z.-J. M. and Shmoys, D. B.},
doi = {10.1287/opre.1100.0866},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusmevichientong, Shen, Shmoys - 2010 - Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint(2).pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
pages = {1666--1680},
title = {{Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint}},
volume = {58},
year = {2010}
}
@article{Rusmevichientong2010a,
author = {Rusmevichientong, Paat and Tsitsiklis, John N.},
doi = {10.1287/moor.1100.0446},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusmevichientong, Tsitsiklis - 2010 - Linearly Parameterized Bandits.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {62f35,62l12,93e35,adaptive control,applications,control,dynamic programming and optimal,ms subject classification,msc2000 subject classification,multi-armed bandit,or,parametric model,primary,secondary,statistics},
month = {may},
number = {2},
pages = {395--411},
title = {{Linearly Parameterized Bandits}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1100.0446},
volume = {35},
year = {2010}
}
@inproceedings{Maillard,
author = {Maillard, Odalric-ambrym and Mannor, Shie},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillard, Mannor - 2014 - Latent bandits.pdf:pdf},
title = {{Latent bandits}},
year = {2014}
}
@misc{Caro2007,
abstract = {Companies such as Zara and World Co. have recently implemented novel$\backslash$nproduct development processes and supply chain architectures enabling$\backslash$nthem to make more product design and assortment decisions during$\backslash$nthe selling season, when actual demand information becomes available.$\backslash$nHow should such retail firms modify their product assortment over$\backslash$ntime in order to maximize overall profits for a given selling season?$\backslash$nFocusing on a stylized version of this problem, we study a finite$\backslash$nhorizon multiarmed bandit model with several plays per stage and$\backslash$nBayesian learning. Our analysis involves the Lagrangian relaxation$\backslash$nof weakly coupled dynamic programs (I)Ps), results contributing to$\backslash$nthe emerging theory of DP cluality and various approximations. It$\backslash$nyields a closed-form dynamic index policy capturing the key exploration$\backslash$nversus exploitation trade-off and associated suboptimality bounds.$\backslash$nIn numerical experiments its performance proves comparable to that$\backslash$nof other closed-form heuristics described in the literature, but$\backslash$nthis policy is particularly easy to implement and interpret. This$\backslash$nlast feature enables extensions to more realistic versions of the$\backslash$nmotivating dynamic assortment problem that include implementation$\backslash$ndelays, switching costs, and demand substitution effects.},
author = {Caro, Felipe and Gallien, Jeremie},
booktitle = {Management Science},
doi = {10.1287/mnsc.1060.0613},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caro, Gallien - 2007 - Dynamic Assortment with Demand Learning for Seasonal Consumer Goods.pdf:pdf},
isbn = {00251909},
issn = {0025-1909},
keywords = {2005,accepted by paul h,bayesian learning,dynamic programming duality,history,management,multiarmed,operations and supply chain,received january 13,retail assortment,the authors,this paper was with,zipkin},
number = {2},
pages = {276--292},
title = {{Dynamic Assortment with Demand Learning for Seasonal Consumer Goods}},
volume = {53},
year = {2007}
}
@article{Dietterich2013,
author = {Dietterich, TG and Taleghan, MA and Crowley, Mark},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich, Taleghan, Crowley - 2013 - PAC optimal planning for invasive species management Improved exploration for reinforcement learn.pdf:pdf},
journal = {AAAI},
title = {{PAC optimal planning for invasive species management: Improved exploration for reinforcement learning from simulator-defined MDPs.}},
year = {2013}
}
@techreport{Zhao2012,
author = {Zhao, Xiaoting},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao - 2012 - Bayesian Contextual Multi-armed Bandits.pdf:pdf},
pages = {1--33},
title = {{Bayesian Contextual Multi-armed Bandits}},
year = {2012}
}
@article{Auer2010a,
author = {Auer, P and Jaksch, Thomas and Ortner, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Auer, Jaksch, Ortner - 2010 - Near-optimal regret bounds for reinforcement learning.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {markov decision process,online learning,regret,sample complexity,undiscounted reinforcement learning},
number = {1},
pages = {1563--1600},
title = {{Near-optimal regret bounds for reinforcement learning}},
volume = {11},
year = {2010}
}
@article{Gittins1979a,
author = {Gittins, JC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gittins - 1979 - Bandit processes and dynamic allocation indices.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B ( {\ldots}},
keywords = {bandit processes,dynamic allocation},
number = {2},
pages = {148--177},
title = {{Bandit processes and dynamic allocation indices}},
volume = {41},
year = {1979}
}
@article{Modaresi2013,
author = {Modaresi, Sajad and Saur, Denis and Vielma, Juan Pablo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Modaresi, Saur, Vielma - 2013 - Learning in Combinatorial Optimization What and How to.pdf:pdf},
pages = {1--58},
title = {{Learning in Combinatorial Optimization : What and How to}},
year = {2013}
}
@article{Agrawal2012,
abstract = {Thompson Sampling is one of the oldest heuristics for multi-armed bandit problems. It is a randomized algorithm based on Bayesian ideas, and has recently generated significant interest after several studies demonstrated it to have better empirical performance compared to the state-of-the-art methods. However, many questions regarding its theoretical performance remained open. In this paper, we design and analyze a generalization of Thompson Sampling algorithm for the stochastic contextual multi-armed bandit problem with linear payoff functions, when the contexts are provided by an adaptive adversary. This is among the most important and widely studied version of the contextual bandits problem. We prove a high probability regret bound of {\$}\backslashtilde{\{}O{\}}(\backslashfrac{\{}d{\^{}}2{\}}{\{}\backslashepsilon{\}}\backslashsqrt{\{}T{\^{}}{\{}1+\backslashepsilon{\}}{\}}){\$} in time {\$}T{\$} for any {\$}0{\textless}\backslashepsilon {\textless}1{\$}, where {\$}d{\$} is the dimension of each context vector and {\$}\backslashepsilon{\$} is a parameter used by the algorithm. Our results provide the first theoretical guarantees for the contextual version of Thompson Sampling, and are close to the lower bound of {\$}\backslashOmega(d\backslashsqrt{\{}T{\}}){\$} for this problem. This essentially solves a COLT open problem of Chapelle and Li [COLT 2012].},
author = {Agrawal, S. and Goyal, N.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal, Goyal - 2012 - Thompson Sampling for contextual bandits with linear payoffs.pdf:pdf},
journal = {International Conference on Machine Learning (ICML)},
title = {{Thompson Sampling for contextual bandits with linear payoffs}},
year = {2012}
}
@article{Lu2010,
author = {Lu, Tyler and P{\'{a}}l, D and P{\'{a}}l, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, P{\'{a}}l, P{\'{a}}l - 2010 - Contextual multi-armed bandits.pdf:pdf},
journal = {International Conference on Machine Learning},
pages = {485--492},
title = {{Contextual multi-armed bandits}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/AISTATS2010{\_}LuPP10.pdf},
volume = {9},
year = {2010}
}
@misc{Agrawal1990,
author = {Agrawal, R. and Hegde, M. and Teneketzis, D.},
booktitle = {An International Journal of Probability and Stochastic Processes},
doi = {10.1080/17442509008833627},
file = {::},
issn = {1744-2508},
pages = {437--459},
title = {{Multi-armed bandit problems with multiple plays and switching cost}},
volume = {29},
year = {1990}
}
@article{Ehrenfeld2010,
abstract = {Exotic species affect the biogeochemical pools and fluxes of materials and energy, thereby altering the fundamental structure and function of their ecosystems. Rapidly accumulating evidence from many species of both an-imal and plant invaders suggests that invasive species often increase pool sizes, particularly of biomass, and promote accelerated flux rates, but many exceptions can be found. Ecosystem dynamics are altered through a variety of interacting, mutually reinforcing mechanistic pathways, including species' resource acquisition traits; population densities; ability to engineer changes to physical environmental conditions; effects on disturbance, especially fire; regimes; the ability to structure habitat for other species; and their impact on food webs. Local factors of landscape setting, history, and other sources of disturbance constrain ecosystem responses to invasions. New research directions are suggested, including the need for whole-system budgets, the quantification of abundance-impact relationships for particular ecosys-tem processes, and a better exploration of food web impacts on ecosystem processes.},
author = {Ehrenfeld, Joan G and Rodriguez, Diego},
doi = {10.1146/annurev-ecolsys-102209-144650},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ehrenfeld, Rodriguez - 2010 - Ecosystem Consequences of Biological Invasions.pdf:pdf},
journal = {Annu. Rev. Ecol. Evol. Syst},
keywords = {biogeochemistry,ecosystem engineers,functional traits,nutrients,transformers},
pages = {59--80},
title = {{Ecosystem Consequences of Biological Invasions}},
volume = {41},
year = {2010}
}
@article{Mero1984,
author = {Mero, L},
journal = {Artificial Intelligence},
pages = {13--27},
title = {{A heuristic search algorithm with modifiable estimate}},
volume = {23},
year = {1984}
}
@article{Zadrozny2001,
abstract = {Accurate, well-calibrated estimates of class membership probabilities are needed in many supervised learning applications, in particular when a cost-sensitive decision must be made about examples with example-dependent costs. This paper presents simple but successful meth- ods for obtaining calibrated probability estimates from decision tree and naive Bayesian classi- fiers. Using the large and challenging KDD'98 contest dataset as a testbed, we report the re- sults of a detailed experimental comparison of ten methods, according to four evaluation mea- sures. We conclude that binning succeeds in significantly improving naive Bayesian probabil- ity estimates, while for improving decision tree probability estimates, we recommend smoothing by that we call curtailment. ? -estimation and a new variant of pruning},
author = {Zadrozny, Bianca and Elkan, C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zadrozny, Elkan - 2001 - Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers.pdf:pdf},
isbn = {1-55860-778-1},
journal = {International Conference of Machine Learning},
pages = {1--8},
title = {{Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.3039{\&}rep=rep1{\&}type=pdf},
year = {2001}
}
@article{Randin2006,
author = {Randin, Christophe F. and Dirnb{\"{o}}ck, Thomas and Dullinger, Stefan and Zimmermann, Niklaus E. and Zappa, Massimiliano and Guisan, Antoine},
doi = {10.1111/j.1365-2699.2006.01466.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Randin et al. - 2006 - Are niche-based species distribution models transferable in space.pdf:pdf},
issn = {0305-0270},
journal = {Journal of Biogeography},
keywords = {Austria,Switzerland,generality,generalized additive models (GAM),generalized linear models (GLM),geographical transferability,habitat distribution,model evaluation,predictions,spatial modelling},
month = {oct},
number = {10},
pages = {1689--1703},
publisher = {Blackwell Publishing Ltd},
title = {{Are niche-based species distribution models transferable in space?}},
url = {http://doi.wiley.com/10.1111/j.1365-2699.2006.01466.x},
volume = {33},
year = {2006}
}
@techreport{Henderson2017,
archivePrefix = {arXiv},
arxivId = {1709.06560},
author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
eprint = {1709.06560},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henderson et al. - 2017 - Deep Reinforcement Learning that Matters.pdf:pdf},
title = {{Deep Reinforcement Learning that Matters}},
year = {2017}
}
@article{Zhou2009,
author = {Zhou, Shuheng and Lafferty, John and Wasserman, Larry},
doi = {10.1109/TIT.2008.2009605},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Lafferty, Wasserman - 2009 - Compressed and Privacy-Sensitive Sparse Regression.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
month = {feb},
number = {2},
pages = {846--866},
title = {{Compressed and Privacy-Sensitive Sparse Regression}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4777644},
volume = {55},
year = {2009}
}
@article{Scherrer2012,
author = {Scherrer, Bruno and Lesner, Boris},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scherrer, Lesner - 2012 - On the Use of Non-Stationary Policies for Stationary Infinite-Horizon Markov Decision Processes.pdf:pdf},
title = {{On the Use of Non-Stationary Policies for Stationary Infinite-Horizon Markov Decision Processes}},
year = {2012}
}
@article{Adelman2008,
author = {Adelman, Daniel and Mersereau, AJ},
doi = {10.1287/xxxx.0000.0000},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adelman, Mersereau - 2008 - Relaxations of weakly coupled stochastic dynamic programs.pdf:pdf},
journal = {Operations Research},
number = {3},
pages = {712--727},
title = {{Relaxations of weakly coupled stochastic dynamic programs}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1070.0445},
volume = {56},
year = {2008}
}
@inproceedings{Guez2012,
abstract = {Bayesian model-based reinforcement learning is a formally elegant approach to learning optimal behaviour under model uncertainty, trading off exploration and exploitation in an ideal way. Unfortunately, finding the resulting Bayes-optimal policies is notoriously taxing, since the search space becomes enormous. In this paper we introduce a tractable, sample-based method for approximate Bayes-optimal planning which exploits Monte-Carlo tree search. Our approach outperformed prior Bayesian model-based RL algorithms by a significant margin on several well-known benchmark problems -- because it avoids expensive applications of Bayes rule within the search tree by lazily sampling models from the current beliefs. We illustrate the advantages of our approach by showing it working in an infinite state space domain which is qualitatively out of reach of almost all previous work in Bayesian exploration.},
archivePrefix = {arXiv},
arxivId = {1205.3109},
author = {Guez, Arthur and Silver, David and Dayan, Peter},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
eprint = {1205.3109},
file = {:home/marek/Downloads/4767-efficient-bayes-adaptive-reinforcement-learning-using-sample-based-search.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
title = {{Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search}},
url = {http://arxiv.org/abs/1205.3109},
year = {2012}
}
@article{Eichorn2005,
author = {Eichorn, A and Romisch, W},
journal = {SIAM Journal on Optimization},
pages = {69--95},
title = {{Polyhedral Measures of Risk}},
volume = {16},
year = {2005}
}
@article{Szepesvari2010,
author = {Szepesvari, Csaba},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szepesvari - 2010 - Algorithms for Reinforcement Learning.pdf:pdf},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {1},
pages = {1--103},
title = {{Algorithms for Reinforcement Learning}},
volume = {4},
year = {2010}
}
@article{Soyster1973,
author = {Soyster, A. L. AL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soyster - 1973 - Technical note—convex programming with set-inclusive constraints and applications to inexact linear programming.pdf:pdf},
journal = {Operation Research},
number = {5},
pages = {1154--1157},
title = {{Convex programming with set-inclusive constraints and applications to inexact linear programming}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0 http://pubsonline.informs.org/doi/abs/10.1287/opre.21.5.1154},
volume = {21},
year = {1973}
}
@phdthesis{Strehl2008a,
annote = {Describes MBIE},
author = {Strehl, Alexander L},
booktitle = {Policy},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strehl - 2007 - Probably Approximately Corrct ( PAC ) Exploration in Reinforcement Learning.pdf:pdf},
title = {{Probably Approximately Corrct ( PAC ) Exploration in Reinforcement Learning}},
year = {2007}
}
@article{Tamar2016,
author = {Tamar, Aviv and Castro, Dotan Di},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar, Castro - 2016 - Learning the Variance of the Reward-To-Go.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {markov decision processes,reinforcement learning,simulation,temporal differences,variance estimation},
pages = {1--36},
title = {{Learning the Variance of the Reward-To-Go}},
volume = {17},
year = {2016}
}
@article{Sun2003,
author = {Sun, Bo and Zhou, Shenglu and Zhao, Qiguo},
doi = {10.1016/S0016-7061(03)00078-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Zhou, Zhao - 2003 - Evaluation of spatial and temporal changes of soil quality based on geostatistical analysis in the hill region.pdf:pdf},
issn = {00167061},
journal = {Geoderma},
month = {jul},
number = {1-2},
pages = {85--99},
title = {{Evaluation of spatial and temporal changes of soil quality based on geostatistical analysis in the hill region of subtropical China}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0016706103000788},
volume = {115},
year = {2003}
}
@article{Littman1994a,
author = {Littman, ML},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Littman - 1994 - Markov games as a framework for multi-agent reinforcement learning.pdf:pdf},
journal = {ICML},
number = {when 1},
title = {{Markov games as a framework for multi-agent reinforcement learning.}},
url = {http://ftp.cs.duke.edu/courses/spring07/cps296.3/littman94markov.pdf},
year = {1994}
}
@book{Porteus2002,
author = {Porteus, Evan L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Porteus - 2002 - Foundations of Stochastic Inventory Theory.pdf:pdf},
publisher = {Stanford Business Books},
title = {{Foundations of Stochastic Inventory Theory}},
year = {2002}
}
@inproceedings{Barahona2013,
author = {Barahona, Francisco and Ettl, Markus and Petrik, Marek and Rimshnick, Peter M.},
booktitle = {Winter Simulation Conference},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barahona et al. - 2013 - Agile logistics simulation and optimization for managing disaster responses.pdf:pdf},
isbn = {9781479939503},
pages = {3340--3351},
title = {{Agile logistics simulation and optimization for managing disaster responses.}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Agile+Logistics+Simulation+and+Optimization+for+Managing+Disaster+Responses{\#}1},
year = {2013}
}
@article{Fowler2009a,
abstract = {Principal component analysis (PCA) is often central to dimensionality reduction and compression in many applications, yet its data-dependent nature as a transform computed via expensive eigendecomposition often hinders its use in severely resource-constrained settings such as satellite-borne sensors. A process is presented that effectively shifts the computational burden of PCA from the resource-constrained encoder to a presumably more capable base-station decoder. The proposed approach, compressive-projection PCA (CPPCA), is driven by projections at the sensor onto lower-dimensional subspaces chosen at random, while the CPPCA decoder, given only these random projections, recovers not only the coefficients associated with the PCA transform, but also an approximation to the PCA transform basis itself. An analysis is presented that extends existing Rayleigh-Ritz theory to the special case of highly eccentric distributions; this analysis in turn motivates a reconstruction process at the CPPCA decoder that consists of a novel eigenvector reconstruction based on a convex-set optimization driven by Ritz vectors within the projected subspaces. As such, CPPCA constitutes a fundamental departure from traditional PCA in that it permits its excellent dimensionality-reduction and compression performance to be realized in an light-encoder/heavy-decoder system architecture. In experimental results, CPPCA outperforms a multiple-vector variant of compressed sensing for the reconstruction of hyperspectral data.},
author = {Fowler, James E},
doi = {10.1109/TIP.2009.2025089},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fowler - 2009 - Compressive-projection principal component analysis.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fowler - 2009 - Compressive-projection principal component analysis(2).pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Data Compression,Data Compression: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Principal Component Analysis,Reproducibility of Results,Sensitivity and Specificity,Signal Processing},
month = {oct},
number = {10},
pages = {2230--42},
pmid = {19520637},
title = {{Compressive-projection principal component analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19520637},
volume = {18},
year = {2009}
}
@article{Lynch2001,
author = {Lynch, A W},
journal = {Journal of Financial Economics},
pages = {67--130},
title = {{Portfolio choice and equity characteristics: Characterizing the hedging demands induced by return predictability}},
volume = {62},
year = {2001}
}
@incollection{Semal1995,
author = {Semal, P},
booktitle = {Computations with Markov Chains},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Semal - 1995 - Two bounding schemes for the steady-state solution of Markov chains.pdf:pdf},
title = {{Two bounding schemes for the steady-state solution of Markov chains}},
url = {http://link.springer.com/chapter/10.1007/978-1-4615-2241-6{\_}18},
year = {1995}
}
@article{Shapiro2012,
abstract = {In this paper we study relations between the minimax, risk averse and nested formulations of multistage stochastic programming problems. In particular, we discuss conditions for time consistency of such formulations of stochastic problems. We also describe a connection between law invariant coherent risk measures and the corresponding sets of probability measures in their dual representation. Finally, we discuss a minimax approach with moment constraints to the classical inventory model. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Shapiro, Alexander},
doi = {10.1016/j.ejor.2011.11.005},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro - 2012 - Minimax and risk averse multistage stochastic programming.pdf:pdf},
isbn = {0377-2217},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Coherent risk measures,Dynamic equations,Problem of moments,Risk averse stochastic optimization,Robust optimization,Stochastic programming},
number = {3},
pages = {719--726},
publisher = {Elsevier B.V.},
title = {{Minimax and risk averse multistage stochastic programming}},
url = {http://dx.doi.org/10.1016/j.ejor.2011.11.005},
volume = {219},
year = {2012}
}
@article{Walraven2015,
author = {Walraven, Erwin and Spaan, Matthijs T. J.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walraven, Spaan - 2015 - Planning under Uncertainty with Weighted State Scenarios.pdf:pdf},
isbn = {9780000000002},
journal = {Proceedings of the 31st Conference on Uncertainty in Artificial Intelligence},
title = {{Planning under Uncertainty with Weighted State Scenarios}},
year = {2015}
}
@phdthesis{Thomas2015b,
author = {Thomas, Phillip},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas - 2015 - Safe Reinforcement Learning.pdf:pdf},
title = {{Safe Reinforcement Learning}},
year = {2015}
}
@incollection{Farahmand2009,
author = {Farahmand, Amir M and Ghavamzadeh, Mohammad and Szepesvari, Csaba and Mannor, Shie},
booktitle = {Advances in Neural Information Processing Systems 21},
editor = {Koller, D and Schuurmans, D and Bengio, Y and Bottou, L},
pages = {441--448},
title = {{Regularized Policy Iteration}},
year = {2009}
}
@article{Lagoudakis2003,
author = {Lagoudakis, Michail G and Parr, Ronald},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lagoudakis, Parr - 2003 - Least-squares policy iteration.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1107--1149},
title = {{Least-squares policy iteration}},
volume = {4},
year = {2003}
}
@inproceedings{Culberson1996a,
author = {Culberson, Joseph C and Schaeffer, Jonathan},
booktitle = {Canadian Conference on AI},
pages = {402--416},
title = {{Searching with pattern databases}},
year = {1996}
}
@article{McCann1992,
author = {McCann, IR},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McCann - 1992 - Operational characteristics of the watermark model 200 soil water potential sensor for irrigation management.pdf:pdf},
journal = {Applied Engineering in Agriculture},
number = {5},
pages = {605--609},
title = {{Operational characteristics of the watermark model 200 soil water potential sensor for irrigation management}},
url = {http://eprints.nwisrl.ars.usda.gov/586/1/783.pdf},
volume = {8},
year = {1992}
}
@article{Petrik2014,
author = {Petrik, Marek and Subramanian, Dharmashankar},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2015 - RAAM The benefits of robustness in approximating aggregated MDPs in reinforcement learning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Subramanian - 2014 - RAAM The benefits of robustness in approximating aggregated MDPs in reinforcement learning.pdf:pdf},
journal = {Advances in Neural Information Processing Systems (NIPS)},
title = {{RAAM: The benefits of robustness in approximating aggregated MDPs in reinforcement learning}},
year = {2014}
}
@inproceedings{Galichet2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1401.1123v1},
author = {Galichet, Nicolas and Sebag, M and Teytaud, Olivier},
booktitle = {Asian Conference on Machine Learning (ACML)},
eprint = {arXiv:1401.1123v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Galichet, Sebag, Teytaud - 2013 - Exploration vs exploitation vs safety Risk-averse multi-armed bandits.pdf:pdf},
issn = {15337928},
keywords = {conditional value at,energy policy,max-min,multi-armed bandits,risk,risk aversion,risk awareness},
title = {{Exploration vs exploitation vs safety: Risk-averse multi-armed bandits}},
url = {http://arxiv.org/abs/1401.1123},
year = {2013}
}
@article{Fasen2010,
author = {Fasen, Vicky and Svejda, Adela},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fasen, Svejda - 2010 - Time Consistency of Multi-Period Distortion Measures.pdf:pdf},
keywords = {acceptability measure,center for mathematical sciences,coherence,conditional consistency,consistency,d-85747 garching,distortion measure,dynamic,email,germany,risk measure,sequential consistency,tail-value-at-risk,technische universit{\"{a}}t m{\"{u}}nchen,time-consistency},
pages = {1--23},
title = {{Time Consistency of Multi-Period Distortion Measures}},
year = {2010}
}
@article{Vandenberghe2011c,
annote = {where do we use the facts that G is like a gradient? If h=0, does this technique NOT work?
We use it in the global inequality... will use it to cancel the v term...},
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 04. Proximal gradient method.pdf:pdf},
journal = {LECTURE NOTES},
title = {{04. Proximal gradient method}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@article{Ramadesigan2012,
abstract = {The lithium-ion battery is an ideal candidate for a wide variety of applications due to its high energy/power density and operating voltage. Some limitations of existing lithium-ion battery technology include underutilization, stress-induced material damage, capacity fade, and the potential for thermal runaway. This paper reviews efforts in the modeling and simulation of lithium-ion batteries and their use in the design of better batteries. Likely future directions in battery modeling and design including promising research opportunities are outlined.},
author = {Ramadesigan, Venkatasailanathan and Northrop, Paul W. C. and De, Sumitava and Santhanagopalan, Shriram and Braatz, Richard D. and Subramanian, Venkat R.},
doi = {10.1149/2.018203jes},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramadesigan et al. - 2012 - Modeling and Simulation of Lithium-Ion Batteries from a Systems Engineering Perspective.pdf:pdf},
isbn = {0013-4651},
issn = {00134651},
journal = {Journal of The Electrochemical Society},
number = {3},
pages = {31--44},
title = {{Modeling and Simulation of Lithium-Ion Batteries from a Systems Engineering Perspective}},
volume = {159},
year = {2012}
}
@inproceedings{Gilpin2006a,
annote = {From Duplicate 2 ( A competitive Texas Hold ' em poker player via automated abstraction and real-time equilibrium computation ∗ - Gilpin, Andrew; Sandholm, Tuomas )
},
author = {Gilpin, Andrew and Sandholm, Tuomas},
booktitle = {National Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilpin, Sandholm - 2006 - A competitive Texas Hold ' em poker player via automated abstraction and real-time equilibrium computation.pdf:pdf},
title = {{A competitive {\{}T{\}}exas hold'em poker player via automated abstraction and real-time equilibrium computation}},
year = {2006}
}
@article{Kou2013,
abstract = {Choosing a proper external risk measure is of great regulatory importance, as exemplified in the Basel II and Basel III Accords, which use value-at-risk with scenario analysis as the risk measures for setting capital requirements. We argue that a good external risk measure should be robust with respect to model misspecification and small changes in the data. A new class of data-based risk measures called natural risk statistics is proposed to incorporate robustness. Natural risk statistics are characterized by a new set of axioms. They include the Basel II and III risk measures and a subclass of robust risk measures as special cases; therefore, they provide a theoretical framework for understanding and, if necessary, extending the Basel Accords.},
author = {Kou, Steven and Peng, Xianhua and Heyde, Chris C.},
doi = {10.1287/moor.1120.0577},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kou, Peng, Heyde - 2013 - External Risk Measures and Basel Accords.pdf:pdf},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {capital requirements,expected shortfall,financial regulation,median shortfall,risk measure,robustness,scenario analysis,value-at-risk},
pages = {393--417},
title = {{External Risk Measures and Basel Accords}},
url = {http://0-pubsonline.informs.org.pugwash.lib.warwick.ac.uk/doi/abs/10.1287/moor.1120.0577},
volume = {38},
year = {2013}
}
@book{Devroye1996,
author = {Devroye, Luc and Gyorfi, Laszlo and Lugosi, G{\'{a}}bor},
title = {{A Probabilistic Theory of Pattern Recognition}},
year = {1996}
}
@article{Iancu2015,
abstract = {This paper compares two frameworks for measuring risk in a multiperiod setting. The first corresponds to applying a single coherent risk measure to the cumulative future costs, and the second involves applying a composition of one-step coherent risk mappings. We characterize several necessary and sufficient conditions under which one measurement always dominates the other and introduce a metric to quantify how close the two measures are. Using this notion, we address the question of how tightly a given coherent measure can be approximated by lower or upper bounding compositional measures. We exhibit an interesting asymmetry between the two cases: the tightest upper bound can be exactly characterized and corresponds to a popular construction in the literature, whereas the tightest lower bound is not readily available. We show that testing domination and computing the approximation factors are generally NP-hard, even when the risk measures are comonotonic and law-invariant. However, we characterize conditio...},
archivePrefix = {arXiv},
arxivId = {1106.6102},
author = {Iancu, Dan A and Petrik, Marek and Subramanian, Dharmashankar},
doi = {10.1287/moor.2014.0689},
eprint = {1106.6102},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iancu, Petrik, Subramanian - 2015 - Tight Approximations of Dynamic Risk Measures.pdf:pdf},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {coherent risk measures,dynamic consistency,polymatroids,submodular functions,tight approximations},
number = {3},
pages = {655--682},
title = {{Tight Approximations of Dynamic Risk Measures}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.2014.0689},
volume = {40},
year = {2015}
}
@techreport{Stan2017,
author = {{Stan Development Team}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stan Development Team - 2017 - Stan Modeling Language User's Guide and Reference Manual.pdf:pdf},
title = {{Stan Modeling Language User's Guide and Reference Manual}},
year = {2017}
}
@article{Chang2012,
author = {Chang, Allison and Bertsimas, Dimitris and Rudin, Cynthia},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chang, Bertsimas, Rudin - 2012 - An Integer Optimization Approach to Associative Classification.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Nips},
pages = {269--277},
title = {{An Integer Optimization Approach to Associative Classification}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}0141.pdf},
year = {2012}
}
@inproceedings{Mahadevan1994,
author = {Mahadevan, Sridhar},
booktitle = {In Proceedings of the Eleventh International Conference on Machine Learning},
pages = {164--172},
title = {{To discount or not to discount in reinforcement learning: A case study comparing R learning and Q learning}},
year = {1994}
}
@inproceedings{Spaan2006,
address = {New York, New York, USA},
annote = {From Duplicate 1 ( Decentralized planning under uncertainty for teams of communicating agents - Spaan, Matthijs T. J.; Gordon, Geoffrey J.; Vlassis, Nikos; andNikos Vlassis, Geoffrey Gordon )
},
author = {Spaan, Matthijs T. J. and andNikos Vlassis, Geoffrey Gordon and Gordon, Geoffrey J. and Vlassis, Nikos},
booktitle = {International Joint Conference Autonomous Agents and Multiagent Systems (AAMAS)},
doi = {10.1145/1160633.1160678},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spaan, Gordon, Vlassis - 2006 - Decentralized planning under uncertainty for teams of communicating agents.pdf:pdf},
isbn = {1595933034},
keywords = {artificial intelligence,coopera-,decentralized pomdps,planning under uncertainty,tive multiagent systems},
pages = {249},
publisher = {ACM Press},
title = {{Decentralized planning under uncertainty for teams of communicating agents}},
url = {http://portal.acm.org/citation.cfm?doid=1160633.1160678},
year = {2006}
}
@phdthesis{Marivate2015,
author = {Marivate, B Y Vukosi N},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marivate - 2015 - Reinforcement-Learning Evaluation.pdf:pdf},
title = {{Reinforcement-Learning Evaluation}},
year = {2015}
}
@article{Vlassis2012,
author = {Vlassis, Nikos and Littman, ML and Barber, David},
doi = {10.1145/0000000.0000000},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vlassis, Littman, Barber - 2012 - On the computational complexity of stochastic controller optimization in POMDPs.pdf:pdf},
journal = {ACM Transactions on Computation Theory},
number = {212},
pages = {1--7},
title = {{On the computational complexity of stochastic controller optimization in POMDPs}},
url = {http://dl.acm.org/citation.cfm?id=2382563},
volume = {V},
year = {2012}
}
@article{Helmert2006,
author = {Helmert, Malte},
journal = {Journal of Artificial Intelligence Research},
pages = {191--246},
title = {{The Fast Downward Planning System}},
volume = {26},
year = {2006}
}
@article{Goulding2008,
abstract = {Increasing the inputs of nutrients has played a major role in increasing the supply of food to a continually growing world population. However, focusing attention on the most important nutrients, such as nitrogen (N), has in some cases led to nutrient imbalances, some excess applications especially of N, inefficient use and large losses to the environment with impacts on air and water quality, biodiversity and human health. In contrast, food exports from the developing to the developed world are depleting soils of nutrients in some countries. Better management of all essential nutrients is required that delivers sustainable agriculture and maintains the necessary increases in food production while minimizing waste, economic loss and environmental impacts. More extensive production systems typified by 'organic farming' may prove to be sustainable. However, for most of the developed world, and in the developing world where an ever-growing population demands more food, it will be essential to increase the efficiency of nutrient use in conventional systems. Nutrient management on farms is under the control of the land manger, the most effective of whom will already use various decision supports for calculating rates of application to achieve various production targets. Increasingly, land managers will need to conform to good practice to achieve production targets and to conform to environmental targets as well.},
author = {Goulding, Keith and Jarvis, Steve and Whitmore, Andy},
doi = {10.1098/rstb.2007.2177},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goulding, Jarvis, Whitmore - 2008 - Optimizing nutrient management for farm systems.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Agriculture,Agriculture: methods,Animal Husbandry,Animal Husbandry: methods,Animals,Biodiversity,Conservation of Natural Resources,Environment,Environmental Pollution,Environmental Pollution: prevention {\&} control,Food Supply,Humans,Nitrogen,Nitrogen: metabolism},
month = {feb},
number = {1491},
pages = {667--80},
pmid = {17652069},
title = {{Optimizing nutrient management for farm systems.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2610177{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {363},
year = {2008}
}
@article{Kveton2015,
abstract = {A search engine usually outputs a list of {\$}K{\$} web pages. The user examines this list, from the first web page to the last, and chooses the first attractive page. This model of user behavior is known as the cascade model. In this paper, we propose cascading bandits, a learning variant of the cascade model where the objective is to identify {\$}K{\$} most attractive items. We formulate our problem as a stochastic combinatorial partial monitoring problem. We propose two algorithms for solving it, CascadeUCB1 and CascadeKL-UCB. We also prove gap-dependent upper bounds on the regret of these algorithms and derive a lower bound on the regret in cascading bandits. The lower bound matches the upper bound of CascadeKL-UCB up to a logarithmic factor. We experiment with our algorithms on several problems. The algorithms perform surprisingly well even when our modeling assumptions are violated.},
archivePrefix = {arXiv},
arxivId = {1502.02763},
author = {Kveton, Branislav and Szepesvari, Csaba and Wen, Zheng and Ashkan, Azin},
eprint = {1502.02763},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kveton et al. - 2015 - Cascading Bandits Learning to Rank in the Cascade Model.pdf:pdf},
isbn = {9781510810587},
journal = {Icml},
title = {{Cascading Bandits: Learning to Rank in the Cascade Model}},
url = {http://arxiv.org/abs/1502.02763},
volume = {37},
year = {2015}
}
@techreport{Lambert2004,
annote = {From Duplicate 2 ( 


Aggregation in Stochastic Dynamic Programming


- Iii, Theodore J Lambert; Epelman, Marina A; Smith, Robert L; Lambert, Theodore )

},
author = {Lambert, Theodore J and Epelman, Marina A and Smith, Robert L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iii, Epelman, Smith - 2004 - Dynamic Programming Aggregation in Stochastic Dynamic Programming.pdf:pdf},
institution = {University of Michigan},
title = {{Aggregation in Stochastic Dynamic Programming}},
year = {2004}
}
@article{Renner2013a,
abstract = {Summary Modeling the spatial distribution of a species is a fundamental problem in ecology. A number of modeling methods have been developed, an extremely popular one being MAXENT, a maximum entropy modeling approach. In this article, we show that MAXENT is equivalent to a Poisson regression model and hence is related to a Poisson point process model, differing only in the intercept term, which is scale-dependent in MAXENT. We illustrate a number of improvements to MAXENT that follow from these relations. In particular, a point process model approach facilitates methods for choosing the appropriate spatial resolution, assessing model adequacy, and choosing the LASSO penalty parameter, all currently unavailable to MAXENT. The equivalence result represents a significant step in the unification of the species distribution modeling literature.},
author = {Renner, Ian W. and Warton, David I.},
doi = {10.1111/j.1541-0420.2012.01824.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Renner, Warton - 2013 - Equivalence of MAXENT and Poisson Point Process Models for Species Distribution Modeling in Ecology(3).pdf:pdf},
isbn = {1541-0420},
issn = {0006341X},
journal = {Biometrics},
keywords = {Habitat modeling,Location-only,Maximum entropy,Poisson likelihood,Presence-only data,Use-availability},
number = {1},
pages = {274--281},
pmid = {23379623},
title = {{Equivalence of MAXENT and Poisson Point Process Models for Species Distribution Modeling in Ecology}},
volume = {69},
year = {2013}
}
@article{List2011,
abstract = {Experimental economics represents a strong growth industry. In the past several decades the method has expanded beyond intellectual curiosity, now merit- ing consideration alongside the other more traditional empirical approaches used in economics. Accompanying this growth is an influx of new experimenters who are in need of straightforward direction to make their designs more powerful. This study provides several simple rules of thumb that researchers can apply to improve the effi- ciency of their experimental designs.We buttress these points by including empirical examples from the literature. Keywords},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {List, John A. and Sadoff, Sally and Wagner, Mathis},
doi = {10.1007/s10683-011-9275-7},
eprint = {arXiv:1011.1669v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/List, Sadoff, Wagner - 2011 - So you want to run an experiment, now what Some simple rules of thumb for optimal experimental design.pdf:pdf},
isbn = {1386-4157},
issn = {13864157},
journal = {Experimental Economics},
keywords = {Experimental design},
number = {4},
pages = {439--457},
pmid = {25246403},
title = {{So you want to run an experiment, now what? Some simple rules of thumb for optimal experimental design}},
volume = {14},
year = {2011}
}
@article{scikit-learn,
author = {Pedregosa, F and Varoquaux, G and Gramfort, A and Michel, V and Thirion, B and Grisel, O and Blondel, M and Prettenhofer, P and Weiss, R and Dubourg, V and Vanderplas, J and Passos, A and Cournapeau, D and Brucher, M and Perrot, M and Duchesnay, E},
journal = {Journal of Machine Learning Research},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in {\{}P{\}}ython}},
volume = {12},
year = {2011}
}
@misc{Rockafellar1970,
abstract = {Available for the first time in paperback, R. Tyrrell Rockafellar's classic$\backslash$nstudy presents readers with a coherent branch of nonlinear mathematical$\backslash$nanalysis that is especially suited to the study of optimization problems.$\backslash$nRockafellar's theory differs from classical analysis in that differentiability$\backslash$nassumptions are replaced by convexity assumptions. The topics treated in this$\backslash$nvolume include: systems of inequalities, the minimum or maximum of a convex$\backslash$nfunction over a convex set, Lagrange multipliers, minimax theorems and$\backslash$nduality, as well as basic results about the structure of convex sets and the$\backslash$ncontinuity and differentiability of convex functions and saddle- functions.$\backslash$nThis book has firmly established a new and vital area not only for pure$\backslash$nmathematics but also for applications to economics and engineering. A sound$\backslash$nknowledge of linear algebra and introductory real analysis should provide$\backslash$nreaders with sufficient background for this book. There is also a guide for$\backslash$nthe reader who may be using the book as an introduction, indicating which$\backslash$nparts are essential and which may be skipped on a first reading. "This book$\backslash$nshould remain for some years as the standard reference for anyone interested$\backslash$nin convex analysis." J. D. Pryce, Edinburgh Mathematical Society},
author = {Rockafellar, R. Tyrrell},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar - 1970 - Convex Analysis.pdf:pdf},
isbn = {0691080690},
pages = {1--467},
title = {{Convex Analysis}},
year = {1970}
}
@article{Secomandi2010,
abstract = {Pipelines play a critical role in matching the supply and demand of natural gas. The pricing of their capacity is an important problem in practice, both for pipeline companies and shippers, the users of this capacity, including natural gas merchants, producers, and local distribution companies. This paper conducts a normative analysis of how pipeline capacity should be priced by each of these players. Although the trading value of this capacity should be relevant to merchants and its substitution and congestion values to shippers and pipelines, respectively, this analysis shows that all of these are equivalent values. Thus, pipeline capacity should be priced at its trading value, a prediction that can be empirically investigated. This paper also conducts an empirical analysis of this prediction based on transacted prices of transport contracts for the capacity of the Tennessee Gas Pipeline, a major interstate pipeline in the United States, and finds support for it. This analysis suggests that the uncertainty in the evolution of natural gas prices is an important driver of operational performance in the pricing of pipeline capacity. The results of this paper have potential relevance for the pricing of the capacity of other commodity conversion assets.},
author = {Secomandi, N.},
doi = {10.1287/msom.1090.0273},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Secomandi - 2010 - On the Pricing of Natural Gas Pipeline Capacity.pdf:pdf},
isbn = {1523-4614},
issn = {1523-4614},
journal = {Manufacturing {\&} Service Operations Management},
pages = {393--408},
title = {{On the Pricing of Natural Gas Pipeline Capacity}},
volume = {12},
year = {2010}
}
@incollection{Philippe1995,
author = {Philippe, B and Sidje, RB},
booktitle = {Computations with Markov Chains},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Philippe, Sidje - 1995 - Transient solutions of Markov processes by Krylov subspaces.pdf:pdf},
pages = {95--119},
title = {{Transient solutions of Markov processes by Krylov subspaces}},
url = {http://link.springer.com/chapter/10.1007/978-1-4615-2241-6{\_}7},
year = {1995}
}
@inproceedings{Thomas2016,
abstract = {In this paper we present a new way of predicting the performance of a reinforcement learning policy given historical data that may have been generated by a different policy. The ability to evaluate a policy from historical data is important for applications where the deployment of a bad policy can be dangerous or costly. We show empirically that our algorithm produces estimates that often have orders of magnitude lower mean squared error than existing methods---it makes more efficient use of the available data. Our new estimator is based on two advances: an extension of the doubly robust estimator (Jiang and Li, 2015), and a new way to mix between model based estimates and importance sampling based estimates.},
archivePrefix = {arXiv},
arxivId = {1604.00923},
author = {Thomas, Philip S. and Brunskill, Emma},
booktitle = {International Conference of Machine Learning (ICML)},
eprint = {1604.00923},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas, Brunskill - 2016 - Data-efficient off-policy policy evaluation for reinforcement learning.pdf:pdf},
title = {{Data-efficient off-policy policy evaluation for reinforcement learning}},
url = {http://arxiv.org/abs/1604.00923},
year = {2016}
}
@article{Confalonieri2006,
author = {Confalonieri, Roberto and Acutis, Marco and Bellocchi, Gianni and Cerrani, Iacopo and Tarantola, Stefano and Donatelli, Marcello and Genovese, Giampiero},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Confalonieri et al. - 2006 - Exploratory sensitivity analysis of crop syst, warm and wofost a case - study with rice biomass simulations.pdf:pdf},
keywords = {crop growth modelling,morris method,oryza sativa l,sensitivity analysis,simlab},
number = {3},
pages = {17--25},
title = {{Exploratory sensitivity analysis of crop syst, warm and wofost: a case - study with rice biomass simulations}},
volume = {25},
year = {2006}
}
@inproceedings{Mahadevan2005c,
author = {Mahadevan, Sridhar and Maggioni, Mauro},
booktitle = {{\{}A{\}}dvances in {\{}N{\}}eural {\{}I{\}}nformation {\{}P{\}}rocessing {\{}S{\}}ystems},
title = {{Value function approximation with diffusion wavelets and {\{}L{\}}aplacian eigenfuctions}},
year = {2005}
}
@article{Weng2014,
author = {Weng, Chao and Yu, Dong and Seltzer, Michael L and Droppo, Jasha},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weng et al. - 2014 - Single-channel mixed speech recognition using deep neural networks.pdf:pdf},
isbn = {9781479928934},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing},
pages = {5669--5673},
title = {{Single-channel mixed speech recognition using deep neural networks}},
year = {2014}
}
@article{Lerma1998,
annote = {From Duplicate 1 ( Approximation schemes for infinite linear programs - Hernandez-Lerma, Onesimo; Lasserre, Jean B; Andez-lerma, Hern )

From Duplicate 1 ( Approximation schemes for infinite linear programs ∗ † - Lasserre, Jean B; Andez-lerma, Hern )
},
author = {Hernandez-Lerma, Onesimo and Lasserre, Jean B and Andez-lerma, Hern},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lasserre, Andez-lerma - 1998 - Approximation schemes for infinite linear programs ∗ †.pdf:pdf},
isbn = {1052623497315},
journal = {SIAM Journal on Optimization},
keywords = {90c05,90c48,aggregation-relaxation,ams subject classifications,infinite-dimensional linear programming,inner approximations,of constraints,pii,s1052623497315768},
number = {4},
pages = {973--988},
title = {{Approximation schemes for infinite linear programs}},
volume = {8},
year = {1998}
}
@article{Solan2003,
author = {Solan, Eilon},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Solan - 2003 - Continuity of the value of competitive Markov decision processes.pdf:pdf},
journal = {Journal of Theoretical Probability},
pages = {1--18},
title = {{Continuity of the value of competitive Markov decision processes}},
url = {http://link.springer.com/article/10.1023/B:JOTP.0000011995.28536.ef},
year = {2003}
}
@article{Knoblock2000,
author = {Ambite, JL and Knoblock, CA and Minton, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ambite, Knoblock, Minton - 2000 - Learning Plan Rewriting Rules.pdf:pdf},
journal = {AIPS},
pages = {3--12},
title = {{Learning Plan Rewriting Rules.}},
url = {http://www.aaai.org/Papers/AIPS/2000/AIPS00-001.pdf},
year = {2000}
}
@article{Glasserman1992,
annote = {From Duplicate 2 ( Some guidelines and guarantees for common random numbers - Glasserman, Paul; Yao, DD )
},
author = {Glasserman, Paul and Yao, Daved DD},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glasserman, Yao - 1992 - Some guidelines and guarantees for common random numbers.pdf:pdf},
journal = {Management Science},
number = {6},
pages = {884--908},
title = {{Some guidelines and guarantees for common random numbers}},
url = {http://mansci.journal.informs.org/content/38/6/884.short},
volume = {38},
year = {1992}
}
@article{Becker2006,
author = {Becker, Raphen and Presented, A Dissertation and Becker, Raphen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Presented, Becker - 2006 - EXPLOITING STRUCTURE IN DECENTRALIZED MARKOV DECISION PROCESSES.pdf:pdf},
number = {May},
title = {{Exploiting Structure in Decentralized Markov Decision Processes}},
year = {2006}
}
@article{Duffin1973,
author = {Duffin, RJ},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duffin - 1973 - Convex analysis treated by linear programming.pdf:pdf},
journal = {Mathematical Programming},
number = {May 1972},
pages = {125--143},
title = {{Convex analysis treated by linear programming}},
url = {http://link.springer.com/article/10.1007/BF01584656},
volume = {4},
year = {1973}
}
@inproceedings{Ahmed2013,
author = {Ahmed, Asrar and Varakantham, P},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Varakantham - 2013 - Regret based Robust Solutions for Uncertain Markov Decision Processes.pdf:pdf},
title = {{Regret based Robust Solutions for Uncertain Markov Decision Processes}},
url = {http://papers.nips.cc/paper/4970-regret-based-robust-solutions-for-uncertain-markov-decision-processes},
year = {2013}
}
@article{Auslender1997,
author = {Auslender, A and Cominetti, R and Haddou, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Auslender, Cominetti, Haddou - 1997 - Asymptotic analysis for penalty and barrier methods in convex and linear programming.pdf:pdf},
journal = {Mathematics of Operations {\ldots}},
number = {1},
pages = {43--62},
title = {{Asymptotic analysis for penalty and barrier methods in convex and linear programming}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Asymptotic+Analysis+for+Penalty+and+Barrier+Methods+in+Convex+and+Linear+Programming{\#}0},
volume = {22},
year = {1997}
}
@article{Astrom1965,
author = {Astrom, K J and Astr{\"{o}}m, K J},
journal = {{\{}J{\}}ournal of {\{}M{\}}athematical {\{}A{\}}nalysis and {\{}A{\}}pplications},
pages = {174--205},
title = {{Optimal Control of Markov Decision Processes with Incomplete State Estimation}},
volume = {10},
year = {1965}
}
@article{Artzner1999,
abstract = {In this paper we study both market risks and nonmarket risks, without complete markets assumption, and discuss methods of measurement of these risks. We present and justify a set of four desirable properties for measures of risk, and call the measures satisfying these properties " coherent. " We examine the measures of risk provided and the related actions required by SPAN, by the SEC/NASD rules, and by quantile-based methods. We demonstrate the universality of scenario-based methods for providing coherent measures. We offer suggestions concerning the SEC method. We also suggest a method to repair the failure of subadditivity of quantile-based methods.},
author = {Artzner, Philippe and Delbaen, Freddy and Eber, Jean-marc and Heath, David},
doi = {10.1111/1467-9965.00068},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Artzner et al. - 1999 - Coherent Measures of Risk.pdf:pdf},
isbn = {1467-9965},
issn = {14679965},
journal = {Mathematical Finance},
keywords = {aggregation of risks,butterfly,capital requirement,coherent risk measure,concentra-tion of risks,currency risk,decentralization,extremal events risk,insurance risk,margin requirement,market risk,mean excess function,measure of risk,model risk,net worth,quantile,risk-based capital,scenario,shortfall,subadditivity,tail value at risk,value at risk},
pages = {203--228},
pmid = {22146444},
title = {{Coherent Measures of Risk}},
volume = {9},
year = {1999}
}
@inproceedings{Benton2007,
author = {Benton, J and van den Briel, Menkes and Kambhampati, Subbarao},
booktitle = {International Conference on Automated Planning and Scheduling (ICAPS)},
title = {{A Hybrid Linear Programming and Relaxed Plan Heuristic for Partial Satisfaction Planning Problems}},
year = {2007}
}
@article{Jensen1970,
annote = {Little progres before the 1970s (and maybe after)

Many factors influencing the timing and the amount of the water; there is more potential of better water control, measurement facilities, more reliable methods for estimating evotranspiration

Farmers used irrigation by calendar at that time 

Both timing and amount of water has the greatest effect on crop yield and quality because at some crop growth stages excessive soil moisture stress, caused by a delayed irrigation and inadequate irrigation, can irreversibly reduce the potential yield and quality of the crop or both.

Salt-River Approach
---------------------------
1. Observe the soil moisture in selected areas
2. 

Predictive approach
---------------------------
1. Estimate daily ovetranspiration
2. Approximate energy balance-aerodynamic equation
3. Determine crop coefficient based on the stage involved
4. Determine time since the last irrigation
5. Estimate the remaining soil moisture},
author = {Jensen, ME},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jensen - 1970 - Scheduling irrigations using climate-crop-soil data.pdf:pdf},
journal = {Journal of the Irrigation and Drainage Division},
pages = {25--38},
title = {{Scheduling irrigations using climate-crop-soil data}},
url = {http://eprints.nwisrl.ars.usda.gov/1207/1/159.pdf},
volume = {159},
year = {1970}
}
@article{Jain1998,
abstract = {This study proposes a methodology for forecasting crop yields at intermediate times in the growing season using Markov chain theory. A Markov chain is constructed, based on historical data, to provide forecast distributions of crop yield for various crop and soil moisture condition classes at selected times prior to harvest. Expected yield and the associated standard error are obtained for each condition class. The methodology is compared to a regression approach in which the independent variables are the various crop and soil moisture conditions. The Markov chain approach requires less stringent assumptions and provides more information than the regression approach. However, the potential loss of precision in the forecast using this approach requires separate evaluation for each application. A data base created by the CERES-Maize model, which simulates the growth and development of a corn crop, is used to demonstrate the development of the forecast yield distributions using the Markov chain approach.},
author = {Jain, RC and Ramasubramanian, V},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Ramasubramanian - 1998 - Forecasting of crop yields using second order Markov Chains.pdf:pdf},
journal = {Journal of the Ind. Soc. of Agril. Stats},
keywords = {composite stage,m,matrix,p,second order markov chain,somc,t,transition probability,yield forecast},
number = {1},
pages = {61--72},
title = {{Forecasting of crop yields using second order Markov Chains}},
url = {http://isas.org.in/jisas/jsp/volume/vol51/R.C. Jain .pdf},
volume = {51},
year = {1998}
}
@article{Bradley2010,
author = {Bradley, Bethany A. and Wilcove, David S. and Oppenheimer, Michael},
doi = {10.1007/s10530-009-9597-y},
issn = {1387-3547},
journal = {Biological Invasions},
keywords = {SLDs,invasion risk,invasives},
mendeley-tags = {SLDs,invasion risk,invasives},
month = {oct},
number = {6},
pages = {1855--1872},
title = {{Climate change increases risk of plant invasion in the Eastern United States}},
url = {http://link.springer.com/10.1007/s10530-009-9597-y},
volume = {12},
year = {2010}
}
@article{Mannor2007,
author = {Mannor, S. and Simester, D. and Sun, P. and Tsitsiklis, J. N.},
doi = {10.1287/mnsc.1060.0614},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannor et al. - 2007 - Bias and Variance Approximation in Value Function Estimates.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
keywords = {2004,4 1,accepted by wallace j,bias,confidence interval,history,hopp,months for 4 revisions,received july 14,stochastic models and simulation,this paper,value function,variance,was with the authors},
month = {feb},
number = {2},
pages = {308--322},
title = {{Bias and Variance Approximation in Value Function Estimates}},
url = {http://mansci.journal.informs.org/cgi/doi/10.1287/mnsc.1060.0614},
volume = {53},
year = {2007}
}
@article{Kantanantha2010,
abstract = {The primary objective of this paper is to develop yield and price forecasting models employed in informed crop decision planning—a key aspect of effective farm management. For yearly yield prediction, we introduce a weather-based regression model with time-dependent varying coefficients. In order to allow for within-year climate variations, we predict yearly crop yield using weekly temperature and rainfall summaries resulting in a large number of correlated predictors. To overcome this difficulty, we reduce the space of predictors to a small number of uncorrelated predictors using Functional Principal Component Analysis (FPCA). For detailed price forecasting, we develop a futures-based model for long-range cash price prediction. In this model, the cash price is predicted as a sum of the nearby settlement futures price and the predicted commodity basis. We predict the one-year commodity basis as a mixture of historical basis data using a functional model-based approach. In both forecasting models, we estimate approximate prediction confidence intervals that are further integrated in a decision planning model. We applied our methods to corn yield and price forecasting for Hancock County in Illinois. Our forecasting results are more accurate in comparison to predictions based on existing methods. The methods introduced in this paper generally apply to other locations in the US and other crop types. The supplemental materials for this article are available online.},
author = {Kantanantha, Nantachai and Serban, Nicoleta and Griffin, Paul},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kantanantha, Serban, Griffin - 2010 - Yield and Price Forecasting for Stochastic Crop Decision Planning.pdf:pdf},
journal = {Journal of Agricultural, Biological, and Environmental Statistics},
number = {3},
pages = {362--380},
title = {{Yield and Price Forecasting for Stochastic Crop Decision Planning}},
volume = {15},
year = {2010}
}
@inproceedings{Aras2007,
author = {Aras, Raghav and Charpillet, Francois},
booktitle = {International Conference on Automated Planning and Scheduling (ICAPS)},
pages = {18--25},
title = {{A mixed integer linear programming method for the finite-horizon Dec-POMDP problem}},
year = {2007}
}
@inproceedings{Parr2007,
annote = {From Duplicate 1 ( Analyzing Feature Generation for Value-Function Approximation - Parr, Ronald; Painter-Wakefield, Christopher; Li, Lihong; Littman, Michael )
},
author = {Parr, Ronald and Painter-Wakefield, Christopher and Li, Lihong and Littman, Michael},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parr et al. - 2007 - Analyzing Feature Generation for Value-Function Approximation.pdf:pdf},
title = {{Analyzing Feature Generation for Value-Function Approximation}},
year = {2007}
}
@article{Korf2001,
author = {Korf, R E and Reid, M and Edelkamp, S},
journal = {Artificial Intelligence},
pages = {199--218},
title = {{Time complexity of {\{}IDA*{\}}}},
volume = {129},
year = {2001}
}
@article{Barto1996,
author = {Barto, AG and Crites, RH},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barto, Crites - 1996 - Improving elevator performance using reinforcement learning.pdf:pdf},
journal = {Advances in neural information processing {\ldots}},
pages = {2--8},
title = {{Improving elevator performance using reinforcement learning}},
url = {http://cseweb.ucsd.edu/users/gary/CSE190/crites-barto.pdf},
volume = {2},
year = {1996}
}
@article{Klocke2009,
author = {Klocke, NL and Currie, RS and Aiken, RM},
journal = {Transactions of the ASABE},
number = {1},
pages = {103--110},
title = {{Soil water evaporation and crop residues}},
volume = {52},
year = {2009}
}
@article{Geramifard2013,
author = {Geramifard, Alborz},
doi = {10.1561/2200000042},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geramifard - 2013 - A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
number = {4},
pages = {375--451},
title = {{A Tutorial on Linear Function Approximators for Dynamic Programming and Reinforcement Learning}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-machine-learning/MAL-042},
volume = {6},
year = {2013}
}
@article{Liberty2013,
address = {New York, New York, USA},
author = {Liberty, Edo},
doi = {10.1145/2487575.2487623},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liberty - 2013 - Simple and deterministic matrix sketching.pdf:pdf},
isbn = {9781450321747},
journal = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '13},
keywords = {frequent items,matrix sketching,streaming},
pages = {581},
publisher = {ACM Press},
title = {{Simple and deterministic matrix sketching}},
url = {http://dl.acm.org/citation.cfm?doid=2487575.2487623},
year = {2013}
}
@inproceedings{Nair2003,
author = {Nair, R and Tambe, M and Yokoo, M and Pynadath, D and Marsella, S},
booktitle = {International Joint Conference on Artificial Inteligence},
pages = {705--711},
title = {{Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings.}},
year = {2003}
}
@article{Tamar2013,
author = {Tamar, Aviv and Castro, Dotan Di and Mannor, Shie},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar, Castro, Mannor - 2013 - Temporal Difference Methods for the Variance of the Reward To Go.pdf:pdf},
journal = {International Conference on Machine Learning (ICML)},
title = {{Temporal Difference Methods for the Variance of the Reward To Go}},
url = {http://jmlr.org/proceedings/papers/v28/tamar13.html},
}
@inproceedings{Petrik2011,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {Conference on Artificial Intelligence (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2011 - Linear Dynamic Programs for Resource Management.pdf:pdf},
title = {{Linear dynamic programs for resource management}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/download/3608/4078},
year = {2011}
}
@inproceedings{Kakade2001,
annote = {From Duplicate 1 ( A Natural Policy Gradient. - Kakade, S )
},
author = {Kakade, Sham Machandranath},
booktitle = {Advances in neural information processing systems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade - 2001 - A Natural Policy Gradient.pdf:pdf},
number = {0},
pages = {1531--1538},
title = {{A Natural Policy Gradient}},
url = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/CN11.ps.gz},
year = {2001}
}
@book{Goldreich1997,
author = {Goldreich, Oded},
booktitle = {Lecture notes. Dept. of Computer Science and Applied {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldreich - 1997 - Introduction to complexity theory.pdf:pdf},
title = {{Introduction to complexity theory}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Introduction+to+Complexity+Theory{\#}0},
year = {1997}
}
@inproceedings{Anava2016,
author = {Anava, Oren and Karmin, Zohar},
booktitle = {Conference on Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anava, Karmin - 2016 - Multi-armed Bandits Competing with Optimal Sequences.pdf:pdf},
title = {{Multi-armed Bandits : Competing with Optimal Sequences}},
year = {2016}
}
@article{Petrik2009d,
author = {Petrik, Marek and Zilberstein, Shlomo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2009 - A Bilinear Programming Approach for Multiagent Planning.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {235--274},
title = {{A bilinear programming approach for multiagent planning}},
volume = {35},
year = {2009}
}
@article{Goodrich,
annote = {From Duplicate 1 ( Efficient Piecewise-Linear Function Approximation Using the Uniform Metric - Goodrich, Michael T. )
},
author = {Goodrich, Michael T.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodrich - Unknown - Efficient Piecewise-Linear Function Approximation Using the Uniform Metric.pdf:pdf},
journal = {Symposium on Computational Geometry},
pages = {322--331},
title = {{Efficient Piecewise-Linear Function Approximation Using the Uniform Metric}},
url = {citeseer.ist.psu.edu/goodrich94efficient.html},
year = {1994}
}
@article{Munos2008,
annote = {From Duplicate 1 ( Finite-time bounds for fitted value iteration - Munos, R; Szepesv{\'{a}}ri, C )
},
author = {Munos, Remi and Szepesvari, Csaba and Szepesv{\'{a}}ri, C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos, Szepesv{\'{a}}ri - 2008 - Finite-time bounds for fitted value iteration.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {discounted markovian decision processes,fitted value iteration,generative model,optimal control,pollard,regression,reinforcement learning,s inequality,statistical learning,supervised learning,theory},
pages = {815--857},
title = {{Finite-time bounds for fitted value iteration}},
url = {http://dl.acm.org/citation.cfm?id=1390708},
volume = {1},
year = {2008}
}
@article{Feder2007g,
address = {New York, New York, USA},
author = {Feder, Tomas and Nazerzadeh, Hamid and Saberi, Amin},
doi = {10.1145/1250910.1250961},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feder, Nazerzadeh, Saberi - 2007 - Approximating nash equilibria using small-support strategies.pdf:pdf},
isbn = {9781595936530},
journal = {Proceedings of the 8th ACM conference on Electronic commerce - EC '07},
pages = {352},
publisher = {ACM Press},
title = {{Approximating nash equilibria using small-support strategies}},
url = {http://portal.acm.org/citation.cfm?doid=1250910.1250961},
year = {2007}
}
@inproceedings{Bernstein2000,
address = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
author = {Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI)},
pages = {819--840},
title = {{The complexity of decentralized control of Markov decision processes}},
volume = {27},
year = {2002}
}
@unpublished{EladHazan,
author = {Hazan, Elad},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan - 2016 - Introduction to Online Convex Optimization.pdf:pdf},
title = {{Introduction to Online Convex Optimization}},
year = {2016}
}
@inproceedings{Ball2008,
author = {Ball, Marcel and Holte, Robert C},
booktitle = {International Conference on Automated Planning and Scheduling (ICAPS)},
title = {{The Compression Power of Symbolic Pattern Databases}},
year = {2008}
}
@article{Vandenberghe2011b,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 03. Subgradient method.pdf:pdf},
journal = {LECTURE NOTES},
pages = {1--21},
title = {{03. Subgradient method}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@book{Bertsekas2003,
author = {Bertsekas, Dimitri P and {Dimitri Bertsekas}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitri Bertsekas - 2005 - Nonlinear Programming.pdf:pdf},
title = {{Nonlinear programming}},
year = {2003}
}
@inproceedings{Abbeel2006,
author = {Abbeel, Pieter and Ganapathi, Varun and Ng, Andrew Y},
booktitle = {Advances in Neural Information Processing Systems},
title = {{Learning vehicular dynamics, with application to modeling helicopters}},
year = {2006}
}
@article{Bashash2011,
author = {Bashash, Saeid and Moura, Scott J. and Forman, Joel C. and Fathy, Hosam K.},
doi = {10.1016/j.jpowsour.2010.07.001},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bashash et al. - 2011 - Plug-in hybrid electric vehicle charge pattern optimization for energy cost and battery longevity.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {charge pattern optimization,lithium-ion battery degradation,plug-in hybrid electric vehicles},
month = {jan},
number = {1},
pages = {541--549},
publisher = {Elsevier B.V.},
title = {{Plug-in hybrid electric vehicle charge pattern optimization for energy cost and battery longevity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378775310011390},
volume = {196},
year = {2011}
}
@inproceedings{Williams1993a,
annote = {From Duplicate 2 ( Tight performance bounds on greedy policies based on imperfect value functions - Williams, Ronald J RJ; Baird, Leemon C LC )
},
author = {Williams, Ronald J RJ and Baird, Leemon C LC},
booktitle = {Yale Workshop on Adaptive and Learning Systems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Baird - 1993 - Tight performance bounds on greedy policies based on imperfect value functions.pdf:pdf},
organization = {Northeastern University},
title = {{Tight performance bounds on greedy policies based on imperfect value functions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.3281{\&}rep=rep1{\&}type=pdf},
year = {1993}
}
@article{Koller1994a,
annote = {From Duplicate 1 ( Fast algorithms for finding randomized strategies in game trees - Koller, Daphne; Megiddo, Nimrod; Stengel, B Von; von Stengel, Bernhard )

From Duplicate 1 ( Fast algorithms for finding randomized strategies in game trees - Koller, Daphne; Megiddo, Nimrod; von Stengel, Bernhard )





From Duplicate 2 ( Fast algorithms for finding randomized strategies in game trees - Koller, D; Megiddo, N; Stengel, B Von )
},
author = {Koller, Daphne and Megiddo, Nimrod and Stengel, B Von and von Stengel, Bernhard},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koller, Megiddo, Stengel - 1994 - Fast algorithms for finding randomized strategies in game trees.pdf:pdf},
journal = {{\ldots} of the twenty-sixth annual ACM {\ldots}},
pages = {750--759},
title = {{Fast algorithms for finding randomized strategies in game trees}},
url = {http://dl.acm.org/citation.cfm?id=195451},
volume = {0},
year = {1994}
}
@article{Letham2013,
abstract = {We aim to produce predictive models that are not only accurate, but are also interpretable to human experts. Our models are deci- sion lists, which consist of a series of if . . . then. . . statements (e.g., if high blood pressure, then stroke) that discretize a high-dimensional, multivariate feature space into a series of simple, readily interpretable decision statements.We introduce a generativemodel called Bayesian Rule Lists that yields a posterior distribution over possible decision lists. It employs a novel prior structure to encourage sparsity. Our experiments show that Bayesian Rule Lists has predictive accuracy on par with the current top algorithms for prediction in machine learning. Our method is motivated by recent developments in per- sonalized medicine, and can be used to produce highly accurate and interpretable medical scoring systems. We demonstrate this by pro- ducing an alternative to the CHADS2 score, actively used in clinical practice for estimating the risk of stroke in patients that have atrial fibrillation. Our model is as interpretable as CHADS2, but more ac- curate.},
archivePrefix = {arXiv},
arxivId = {arXiv:1511.01644v1},
author = {Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H and Madigan, David},
doi = {10.1214/15-AOAS848},
eprint = {arXiv:1511.01644v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Letham et al. - 2013 - Interpretable classifiers using rules and Bayesian analysis Building a better stroke prediction model.pdf:pdf},
issn = {19417330},
journal = {The Annals of Applied Statistics},
keywords = {Bayesian analysis,classification,interpretabilit},
number = {3},
pages = {1350--1371},
title = {{Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model}},
volume = {9},
year = {2013}
}
@incollection{Response1999,
annote = {Computer models and expert systems are extensively used in irrigation.

Packages are available that deal with irrigation scheduling, irrigation system evaluation, crop planning and selection of crop varieties, and irrigation system operation.

Hammer, Holzworth, and Stone (1996) calculated the benefits of sea-sonal forecasting for tactical management of nitrogen fertilizer and cultivar maturity of wheat at Goondiwindi, Australia.

In tactical applications, crop models are actually run prior to or during the growing season to integrate the growth of a crop with the current ob- served weather conditions and to decide, on a daily basis, which manage- ment decisions should be made

Another application of crop simulation models is in policy manage- ment. Whisler and colleagues (1986) and Hoogenboom (2000) described a wide range of major areas in which the application of models is well estab- lished.

Crop simulation models play an important role at different levels of ap-plication, ranging from decision support for crop management at a farm level to advancing understanding of sciences at a research level.

Simulation means that the model acts like a real crop, gradually germi-nating and growing leaves, stems, and roots during the season. In other words, simulation is the process of using a model dynamically by following a system over a time period

Regression models are attractive because of their simple and straightfor-ward relationship between yield and one or more environmental factors, but these are not accurate enough to be used for other areas and other crops.


In other cases, complex models are not appropriate be- cause they may require inputs that are not practical to obtain in a field situation (Boote, Jones, and Pickering, 1996; Jorgensen, 1999). In},
author = {Response, Modeling Biological and Conditions, T O Weather},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Response, Conditions - 1999 - Role of Computer Models in Models in Managing Agricultural Systems.pdf:pdf},
number = {1994},
title = {{Role of Computer Models in Models in Managing Agricultural Systems}},
year = {1999}
}
@techreport{GWP,
author = {GWP},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/GWP - 2012 - Groundwater Resources and Irrigated Agriculture.pdf:pdf},
institution = {Global Water Partnership},
title = {{Groundwater Resources and Irrigated Agriculture}},
year = {2012}
}
@inproceedings{Poupart2006,
author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
booktitle = {International Conference on Machine Learning},
title = {{An Analytic Solution to Discrete Bayesian Reinforcement Learning}},
year = {2006}
}
@inproceedings{Metsis2006,
abstract = {Naive Bayes is very popular in commercial and open-source anti-spam e-mail filters. There are, however, several forms of Naive Bayes, something the anti-spam literature does not always acknowledge. We discuss five different versions of Naive Bayes, and compare them on six new, non-encoded datasets, that contain ham messages of particular Enron users and fresh spam messages. The new datasets, which we make publicly available, are more realistic than previous comparable benchmarks, because they maintain the tempo- ral order of the messages in the two categories, and they emulate the varying proportion of spam and ham messages that users receive over time. We adopt an experimental procedure that emulates the incremental training of person- alized spam filters, and we plot roc curves that allow us to compare the different versions of nb over the entire tradeoff between true positives and true negatives.},
author = {Metsis, Vangelis and Androutsopoulos, I and Paliouras, G},
booktitle = {Third Conference on Email and Anti-Spam},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Metsis, Androutsopoulos, Paliouras - 2006 - Spam filtering with naive Bayes - which naive Bayes.pdf:pdf},
title = {{Spam filtering with naive Bayes - which naive Bayes?}},
url = {http://classes.soe.ucsc.edu/cmps242/Fall09/lect/12/CEAS2006{\_}corrected-naiveBayesSpam.pdf},
year = {2006}
}
@article{Bertsimas2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1507.03133v1},
author = {Bertsimas, Dimitris and King, Angela and Mazumder, Rahul},
eprint = {arXiv:1507.03133v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, King, Mazumder - 2014 - Best Subset Selection via a Modern Optimization Lens.pdf:pdf},
pages = {1--63},
title = {{Best Subset Selection via a Modern Optimization Lens}},
year = {2014}
}
@inproceedings{Das2009,
abstract = {Abstract: Traditional recommendation systems make recommendations based solely on the customer's past purchases, product ratings and demographic data without considering the profitability the items being recommended. In this work we study the question of how a ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {0908.3633},
author = {Das, Aparna and Mathieu, Claire and Ricketts, Daniel},
booktitle = {WWW},
eprint = {0908.3633},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das, Mathieu, Ricketts - 2010 - Maximizing profit using recommender systems.pdf:pdf},
keywords = {recommender system},
title = {{Maximizing profit using recommender systems}},
url = {http://arxiv.org/abs/0908.3633{\%}5Cnpapers2://publication/uuid/D9778D8A-0344-4B9C-ADAB-5B0D21A4F873},
year = {2010}
}
@article{Feinberg2000a,
abstract = {This paper establishes new links between stochastic and discrete optimization. We consider the following three problems for discrete time Markov Decision Processes with finite states and action sets: (i) find an optimal deterministic policy for a discounted problem with constraints, (ii) find an optimal stationary policy for a weighted discounted problem with constraints, (iii) find an optimal deterministic policy for a weighted discounted problem with constraints. We formulate mathematical programs for problems (i)?(iii) and show that the Hamiltonian Cycle Problem is a special case of each of these problems. Therefore problems (i)?(iii) are NP-hard. We also provide new mathematical programming formulations for the Hamiltonian Cycle and Traveling Salesman Problems.},
annote = {From Duplicate 2 (Constrained discounted Markov decision processes and Hamiltonian cycles - Feinberg, EA)

Looks for non-randomized policies},
author = {Feinberg, Eugene A EA},
doi = {10.1287/moor.25.1.130.15210},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinberg - 2000 - Constrained discounted Markov decision processes and Hamiltonian cycles.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinberg - 2000 - Constrained Discounted Markov Decision Processes and Hamiltonian Cycles.pdf:pdf},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {1},
pages = {130--140},
title = {{Constrained discounted Markov decision processes and Hamiltonian cycles}},
url = {http://dx.doi.org/10.1287/moor.25.1.130.15210 http://pubsonline.informs.org/doi/abs/10.1287/moor.25.1.130.15210},
volume = {25},
year = {2000}
}
@inproceedings{Billings2003,
annote = {From Duplicate 1 ( Approximating Game-Theoretic Optimal Strategies for Full-scale Poker - Billings, Darse; Burch, Neil; Davidson, Aaron; Holte, Robert; Schaeffer, Jonathan; Schauenberg, Terence; Szafron, Duane )
},
author = {Billings, Darse and Burch, Neil and Davidson, Aaron and Holte, Robert and Schaeffer, Jonathan and Schauenberg, Terence and Szafron, Duane},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Billings et al. - 2003 - Approximating Game-Theoretic Optimal Strategies for Full-scale Poker.pdf:pdf},
title = {{Approximating Game-Theoretic Optimal Strategies for Full-scale Poker}},
year = {2003}
}
@article{Paletta2007,
author = {Paletta, Lucas and Fritz, Gerald},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paletta, Fritz - 2007 - Reinforcement Learning for Decision Making in Sequential Visual Attention.pdf:pdf},
journal = {Wapcv},
keywords = {printed},
pages = {293--306},
title = {{Reinforcement Learning for Decision Making in Sequential Visual Attention}},
year = {2007}
}
@article{Rebennack2016,
author = {Rebennack, Steffen},
doi = {10.1007/s10107-015-0884-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rebennack - 2016 - Combining sampling-based and scenario-based nested Benders decomposition methods application to stochastic dual dynam.pdf:pdf},
issn = {14364646},
journal = {Mathematical Programming},
keywords = {Electricity demand and inflow uncertainty,Hydro-thermal power system,Nested Benders decomposition,Sampling,Scenario tree,Stochastic dual dynamic programming},
number = {1-2},
pages = {343--389},
publisher = {Springer Berlin Heidelberg},
title = {{Combining sampling-based and scenario-based nested Benders decomposition methods: application to stochastic dual dynamic programming}},
url = {http://dx.doi.org/10.1007/s10107-015-0884-3},
volume = {156},
year = {2016}
}
@book{Rockafellar1996,
author = {Rockafellar, Ralph Tyrell},
publisher = {Princeton University Press},
title = {{Convex Analysis}},
year = {1996}
}
@inproceedings{Ng1999,
author = {Ng, Andrew and Harada, Daishi and Russell, Stuart},
booktitle = {International Conference on Machine Learning},
title = {{Policy invariance under reward transformations: Theory and application to reward shaping}},
year = {1999}
}
@inproceedings{Dolgov2005,
abstract = {We consider the problem of policy optimization for a resource-limited$\backslash$nagent with multiple timedependent objectives, represented as an MDP$\backslash$nwith multiple discount factors in the objective function and constraints.We$\backslash$nshow that limiting search to stationary deterministic policies, coupled$\backslash$nwith a novel problem reduction to mixed integer programming, yields$\backslash$nan algorithm for finding such policies that is computationally feasible,$\backslash$nwhere no such algorithm has heretofore been identified. In the simpler$\backslash$ncase where the constrained MDP has a single discount factor, our$\backslash$ntechnique provides a new way for finding an optimal deterministic$\backslash$npolicy, where previous methods could only find randomized policies.$\backslash$nWe analyze the properties of our approach and describe implementation$\backslash$nresults.},
author = {Dolgov, Dmitri and Durfee, Edmund},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dolgov, Durfee - 2005 - Stationary deterministic policies for constrained MDPs with multiple rewards, costs, and discount factors.pdf:pdf},
issn = {10450823},
pages = {1326--1331},
title = {{Stationary deterministic policies for constrained MDPs with multiple rewards, costs, and discount factors}},
year = {2005}
}
@article{White1994,
author = {White, CC and Eldeib, HK},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/White, Eldeib - 1994 - Markov decision processes with imprecise transition probabilities.pdf:pdf},
journal = {Operations Research},
number = {4},
pages = {739--749},
title = {{Markov decision processes with imprecise transition probabilities}},
url = {http://or.journal.informs.org/content/42/4/739.short},
volume = {42},
year = {1994}
}
@inproceedings{Buckmann2015,
author = {Simsek, Ozgur and Buckmann, Marcus},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simsek, Buckmann - 2015 - Learning From Small Samples An Analysis of Simple Decision Heuristics.pdf:pdf},
title = {{Learning From Small Samples: An Analysis of Simple Decision Heuristics}},
year = {2015}
}
@inproceedings{Dietrich2012,
author = {Dietrich, Brenda and Ettl, Markus and Lederman, Roger and Petrik, Marek},
booktitle = {Symposium on Process Systems Engineering},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietrich et al. - 2012 - Optimizing the end-to-end value chain through demand shaping and advanced customer analytics.pdf:pdf},
keywords = {configure-to-order,demand shaping,mixed choice models,product substitution,supply chain visibility},
pages = {15--19},
title = {{Optimizing the end-to-end value chain through demand shaping and advanced customer analytics}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=GBciDxg-TfgC{\&}oi=fnd{\&}pg=PA8{\&}dq=Optimizing+the+end-to-end+value+chain+through+demand+shaping+and+advanced+customer+analytics{\&}ots=Mw-YeV-Ac9{\&}sig=c6pEO8HhY7oTxEziY2Vl9tSnWZE},
year = {2012}
}
@article{Guestrin2003,
author = {Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guestrin, Koller, Parr - 2003 - Efficient Solution Algorithms for Factored MDPs.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
number = {c},
pages = {399--468},
title = {{Efficient Solution Algorithms for Factored MDPs}},
volume = {19},
year = {2003}
}
@inproceedings{Dolgov2006,
author = {Dolgov, Dmitri and Durfee, Edmund},
booktitle = {International Symposium on Artificial Intelligence and Mathematics},
title = {{Symmetric primal-dual approximate linear programming for factored MDPs}},
year = {2006}
}
@phdthesis{SoneEkm,
author = {Ekman, Sone},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ekman - Unknown - Modeling Agricultural Production Systems using Mathematical Programming.pdf:pdf},
title = {{Modeling Agricultural Production Systems using Mathematical Programming}}
}
@misc{landsat8,
author = {LANDSAT},
title = {{LANDSAT 8}},
url = {www.nasa.gov/mission{\_}pages/landsat/main},
year = {2013}
}
@article{Petersen2007,
abstract = {These pages are a collection of facts (identities, approxima- tions, inequalities, relations, ...) about matrices and matters relating to them. It is collected in this form for the convenience of anyone who wants a quick desktop reference .},
author = {Petersen, Kaare Breandt and Pedersen, Michael Syskind},
doi = {10.1111/j.1365-294X.2006.03161.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petersen, Pedersen - 2007 - The Matrix Cookbook.pdf:pdf},
isbn = {0962-1083 (Print)$\backslash$r0962-1083 (Linking)},
issn = {09621083},
journal = {Citeseer},
keywords = {acknowledgements,and suggestions,bill baxter,christian rish{\o}j,contributions,derivative of,derivative of inverse matrix,determinant,di erentiate a matrix,douglas l,esben,matrix algebra,matrix identities,matrix relations,thank the following for,theobald,we would like to},
number = {4},
pages = {1--66},
pmid = {17284204},
title = {{The Matrix Cookbook}},
volume = {16},
year = {2007}
}
@article{Margineantu2003,
abstract = {Decision tree models typically give good classification decisions but poor probability estimates. In many applications, it is important to have good probability estimates as well. This chapter introduces a new algorithm, Bagged Lazy Option Trees (B-LOTs), for constructing decision trees and compares it to an alternative, Bagged Probability Estimation Trees (B-PETs). The quality of the class probability estimates produced by the two methods is evaluated in two ways. First, we compare the ability of the two methods to make good classification decisions when the misclassification costs are asymmetric. Second, we compare the absolute accuracy of the estimates themselves. The experiments show that B-LOTs, produce better decisions and more accurate probability estimates than B-PETs.},
author = {Margineantu, D.D. D and Dietterich, Thomas G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Margineantu, Dietterich - 2003 - Improved class probability estimates from decision tree models.pdf:pdf},
isbn = {978-0-387-95471-4},
journal = {Lecture Notes in Statistics - Nonlinear Estimation and Classification},
keywords = {Decision Tree},
pages = {173--188},
title = {{Improved class probability estimates from decision tree models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.1207{\&}rep=rep1{\&}type=pdf{\%}5Cnciteseer.ist.psu.edu/margineantu02improved.html},
volume = {171},
year = {2003}
}
@article{Agrawal2012,
abstract = {Thompson Sampling is one of the oldest heuristics for multi-armed bandit problems. It is a randomized algorithm based on Bayesian ideas, and has recently generated significant interest after several studies demonstrated it to have better empirical performance compared to the state-of-the-art methods. However, many questions regarding its theoretical performance remained open. In this paper, we design and analyze a generalization of Thompson Sampling algorithm for the stochastic contextual multi-armed bandit problem with linear payoff functions, when the contexts are provided by an adaptive adversary. This is among the most important and widely studied version of the contextual bandits problem. We prove a high probability regret bound of {\$}\backslashtilde{\{}O{\}}(\backslashfrac{\{}d{\^{}}2{\}}{\{}\backslashepsilon{\}}\backslashsqrt{\{}T{\^{}}{\{}1+\backslashepsilon{\}}{\}}){\$} in time {\$}T{\$} for any {\$}0{\textless}\backslashepsilon {\textless}1{\$}, where {\$}d{\$} is the dimension of each context vector and {\$}\backslashepsilon{\$} is a parameter used by the algorithm. Our results provide the first theoretical guarantees for the contextual version of Thompson Sampling, and are close to the lower bound of {\$}\backslashOmega(d\backslashsqrt{\{}T{\}}){\$} for this problem. This essentially solves a COLT open problem of Chapelle and Li [COLT 2012].},
archivePrefix = {arXiv},
arxivId = {1209.3352},
author = {Agrawal, S. and Goyal, N.},
eprint = {1209.3352},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal, Goyal - 2012 - Thompson Sampling for contextual bandits with linear payoffs.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning (ICML)},
pages = {127--135},
title = {{Thompson Sampling for contextual bandits with linear payoffs}},
volume = {28},
year = {2012}
}
@article{Bastiaanssen2007,
author = {Bastiaanssen, W.G.M. and Allen, R.G. and Droogers, P. and D'Urso, G. and Steduto, P.},
doi = {10.1016/j.agwat.2007.05.013},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastiaanssen et al. - 2007 - Twenty-five years modeling irrigated and drained soils State of the art.pdf:pdf},
issn = {03783774},
journal = {Agricultural Water Management},
keywords = {soil water flow models},
month = {sep},
number = {3},
pages = {111--125},
title = {{Twenty-five years modeling irrigated and drained soils: State of the art}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378377407001400},
volume = {92},
year = {2007}
}
@article{Chen2009a,
author = {Chen, Y. and Xu, M. and Zhang, Z. G.},
doi = {10.1287/opre.1080.0603},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Xu, Zhang - 2009 - Technical Note--A Risk-Averse Newsvendor Model Under the CVaR Criterion.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {mar},
number = {4},
pages = {1040--1044},
title = {{Technical Note--A Risk-Averse Newsvendor Model Under the CVaR Criterion}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1080.0603},
volume = {57},
year = {2009}
}
@misc{Sutton1984,
author = {Sutton, Richard S and Barto, Andrew G},
title = {{Temporal credit assignment in reinforcement learning}},
year = {1984}
}
@article{Roorda2005,
author = {Roorda, Berend and Schumacher, Hans and Engwerda, Jacob},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roorda, Schumacher, Engwerda - 2005 - Coherent acceptability measures in multiperiod models.pdf:pdf},
journal = {Mathematical Finance},
keywords = {acceptability measures,bustness,coherent risk measures,dynamic consistency,g11,g13,incomplete markets,jel classification,option pricing,ro-},
pages = {1--29},
title = {{Coherent acceptability measures in multiperiod models}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9965.2005.00252.x/full},
year = {2005}
}
@article{Stieglitz2003,
author = {Stieglitz, Marc and Shaman, Jeff and McNamara, James and Engel, Victor and Shanley, Jamie and Kling, George W.},
doi = {10.1029/2003GB002041},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stieglitz et al. - 2003 - An approach to understanding hydrologic connectivity on the hillslope and the implications for nutrient transp.pdf:pdf},
issn = {08866236},
journal = {Global Biogeochemical Cycles},
month = {dec},
number = {4},
pages = {n/a--n/a},
title = {{An approach to understanding hydrologic connectivity on the hillslope and the implications for nutrient transport}},
url = {http://doi.wiley.com/10.1029/2003GB002041},
volume = {17},
year = {2003}
}
@article{Daughtry2000,
author = {Daughtry, CST and Walthall, CL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daughtry, Walthall - 2000 - Estimating corn leaf chlorophyll concentration from leaf and canopy reflectance.pdf:pdf},
journal = {Remote Sensing of Environment},
number = {00},
title = {{Estimating corn leaf chlorophyll concentration from leaf and canopy reflectance}},
url = {http://www.sciencedirect.com/science/article/pii/S0034425700001139},
volume = {4257},
year = {2000}
}
@article{Prashanth2016,
author = {Prashanth, L.A. and Ghavamzadeh, Mohammad},
journal = {Machine Learning Journal},
title = {{Variance-constrained Actor-Critic Algorithms for Discounted and Average Reward MDPs}},
year = {2016}
}
@article{Govindan2002,
abstract = {Kohlberg and Mertens [Kohlberg, E. {\&} Mertens, J. (1986) Econometrica 54, 1003-1039] proved that the graph of the Nash equilibrium correspondence is homeomorphic to its domain when the domain is the space of payoffs in normal-form games. A counterexample disproves the analog for the equilibrium outcome correspondence over the space of payoffs in extensive-form games, but we prove an analog when the space of behavior strategies is perturbed so that every path in the game tree has nonzero probability. Without such perturbations, the graph is the closure of the union of a finite collection of its subsets, each diffeomorphic to a corresponding path-connected open subset of the space of payoffs. As an application, we construct an algorithm for computing equilibria of an extensive-form game with a perturbed strategy space, and thus approximate equilibria of the unperturbed game.},
author = {Govindan, Srihari and Wilson, Robert},
doi = {10.1073/pnas.082249599},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Govindan, Wilson - 2002 - Structure theorems for game trees.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
month = {jun},
number = {13},
pages = {9077--80},
pmid = {12060702},
title = {{Structure theorems for game trees.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=124887{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {99},
year = {2002}
}
@article{Nahmias1982,
abstract = {This paper reviews the relevant literature on the problem of determining suitable ordering policies for both fixed life perishable inventory, and inventory subject to continuous exponential decay. We consider both deterministic and stochastic demand for single and multiple products. Both optimal and suboptimal order policies are discussed. In addition, a brief review of the application of these models to blood bank management is included. The review concludes with a discussion of some of the interesting open research questions in the area.},
author = {Nahmias, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nahmias - 1982 - Perishable inventory theory A review.pdf:pdf},
issn = {0030-364X},
journal = {Operations research},
keywords = {Blood Banks,Blood Banks: organization {\&} administration,Blood Preservation,Hospital,Hospital: methods,Humans,Inventories,Materials Management,Models,Stochastic Processes,Theoretical},
number = {4},
pages = {680--708},
pmid = {10298625},
title = {{Perishable inventory theory: A review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10298625},
volume = {30},
year = {1982}
}
@article{Petrik2011b,
author = {Petrik, Marek and Zilberstein, Shlomo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2011 - Robust approximate bilinear programming for value function approximation.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {approximate dynamic programming,markov decision processes,reinforcement learning,value function approximation},
number = {1},
pages = {3027--3063},
title = {{Robust approximate bilinear programming for value function approximation}},
url = {http://dl.acm.org/citation.cfm?id=2078202},
volume = {12},
year = {2011}
}
@article{Pereira1991,
abstract = {This paper presents a methodology for the solution of multistage stochastic optimization problems, based on the approximation of the expected-cost-to-go functions of stochastic dynamic programming by piecewise linear functions. No state discretization is necessary, and the combinatorial "explosion" with the number of states (the well known "curse of dimensionality" of dynamic programming) is avoided. The piecewise functions are obtained from the dual solutions of the optimization problem at each stage and correspond to Benders cuts in a stochastic, multistage decomposition framework. A case study of optimal stochastic scheduling for a 39-reservoir system is presented and discussed.},
author = {Pereira, M.V.F. and Pinto, L.M.V.G.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira, Pinto - 1991 - Multi-stage stochastic optimization applied to energy planning.pdf:pdf},
journal = {Mathematical Programming},
pages = {359--375},
title = {{Multi-stage stochastic optimization applied to energy planning}},
volume = {52},
year = {1991}
}
@inproceedings{Yao2014,
author = {Yao, Hengshuai and Szepesv{\'{a}}ri, Csaba and Pires, Bernardo Avila and Zhang, Xinhua},
booktitle = {Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
pages = {1--9},
title = {{Pseudo-MDPs and factored linear action models}},
year = {2014}
}
@article{Nesterov2009,
abstract = {In this paper we present a new approach for constructing subgradient schemesfordifferent types ofnonsmoothproblems withconvexstructure.Ourmethods are primal-dual since they are always able to generate a feasible approximation to the optimum of an appropriately formulated dual problem. Besides other advantages, this useful feature provides the methods with a reliable stopping criterion. The proposed schemes differ from the classical approaches (divergent series methods, mirror descent methods) by presence of two control sequences. The first sequence is responsible for aggregating the support functions in the dual space, and the second one establishes a dynamically updated scale between the primal and dual spaces. This additional flexi- bility allows to guarantee a boundedness of the sequence of primal test points even in the case of unbounded feasible set (however, we always assume the uniform bounded- ness of subgradients).We present the variants of subgradient schemes for nonsmooth convex minimization, minimax problems, saddle point problems, variational inequali- ties, and stochastic optimization. In all situations our methods are proved to be optimal from the view point of worst-case black-box lower complexity bounds.},
author = {Nesterov, Yurii},
doi = {10.1007/s10107-007-0149-x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nesterov - 2009 - Primal-dual subgradient methods for convex problems.pdf:pdf},
issn = {00255610},
journal = {Mathematical Programming},
keywords = {Black-box methods,Convex optimization,Lower complexity bounds,Minimax problems,Non-smooth optimization,Saddle points,Stochastic optimization,Subgradient methods,Variational inequalities},
number = {1 SPEC. ISS.},
pages = {221--259},
title = {{Primal-dual subgradient methods for convex problems}},
volume = {120},
year = {2009}
}
@inproceedings{Becker2017a,
abstract = {{\textcopyright} Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Randomized matrix compression techniques, such as the Johnson-Lindenstrauss transform, have emerged as an effective and practical way for solving large-scale problems efficiently. With a focus on computational efficiency, however, forsaking solutions quality and accuracy becomes the tradeoff. In this paper, we investigate compressed least-squares problems and propose new models and algorithms that address the issue of error and noise introduced by compression. While maintaining computational efficiency, our models provide robust solutions that are more accurate than those of classical compressed variants.We introduce tools from robust optimization together with a form of partial compression to improve the error-time trade-offs of compressed least-squares solvers. We develop an efficient solution algorithm for our Robust Partially-Compressed (RPC) model based on a reduction to a one-dimensional search.},
author = {Becker, S. and Kawas, B. and Petrik, M.},
booktitle = {Conference on Artificial Intelligence (AAAI)},
title = {{Robust partially-compressed least-squares}},
year = {2017}
}
@book{Jones2003,
author = {Jones, J.W and Hoogenboom, G and Porter, C.H and Boote, K.J and Batchelor, W.D and Hunt, L.a and Wilkens, P.W and Singh, U and a.J Gijsman and Ritchie, J.T},
booktitle = {European Journal of Agronomy},
doi = {10.1016/S1161-0301(02)00107-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones et al. - 2003 - The DSSAT cropping system model.pdf:pdf},
isbn = {1352392186},
issn = {11610301},
keywords = {1 corresponding author,1-352-392-1864x289,1-352-392-4092,agen,contribution from florida agricultural,crop simulation,decision aid,e-mail address,edu,experiment station,fax,florida,j,jjones,jones,journal series no,r-08916,research tool,tel,ufl,uni v ersity of,w,weather},
month = {jan},
number = {3-4},
pages = {235--265},
title = {{The DSSAT cropping system model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1161030102001077},
volume = {18},
year = {2003}
}
@inproceedings{Sandholm2005,
annote = {From Duplicate 1 ( Mixed-integer programming methods for finding {\{}N{\}}ash equilibria - Sandholm, Tuomas; Gilpin, Andrew; Conitzer, Vincent )

From Duplicate 1 ( Mixed-integer programming methods for finding {\{}N{\}}ash equilibria - Sandholm, Tuomas; Gilpin, Andrew; Conitzer, Vincent )





From Duplicate 2 ( Mixed-integer programming methods for finding Nash equilibria - Sandholm, Tuomas; Gilpin, Andrew; Conitzer, Vincent )
},
author = {Sandholm, Tuomas and Gilpin, Andrew and Conitzer, Vincent},
booktitle = {{\{}N{\}}ational {\{}C{\}}onference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sandholm, Gilpin, Conitzer - 2005 - Mixed-integer programming methods for finding Nash equilibria.pdf:pdf},
pages = {495--501},
title = {{Mixed-integer programming methods for finding {\{}N{\}}ash equilibria}},
url = {http://www.aaai.org/Papers/AAAI/2005/AAAI05-078.pdf},
year = {2005}
}
@article{Fern2014,
abstract = {This paper addresses adaptive conservation planning, where the objective is to maximize the population spread of a species by allocating limited resources over time to conserve land parcels. This problem is characterized by having highly stochastic exogenous events (population spread), a large action branching factor (number of allocation options) and state space, and the need to reason about numeric resources. Together these characteristics render most existing AI planning techniques ineffective. The main contribution of this paper is to design and evaluate an online planner for this problem based on Hindsight Optimization (HOP), a technique that has shown promise in other stochastic planning problems. Unfortunately, standard implementations of HOP scale linearly with the number of actions in a domain, which is not feasible for conservation problems such as ours. Thus, we develop a new approach for computing HOP policies based on mixed-integer programming and dual decomposition. Our experiments on synthetic and real-world scenarios show that this approach is effective and scalable compared to existing alternatives.},
author = {Fern, Alan and Sheldon, Daniel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern, Sheldon - 2014 - Dynamic Resource Allocation for Optimizing Population Diffusion.pdf:pdf},
issn = {15337928},
journal = {Artificial Intelligence and Statistics (AISTATS)},
pages = {1033--1041},
title = {{Dynamic Resource Allocation for Optimizing Population Diffusion}},
volume = {33},
year = {2014}
}
@phdthesis{ShamM.Kaka2003,
author = {Kakade, Sham M.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade - 2003 - On the Sample Complexity of Reinforcement Learning.pdf:pdf},
title = {{On the Sample Complexity of Reinforcement Learning}},
year = {2003}
}
@article{Perkins2002a,
author = {Perkins, TJ and Precup, Doina},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perkins, Precup - 2002 - A convergent form of approximate policy iteration.pdf:pdf},
journal = {Advances in neural information {\ldots}},
title = {{A convergent form of approximate policy iteration}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/CN11.pdf},
year = {2002}
}
@techreport{ODonoghue2011,
annote = {report for Emmanuel's 301 optimization class at Stanford. Later, Brendan and Emmanuel wrote a paper that analyzes this idea in the case of quadratics.

The first I know of this idea goes to Michael Grant in our joint paper on TFOCS},
author = {O'Donoghue, Brendan},
booktitle = {REPORT},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Donoghue - 2011 - Adaptive Restarting for First Order Optimization Methods.pdf:pdf},
keywords = {Stanford,class project,restart},
mendeley-tags = {Stanford,class project,restart},
pages = {1--26},
title = {{Adaptive Restarting for First Order Optimization Methods}},
year = {2011}
}
@article{Sabharwal2016a,
abstract = {We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples. This is motivated by large modern datasets and ML toolkits with many combinations of learning algorithms and hyper-parameters. Inspired by the principle of "optimism under uncertainty," we propose an innovative strategy, Data Allocation using Upper Bounds (DAUB), which robustly achieves these objectives across a variety of real-world datasets. We further develop substantial theoretical support for DAUB in an idealized setting where the expected accuracy of a classifier trained on {\$}n{\$} samples can be known exactly. Under these conditions we establish a rigorous sub-linear bound on the regret of the approach (in terms of misallocated data), as well as a rigorous bound on suboptimality of the selected classifier. Our accuracy estimates using real-world datasets only entail mild violations of the theoretical scenario, suggesting that the practical behavior of DAUB is likely to approach the idealized behavior.},
archivePrefix = {arXiv},
arxivId = {1601.00024},
author = {Sabharwal, Ashish and Samulowitz, Horst and Tesauro, Gerald},
eprint = {1601.00024},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabharwal, Samulowitz, Tesauro - 2016 - Selecting Near-Optimal Learners via Incremental Data Allocation.pdf:pdf},
isbn = {9781577357605},
journal = {Proceedings of the 30th Conference on Artificial Intelligence (AAAI 2016)},
keywords = {Technical Papers: Machine Learning Methods},
pages = {2007--2015},
title = {{Selecting Near-Optimal Learners via Incremental Data Allocation}},
year = {2016}
}
@article{Al2009,
abstract = {This paper presents a new algorithm for on- line linear regression whose efficiency guar- antees satisfy the requirements of the KWIK (KnowsWhat It Knows) framework. The al- gorithm improves on the complexity bounds of the current state-of-the-art procedure in this setting. We explore several applica- tions of this algorithm for learning compact reinforcement-learning representations. We show that KWIK linear regression can be used to learn the reward function of a fac- tored MDP and the probabilities of action outcomes in Stochastic STRIPS and Object Oriented MDPs, none of which have been proven to be efficiently learnable in the RL setting before. We also combine KWIK lin- ear regression with other KWIK learners to learn larger portions of these models, includ- ing experiments on learning factored MDP transition and reward functions together.},
archivePrefix = {arXiv},
arxivId = {1205.2606},
author = {Al, Walsh E T and Walsh, Thomas J and Diuk, Carlos and Littman, Michael L},
eprint = {1205.2606},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al et al. - 2009 - Exploring compact reinforcement-learning representations with linear regression.pdf:pdf},
isbn = {978-0-9749039-5-8},
journal = {Uai 2009},
pages = {591--598},
title = {{Exploring compact reinforcement-learning representations with linear regression}},
year = {2009}
}
@article{Koessler2000d,
author = {Koessler, Fr�d�ric},
doi = {10.1051/ejess:2000120},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koessler - 2000 - Common knowledge and interactive behaviors A survey.pdf:pdf},
issn = {1292-8895},
journal = {European Journal of Economic and Social Systems},
keywords = {common knowledge,communication,information structure,interactive knowledge},
number = {3},
pages = {271--308},
title = {{Common knowledge and interactive behaviors: A survey}},
url = {http://www.edpsciences.org/10.1051/ejess:2000120},
volume = {14},
year = {2000}
}
@article{Hadjimitsis2010,
author = {Hadjimitsis, D. G. and Papadavid, G. and Agapiou, A. and Themistocleous, K. and Hadjimitsis, M. G. and Retalis, A. and Michaelides, S. and Chrysoulakis, N. and Toulios, L. and Clayton, C. R. I.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadjimitsis et al. - 2010 - Atmospheric correction for satellite remotely sensed data intended for agricultural applications impact on v.pdf:pdf},
journal = {Natural Hazards {\&} {\ldots}},
number = {1984},
pages = {89--95},
title = {{Atmospheric correction for satellite remotely sensed data intended for agricultural applications: impact on vegetation indices.}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}profile=ehost{\&}scope=site{\&}authtype=crawler{\&}jrnl=15618633{\&}AN=49137765{\&}h=4PcrzLXEU+e2A9sNpvMbsF9lDmv7Y25DEHpa6IhOx8K9/ZpBb9RNsa8EzOcbVfsGFq49/BJzUuz5bn83zR3tug=={\&}crl=c},
year = {2010}
}
@article{Lim2013,
abstract = {An important challenge in Markov decision processes is to ensure robustness with respect to unexpected or adversarial system behavior while taking advantage of well-behaving parts of the system. We consider a problem setting where some unknown parts of the state space can have arbitrary transitions while other parts are purely stochastic. We devise an algorithm that is adaptive to potentially ad-versarial behavior and show that it achieves similar regret bounds as the purely stochastic case.},
author = {Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
journal = {Advances in Neural Information Processing Systems (NIPS)},
doi = {10.1287/moor.2016.0779},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim, Xu, Mannor - 2013 - Reinforcement Learning in Robust Markov Decision Processes.pdf:pdf},
issn = {10495258},
title = {{Reinforcement Learning in Robust Markov Decision Processes}},
url = {http://papers.nips.cc/paper/5183-reinforcement-learning-in-robust-markov-decision-processes},
year = {2013}
}
@inproceedings{Becker2005,
author = {Becker, Raphen and Zilberstein, Shlomo and Lesser, Victor},
booktitle = {Intelligent Agent Technology},
pages = {550--557},
title = {{Analyzing Myopic Approaches for Multi-Agent Communication}},
year = {2005}
}
@article{Tsitsiklis1994a,
abstract = {Provides some general results on the convergence of a class of$\backslash$nstochastic approximation algorithms and their parallel and asynchronous$\backslash$nvariants. The author then uses these results to study the Q-learning$\backslash$nalgorithm, a reinforcement learning method for solving Markov decision$\backslash$nproblems, and establishes its convergence under conditions more general$\backslash$nthan previously available},
author = {Tsitsiklis, John N.},
doi = {10.1023/A:1022689125041},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis - 1994 - Asynchronous Stochastic Approximation and Q-Learning.pdf:pdf},
isbn = {0-7803-1298-8},
issn = {15730565},
journal = {Machine Learning},
keywords = {Q-learning,Reinforcement learning,dynamic programming,stochastic approximation},
number = {3},
pages = {185--202},
title = {{Asynchronous Stochastic Approximation and Q-Learning}},
volume = {16},
year = {1994}
}
@article{Ernst2004,
author = {Ernst, Daniel and Glavic, Mevluding and Wehenkel, Loius},
journal = {IEEE Transations on Power Systems},
pages = {427--435},
title = {{Power systems stability control: Reinforcement learning framework}},
volume = {19},
year = {2004}
}
@article{Senay2000,
abstract = {Digital images of a corn and soybean site in Ohio were acquired several times during the growing season using a multispectral scanner mounted on an aircraft. The goal of this study was to evaluate the use of this high spatial resolution (1-m) data to identifl corn and soybean crops at various growth stages. Maximum distinction between corn and soybeans was achieved using the near-infrared bands when the crops were mature, while the visible bands were more useful when the soybeans were senescing. Spectral class differences were related to leaf nitrogen, soil water content, soil organic matter, and plant biomass. An approach is presented for identifying corn and soybeans crops where little or no reference data are available. The approach is based on the red and near-infrared bands and using the Simple Vegetation Index or the Normalized Difference Vegetation Index},
author = {Senay, GB and Lyon, JG and Ward, AD and Nokes, SE},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Senay et al. - 2000 - Using high spatial resolution multispectral data to classify corn and soybean crops.pdf:pdf},
journal = {Photographic Engineering and Remote Sensing},
keywords = {American Society for Photogrammetry and Remote Sen,March 2000,No. 3,Photogrammetric Engineering {\&} Remote Sensing,Vol. 66,pp. 319-327.},
number = {3},
pages = {319--327},
title = {{Using high spatial resolution multispectral data to classify corn and soybean crops}},
url = {http://www.asprs.org/a/publications/pers/2000journal/march/2000{\_}mar{\_}319-327.pdf},
volume = {66},
year = {2000}
}
@article{Powell2008,
author = {Powell, Warren B},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Powell - 2008 - Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {adaptive,approximate dynamic programming,hierarchical statistics,learning,mixture models,multiattribute resources},
pages = {2079--2111},
title = {{Value Function Approximation using Multiple Aggregation for Multiattribute Resource Management}},
volume = {9},
year = {2008}
}
@article{Bellman1963,
annote = {From Duplicate 2 ( Polynomial Approximation -- A New Computational Technique in Dynamic Programming: Allocation Processes - Bellman, Richard; Kalaba, Robert; Kotkin, Bella )
},
author = {Bellman, Richard and Kalaba, Robert and Kotkin, Bella and Bellman, By Richard},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellman et al. - 1963 - Polynomial Approximation-A New Computa- tional Technique in Dynamic Programming Allocation Processes.pdf:pdf},
journal = {Mathematics of Computation},
number = {82},
pages = {155--161},
title = {{Polynomial Approximation -- A New Computational Technique in Dynamic Programming: Allocation Processes}},
volume = {17},
year = {1963}
}
@article{Martinelli2015,
abstract = {Plant diseases are responsible for major economic losses in the agricultural industry worldwide. Monitoring plant health and detecting pathogen early are essential to reduce disease spread and facilitate effective management practices. DNA-based and serological methods now provide essential tools for accurate plant disease diagnosis, in addition to the traditional visual scouting for symptoms. Although DNA-based and serological methods have revolutionized plant disease detection, they are not very reliable at asymptomatic stage, especially in case of pathogen with systemic diffusion. They need at least 1–2 days for sample harvest, processing, and analysis. Here, we describe modern methods based on nucleic acid and protein analysis. Then, we review innovative approaches currently under development. Our main findings are the following: (1) novel sensors based on the analysis of host responses, e.g., differential mobility spectrometer and lateral flow devices, deliver instantaneous results and can effectively detect early infections directly in the field; (2) biosensors based on phage display and biophotonics can also detect instantaneously infections although they can be integrated with other systems; and (3) remote sensing techniques coupled with spectroscopy-based methods allow high spatialization of results, these techniques may be very useful as a rapid preliminary identification of primary infections. We explain how these tools will help plant disease management and complement serological and DNA-based methods. While serological and PCR-based methods are the most available and effective to confirm disease diagnosis, volatile and biophotonic sensors provide instantaneous results and may be used to identify infections at asymptomatic stages. Remote sensing technologies will be extremely helpful to greatly spatialize diagnostic results. These innovative techniques represent unprecedented tools to render agriculture more sustainable and safe, avoiding expensive use of pesticides in crop protection.},
author = {Martinelli, Federico and Scalenghe, Riccardo and Davino, Salvatore and Panno, Stefano and Scuderi, Giuseppe and Ruisi, Paolo and Villa, Paolo and Stroppiana, Daniela and Boschetti, Mirco and Goulart, Luiz R. and Davis, Cristina E. and Dandekar, Abhaya M.},
doi = {10.1007/s13593-014-0246-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinelli et al. - 2015 - Advanced methods of plant disease detection. A review.pdf:pdf},
isbn = {1359301402},
issn = {17730155},
journal = {Agronomy for Sustainable Development},
keywords = {Biophotonics,Commercial kits,DNA-based methods,Immunological assays,Plant disease,Remote sensing,Spectroscopy,Volatile organic compounds},
number = {1},
pages = {1--25},
title = {{Advanced methods of plant disease detection. A review}},
volume = {35},
year = {2015}
}
@article{Delhi-1999,
author = {RAMASUBRAMANIAN, V},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/RAMASUBRAMANIAN - 1999 - FORECASTING BASED ON MARKOV CHAIN MODEL.pdf:pdf},
journal = {iasri.res.in},
number = {1996},
pages = {0--8},
title = {{FORECASTING BASED ON MARKOV CHAIN MODEL}},
url = {http://www.iasri.res.in/cbp/data/Coordinator/lecture{\_}Presentation{\_}files/80/Forecasting Based on Markov Chain Model.pdf},
year = {1999}
}
@inproceedings{Powell2007,
author = {Powell, Warren B},
booktitle = {Tutorial presented at the IEEE Symposium on Approximate Dynamic Programming and Reinforcement Learning},
title = {{Approximate Dynamic Programming for High-Dimensional Problems}},
year = {2007}
}
@article{Modaresi2013,
author = {Modaresi, Sajad and Saur, Denis and Vielma, Juan Pablo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Modaresi, Saur, Vielma - 2013 - Learning in Combinatorial Optimization What and How to.pdf:pdf},
pages = {1--58},
title = {{Learning in Combinatorial Optimization : What and How to}},
year = {2013}
}
@techreport{Friedman2011,
author = {Friedman, Daniel and Sunder, Shyam},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman, Sunder - 2011 - Risky Curves From Unobservable Utility to Observable Opportunity Sets.pdf:pdf},
keywords = {decisions under uncertainty,expected utility,petersburg paradox,risk aversion,st},
title = {{Risky Curves: From Unobservable Utility to Observable Opportunity Sets}},
year = {2011}
}
@article{Facchinei1997,
author = {Facchinei, Francisco and Fischer, Andreas and Kanzow, Christian},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Facchinei, Fischer, Kanzow - 1997 - A semismooth Newton method for variational inequalities The case of box constraints.pdf:pdf},
journal = {{\ldots} {\&} Variational Problems: {\ldots}},
title = {{A semismooth Newton method for variational inequalities: The case of box constraints}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=vQXA3oqLcnUC{\&}oi=fnd{\&}pg=PA76{\&}dq=A+semismooth+newton+method+for+variational+inequalities:+the+case+of+box+constraints{\&}ots=1zavZQpFea{\&}sig=5KIJslrQTfpTNpQZlyeu2brSfjE},
year = {1997}
}
@inproceedings{Bernstein2008,
author = {Bernstein, Andrey and Shikim, Nahum},
booktitle = {Conference on Learning Theory (COLT)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernstein, Shikim - 2008 - Adaptive Aggregation for Reinforcement Learning with Efficient Exploration Deterministic Domains.pdf:pdf},
title = {{Adaptive aggregation for reinforcement learning with efficient exploration: Deterministic domains}},
year = {2008}
}
@article{Ermon2011,
author = {Ermon, Stefano and Conrad, Jon and Gomes, Carla and Selman, Bart},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ermon et al. - 2011 - Risk-Sensitive Policies for Sustainable Renewable Resource Allocation.pdf:pdf},
isbn = {978-1-57735-516-8},
journal = {Twenty-Second International Joint Conference on Artificial Intelligence},
keywords = {Planning and Scheduling},
pages = {1942--1948},
title = {{Risk-Sensitive Policies for Sustainable Renewable Resource Allocation}},
year = {2011}
}
@article{RobSchapire2013,
author = {{Rob Schapire}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rob Schapire - 2013 - Lecture 9 Definition of Rademacher Complexity.pdf:pdf},
journal = {COS 511: Theoretical Machine Learning},
number = {5},
pages = {1--5},
title = {{Lecture 9: Definition of Rademacher Complexity}},
url = {http://www.cs.princeton.edu/courses/archive/spring13/cos511/scribe{\_}notes/0305.pdf},
year = {2013}
}
@inproceedings{Chow2014,
archivePrefix = {arXiv},
arxivId = {1406.3339},
author = {Chow, Yinlam},
booktitle = {Neural Information Processing Systems (NIPS)},
eprint = {1406.3339},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chow - 2014 - Algorithms for CVaR Optimization in MDPs.pdf:pdf},
title = {{Algorithms for CVaR Optimization in MDPs}},
year = {2014}
}
@article{Fox2002,
author = {Fox, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fox - 2002 - Nonparametric Regression.pdf:pdf},
number = {January},
pages = {1--15},
title = {{Nonparametric Regression}},
volume = {2},
year = {2002}
}
@article{Kawas2011,
author = {Kawas, Ban and Thiele, Aur{\'{e}}lie},
doi = {10.1016/j.ejor.2011.06.042},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kawas, Thiele - 2011 - Short sales in Log-robust portfolio management.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
month = {dec},
number = {3},
pages = {651--661},
publisher = {Elsevier B.V.},
title = {{Short sales in Log-robust portfolio management}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377221711005716},
volume = {215},
year = {2011}
}
@book{Singh2012,
author = {Singh, Vijay P.},
title = {{Computer Models of Watershed Hydrology}},
year = {2012}
}
@inproceedings{Feng2005,
author = {Feng, Zhengzhu and Zilberstein, Shlomo},
booktitle = {National Conference on Artificial Intelligence},
title = {{Efficient maximization in solving POMDPs}},
year = {2005}
}
@article{Pflug2014,
annote = {See the newer 2016 version in Math of OR},
author = {Pflug, Georg Ch and Pichler, Alois},
doi = {10.1287/moor.2015.0747},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pflug, Pichler - 2014 - Time Consistent Decisions and Temporal Decomposition of Coherent Risk Functionals.pdf:pdf},
issn = {15265471},
journal = {Optimization Online},
number = {1},
pages = {1--22},
title = {{Time Consistent Decisions and Temporal Decomposition of Coherent Risk Functionals}},
year = {2014}
}
@article{Bennett1993,
author = {Bennett, KP and Mangasarian, OL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bennett, Mangasarian - 1993 - Bilinear separation of two sets inn-space.pdf:pdf},
journal = {Computational Optimization and {\ldots}},
title = {{Bilinear separation of two sets inn-space}},
url = {http://link.springer.com/article/10.1007/BF01299449},
year = {1993}
}
@article{Bertsimas2012,
author = {Bertsimas, Dimitris and Goyal, Vineet},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Goyal - 2012 - On the power and limitations of affine policies in two-stage adaptive optimization.pdf:pdf},
journal = {Mathematical programming},
keywords = {affine control policies,and efri-0735905,by nsf grants dmi-0556106,research is partially supported,robust optimization},
title = {{On the power and limitations of affine policies in two-stage adaptive optimization}},
url = {http://link.springer.com/article/10.1007/s10107-011-0444-4},
year = {2012}
}
@book{Powell2007,
annote = {From Duplicate 1 ( 


Approximate Dynamic Programming


- Powell, Warren B )

},
author = {Powell, Warren B},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Powell - 2006 - Approximate Dynamic Programming Solving the curses of dimensionality.pdf:pdf},
title = {{Approximate Dynamic Programming}},
year = {2007}
}
@article{Liu2004a,
annote = {This appears to be the basis for the US National Cropland Data Layer (CDL).

http://www.nass.usda.gov/research/Cropland/Release/},
author = {Liu, Weiguo and Gopal, Sucharita and Woodcock, Curtis E.},
doi = {10.14358/PERS.70.8.963},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Gopal, Woodcock - 2004 - Uncertainty and Confidence in Land Cover Classification Using a Hybrid Classifier Approach.pdf:pdf},
issn = {0099-1112},
journal = {Photogrammetric Engineering {\&} Remote Sensing},
month = {aug},
number = {8},
pages = {963--971},
title = {{Uncertainty and Confidence in Land Cover Classification Using a Hybrid Classifier Approach}},
volume = {70},
year = {2004}
}
@article{Adelman2004,
author = {Adelman, Daniel},
doi = {10.1287/opre.1040.0114},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adelman - 2004 - A Price-Directed Approach to Stochastic InventoryRouting.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {aug},
number = {4},
pages = {499--514},
title = {{A Price-Directed Approach to Stochastic Inventory/Routing}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1040.0114},
volume = {52},
year = {2004}
}
@inproceedings{Petrik2007e,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2007 - Average-Reward Decentralized Markov Decision Processes.pdf:pdf},
pages = {1997--2002},
title = {{Average-reward decentralized Markov decision processes}},
url = {http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-322.pdf},
year = {2007}
}
@book{Axsater2006,
author = {Axsater, Sven},
edition = {2nd},
publisher = {Springer},
title = {{Inventory Control}},
year = {2006}
}
@inproceedings{Regan2009,
abstract = {The specification of aMarkov decision process (MDP) can be difficult.$\backslash$nReward function specification is especially problematic; in practice,$\backslash$nit is often cognitively complex and time-consuming for users to precisely$\backslash$nspecify rewards. This work casts the problem of specifying rewards$\backslash$nas one of preference elicitation and aims to minimize the degree$\backslash$nof precision with which a reward function must be specified while$\backslash$nstill allowing optimal or near-optimal policies to be produced. We$\backslash$nfirst discuss how robust policies can be computed for MDPs given$\backslash$nonly partial reward information using the minimax regret criterion.$\backslash$nWe then demonstrate how regret can be reduced by efficiently eliciting$\backslash$nreward information using bound queries, using regret-reduction as$\backslash$na means for choosing suitable queries. Empirical results demonstrate$\backslash$nthat regret-based reward elicitation offers an effective way to produce$\backslash$nnear-optimal policies without resorting to the precise specification$\backslash$nof the entire reward function.},
archivePrefix = {arXiv},
arxivId = {1205.2619},
author = {Regan, Kevin and Boutilier, Craig},
booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI)},
eprint = {1205.2619},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Regan, Boutilier - 2009 - Regret-based reward elicitation for Markov decision processes.pdf:pdf},
isbn = {978-0-9749039-5-8},
pages = {444--451},
title = {{Regret-based reward elicitation for Markov decision processes}},
year = {2009}
}
@article{Ernst2006,
abstract = {This paper addresses the problem of computing optimal structured treatment interruption strategies for HIV infected patients. We show that reinforcement learning may be useful to extract such strategies directly from clinical data, without the need of an accurate mathematical model of HIV infection dynamics. To support our claims, we report simulation results obtained by running a recently proposed batch-mode reinforcement learning algorithm, known as fitted Q iteration, on numerically generated data},
author = {Ernst, Damien and Stan, Guy-Bart and Goncalves, Jorge and Wehenkel, Louis},
doi = {10.1109/CDC.2006.377527},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ernst et al. - 2006 - Clinical data based optimal STI strategies for HIV a reinforcement learning approach.pdf:pdf},
isbn = {1-4244-0171-2},
issn = {01912216},
journal = {Proceedings of the 45th IEEE Conference on Decision and Control},
pages = {667--672},
title = {{Clinical data based optimal STI strategies for HIV: a reinforcement learning approach}},
url = {http://ieeexplore.ieee.org/document/4177178/},
year = {2006}
}
@article{Kumar2013,
author = {Kumar, Shamanth and Morstatter, Fred and Liu, Huan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Morstatter, Liu - 2013 - Twitter Data Analytics.pdf:pdf},
title = {{Twitter Data Analytics}},
url = {http://www.csi.ucd.ie/files/Twitter Data Analytics.pdf},
year = {2013}
}
@techreport{Zhang2017,
author = {Zhang, Yuanhui and Steimle, Lauren N and Denton, Brian T},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Steimle, Denton - Unknown - Robust Markov Decision Processes for Medical Treatment Decisions.pdf:pdf},
keywords = {Optimization Online,application,diabetes,dynamic,dynamic programming,finite states,glycemic control,health care,markov,medical decision making,optimal control,programming,robust markov decision process,robust optimization,subject classifications,treatment,type 2},
mendeley-tags = {Optimization Online},
pages = {1--35},
title = {{Robust Markov Decision Processes for Medical Treatment Decisions}},
year = {2017}
}
@inproceedings{Chow2015,
abstract = {In this paper we address the problem of decision making within a Markov decision process (MDP) framework where risk and modeling errors are taken into account. Our approach is to minimize a risk-sensitive conditional-value-at-risk (CVaR) objective, as opposed to a standard risk-neutral expectation. We refer to such problem as CVaR MDP. Our first contribution is to show that a CVaR objective, besides capturing risk sensitivity, has an alternative interpretation as expected cost under worst-case modeling errors, for a given error budget. This result, which is of independent interest, motivates CVaR MDPs as a unifying framework for risk-sensitive and robust decision making. Our second contribution is to present an approximate value-iteration algorithm for CVaR MDPs and analyze its convergence rate. To our knowledge, this is the first solution algorithm for CVaR MDPs that enjoys error guarantees. Finally, we present results from numerical experiments that corroborate our theoretical findings and show the practicality of our approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1506.02188v1},
author = {Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
booktitle = {Neural Information Processing Systems (NIPS)},
eprint = {arXiv:1506.02188v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chow et al. - 2015 - Risk-sensitive and robust decision-making A CVaR optimization approach.pdf:pdf},
issn = {10495258},
title = {{Risk-sensitive and robust decision-making : A CVaR optimization approach}},
year = {2015}
}
@article{Schweitzer1985a,
author = {Schweitzer, Paul J and Puterman, Martin L and Kindle, Kyle W},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schweitzer, Puterman, Kindle - 1985 - Iterative Aggregation-Disaggregation Procedures for Discounted Semi-Markov Reward Processes.pdf:pdf},
journal = {Operations Research},
number = {3},
pages = {589--606},
title = {{Iterative Aggregation-Disaggregation Procedures for Discounted Semi-Markov Reward Processes}},
volume = {33},
year = {1985}
}
@article{Porteus1971,
author = {Porteus, E L},
journal = {Management Science},
title = {{Some bounds for discounted sequential decision processes}},
volume = {18},
year = {1971}
}
@article{Avron2010,
author = {Avron, H and Maymounkov, Petar and Toledo, Sivan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Avron, Maymounkov, Toledo - 2010 - Blendenpik Supercharging LAPACK's least-squares solver.pdf:pdf},
journal = {SIAM Journal on Scientific Computing},
keywords = {dense linear least squares,randomized numerical linear algebra,randomized pre-},
title = {{Blendenpik: Supercharging LAPACK's least-squares solver}},
url = {http://epubs.siam.org/doi/abs/10.1137/090767911},
year = {2010}
}
@inproceedings{Feng2002,
author = {Feng, Zhengzhu and Hansen, Eric A},
booktitle = {National Conference on Artificial Intelligence},
pages = {455--460},
title = {{Symbolic Heuristic Search for Factored Markov Decision Processes}},
year = {2002}
}
@article{Caro2007a,
abstract = {Companies such as Zara and World Co. have recently implemented novel$\backslash$nproduct development processes and supply chain architectures enabling$\backslash$nthem to make more product design and assortment decisions during$\backslash$nthe selling season, when actual demand information becomes available.$\backslash$nHow should such retail firms modify their product assortment over$\backslash$ntime in order to maximize overall profits for a given selling season?$\backslash$nFocusing on a stylized version of this problem, we study a finite$\backslash$nhorizon multiarmed bandit model with several plays per stage and$\backslash$nBayesian learning. Our analysis involves the Lagrangian relaxation$\backslash$nof weakly coupled dynamic programs (I)Ps), results contributing to$\backslash$nthe emerging theory of DP cluality and various approximations. It$\backslash$nyields a closed-form dynamic index policy capturing the key exploration$\backslash$nversus exploitation trade-off and associated suboptimality bounds.$\backslash$nIn numerical experiments its performance proves comparable to that$\backslash$nof other closed-form heuristics described in the literature, but$\backslash$nthis policy is particularly easy to implement and interpret. This$\backslash$nlast feature enables extensions to more realistic versions of the$\backslash$nmotivating dynamic assortment problem that include implementation$\backslash$ndelays, switching costs, and demand substitution effects.},
author = {Caro, Felipe and Gallien, J{\'{e}}r{\'{e}}mie},
doi = {10.1287/mnsc.1060.0613},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caro, Gallien - 2007 - Dynamic Assortment with Demand Learning for Seasonal Consumer Goods.pdf:pdf},
isbn = {00251909},
issn = {0025-1909},
journal = {Management Science},
keywords = {2005,accepted by paul h,bayesian learning,dynamic programming duality,history,management,multiarmed,operations and supply chain,received january 13,retail assortment,the authors,this paper was with,zipkin},
number = {2},
pages = {276--292},
pmid = {24272627},
title = {{Dynamic Assortment with Demand Learning for Seasonal Consumer Goods}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0613},
volume = {53},
year = {2007}
}
@book{Bertsekas1996,
author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
booktitle = {Athena {\{}S{\}}cientific},
title = {{Neuro-dynamic programming}},
publisher = {Athena Scientific},
year = {1996}
}
@article{Zhou2009a,
author = {Zhou, Shuheng and Ligett, Katrina and Wasserman, Larry},
doi = {10.1109/ISIT.2009.5205863},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Ligett, Wasserman - 2009 - Differential privacy with compression.pdf:pdf},
isbn = {978-1-4244-4312-3},
journal = {2009 IEEE International Symposium on Information Theory},
month = {jun},
number = {1},
pages = {2718--2722},
publisher = {Ieee},
title = {{Differential privacy with compression}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5205863},
year = {2009}
}
@article{Richter1983,
author = {Richter, S. and DeCarlo, R.},
doi = {10.1109/TAC.1983.1103294},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Richter, DeCarlo - 1983 - Continuation methods Theory and applications.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {jun},
number = {6},
pages = {660--665},
title = {{Continuation methods: Theory and applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1103294},
volume = {28},
year = {1983}
}
@article{Todorovic2009,
author = {Todorovic, Mladen and Albrizio, Rossella and Zivotic, Ljubomir and Saab, Marie-Therese Abi and St{\"{o}}ckle, Claudio and Steduto, Pasquale},
doi = {10.2134/agronj2008.0166s},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todorovic et al. - 2009 - Assessment of AquaCrop, CropSyst, and WOFOST Models in the Simulation of Sunflower Growth under Different Wate.pdf:pdf},
issn = {1435-0645},
journal = {Agronomy Journal},
number = {3},
pages = {509},
title = {{Assessment of AquaCrop, CropSyst, and WOFOST Models in the Simulation of Sunflower Growth under Different Water Regimes}},
url = {https://www.agronomy.org/publications/aj/abstracts/101/3/509},
volume = {101},
year = {2009}
}
@inproceedings{Abbeel2006a,
author = {Abbeel, Pieter and Quigley, Morgan and Ng, Andrew},
booktitle = {International Conference of Machine Learning},
title = {{Using Inaccurate Models in Reinforcement Learning}},
year = {2006}
}
@article{Klema1980,
author = {Klema, V. and Laub, a.},
doi = {10.1109/TAC.1980.1102314},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klema, Laub - 1980 - The singular value decomposition Its computation and some applications.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {apr},
number = {2},
pages = {164--176},
title = {{The singular value decomposition: Its computation and some applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1102314},
volume = {25},
year = {1980}
}
@inproceedings{Asmuth2009a,
author = {Asmuth, John and Li, Lihong and Littman, Michael L. and Nouri, Ali and Wingate, David},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asmuth et al. - 2009 - A Bayesian Sampling Approach to Exploration in Reinforcement Learning.pdf:pdf},
title = {{A Bayesian Sampling Approach to Exploration in Reinforcement Learning}},
year = {2009}
}
@article{George2004,
annote = {From Duplicate 1 ( Value function approximation using hierarchical aggregation for multi-attribute resource management - George, Abraham P; Powell, Warren B; Kulkarni, Sanjeev R )
},
author = {George, Abraham P and Powell, Warren B and Kulkarni, Sanjeev R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/George, Powell, Kulkarni - 2004 - Value Function Approximation using Hierarchical Aggregation for Multiattribute Resource Management.pdf:pdf},
institution = {Department of Operations Research and Financial Engineering, Princeton University},
title = {{Value function approximation using hierarchical aggregation for multi-attribute resource management}},
year = {2004}
}
@phdthesis{Kantanantha2007,
author = {Kantanantha, Nantachai},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kantanantha - 2007 - Crop decision planning under yield and price uncertainties.pdf:pdf},
number = {August},
title = {{Crop decision planning under yield and price uncertainties}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=-{\_}fbR14wNUoC{\&}oi=fnd{\&}pg=PR4{\&}dq=Crop+decision+planning+under+yield+and+price+uncertainties{\&}ots=5cD1sCiyW3{\&}sig=9{\_}rKIvAKjYk4HwWlCRwlzPOmW8k},
year = {2007}
}
@book{Friedman2014,
author = {Friedman, Daniel and Isaac, R. Mark and James, Duncan and Sunder, Shyam},
title = {{Risky Curves: On the Empirical Failure of Expected Utility}},
year = {2014}
}
@article{Ailon2009,
author = {Ailon, N I R and Chazelle, Bernard},
doi = {10.1137/060673096},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ailon, Chazelle - 2009 - THE FAST JOHNSON–LINDENSTRAUSS TRANSFORM AND APPROXIMATE NEAREST NEIGHBORS.pdf:pdf},
issn = {0097-5397, 1095-7111},
keywords = {060673096,10,1137,68q01,ams subject classification,approximate nearest neighbors,dimension reduction,doi,random matrices,toclassify},
mendeley-tags = {toclassify},
number = {1},
pages = {302--322},
title = {{THE FAST JOHNSON–LINDENSTRAUSS TRANSFORM AND APPROXIMATE NEAREST NEIGHBORS}},
url = {http://www.cs.helsinki.fi/hecse/sada07/lectures/slides/Ailon{\_}talk1a{\_}fjlt.pdf},
volume = {39},
year = {2009}
}
@inproceedings{Mahadevan2005b,
author = {Mahadevan, Sridhar},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahadevan - 2005 - Proto-Value Functions Developmental Reinforcement Learning.pdf:pdf},
title = {{Proto-value functions: Developmental reinforcement learning}},
year = {2005}
}
@inproceedings{Szepesvari2005,
author = {Szepesvari, Csaba and Munos, Remi},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Finite time bounds for sampling-based fitted value iteration}},
year = {2005}
}
@article{Petrik2007c,
author = {Petrik, Marek and Zilberstein, Shlomo},
doi = {10.1007/s10472-007-9050-9},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2007 - Learning parallel portfolios of algorithms.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2006 - Learning parallel portfolios of algorithms.pdf:pdf},
issn = {1012-2443},
journal = {Annals of Mathematics and Artificial Intelligence},
keywords = {algorithm portfolios,combinatorial optimiza-,resource bounded reasoning},
month = {may},
number = {1-2},
pages = {85--106},
title = {{Learning parallel portfolios of algorithms}},
url = {http://link.springer.com/article/10.1007/s10472-007-9050-9 http://link.springer.com/10.1007/s10472-007-9050-9},
volume = {48},
year = {2007}
}
@article{Arapostathis1993,
author = {Arapostathis, A and Borkar, V S and Fernandez-gaucherand, E and Ghosh, M K and Markus, S},
journal = {SIAM Journal of Control and Optimization},
pages = {282--344},
title = {{Discrete time controlled {\{}M{\}}arkov processes with average cost criterion - a survey}},
volume = {31},
year = {1993}
}
@inproceedings{Jiang2015,
abstract = {State abstractions are often used to reduce the complexity of model-based reinforcement learning when only limited quantities of data are available. However, choosing the appropriate level of abstraction is an important problem in practice. Existing approaches have theoretical guarantees only under strong assumptions on the domain or asymptotically large amounts of data, but in this paper we propose a simple algorithm based on statistical hypothesis testing that comes with a finite-sample guarantee under assumptions on candidate abstractions. Our algorithm trades off the low approximation error of finer abstractions against the low estimation error of coarser abstractions, resulting in a loss bound that depends only on the quality of the best available abstraction and is polynomial in planning horizon.},
author = {Jiang, Nan and Kules, Alex and Singh, Satinder},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Kules, Singh - 2015 - Abstraction selection in model-based reinforcement learning.pdf:pdf},
title = {{Abstraction selection in model-based reinforcement learning}},
year = {2015}
}
@book{Saad2003,
author = {Saad, Yousef},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad - 2000 - Iterative Methods for Sparse Linear Systems.pdf:pdf},
title = {{Iterative methods for sparse linear systems}},
year = {2003}
}
@article{Woodward2014,
author = {Woodward, Richard T. and Tomberlin, David},
doi = {10.1007/s00267-014-0348-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Woodward, Tomberlin - 2014 - Practical Precautionary Resource Management Using Robust Optimization.pdf:pdf},
issn = {14321009},
journal = {Environmental Management},
keywords = {Dynamic optimization,Fisheries management,Numerical methods,Precautionary management,Robust optimization},
number = {4},
pages = {828--839},
title = {{Practical Precautionary Resource Management Using Robust Optimization}},
volume = {54},
year = {2014}
}
@inproceedings{Thayer2008,
author = {Thayer, Jordan T and Ruml, Wheeler},
booktitle = {International Conference on Automated Planning and Scheduling},
title = {{Faster Than Weighted A*: An Optimistic Approach to Bounded Suboptimal Search}},
year = {2008}
}
@article{Bergez2001,
author = {Bergez, JE and Debaeke, P and Deumier, JM},
journal = {Ecological Modelling},
pages = {43--60},
title = {{MODERATO: an object-oriented decision tool for designing maize irrigation schedules}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380000004312},
volume = {137},
year = {2001}
}
@book{Gelman2004,
abstract = {Incorporating new and updated information, this second edition of THE bestselling text in Bayesian data analysis continues to emphasize practice over theory, describing how to conceptualize, perform, and critique statistical analyses from a Bayesian perspective. Its world-class authors provide guidance on all aspects of Bayesian data analysis and include examples of real statistical analyses, based on their own research, that demonstrate how to solve complicated problems. Changes in the new edition include: Stronger focus on MCMCRevision of the computational advice in Part IIINew chapters on nonlinear models and decision analysisSeveral additional applied examples from the authors' recent researchAdditional chapters on current models for Bayesian data analysis such as nonlinear models, generalized linear mixed models, and moreReorganization of chapters 6 and 7 on model checking and data collectionBayesian computation is currently at a stage where there are many reasonable ways to compute any given posterior distribution. However, the best approach is not always clear ahead of time. Reflecting this, the new edition offers a more pluralistic presentation, giving advice on performing computations from many perspectives while making clear the importance of being aware that there are different ways to implement any given iterative simulation computation. The new approach, additional examples, and updated information make Bayesian Data Analysis an excellent introductory text and a reference that working scientists will use throughout their professional life.},
author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donald B},
booktitle = {Chapman Texts in Statistical Science Series},
doi = {10.1007/s13398-014-0173-7.2},
edition = {3rd},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman et al. - 2014 - Bayesian Data Analysis.pdf:pdf},
isbn = {978-1-4398-9820-8},
issn = {1467-9280},
pages = {696},
pmid = {25052830},
title = {{Bayesian Data Analysis}},
year = {2014}
}
@article{Audibert2010,
abstract = {We consider the problem of finding the best arm in a stochastic multi-armed bandit game. The regret of a forecaster is here defined by the gap between the mean reward of the optimal arm and the mean reward of the ultimately chosen arm. We propose a highly exploring UCB policy and a new algorithm based on successive rejects. We show that these algorithms are essentially optimal since their regret decreases exponentially at a rate which is, up to a logarithmic factor, the best possible. However, while the UCB policy needs the tuning of a parameter depending on the unobservable hardness of the task, the successive rejects policy benefits from being parameter-free, and also independent of the scaling of the rewards. As a by-product of our analysis, we show that identifying the best arm (when it is unique) requires a number of samples of order (up to a log(K) factor) $\Sigma$ i 1/$\Delta$2i, where the sum is on the suboptimal arms and$\Delta$i represents the difference between the mean reward of the best arm and the one of arm i. This generalizes the well-known fact that one needs of order of 1/$\Delta$2 samples to differentiate the means of two distributions with gap $\Delta$.},
author = {Audibert, Jean-Yves and Bubeck, S{\'{e}}bastien},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Audibert, Bubeck - 2010 - Best Arm Identification in Multi-Armed Bandits.pdf:pdf},
isbn = {9780982252925},
journal = {COLT 2010 - Proceedings},
pages = {13 p.},
title = {{Best Arm Identification in Multi-Armed Bandits}},
url = {https://hal-enpc.archives-ouvertes.fr/hal-00654404},
year = {2010}
}
@article{Sion1958,
annote = {- Note that this result requires continuity of the function
- The standard duality argument does not, however it requires the slaters condition to be satisfied},
author = {Sion, Maurice},
doi = {1103040253},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sion - 1958 - On general minimax theorems.pdf:pdf},
issn = {0030-8730},
journal = {Pacific Journal of Mathematics},
number = {4},
pages = {171--176},
title = {{On general minimax theorems.}},
url = {http://projecteuclid.org/euclid.pjm/1103040253},
volume = {8},
year = {1958}
}
@inproceedings{Frank1998,
author = {Frank, Ian and Basin, David A and Matsubara, Hitoshi},
booktitle = {National Conference on Artificial Intelligence},
pages = {500--507},
title = {{Finding Optimal Strategies for Imperfect Information Games}},
url = {citeseer.ist.psu.edu/frank98finding.html},
year = {1998}
}
@article{Bousquet2002,
author = {Bousquet, Olivier and Elisseeff, A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bousquet, Elisseeff - 2002 - Stability and generalization.pdf:pdf},
journal = {The Journal of Machine Learning Research},
pages = {499--526},
title = {{Stability and generalization}},
url = {http://dl.acm.org/citation.cfm?id=944801},
volume = {2},
year = {2002}
}
@inproceedings{RaymondM,
abstract = {Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes. Most existing recommender systems use collaborative filtering methods that base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization. Initial experimental results demonstrate that this approach can produce accurate recommendations.},
author = {Mooney, Raymond J. and Roy, Loriene},
booktitle = {ACM conference on Digital libraries},
pages = {195--204},
title = {{Content-based book recommending using learning for text categorization}},
year = {2000}
}
@inproceedings{Reinefeld1993,
author = {Reinefeld, Alexander},
booktitle = {International Joint Conference on AI},
pages = {248--253},
title = {{Complete Solution of the Eight-Puzzle and the Benefit of Node Ordering in {\{}IDA{\}}*}},
year = {1993}
}
@article{Naidu2009,
abstract = {The detection of viruses in plants involves destructive sampling followed by testing by enzyme-linked immunosorbent assay (ELISA) and/or reverse transcription-polymerase chain reaction (RT-PCR). In this study, we have investigated the potential of leaf spectral reflectance changes between virus infected and uninfected grapevines (Vitis vinifera L.) in developing non-invasive techniques for field-based 'real-time' diagnosis of grapevine leafroll disease (GLD). In situ leaf reflectance spectra were taken with a portable spectrometer using detached leaves from uninfected and Grapevine leafroll-associated virus-3 (GLRaV-3) infected plants of two wine grape cultivars (Cabernet Sauvignon and Merlot). Specific differences in vegetation indices and wavelength intervals were observed between virus-infected and uninfected leaves in the green peak (near 550 nm), the near infrared (near 900 nm) and in the mid-infrared (near 1600 nm and 2200 nm). Results of reflectance spectra and classification analysis suggest that different vegetation indices and/or individual wavelength bands may differ in their ability to detect GLD depending on whether there are visible symptoms in the virus-infected leaves. The differences in leaf reflectance measurements at specific wavelength intervals between virus-infected and uninfected grapevines and their correlation with RT-PCR results for the presence of GLRaV-3 suggest spectral reflectance technique as a promising tool for cost-effective, nondestructive method for diagnosis of GLD in the field. To our knowledge this represents the first study to report the potential of using leaf spectral data for virus disease diagnosis in a perennial crop. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Naidu, Rayapati A. and Perry, Eileen M. and Pierce, Francis J. and Mekuria, Tefera},
doi = {10.1016/j.compag.2008.11.007},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Naidu et al. - 2009 - The potential of spectral reflectance technique for the detection of Grapevine leafroll-associated virus-3 in two.pdf:pdf},
isbn = {0168-1699},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {Closteroviridae,Grapevine leafroll disease,Grapevine leafroll-associated virus,Spectral reflectance,Virus detection,Wine grapes},
number = {1},
pages = {38--45},
pmid = {51},
title = {{The potential of spectral reflectance technique for the detection of Grapevine leafroll-associated virus-3 in two red-berried wine grape cultivars}},
volume = {66},
year = {2009}
}
@article{Saxton2006,
author = {Saxton, K. E. and Rawls, W. J.},
doi = {10.2136/sssaj2005.0117},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saxton, Rawls - 2006 - Soil Water Characteristic Estimates by Texture and Organic Matter for Hydrologic Solutions.pdf:pdf},
issn = {1435-0661},
journal = {Soil Science Society of America Journal},
number = {5},
pages = {1569},
title = {{Soil Water Characteristic Estimates by Texture and Organic Matter for Hydrologic Solutions}},
url = {https://www.soils.org/publications/sssaj/abstracts/70/5/1569},
volume = {70},
year = {2006}
}
@article{Hall1993,
author = {Hall, LA and Vanderbei, RJ},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall, Vanderbei - 1993 - Two-thirds is sharp for affine scaling.pdf:pdf},
journal = {Operations Research Letters},
pages = {0--6},
title = {{Two-thirds is sharp for affine scaling}},
url = {http://www.sciencedirect.com/science/article/pii/016763779390040N},
year = {1993}
}
@phdthesis{Datta2003,
author = {Datta, RS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Datta - 2003 - Algebraic methods in game theory.pdf:pdf},
title = {{Algebraic methods in game theory}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.4019{\&}rep=rep1{\&}type=pdf},
year = {2003}
}
@article{Xu2006,
author = {Xu, Huan and Mannor, Shie},
journal = {Advances in Neural Information Processing Systems},
title = {{The robustness-performance tradeoff in Markov decision processes}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2006{\_}556.pdf},
year = {2006}
}
@article{Brodie2009,
abstract = {We consider the problem of portfolio selection within the classical Markowitz mean-variance framework, reformulated as a constrained least-squares regression problem. We propose to add to the objective function a penalty proportional to the sum of the absolute values of the portfolio weights. This penalty regularizes (stabilizes) the optimization problem, encourages sparse portfolios (i.e., portfolios with only few active positions), and allows accounting for transaction costs. Our approach recovers as special cases the no-short-positions portfolios, but does allow for short positions in limited number. We implement this methodology on two benchmark data sets constructed by Fama and French. Using only a modest amount of training data, we construct portfolios whose out-of-sample performance, as measured by Sharpe ratio, is consistently and significantly better than that of the na{\"{i}}ve evenly weighted portfolio.},
archivePrefix = {arXiv},
arxivId = {0708.0046},
author = {Brodie, Joshua and Daubechies, Ingrid and {De Mol}, Christine and Giannone, Domenico and Loris, Ignace},
doi = {10.1073/pnas.0904287106},
eprint = {0708.0046},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brodie et al. - 2009 - Sparse and stable Markowitz portfolios.pdf:pdf},
isbn = {0027-8424},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {30},
pages = {12267--12272},
pmid = {19617537},
title = {{Sparse and stable Markowitz portfolios.}},
volume = {106},
year = {2009}
}
@article{Asif2009,
annote = {From Duplicate 1 ( Dantzig selector homotopy with dynamic measurements - Asif, M. Salman; Romberg, Justin )
},
author = {Asif, Salman and Asif, M. Salman and Romberg, Justin},
doi = {10.1117/12.813436},
editor = {Bouman, Charles A. and Miller, Eric L. and Pollak, Ilya},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asif, Romberg - 2009 - Dantzig selector homotopy with dynamic measurements.pdf:pdf},
journal = {IS{\&}T/SPIE Computational Imaging VII},
keywords = {compressive sensing},
month = {feb},
number = {2},
pages = {72460E--72460E--11},
title = {{Dantzig selector homotopy with dynamic measurements}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=812484},
year = {2009}
}
@techreport{Parys2017,
archivePrefix = {arXiv},
arxivId = {1704.04118},
author = {Parys, Bart P G Van and Esfahani, Peyman Mohajerin and Kuhn, Daniel},
eprint = {1704.04118},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parys, Esfahani, Kuhn - 2017 - From Data to Decisions Distributionally Robust Optimization is Optimal.pdf:pdf},
keywords = {convex optimization,data-driven optimization,distributionally robust optimization,large deviations theory,observed fisher information,relative entropy},
pages = {1--30},
title = {{From Data to Decisions : Distributionally Robust Optimization is Optimal}},
year = {2017}
}
@article{Pflug2016,
author = {Pflug, Georg Ch and Pichler, Alois},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pflug, Pichler - 2016 - Time-Consistent Decisions and Temporal Decomposition of Coherent Risk Functionals.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {2},
pages = {682--699},
title = {{Time-Consistent Decisions and Temporal Decomposition of Coherent Risk Functionals}},
volume = {41},
year = {2016}
}
@article{Li2013,
author = {Li, Jonathan Y and Kwon, Roy H},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Kwon - 2013 - Portfolio Selection under model uncertainty A penalized moment-based optimization approach.pdf:pdf},
journal = {Journal of Global},
keywords = {distributionally robust optimization,finance,investment analysis,model uncertainty,penalty method,portfolio selection,programming},
pages = {131--164},
title = {{Portfolio Selection under model uncertainty : A penalized moment-based optimization approach}},
volume = {56},
year = {2013}
}
@inproceedings{Ny2006,
abstract = {The multi-armed bandit problem and one of its most interesting extensions, the restless bandits problem, are frequently encountered in various stochastic control problems. We present a linear programming relaxation for the restless bandits problem with discounted rewards, where only one project can be activated at each period but with additional costs penalizing switching between projects. The relaxation can be efficiently computed and provides a bound on the achievable performance. We describe several heuristic policies; in particular, we show that a policy adapted from the primal-dual heuristic of Bertsimas and Nino-Mora (2000) for the classical restless bandits problem is in fact equivalent to a one-step lookahead policy; thus, the linear programming relaxation provides a means to compute an approximation of the cost-to-go. Moreover, the approximate cost-to-go is decomposable by project, and this allows the one-step lookahead policy to take the form of an index policy, which can be computed on-line very efficiently. We present numerical experiments, for which we assess the quality of the heuristics using the performance bound},
author = {Ny, J. Le and Feron, E.},
booktitle = {American Control Conference},
doi = {10.1109/ACC.2006.1656445},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ny, Feron - 2006 - Restless bandits with switching costs linear programming relaxations, performance bounds and limited lookahead polici.pdf:pdf},
isbn = {1-4244-0210-7},
issn = {07431619},
pages = {1587--1592},
title = {{Restless bandits with switching costs: linear programming relaxations, performance bounds and limited lookahead policies}},
year = {2006}
}
@inproceedings{Ziv2005,
author = {Ziv, Omer and Shimkin, Nahum},
booktitle = {ICML'05 Workshop on Rich Representations for Reinforcement Learning},
title = {{Multigrid Algorithms for Temporal Difference Reinforcement Learning}},
year = {2005}
}
@inproceedings{Mercier2007,
annote = {
        {\textless}m:bold{\textgreater}From Duplicate 2 ( {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}
          {\textless}m:italic{\textgreater}Performance Analysis of Online Anticipatory Algorithms for Large Multistage Stochastic Integer Programs{\textless}/m:italic{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater} - Mercier, Luc; Hentenryck, Pascal Van ){\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Mercier, Luc and Hentenryck, Pascal Van},
booktitle = {International Joint Conference on Aritificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mercier, Hentenryck - 2006 - Performance Analysis of Online Anticipatory Algorithms for Large Multistage Stochastic Integer Programs.pdf:pdf},
pages = {1979--1985},
title = {{Performance analysis of online anticipatory algorithms for large multistage stochastic integer programs}},
year = {2007}
}
@book{Bauschke2011,
author = {Bauschke, Heinz H. and Combettes, Patrick L.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bauschke, Combettes - 2011 - Convex analysis and monotone operator theory in Hilbert spaces.pdf:pdf},
isbn = {9781441994660},
title = {{Convex analysis and monotone operator theory in Hilbert spaces}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=cxL3jL7ONjQC{\&}oi=fnd{\&}pg=PR7{\&}dq=Convex+Analysis+and+Monotone+Operator+Theory+in+Hilbert+Spaces{\&}ots=po51CEONqU{\&}sig=S1ea{\_}-nit--1KT2ZYVA{\_}H4T4f3g},
year = {2011}
}
@inproceedings{Shidore2009,
author = {Shidore, Neeraj and Kwon, Jason and Vyas, Anant},
booktitle = {IEEE Vehicle Power and Propulsion Conference},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shidore, Kwon, Vyas - 2009 - Trade-off between PHEV fuel efficiency and estimated battery cycle life with cost analysis.pdf:pdf},
isbn = {9781424426010},
keywords = {battery,battery utilization,cost analysis,cycle life,fuel economy,in figure 1,phev,plug-in hybrid vehicles,saved,the gasoline,the lower would be,this trade-off is depicted},
number = {978},
pages = {669--677},
title = {{Trade-off between PHEV fuel efficiency and estimated battery cycle life with cost analysis}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5289784},
year = {2009}
}
@inproceedings{Jiang2002,
author = {Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
booktitle = {International Joint Conference on Aritificial Intelligence (IJCAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Singh, Tewari - 2016 - On Structural Properties of MDPs that Bound Loss Due to Shallow Planning.pdf:pdf},
keywords = {Machine Learning},
title = {{On Structural Properties of MDPs that Bound Loss Due to Shallow Planning}},
year = {2016}
}
@article{Rosenzweig2013,
author = {Rosenzweig, C. and Jones, J.W. and Hatfield, J.L. and a.C. Ruane and Boote, K.J. and Thorburn, P. and Antle, J.M. and Nelson, G.C. and Porter, C. and Janssen, S. and Asseng, S. and Basso, B. and Ewert, F. and Wallach, D. and Baigorria, G. and Winter, J.M.},
doi = {10.1016/j.agrformet.2012.09.011},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenzweig et al. - 2013 - The Agricultural Model Intercomparison and Improvement Project (AgMIP) Protocols and pilot studies.pdf:pdf},
issn = {01681923},
journal = {Agricultural and Forest Meteorology},
month = {mar},
pages = {166--182},
publisher = {Elsevier B.V.},
title = {{The Agricultural Model Intercomparison and Improvement Project (AgMIP): Protocols and pilot studies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168192312002857},
volume = {170},
year = {2013}
}
@article{Kaufman2013,
annote = {From Duplicate 1 ( 


Robust Modified Policy Iteration


- Kaufman, David L; Schaefer, Andrew J )








From Duplicate 2 ( 


Robust Modified Policy Iteration


- Kaufman, DL David L; Schaefer, AJ Andrew J )




From Duplicate 2 ( 


Robust Modified Policy Iteration


- Kaufman, DL David L; Schaefer, AJ Andrew J )

},
author = {Kaufman, David L and Schaefer, Andrew J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaufman, Schaefer - 2012 - Robust Modified Policy Iteration.pdf:pdf},
journal = {INFORMS Journal on Computing},
keywords = {control,control processes,dynamic,markov processes,optimization,programming},
number = {3},
pages = {396--410},
title = {{Robust modified policy iteration}},
url = {http://joc.journal.informs.org/content/early/2012/06/06/ijoc.1120.0509.abstract},
volume = {25},
year = {2013}
}
@article{Efron2004,
annote = {From Duplicate 2 ( Least angle regression - Efron, B; Hastie, T )
},
author = {Efron, Bradley and Hastie, Trevor},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron, Hastie - 2004 - Least angle regression.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Efron, Hastie - 2004 - Least angle regression(2).pdf:pdf},
journal = {The Annals of statistics},
pages = {1--44},
title = {{Least angle regression}},
url = {http://projecteuclid.org/euclid.aos/1083178935},
year = {2004}
}
@article{Anstreicher2009,
abstract = {We consider relaxations for nonconvex quadratically constrained quadratic$\backslash$nprogramming (QCQP) based on semidefinite programming (SDP) and the$\backslash$nreformulation-linearization technique (RLT). From a theoretical standpoint$\backslash$nwe show that the addition of a semidefiniteness condition removes$\backslash$na substantial portion of the feasible region corresponding to product$\backslash$nterms in the RLT relaxation. On test problems we show that the use$\backslash$nof SDP and RLT constraints together can produce bounds that are substantially$\backslash$nbetter than either technique used alone. For highly symmetric problems$\backslash$nwe also consider the effect of symmetry-breaking based on tightened$\backslash$nbounds on variables and/or order constraints.},
author = {Anstreicher, Kurt M.},
doi = {10.1007/s10898-008-9372-0},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anstreicher - 2009 - Semidefinite programming versus the reformulation-linearization technique for nonconvex quadratically constrained q.pdf:pdf},
issn = {09255001},
journal = {Journal of Global Optimization},
keywords = {Quadratically constrained quadratic programming,Reformulation-linearization technique,Semidefinite programming},
number = {2-3},
pages = {471--484},
title = {{Semidefinite programming versus the reformulation-linearization technique for nonconvex quadratically constrained quadratic programming}},
volume = {43},
year = {2009}
}
@article{Johns2010,
abstract = {Recent work in reinforcement learning has emphasized the power of L1 regularization to perform feature selection and prevent overfitting. We propose formulating the L1 regularized linear fixed point problem as a linear complementarity problem (LCP). This formulation offers several advantages over the LARS-inspired formulation, LARS-TD. The LCP formulation allows the use of efficient off-the- shelf solvers, leads to a new uniqueness result, and can be initialized with starting points from similar problems (warm starts). We demonstrate that warm starts, as well as the efficiency of LCP solvers, can speed up policy iteration. Moreover, warm starts permit a form of modified policy iteration that can be used to approximate a ``greedy'' homotopy path, a generalization of the LARS-TD homotopy path that combines policy evaluation and optimization.},
author = {Johns, Jeff and Painter-Wakefield, Christopher and Parr, Ronald},
journal = {Advances in Neural Information Processing Systems (NIPS) 23},
keywords = {L1,basis functions,linear complementarity,model learning,regularization},
pages = {1009--1017},
title = {{Linear Complementarity for Regularized Policy Evaluation and Improvement}},
year = {2010}
}
@article{Ferris1989b,
author = {Ferris, M. C. and Philpott, a. B.},
doi = {10.1007/BF01582293},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferris, Philpott - 1989 - An interior point algorithm for semi-infinite linear programming.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {chebyshev,discretizations,karmarkar,s method,semi-infinite linear programming},
month = {jan},
number = {1-3},
pages = {257--276},
title = {{An interior point algorithm for semi-infinite linear programming}},
url = {http://link.springer.com/10.1007/BF01582293},
volume = {43},
year = {1989}
}
@article{Paish2002,
author = {Paish, Oliver},
doi = {10.1016/S1364-0321(02)00006-0},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paish - 2002 - Small hydro power technology and current status.pdf:pdf},
issn = {13640321},
journal = {Renewable and Sustainable Energy Reviews},
keywords = {hydropower,micro-hydro,mini-hydro,small hydro,water power},
month = {dec},
number = {6},
pages = {537--556},
title = {{Small hydro power: technology and current status}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364032102000060},
volume = {6},
year = {2002}
}
@inproceedings{Cassandra1997,
author = {Cassandra, Anthony R and Littman, Michael L and Zhang, Nevin},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
title = {{Pruning: A simple, fast, exact algorithm for partially observable Markov decision processes}},
year = {1997}
}
@article{Prasad2006,
annote = {QUuite rudimentary},
author = {Prasad, Anup K. and Chai, Lim and Singh, Ramesh P. and Kafatos, Menas},
doi = {10.1016/j.jag.2005.06.002},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prasad et al. - 2006 - Crop yield estimation model for Iowa using remote sensing and surface parameters.pdf:pdf},
issn = {03032434},
journal = {International Journal of Applied Earth Observation and Geoinformation},
keywords = {corn,crop yield prediction model,iowa,ndvi,soybean},
month = {jan},
number = {1},
pages = {26--33},
title = {{Crop yield estimation model for Iowa using remote sensing and surface parameters}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0303243405000553},
volume = {8},
year = {2006}
}
@article{Yoshioka2010,
author = {Yoshioka, Hiroki and Miura, Tomoaki and Dematt{\^{e}}, Jos{\'{e}} a. M. and Batchily, Karim and Huete, Alfredo R.},
doi = {10.3390/rs2020545},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yoshioka et al. - 2010 - Soil Line Influences on Two-Band Vegentation Indices and Vegetation Isolines A Numetical Study.pdf:pdf},
issn = {2072-4292},
journal = {Remote Sensing},
month = {feb},
number = {2},
pages = {545--561},
title = {{Soil Line Influences on Two-Band Vegentation Indices and Vegetation Isolines: A Numetical Study}},
url = {http://www.mdpi.com/2072-4292/2/2/545/},
volume = {2},
year = {2010}
}
@inproceedings{Oroojeni2015,
author = {Oroojeni, Mahsa and Javad, Mohammad and Agboola, Stephen and Jethwani, Kamal and Zeid, Ibrahim and Kamarthi, Sagar},
booktitle = {International Mechanical Engineering Congress and Exposition},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oroojeni et al. - 2015 - Reinforcement learning algorithms for blood glucose control in diabetic patients.pdf:pdf},
keywords = {IMECE2015-53420,reinforcement learning,type i diabetes},
title = {{Reinforcement learning algorithms for blood glucose control in diabetic patients}},
year = {2015}
}
@book{Vanderbei1998,
author = {Vanderbei, R J},
booktitle = {Journal of the Operational Research Society},
doi = {10.1038/sj.jors.2600987},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbei - 1998 - Linear Programming Foundations and Extensions.pdf:pdf},
isbn = {0000000000},
issn = {01605682},
month = {mar},
number = {1},
pages = {93--98},
title = {{Linear Programming: Foundations and Extensions}},
url = {http://www.nature.com/doifinder/10.1038/sj.jors.2600987},
volume = {49},
year = {1998}
}
@article{Holte2005a,
author = {Holte, Robert C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holte - 2005 - Where Do Heuristics Come From ( Using Abstraction to Speed Up Search ).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holte - 2005 - Where Do Heuristics Come From Part 2.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holte - 2005 - Where Do Heuristics Come From Part 3.pdf:pdf},
pages = {1--52},
title = {{Where Do Heuristics Come From ? ( Using Abstraction to Speed Up Search )}},
year = {2005}
}
@article{Bilskie2001,
author = {Bilskie, J and Scientific, C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bilskie, Scientific - 2001 - Soil water status content and potential.pdf:pdf},
journal = {Campbell Scientific, Inc. App. Note: 2S-1 http:/ {\ldots}},
number = {435},
pages = {84321},
title = {{Soil water status: content and potential}},
url = {ftp://ftp.cmdl.noaa.gov/user/albee/{\_}Arctic  VALUABLE instrumention documentation/Campbell/Campbell CD/Documents/Application Notes/soilh20c.pdf},
volume = {1784},
year = {2001}
}
@article{Ebaeke2004,
author = {Ebaeke, Philippe D},
doi = {10.1051/agro},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ebaeke - 2004 - Original article Scenario analysis for cereal management in water-limited conditions by the means of a crop simulation m.pdf:pdf},
pages = {315--326},
title = {{Original article Scenario analysis for cereal management in water-limited conditions by the means of a crop simulation model ( STICS )}},
volume = {24},
year = {2004}
}
@article{Moura2011,
author = {Moura, Scott Jason and Fathy, Hosam K. and Callaway, Duncan S.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moura, Fathy, Callaway - 2011 - A stochastic optimal control approach for power management in plug-in hybrid electric vehicles.pdf:pdf},
journal = {IEEE Transactions on Control Systems Technology},
pages = {1--11},
title = {{A stochastic optimal control approach for power management in plug-in hybrid electric vehicles}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5439900},
year = {2011}
}
@article{Nearing2012,
author = {Nearing, G. S. and Crow, W. T. and Thorp, K. R. and Moran, M. S. and Reichle, R. H. and Gupta, H. V.},
doi = {10.1029/2011WR011420},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nearing et al. - 2012 - Assimilating remote sensing observations of leaf area index and soil moisture for wheat yield estimates An obser.pdf:pdf},
issn = {00431397},
journal = {Water Resources Research},
month = {may},
number = {5},
pages = {n/a--n/a},
title = {{Assimilating remote sensing observations of leaf area index and soil moisture for wheat yield estimates: An observing system simulation experiment}},
url = {http://doi.wiley.com/10.1029/2011WR011420},
volume = {48},
year = {2012}
}
@article{Vidal,
author = {Vidal, R. and Chiuso, A. and Soatto, S.},
doi = {10.1109/CDC.2002.1184923},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vidal, Chiuso, Soatto - Unknown - Observability and identifiability of jump linear systems.pdf:pdf},
isbn = {0-7803-7516-5},
journal = {IEEE Conference on Decision and Control, 2002.},
pages = {3614--3619},
publisher = {Ieee},
title = {{Observability and identifiability of jump linear systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1184923},
volume = {4}
}
@article{Reddy2012,
author = {Reddy, Sravana and Kevin, Knight and Knight, Kevin and Rey, Marina},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reddy et al. - 2012 - Decoding Running Key Ciphers.pdf:pdf},
isbn = {9781937284251},
journal = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics},
number = {July},
pages = {80--84},
title = {{Decoding Running Key Ciphers}},
url = {http://anthology.aclweb.org//P/P12/P12-2016.pdf},
year = {2012}
}
@inproceedings{Abbasi-yadkori2016,
author = {Abbasi-yadkori, Yasin and Bartlett, Peter L and Wright, Stephen J},
booktitle = {Artificial Intelligence and Statistics (AISTATS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbasi-yadkori, Bartlett, Wright - 2016 - A Fast and Reliable Policy Improvement Algorithm.pdf:pdf},
title = {{A Fast and Reliable Policy Improvement Algorithm}},
volume = {51},
year = {2016}
}
@article{Singh2010,
annote = {Uses HMM to model changing user preferences over time},
author = {Singh, Param Vir},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh - 2010 - Seeking Variety A Dynamic Model of Employee Blog Reading Behavior.pdf:pdf},
title = {{Seeking Variety : A Dynamic Model of Employee Blog Reading Behavior}},
year = {2010}
}
@article{Vellidis2008,
author = {Vellidis, G. and Tucker, M. and Perry, C. and Kvien, C. and Bednarz, C.},
doi = {10.1016/j.compag.2007.05.009},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vellidis et al. - 2008 - A real-time wireless smart sensor array for scheduling irrigation.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {irrigation scheduling},
month = {apr},
number = {1},
pages = {44--50},
title = {{A real-time wireless smart sensor array for scheduling irrigation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169907001706},
volume = {61},
year = {2008}
}
@article{Buyuktahtakin2014,
abstract = {Buffelgrass (Pennisetum ciliare) is a fire-prone, African bunchgrass spreading rapidly across the southern Arizona desert. This article introduces a model that simulates buffelgrass spread over a gridded landscape over time to evaluate strategies to control this invasive species. Weed-carrying capacity, treatment costs, and damages vary across grid cells. Damage from buffelgrass depends on its density and proximity to valued resources. Damages include negative effects on native species (through spatial competition) and increased fire risk to land and buildings. We evaluate recommended “rule of thumb” control strategies in terms of their ability to prevent weed establishment in newly infested areas and to reduce damage indices over time. Two such strategies—potential damage weighting and consecutive year treatment—used in combination, provided significant improvements in long-term control over no control and over a strategy of minimizing current damages in each year. Results suggest specific recommendations for deploying rapid-response teams to prevent establishment in new areas. The long-run population size and spatial distribution of buffelgrass is sensitive to the priority given to protecting different resources. Land managers with different priorities may pursue quite different control strategies, posing a challenge for coordinating control across jurisdictions.},
author = {Buyuktahtakin, I. Esra and Feng, Zhuo and Olsson, Aaryn D. and Frisvold, George and Szidarovszky, Ferenc},
doi = {10.1614/IPSM-D-13-00057.1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buyuktahtakin et al. - 2014 - Invasive Species Control Optimization as a Dynamic Spatial Process An Application to Buffelgrass ( Pennise.pdf:pdf},
issn = {1939-7291},
journal = {Invasive Plant Science and Management},
keywords = {biological invasion,buffelgrass,dynamic spatial processes,environmental studies,integer,invasive species,invasive weeds as a,land management,optimal control,programming,smith et al,spatial-dynamic problem,spread and management of,this study examines the},
number = {1},
pages = {132--146},
title = {{Invasive Species Control Optimization as a Dynamic Spatial Process: An Application to Buffelgrass ( Pennisetum ciliare ) in Arizona}},
url = {http://www.bioone.org/doi/abs/10.1614/IPSM-D-13-00057.1},
volume = {7},
year = {2014}
}
@article{Nishimura2009,
author = {Nishimura, Kazuo and Reffett, Kevin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nishimura, Reffett - 2009 - Continuous State Dynamic Programming Via Nonexpansive Approximation.pdf:pdf},
journal = {Computational Economics},
keywords = {and phrases,nonexpansive,numerical dynamic programming},
pages = {141--160},
title = {{Continuous State Dynamic Programming Via Nonexpansive Approximation}},
volume = {31},
year = {2009}
}
@article{Meuleau2009,
author = {Meuleau, Nicolas and Benazera, Emmanuel and Brafman, Ronen I and a. Hansen, Eric and Mausam},
journal = {Journal of Artificial Intelligence Research},
pages = {27--59},
title = {{A Heuristic Search Approach to Planning with Continuous Resources in Stochastic Domains}},
volume = {34},
year = {2009}
}
@misc{Oreopoulus,
author = {Oreopoulus, Lazaros and Wilson, Mike},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oreopoulus, Wilson - Unknown - An overview of cloud masking and other research for Landsat and LDCM.pdf:pdf},
title = {{An overview of cloud masking and other research for Landsat and LDCM}}
}
@phdthesis{Petrik2010th,
author = {Petrik, Marek},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2010 - Optimization-based Approximate Dynamic Programming.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Presented, Petrik, Philosophy - 2010 - OPTIMIZATION-BASED APPROXIMATE DYNAMIC PROGRAMMING.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2010 - Optimization-based approximate dynamic programming.pdf:pdf},
number = {September},
title = {{Optimization-based Approximate Dynamic Programming}},
url = {http://scholarworks.umass.edu/open{\_}access{\_}dissertations/308/},
year = {2010}
}
@misc{Pruzhansky1998,
author = {Pruzhansky, Vitaly},
institution = {Vriji Universiteit Amsterdam},
title = {{On finding curb sets in extensive games}},
year = {1998}
}
@inproceedings{Boutilier1996,
address = {Portland, Oregon, USA},
author = {Boutilier, Craig and Poole, David},
booktitle = {National Conference on Artificial Intelligence},
pages = {1168--1175},
title = {{Computing Optimal Policies for Partially Observable Decision Processes Using Compact Representations}},
url = {citeseer.ist.psu.edu/boutilier96computing.html},
year = {1996}
}
@article{Hanasusanto2013,
author = {Hanasusanto, GA and Kuhn, Daniel},
journal = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hanasusanto, Kuhn - 2013 - Robust Data-Driven Dynamic Programming.pdf:pdf},
title = {{Robust Data-Driven Dynamic Programming}},
url = {http://papers.nips.cc/paper/5123-robust-data-driven-dynamic-programming},
year = {2013}
}
@inproceedings{Bonet2003b,
author = {Bonet, Blai and Geffner, Hector},
booktitle = {International Conference on Autonomous Planning (ICAPS)},
title = {{Labeled RTDP: Improving the convergence of real-time dynamic programming}},
year = {2003}
}
@phdthesis{Nadarajah2014,
author = {Nadarajah, Selvaprabu},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nadarajah - 2014 - Approximate Dynamic Programming for Commodity and Energy Merchant Operations.pdf:pdf},
school = {Carnegie Mellon},
title = {{Approximate Dynamic Programming for Commodity and Energy Merchant Operations}},
year = {2014}
}
@article{Munos2007,
author = {Munos, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos - 2007 - Performance Bounds in Lp-norm for Approximate Value Iteration.pdf:pdf},
journal = {SIAM journal on control and optimization},
number = {2},
pages = {541--561},
title = {{Performance Bounds in Lp-norm for Approximate Value Iteration}},
url = {http://epubs.siam.org/doi/abs/10.1137/040614384},
volume = {46},
year = {2007}
}
@article{Tibshirani2011,
author = {Tibshirani, Ryan J. and Taylor, Jonathan},
doi = {10.1214/11-AOS878},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tibshirani, Taylor - 2011 - The solution path of the generalized lasso.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {degrees of freedom,lagrange dual,lars,lasso,path algorithm},
month = {jun},
number = {3},
pages = {1335--1371},
title = {{The solution path of the generalized lasso}},
url = {http://projecteuclid.org/euclid.aos/1304514656},
volume = {39},
year = {2011}
}
@article{Roy2005,
author = {Roy, Nicholas and Gordon, Geoffrey and Thrun, Sebastian},
journal = {Journal of Artificial Intelligence Research},
pages = {1--40},
title = {{Finding approximate POMDP solutions through belief compression}},
volume = {23},
year = {2005}
}
@misc{Hydro-Quebec,
author = {Hydro-Quebec},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hydro-Quebec - Unknown - A new simulation approach for the assessment of wind integration impact on system operations.ppt:ppt},
title = {{A new simulation approach for the assessment of wind integration impact on system operations}}
}
@book{Kery2012,
author = {Kery, Marc and Schaub, Michael},
doi = {10.1016/B978-0-12-387020-9.00024-9},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kery, Schaub - 2012 - Bayesian Population Analysis Using WinBUGS.pdf:pdf},
isbn = {9780123870209},
title = {{Bayesian Population Analysis Using WinBUGS}},
year = {2012}
}
@article{VanHasselt2015,
abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether this harms performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
archivePrefix = {arXiv},
arxivId = {1509.06461},
author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
eprint = {1509.06461},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Hasselt, Guez, Silver - 2015 - Deep Reinforcement Learning with Double Q-learning.pdf:pdf},
journal = {arXiv:1509.06461 [cs]},
title = {{Deep Reinforcement Learning with Double Q-learning}},
url = {http://arxiv.org/abs/1509.06461{\%}5Cnhttp://www.arxiv.org/pdf/1509.06461.pdf},
year = {2015}
}
@article{Vandenberghe2011d,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 06. Quasi-Newton methods.pdf:pdf},
journal = {LECTURE NOTES},
pages = {1--15},
title = {{06. Quasi-Newton methods}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@article{Scott2003,
author = {Scott, C H and Jefferson, T R},
journal = {Journal of optimization theory and applications},
pages = {575--583},
title = {{On duality for a class of quasiconcave multiplicative programs}},
volume = {117},
year = {2003}
}
@article{Jornsten1999,
annote = {From Duplicate 2 ( Convergence aspects of adaptive clustering in variable aggregation - Kurt, J; Leisten, Rainer; Stor, Sverre )
},
author = {Kurt, J and Leisten, Rainer and Stor, Sverre and Jornsten, Kurt and Story, Rainer Leistenand Sverre},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kurt, Leisten, Stor - 1999 - Convergence aspects of adaptive clustering in variable aggregation.pdf:pdf},
journal = {Computers and Operations Research},
keywords = {convergence,iterative aggregation,linear programming,variable aggregation},
pages = {955--966},
title = {{Convergence aspects of adaptive clustering in variable aggregation}},
volume = {26},
year = {1999}
}
@article{Doucet2001,
abstract = {Many real-world data analysis tasks involve estimating unknown quantities from some given observations. In most of these applications, prior knowledge about the phenomenon being modelled is available. This knowledge allows us to formulate Bayesian models, that is prior distributions for the unknown quantities and likelihood functions relating these quantities to the observations. Within this setting, all inference on the unknown quantities is based on the posterior distribution obtained from Bayes' theorem. Often, the observations arrive sequentially in time and one is interested in performing inference on-line. It is therefore necessary to update the posterior distribution as data become available. Examples include tracking an aircraft using radar measurements, estimating a digital communications signal using noisy measurements, or estimating the volatility of financial instruments using stock market data. Computational simplicity in the form of not having to store all the data might also be an additional motivating factor for sequential methods.},
author = {Doucet, Arnaud and de Freitas, Nando and Gordon, Neil},
doi = {10.1007/978-1-4757-3437-9_1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doucet, de Freitas, Gordon - 2001 - An Introduction to Sequential Monte Carlo Methods.pdf:pdf},
isbn = {978-1-4419-2887-0},
issn = {0040-1706},
journal = {Sequential; Monte Carlo Methods in Practice},
pages = {3--14},
pmid = {12171084},
title = {{An Introduction to Sequential Monte Carlo Methods}},
url = {http://link.springer.com/chapter/10.1007/978-1-4757-3437-9{\_}1},
year = {2001}
}
@misc{Guerra2009,
abstract = {The integration of usable and flexible analysis support in modelling environments is a key success factor in Model-Driven Development. In this paradigm, models are the core asset from which code is automatically generated, and thus ensuring model correctness is a fundamental quality control activity. For this purpose, a common approach is to transform the system models into formal semantic domains for verification. However, if the analysis results are not shown in a proper way to the end-user (e.g. in terms of the original language) they may become useless. In this paper we present a novel DSVL called BaVeL that facilitates the flexible annotation of verification results obtained in semantic domains to different formats, including the context of the original language. BaVeL is used in combination with a consistency framework, providing support for all steps in a verification process: acquisition of additional input data, transformation of the system models into semantic domains, verification, and flexible annotation of analysis results. The approach has been validated analytically by the cognitive dimensions framework, and empirically by its implementation and application to several DSVLs. Here we present a case study of a notation in the area of Digital Libraries, where the analysis is performed by transformations into Petri nets and a process algebra. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0402594v3},
author = {Guerra, Esther and de Lara, Juan and Malizia, Alessio and D{\'{i}}az, Paloma},
booktitle = {Information and Software Technology},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {0402594v3},
isbn = {0950-5849},
issn = {09505849},
keywords = {Back-annotation,Consistency,Domain-specific visual languages,Formal methods,Model transformation,Modelling environments},
number = {4},
pages = {769--784},
primaryClass = {arXiv:cond-mat},
title = {{Supporting user-oriented analysis for multi-view domain-specific visual languages}},
volume = {51},
year = {2009}
}
@article{Sterck2008,
author = {Sterck, H. De and Manteuffel, Thomas and McCormick, Stephen and Nguyen, Quoc and Ruge, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sterck et al. - 2008 - Multilevel adaptive aggregation for Markov chains, with application to web ranking.pdf:pdf},
journal = {SIAM Journal on {\ldots}},
keywords = {adaptive aggregation,markov chain,multilevel method,stationary probability},
pages = {1--23},
title = {{Multilevel adaptive aggregation for Markov chains, with application to web ranking}},
url = {http://epubs.siam.org/doi/abs/10.1137/070685142},
year = {2008}
}
@article{Taleghan2015,
abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taleghan et al. - 2015 - PAC Optimal MDP Planning with Application to Invasive Species Management.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Good- Turing estimate,MDP planning,Markov decision processes,invasive species management,reinforcement learning},
number = {1},
pages = {3877--3903},
title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
url = {http://jmlr.org/papers/v16/taleghan15a.html},
volume = {16},
year = {2015}
}
@article{Bermudes2002,
author = {Berm{\'{u}}dez, JMV},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berm{\'{u}}dez - 2002 - GDDP generalized dual dynamic programming theory.pdf:pdf},
journal = {Annals of Operations Research},
keywords = {benders decomposition,control theory,dual dynamic programming,dynamic programming},
pages = {21--31},
title = {{GDDP: generalized dual dynamic programming theory}},
url = {http://link.springer.com/article/10.1023/A:1021557003554},
year = {2002}
}
@article{Rockafellar1976a,
abstract = {For the problem of minimizing a lower semicontinuous proper convex function f on a Hilbert space, the proximal point algorithm in exact form generates a sequence {\$}\backslash{\{} z{\^{}}k \backslash{\}} {\$} by taking {\$}z{\^{}}{\{}k + 1{\}} {\$} to be the minimizes of {\$}f(z) + ({\{}1 / {\{}2c{\_}k {\}}{\}})\backslash| {\{}z - z{\^{}}k {\}} \backslash|{\^{}}2 {\$}, where {\$}c{\_}k {\textgreater} 0{\$}. This algorithm is of interest for several reasons, but especially because of its role in certain computational methods based on duality, such as the Hestenes-Powell method of multipliers in nonlinear programming. It is investigated here in a more general form where the requirement for exact minimization at each iteration is weakened, and the subdifferential {\$}\backslashpartial f{\$} is replaced by an arbitrary maximal monotone operator T. Convergence is established under several criteria amenable to implementation. The rate of convergence is shown to be “typically” linear with an arbitrarily good modulus if {\$}c{\_}k {\$} stays large enough, in fact superlinear if {\$}c{\_}k \backslashto \backslashinfty {\$}. The case of {\$}T = \backslashpartial f{\$} is treated in extra detail. Applicati...},
author = {Rockafellar, R. Tyrrell},
doi = {10.1137/0314056},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar - 1976 - Monotone Operators and the Proximal Point Algorithm.pdf:pdf},
isbn = {0233193960},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
number = {5},
pages = {877--898},
title = {{Monotone Operators and the Proximal Point Algorithm}},
url = {http://epubs.siam.org/doi/abs/10.1137/0314056},
volume = {14},
year = {1976}
}
@inproceedings{Malioutov2013,
abstract = {We propose an interpretable rule-based classification system based on ideas from Boolean compressed sensing. We represent the problem of learning individual conjunctive clauses or individual disjunctive clauses as a Boolean group testing problem, and apply a novel linear programming relaxation to find solutions. We derive results for exact rule recovery which parallel the conditions for exact recovery of sparse signals in the compressed sensing literature: although the general rule recovery problem is NP-hard, under some conditions on the Boolean 'sensing' matrix, the rule can be recovered exactly. This is an exciting development in rule learning where most prior work focused on heuristic solutions. Furthermore we construct rule sets from these learned clauses using set covering and boosting. We show competitive classification accuracy using the proposed approach. Copyright 2013 by the author(s).},
author = {Malioutov, D M and Varshney, K R},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malioutov, Varshney - 2013 - Exact rule learning via Boolean compressed sensing.pdf:pdf},
keywords = {Classification accuracy,Exact recoveries,Group,Learning systems,Recovery,Signal reconstruction},
pages = {1802--1810},
title = {{Exact rule learning via Boolean compressed sensing}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84897531301{\&}partnerID=40{\&}md5=896c81fac3b62d2c5b6e9f3cf3a5a96d},
year = {2013}
}
@article{Bertsekas1991,
author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas, Tsitsiklis - 1991 - An analysis of stochastic shortest path problems.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {3},
pages = {580--595},
title = {{An analysis of stochastic shortest path problems}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:An+Analysis+of+Stochastic+Shortest+Path+Problems{\#}0},
volume = {16},
year = {1991}
}
@article{Xu2009,
abstract = {We consider decision making in a Markovian setup where the reward parameters are not known in advance. Our performance criterion is the gap between the performance of the best strategy that is chosen after the true parameter realization is revealed and the performance of the strategy that is chosen before the parameter realization is revealed. We call this gap the parametric regret. We consider two related problems: minimax regret and mean-variance tradeoff of the regret. The minimax regret strategy minimizes the worst-case regret under the most adversarial possible realization. We show that the problem of computing a minimax regret strategy is NP-hard and propose algorithms to efficiently finding it under favorable conditions. The mean-variance tradeoff formulation requires a probabilistic model of the uncertain parameters and looks for a strategy that minimizes a convex combination of the mean and the variance of the regret. We prove that computing such a strategy can be done numerically in an efficient way.},
author = {Xu, Huan and Mannor, Shie},
doi = {10.1109/CDC.2009.5400796},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Mannor - 2009 - Parametric regret in uncertain Markov decision processes.pdf:pdf},
isbn = {9781424438716},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
keywords = {Markov processes,Stochastic optimal control,Uncertain systems},
pages = {3606--3613},
title = {{Parametric regret in uncertain Markov decision processes}},
year = {2009}
}
@article{Tamar2016a,
abstract = {We introduce the value iteration network: a fully differentiable neural network with a `planning module' embedded within. Value iteration networks are suitable for making predictions about outcomes that involve planning-based reasoning, such as predicting a desired trajectory from an observation of a map. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate our value iteration networks on the task of predicting optimal obstacle-avoiding trajectories from an image of a landscape, both on synthetic data, and on challenging raw images of the Mars terrain.},
archivePrefix = {arXiv},
arxivId = {1602.02867},
author = {Tamar, Aviv and Levine, Sergey and Abbeel, Pieter},
eprint = {1602.02867},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar, Levine, Abbeel - 2016 - Value Iteration Networks.pdf:pdf},
journal = {arXiv},
pages = {1--14},
title = {{Value Iteration Networks}},
url = {http://arxiv.org/abs/1602.02867},
year = {2016}
}
@article{Mateo2005,
author = {Mateo, Alicia and Mu{\~{n}}oz, Antonio and Garc{\'{i}}a-Gonz{\'{a}}lez, Javier},
doi = {10.1109/TPWRS.2004.840412},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mateo, Mu{\~{n}}oz, Garc{\'{i}}a-Gonz{\'{a}}lez - 2005 - Modeling and Forecasting Electricity Prices with InputOutput Hidden Markov Models.pdf:pdf},
issn = {0885-8950},
journal = {IEEE Transactions on Power Systems},
number = {1},
pages = {13--24},
title = {{Modeling and Forecasting Electricity Prices with Input/Output Hidden Markov Models}},
volume = {20},
year = {2005}
}
@article{Kaufmann2012a,
abstract = {the frequentist cumulated regret as a mea- sure of performance. We give a general for- mulation for a class of Bayesian index policies that rely on quantiles of the posterior distri- bution. For binary bandits, we prove that the corresponding algorithm, termed Bayes- UCB, satisfies finite-time regret bounds that imply its asymptotic optimality. More gen- erally, Bayes-UCB appears as an unifying framework for several variants of the UCB algorithm addressing different bandit prob- lems (parametricmulti-armed bandits, Gaus- sian bandits with unknown mean and vari- ance, linear bandits). But the generality of the Bayesian approach makes it possible to address more challenging models. In par- ticular, we show how to handle linear ban- dits with sparsity constraints by resorting to Gibbs sampling.},
author = {Kaufmann, Emilie and Capp{\'{e}}, Olivier and Garivier, Aur{\'{e}}lien},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaufmann, Capp{\'{e}}, Garivier - 2012 - On Bayesian upper confidence bounds for bandit problems.pdf:pdf},
issn = {15337928},
journal = {International Conference on Artificial Intelligence and Statistics},
pages = {592--600},
title = {{On Bayesian upper confidence bounds for bandit problems}},
year = {2012}
}
@article{Coleman2009,
author = {Zhu, Lei and Coleman, Thomas F. and Li, Yuying},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Coleman, Li - 2008 - Min-Max Robust and CVaR Robust Mean-Variance Portfolios{\pounds}.pdf:pdf},
number = {3},
title = {{Min-Max Robust and CVaR Robust Mean-Variance Portfolios{\pounds}}},
url = {http://wise.xmu.edu.cn/uncc-wise/files/ProgramPapers/LI{\_}Yuying.pdf},
volume = {11},
year = {2008}
}
@book{Hordijk1974,
annote = {From Duplicate 1 ( Dynamic programming and Markov potential theory - Hordijk, A )
},
author = {Hordijk, A},
publisher = {Amsterdam : Mathematisch Centrum},
title = {{Dynamic programming and {\{}M{\}}arkov potential theory}},
year = {1974}
}
@article{Golub1999,
author = {Golub, Gene H. and Hansen, Per Christian and O'Leary, Dianne P.},
doi = {10.1137/S0895479897326432},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golub, Hansen, O'Leary - 1999 - Tikhonov Regularization and Total Least Squares.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {1,65f20,65f30,a is m n,a x b where,ams,approximate solution to a,bidiagonalization,discrete ill-posed problems,in this paper we,introduction,linear system of equations,methods for producing an,mos,regularization,study a class of,subject classi cations,total least squares,with},
month = {jan},
number = {1},
pages = {185--194},
title = {{Tikhonov Regularization and Total Least Squares}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0895479897326432},
volume = {21},
year = {1999}
}
@article{Tovey1984,
abstract = {￼￼3-SAT is NP-complete when restricted to instances where each variable appears in at most four clauses. When no variable appears in more than three clauses, 3-SAT is trivial and SAT is NP- complete. When no variable appears in more than two clauses, SAT may be solved in linear time.},
author = {Tovey, Craig a.},
doi = {10.1016/0166-218X(84)90081-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tovey - 1984 - A simplified NP-complete satisfiability problem.pdf:pdf},
issn = {0166218X},
journal = {Discrete Applied Mathematics},
number = {1},
pages = {85--89},
title = {{A simplified NP-complete satisfiability problem}},
volume = {8},
year = {1984}
}
@inproceedings{Zhang2009,
author = {Zhang, Zhifu and Sturtevant, Nathan R and Holte, Robert and Schaeffer, Jonathan and Felner, Ariel},
booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
title = {{A* Search with Inconsistent Heuristics}},
year = {2009}
}
@book{Zipkin200,
author = {Zipkin, Paul H.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zipkin - 2000 - Foundations of Inventory Management.pdf:pdf},
isbn = {0256113793},
title = {{Foundations of Inventory Management}},
year = {2000}
}
@incollection{Pearl2004,
author = {Pearl, J},
booktitle = {Computer Science Handbook, Second Edition, Chapter 70},
chapter = {70},
doi = {10.1007/978-94-017-1735-9_12},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearl - 2004 - Graphical models for probabilistic and causal reasoning.pdf:pdf},
isbn = {158488360X},
pages = {1--18},
title = {{Graphical models for probabilistic and causal reasoning}},
url = {http://link.springer.com/chapter/10.1007/978-94-017-1735-9{\_}12},
year = {2004}
}
@article{Rust1994,
author = {Rust, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rust - 1996 - Numerical dynamic programming in economics.pdf:pdf},
journal = {Handbook of computational economics},
number = {November},
title = {{Numerical dynamic programming in economics}},
url = {http://www.sciencedirect.com/science/article/pii/S1574002196010167},
year = {1996}
}
@inproceedings{Bernstein2005,
author = {Bernstein, Daniel S and Hansen, Eric A and Zilberstein, Shlomo},
booktitle = {International Joint Conference on Artificial Intelligence},
title = {{Bounded policy iteration for decentralized POMDPs}},
year = {2005}
}
@inproceedings{Smart2004,
author = {Smart, William},
booktitle = {International Symposium on {\{}AI{\}} and Mathematics},
title = {{Explicit manifold representations for value-functions in reinforcement learning}},
year = {2004}
}
@inproceedings{Tamar2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1502.03919v2},
author = {Tamar, Aviv and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
booktitle = {Neural Information Processing Systems (NIPS)},
eprint = {arXiv:1502.03919v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar et al. - 2015 - Policy Gradient for Coherent Risk Measures.pdf:pdf},
title = {{Policy Gradient for Coherent Risk Measures}},
year = {2015}
}
@article{Szita2006,
abstract = {The cross-entropy method is an efficient and general optimization algorithm. However, its applicability in reinforcement learning (RL) seems to be limited because it often converges to suboptimal policies. We apply noise for preventing early convergence of the cross-entropy method, using Tetris, a computer game, for demonstration. The resulting policy outperforms previous RL algorithms by almost two orders of magnitude.},
annote = {From Duplicate 2 ( Learning Tetris using the noisy cross-entropy method. - Szita, Istv{\'{a}}n; L{\"{o}}rincz, Andr{\'{a}}s )
},
author = {Szita, Istv{\'{a}}n Istvan and Lorincz, Andras and L{\"{o}}rincz, Andr{\'{a}}s},
doi = {10.1162/neco.2006.18.12.2936},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szita, L{\"{o}}rincz - 2006 - Learning Tetris using the noisy cross-entropy method.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {Algorithms,Computer Simulation,Entropy,Humans,Learning,Models,Reinforcement (Psychology),Statistical},
month = {dec},
number = {12},
pages = {2936--2941},
pmid = {17052153},
title = {{Learning Tetris Using the Noisy Cross-Entropy Method}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17052153},
volume = {18},
year = {2006}
}
@inproceedings{Haslum2005,
author = {Haslum, Patrik and Bonet, Blai and Geffner, Hector},
booktitle = {National Conference on AI},
title = {{New Admissible Heuristics for Domain-Independent Planning}},
year = {2005}
}
@incollection{Beck2010,
annote = {Proves ISTA converges strongly; but not for FISTA},
author = {Beck, Amir and Teboulle, Marc},
booktitle = {Convex Optimization in Signal Processing and Communications},
chapter = {1},
edition = {1},
editor = {Palomar, D and Eldar, Yonina C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beck, Teboulle - 2010 - Gradient-Based Algorithms with Applications to Signal Recovery Problems.pdf:pdf},
pages = {3--51},
publisher = {Cambridge University Press},
title = {{Gradient-Based Algorithms with Applications to Signal Recovery Problems}},
url = {http://www.math.tau.ac.il/{~}teboulle/papers/gradient{\_}chapter.pdf},
year = {2010}
}
@inproceedings{Kearns1998a,
annote = {From Duplicate 2 (Near-optimal reinforcement learning in polynomial time - Kearns, Michael; Singh, Satinder)

From Duplicate 1 ( 


Near-optimal reinforcement learning in polynomial time


- Kearns, Michael; Singh, Satinder )

},
author = {Kearns, Michael and Singh, Satinder},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kearns, Singh - 1998 - Near-optimal reinforcement learning in polynomial time.pdf:pdf},
pages = {260--268},
publisher = {Morgan Kaufmann},
title = {{Near-optimal reinforcement learning in polynomial time}},
volume = {49},
year = {1998}
}
@article{Powell2004,
author = {Powell, Warren and Ruszczynski, Andrzej and Topaloglu, Huseyin},
doi = {10.1287/moor.1040.0107},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Powell, Ruszczynski, Topaloglu - 2004 - Learning Algorithms for Separable Approximations of Discrete Stochastic Optimization Problems.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
month = {nov},
number = {4},
pages = {814--836},
title = {{Learning Algorithms for Separable Approximations of Discrete Stochastic Optimization Problems}},
url = {http://mor.journal.informs.org/cgi/doi/10.1287/moor.1040.0107},
volume = {29},
year = {2004}
}
@book{Nocedal2006,
author = {Nocedal, Jorge and {Wright  J.}, Stephen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nocedal, Wright J. - 2006 - Numerical Optimization.pdf:pdf},
isbn = {0387987932},
keywords = {article mescles},
title = {{Numerical Optimization}},
volume = {2nd},
year = {2006}
}
@article{Diuk2008a,
abstract = {Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the wellknown Taxi domain, plus a real-life videogame.},
author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
doi = {10.1145/1390156.1390187},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diuk, Cohen, Littman - 2008 - An object-oriented representation for efficient reinforcement learning.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {240--247},
pmid = {847163450},
title = {{An object-oriented representation for efficient reinforcement learning}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390187},
year = {2008}
}
@article{Ghaoui1997,
author = {Ghaoui, L El and Lebret, H},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghaoui, Lebret - 1997 - Robust solutions to least-squares problems with uncertain data.pdf:pdf},
isbn = {0895479896298},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {ill-conditioned problem,least-squares problems,regularization,robust identification,robust in-,robustness,second-order cone programming,semidefinite programming,uncertainty},
number = {4},
pages = {1035--1064},
title = {{Robust solutions to least-squares problems with uncertain data}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0895479896298130},
volume = {18},
year = {1997}
}
@inproceedings{Paduraru2003,
author = {Paduraru, Cosmin and Kaplow, Robert and Precup, Doina and Pineau, Joelle},
booktitle = {European Workshop on Reinforcement Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paduraru et al. - 2008 - Model-based Reinforcement Learning with State Aggregation.pdf:pdf},
title = {{Model-based Reinforcement Learning with State Aggregation}},
year = {2008}
}
@article{Zhao2014,
abstract = {We consider information filtering, in which we face a stream of items too voluminous to process by hand (e.g., scientific articles, blog posts, emails), and must rely on a computer system to automatically filter out irrelevant items. Such systems face the exploration vs. exploitation tradeoff, in which it may be beneficial to present an item despite a low probability of relevance, just to learn about future items with similar content. We present a Bayesian sequential decision-making model of this problem, show how it may be solved to optimality using dynamic programming and a decomposition that exploits problem structure, and show structural results for the optimal policy. We show that the resulting method is especially useful when facing the cold start problem, i.e., when filtering items for new users without a long history of past interactions. We then present an application of this information filtering method to a historical dataset from the arXiv.org repository of scientific articles.},
archivePrefix = {arXiv},
arxivId = {1407.8186},
author = {Zhao, Xiaoting and Frazier, Peter I.},
eprint = {1407.8186},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Frazier - 2014 - Exploration vs. Exploitation in the Information Filtering Problem.pdf:pdf},
month = {jul},
number = {2012},
pages = {32},
title = {{Exploration vs. Exploitation in the Information Filtering Problem}},
url = {http://arxiv.org/abs/1407.8186},
year = {2014}
}
@article{Hoffman2001,
author = {Hoffman, J and Nebel, B},
journal = {Journal of Artificial Intelligence Research},
pages = {253--302},
title = {{The {\{}FF{\}} planning system: Fast plan generation through heuristic search}},
volume = {14},
year = {2001}
}
@article{Hansen2016,
author = {Hansen, Eric A and Abdoulahi, Ibrahim},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Abdoulahi - 2016 - Efficient Bounds in Heuristic Search Algorithms for Stochastic Shortest Path Problems.pdf:pdf},
isbn = {9781577357032},
journal = {Proceedings of the 30th Conference on Artificial Intelligence (AAAI 2016)},
keywords = {Technical Papers: Planning and Scheduling},
pages = {3130--3137},
title = {{Efficient Bounds in Heuristic Search Algorithms for Stochastic Shortest Path Problems}},
year = {2016}
}
@article{Amiri2009,
author = {Amiri, Meisam and Esfahanian, Mohsen and Hairi-Yazdi, Mohammad Reza and Esfahanian, Vahid},
doi = {10.1016/j.jpowsour.2009.01.072},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amiri et al. - 2009 - Minimization of power losses in hybrid electric vehicles in view of the prolonging of battery life.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {hybrid electric vehicle},
month = {may},
number = {2},
pages = {372--379},
title = {{Minimization of power losses in hybrid electric vehicles in view of the prolonging of battery life}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378775309001724},
volume = {190},
year = {2009}
}
@book{Goodfellow2015,
abstract = {www.deeplearningbook.org},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
doi = {10.1038/nmeth.3707},
eprint = {arXiv:1312.6184v5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow, Bengio, Courville - 2016 - Deep Learning.pdf:pdf},
isbn = {9780521835688},
issn = {1548-7091},
pmid = {10463930},
title = {{Deep Learning}},
url = {http://www.nature.com/doifinder/10.1038/nature14539{\%}5Cnhttp://www.nature.com/doifinder/10.1038/nmeth.3707},
year = {2016}
}
@article{Li2006a,
annote = {Has a great overview of what is out there},
author = {Li, Lihong and Walsh, TJ Tomas J and Littman, ML Michael L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Walsh, Littman - 2006 - Towards a Unified Theory of State Abstraction for MDPs.pdf:pdf},
journal = {Internaltional Symposium on Artificial Intelligence and Mathematics},
title = {{Towards a Unified Theory of State Abstraction for MDPs.}},
url = {http://www.cs.rutgers.edu/{~}lihong/pub/Li06Towards.pdf},
year = {2006}
}
@inproceedings{Hansen2004,
annote = {From Duplicate 1 ( Dynamic programming for partially observable stochastic games - Hansen, Eric A; Bernstein, Daniel S; Zilberstein, Shlomo )

From Duplicate 1 ( Dynamic Programming for Partially Observable Stochastic Games - Hansen, Eric A; Bernstein, Daniel S; Zilberstein, Shlomo )
},
author = {Hansen, Eric A and Bernstein, Daniel S and Zilberstein, Shlomo},
booktitle = {National Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Bernstein, Zilberstein - 2003 - Dynamic Programming for Partially Observable Stochastic Games.pdf:pdf},
number = {2000},
pages = {709--715},
title = {{Dynamic programming for partially observable stochastic games}},
year = {2004}
}
@phdthesis{Ozbay2006,
author = {Ozbay, Nuri Sercan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozbay - 2006 - Solving Robust Inventory Problems.pdf:pdf},
title = {{Solving Robust Inventory Problems}},
year = {2006}
}
@article{Mangasarian1995,
annote = {From Duplicate 2 ( The linear complementarity problem as a separable bilinear program - Mangasarian, OL )
},
author = {Mangasarian, OL L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangasarian - 1995 - The linear complementarity problem as a separable bilinear program.pdf:pdf},
journal = {Journal of Global Optimization},
pages = {1--7},
title = {{The linear complementarity problem as a separable bilinear program}},
url = {http://link.springer.com/article/10.1007/BF01096765},
volume = {12},
year = {1995}
}
@book{Baccelli1992,
author = {Baccelli, F and Cohen, Guy and Olsder, GJ and Quadrat, JP},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baccelli et al. - 1992 - Synchronization and linearity.pdf:pdf},
title = {{Synchronization and linearity}},
url = {http://cermics.enpc.fr/{~}cohen-g/documents/BCOQ-book.pdf},
year = {1992}
}
@article{Durrant2012,
author = {Durrant, Robert J and Kab, Ata},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Durrant, Kab - 2012 - Random Projections for Machine Learning and Data Mining Theory and Applications.pdf:pdf},
number = {September},
title = {{Random Projections for Machine Learning and Data Mining : Theory and Applications}},
year = {2012}
}
@article{Vandenberghe2011g,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 08. Fast gradient methods.pdf:pdf},
journal = {LECTURE NOTES},
title = {{08. Fast gradient methods}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@book{Golub2012,
abstract = {Revised and updated, the third edition of Golub and Van Loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. This new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of CS decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified Gram-Schmidt process, and new material devoted to GMRES, QMR, and other methods designed to handle the sparse unsymmetric linear system problem.},
author = {Golub, Gene H and {Van Loan}, Charles F},
booktitle = {Johns Hopkins University Press},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golub, Van Loan - 2013 - Matrix Computations.pdf:pdf},
isbn = {9781421407944},
pages = {780},
title = {{Matrix Computations}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=5U-l8U3P-VUC{\&}oi=fnd{\&}pg=PT10{\&}dq=Matrix+Computations{\&}ots=7ZCDOl{\_}R6m{\&}sig=qZWur-3UCyKOgcoPpFeRJ2UhCRs},
year = {2013}
}
@techreport{Borm2001,
annote = {From Duplicate 2 ( Operations research games: A survey - Borm, Peter; Hamers, Herbert; Hendrickx, Ruud )
},
author = {Borm, Peter and Hamers, Herbert and Hendrickx, Ruud},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Borm, Hamers, Hendrickx - 2001 - Operations research games A survey.pdf:pdf},
institution = {CentER},
title = {{Operations research games: A survey}},
year = {2001}
}
@article{Brown2010a,
author = {Brown, Peter D. and Cochrane, Thomas a. and Krom, Thomas D.},
doi = {10.1016/j.agwat.2010.01.020},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown, Cochrane, Krom - 2010 - Optimal on-farm irrigation scheduling with a seasonal water limit using simulated annealing.pdf:pdf},
issn = {03783774},
journal = {Agricultural Water Management},
month = {jun},
number = {6},
pages = {892--900},
title = {{Optimal on-farm irrigation scheduling with a seasonal water limit using simulated annealing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378377410000387},
volume = {97},
year = {2010}
}
@article{Markovsky2007,
author = {Markovsky, Ivan and {Van Huffel}, Sabine},
doi = {10.1016/j.sigpro.2007.04.004},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Markovsky, Van Huffel - 2007 - Overview of total least-squares methods.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {deconvolution,diction,errors-in-variables model,linear pre-,orthogonal regression,system identification,total least squares},
month = {oct},
number = {10},
pages = {2283--2302},
title = {{Overview of total least-squares methods}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0165168407001405},
volume = {87},
year = {2007}
}
@misc{Bennett1992,
author = {Bennett, Kristin P and Mangasarian, O L},
institution = {Computer Science Department, University of Wisconsin},
title = {{Bilinear separation of two sets in n-space}},
year = {1992}
}
@article{Castronovo2016,
abstract = {In the Bayesian Reinforcement Learning (BRL) setting, agents try to maximise the collected rewards while interacting with their environment while using some prior knowledge that is accessed beforehand. Many BRL algorithms have already been proposed, but even though a few toy examples exist in the literature, there are still no extensive or rigorous benchmarks to compare them. The paper addresses this problem, and provides a new BRL comparison methodology along with the corresponding open source library. In this methodology, a comparison criterion that measures the performance of algorithms on large sets of Markov Decision Processes (MDPs) drawn from some probability distributions is defined. In order to enable the comparison of non-anytime algorithms, our methodology also includes a detailed analysis of the computation time requirement of each algorithm. Our library is released with all source code and documentation: it includes three test problems, each of which has two different prior distributions, and seven state-of-the-art RL algorithms. Finally, our library is illustrated by comparing all the available algorithms and the results are discussed.},
archivePrefix = {arXiv},
arxivId = {1509.04064},
author = {Castronovo, Michael and Ernst, Damien and Cou{\"{e}}toux, Adrien and Fonteneau, Raphael},
doi = {10.1371/journal.pone.0157088},
eprint = {1509.04064},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castronovo et al. - 2016 - Benchmarking for Bayesian reinforcement learning.pdf:pdf},
isbn = {1932-6203},
issn = {19326203},
journal = {PLoS ONE},
number = {6},
pages = {1--25},
pmid = {27304891},
title = {{Benchmarking for Bayesian reinforcement learning}},
volume = {11},
year = {2016}
}
@article{Potapov2012,
author = {Potapov, Peter V. and Turubanova, Svetlana a. and Hansen, Matthew C. and Adusei, Bernard and Broich, Mark and Altstatt, Alice and Mane, Landing and Justice, Christopher O.},
doi = {10.1016/j.rse.2011.08.027},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Potapov et al. - 2012 - Quantifying forest cover loss in Democratic Republic of the Congo, 2000–2010, with Landsat ETM data.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {Congo,Forest cover,Forest cover loss,Landsat},
month = {jul},
pages = {106--116},
publisher = {Elsevier Inc.},
title = {{Quantifying forest cover loss in Democratic Republic of the Congo, 2000–2010, with Landsat ETM+ data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0034425712000430},
volume = {122},
year = {2012}
}
@article{Federgruen1999,
author = {Federgruen, A and Heching, Aliza},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Federgruen, Heching - 1999 - Combined pricing and inventory control under uncertainty.pdf:pdf},
journal = {Operations research},
number = {3},
pages = {454--475},
title = {{Combined pricing and inventory control under uncertainty}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.47.3.454},
volume = {47},
year = {1999}
}
@article{Kretchmar2001,
abstract = {Robust control theory is used to design stable controllers in the presence of uncertainties. This provides powerful closed-loop robustness guarantees, but can result in controllers that are conservative with regard to performance. Here we present an approach to learning a better controller through observing actual controlled behaviour. A neural network is placed in parallel with the robust controller and is trained through reinforcement learning to optimize performance over time. By analysing nonlinear and time- varying aspects of a neural network via uncertainty models, a robust reinforcement learning procedure results that is guaranteed to remain stable even as the neural network is being trained. The behaviour of this procedure is demonstrated and analysed on two control tasks. Results show that at intermediate stages the system without robust constraints goes through a period of unstable behaviour that is avoided when the robust constraints are included.},
author = {Kretchmar, R. Matthew and Young, Peter M. and Anderson, Charles W. and Hittle, Douglas C. and Anderson, Michael L. and Delnero, Christopher C.},
doi = {10.1002/rnc.670},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kretchmar et al. - 2001 - Robust reinforcement learning control with static and dynamic stability.pdf:pdf},
issn = {10498923},
journal = {International Journal of Robust and Nonlinear Control},
number = {15},
pages = {1469--1500},
title = {{Robust reinforcement learning control with static and dynamic stability}},
volume = {11},
year = {2001}
}
@misc{cdl2014,
author = {CDL},
title = {{Cropland Data Layer}},
url = {http://www.nass.usda.gov/research/Cropland/Release/index.htm},
year = {2014}
}
@article{Lomax2013,
abstract = {The past decade has seen a significant interest on the problem of inducing decision trees that take account of costs of misclassification and costs of acquiring the features used for decision making. This survey identifies over 50 algorithms including approaches that are direct adaptations of accuracy-based methods, use genetic algorithms, use anytime methods and utilize boosting and bagging. The survey brings together these different studies and novel approaches to cost-sensitive decision tree learning, provides a useful taxonomy, a historical timeline of how the field has developed and should provide a useful reference point for future research in this field. [ABSTRACT FROM AUTHOR]},
author = {Lomax, Susan and Vadera, Sunil},
doi = {10.1145/2431211.2431215},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lomax, Vadera - 2013 - A Survey of Cost-Sensitive Decision Tree Induction Algorithms.pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {2},
pages = {16--16:35},
title = {{A Survey of Cost-Sensitive Decision Tree Induction Algorithms}},
url = {10.1145/2431211.2431215{\%}5Cnhttp://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=87522704{\&}site=ehost-live},
volume = {45},
year = {2013}
}
@article{Aras2008a,
author = {Aras, Raghav and Dutech, Alain},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aras, Dutech - 2008 - Fast Mathematical Programming for Decentralized POMDPs.pdf:pdf},
title = {{Fast Mathematical Programming for Decentralized POMDPs}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Fast+Mathematical+Programming+for+Decentralized+POMDPs{\#}0},
year = {2008}
}
@inproceedings{Asmuth2009,
author = {Asmuth, John and Li, Lihong and Littman, Michael and Nouri, Ali and Wingate, David},
booktitle = {Uncertainty in Artificial Intelligence},
title = {{A Bayesian Sampling Approach to Exploration in Reinforcement Learning}},
year = {2009}
}
@techreport{Guigues2010,
author = {Guigues, Vincent and Abal, Claudia Sagastiz},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guigues, Abal - Unknown - The value of rolling horizon policies for risk-averse hydro-thermal planning ´.pdf:pdf},
institution = {Optimization Online},
keywords = {and phrases,constraints and cvar and,interstage dependence,stochastic programming and chance},
number = {382},
title = {{The Value of rolling horizon policies for risk-averse hydro-thermal planning}},
year = {2010}
}
@unpublished{Aboudi1993,
author = {Aboudi, R and Jornsten, K and Leisten, R},
title = {{Solving Large-Scale Linear Programs with Bounded Variables by Iterative Aggregation}},
year = {1993}
}
@article{Gutierrez-Alcaraz2004,
abstract = {Market dynamics have been studied with emphasis on price stability. Dynamic market pricing in a purely competitive environment for a given trading period is determined by the interaction of the supplier and buyer with information available to each. The scheduling of generation is determined according to a generation company's (GENCOs) perception of the expected future conditions. Future conditions include equipment availability and competitor play. These decisions, which attempt to maximize profits, and the resulting interactions represents a major source of electric market dynamics. Profits in any period depend on level of efficiency as well as on the levels of efficiency of other competing GENCOs. Incorrect, untimely, and improperly analyzed information often lead to suboptimal solutions for the profit maximizing player, This paper analyzes market price dynamics by using Markov process (MP) modeling. An example application is presented as would be conducted by information seeking players to maximize profit. Key issues with applying Markov chains to different market conditions are identified. The key economic pricing signals, representing different forces, are examined as a basis of influencing these key decisions by each player},
author = {Gutierrez-Alcaraz, G. and Sheble, G.B.},
doi = {10.1109/PMAPS.2004.242551},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gutierrez-Alcaraz, Sheble - 2004 - Electricity market price dynamics Markov process analysis.pdf:pdf},
isbn = {0-9761319-1-9},
journal = {2004 International Conference on Probabilistic Methods Applied to Power Systems},
pages = {14--19},
title = {{Electricity market price dynamics: Markov process analysis}},
year = {2004}
}
@article{Amato2009,
author = {Amato, Christopher and Bernstein, Daniel S. and Zilberstein, Shlomo},
doi = {10.1007/s10458-009-9103-z},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amato, Bernstein, Zilberstein - 2009 - Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs.pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {decision theory,multiagent systems,planning under uncertainty,pomdps},
number = {3},
pages = {293--320},
title = {{Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs}},
url = {http://link.springer.com/10.1007/s10458-009-9103-z},
volume = {21},
year = {2009}
}
@article{Friedlander2007,
annote = {From Duplicate 1 ( Discussion: The Dantzig selector: Statistical estimation when p is much larger than n - Friedlander, Michael P.; Saunders, Michael a. )
And Duplicate 3 ( The Dantzig selector : statistical estimation when p is much larger than n - Candes, Emmanuel; Tao, Terence )
},
author = {Candes, Emmanuel and Tao, Terence and Friedlander, Michael P. and Saunders, Michael a.},
doi = {10.1214/009053607000000479},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candes, Tao - 2005 - The Dantzig selector statistical estimation when p is much larger than n.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedlander, Saunders - 2007 - Discussion The Dantzig selector Statistical estimation when p is much larger than n.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {ideal estimation,model selection,oracle inequali-,statistical linear model},
month = {dec},
number = {6},
pages = {2385--2391},
title = {{Discussion:The {\{}Dantzig{\}} selector:Statistical estimation when p is much larger than n}},
url = {http://projecteuclid.org/euclid.aos/1201012964},
volume = {35},
year = {2007}
}
@book{Bossavit2003,
author = {Bossavit, Alain},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bossavit - 2003 - A course in Convex Analysis.pdf:pdf},
number = {June},
title = {{A course in Convex Analysis}},
year = {2003}
}
@incollection{Dyer2004,
annote = {From Duplicate 1 (Linear programming (ch 38) - Dyer, Martin; Megiddo, Nimrod; Welzl, Emo)

http://www.inf.ethz.ch/personal/emo/PublFiles/LpSurvey03.pdf

great overview of Megiddo's O(n) algo for fixed dimension, and extensions

also discusses linear-like algorithms

Can be very fast when there are few variables and many constraints.

From Duplicate 2 (Linear programming (ch 38) - Dyer, Martin; Megiddo, Nimrod; Welzl, Emo)

http://www.inf.ethz.ch/personal/emo/PublFiles/LpSurvey03.pdf


great overview of Megiddo's O(n) algo for fixed dimension, and extensions


also discusses linear-like algorithms


printed},
author = {Dyer, Martin and Megiddo, Nimrod and Welzl, Emo},
booktitle = {Handbook of Discrete and Computational Geometry},
edition = {1},
editor = {Goodman, J.E. and O'Rourke, J.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dyer, Megiddo, Welzl - 2004 - Linear programming (ch 38).pdf:pdf},
isbn = {0849385245},
keywords = {LP,complexity,fixed dimension,linear programing},
mendeley-tags = {LP,complexity,fixed dimension,linear programing},
pages = {999--1014},
publisher = {Chapman and Hall/CRC},
title = {{Linear programming (ch 38)}},
year = {2004}
}
@article{Ghosh1994,
author = {Ghosh, M and Rao, J N K},
doi = {10.1214/ss/1177010647},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh, Rao - 1994 - Small area estimation an appraisal.pdf:pdf},
issn = {0883-4237},
journal = {Stat Sci},
number = {1},
pages = {55--93},
title = {{Small area estimation: an appraisal}},
volume = {9},
year = {1994}
}
@article{Al-Khayyal1983,
author = {Al-Khayyal, FA and Falk, JE},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Khayyal, Falk - 1983 - Jointly constrained biconvex programming.pdf:pdf},
isbn = {0001475061},
journal = {Mathematics of Operations {\ldots}},
number = {2},
pages = {273--286},
title = {{Jointly constrained biconvex programming}},
url = {http://mor.journal.informs.org/content/8/2/273.short},
volume = {8},
year = {1983}
}
@phdthesis{LeTallec2007,
author = {{Le Tallec}, Yann},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Tallec - 2007 - Robust, Risk-Sensitive, and Data-driven Control of Markov Decision Processes.pdf:pdf},
school = {MIT},
title = {{Robust, Risk-Sensitive, and Data-driven Control of Markov Decision Processes}},
year = {2007}
}
@inproceedings{Shapley1953,
author = {Shapley, L S},
booktitle = {Proceedings of the {\{}N{\}}ational {\{}A{\}}cadamy of the {\{}S{\}}ciences of the {\{}USA{\}}, 39},
title = {{Stochastic games}},
year = {1953}
}
@article{Messner2003c,
author = {Messner, Matthias and Polborn, Mattias K.},
doi = {10.1016/S0022-0531(02)00013-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Messner, Polborn - 2003 - Cooperation in Stochastic OLG games.pdf:pdf},
issn = {00220531},
journal = {Journal of Economic Theory},
keywords = {and,anonymous referee for helpful,comments,cooperation,education,financial support from daad,game theory,ig horstmann and an,is gratefully acknowledged,joan esteban,messner,overlapping generations,polborn,thank antonio cabrales,the spanish ministry of,we would like to},
month = {jan},
number = {1},
pages = {152--168},
title = {{Cooperation in Stochastic OLG games}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022053102000133},
volume = {108},
year = {2003}
}
@inproceedings{Hadwin2006,
author = {Hadwin, D and Harrison, K and Ward, J},
booktitle = {Proceedings of the American Mathematical {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadwin, Harrison, Ward - 2006 - Rank-one completions of partial matrices and completely rank-nonincreasing linear functionals.pdf:pdf},
number = {8},
pages = {2169--2178},
title = {{Rank-one completions of partial matrices and completely rank-nonincreasing linear functionals}},
url = {http://www.ams.org/proc/2006-134-08/S0002-9939-06-08094-4/},
volume = {134},
year = {2006}
}
@techreport{Guigues2011,
author = {Guigues, Vincent},
institution = {Optimization Online},
title = {{SDDP for some interstage dependent risk averse problems and application to hydro-thermal planning}},
year = {2011}
}
@article{Gallo1977,
author = {Gallo, G and {\"{U}}lk{\"{u}}c{\"{u}}, A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gallo, {\"{U}}lk{\"{u}}c{\"{u}} - 1977 - Bilinear programming an exact algorithm.pdf:pdf},
journal = {Mathematical Programming},
pages = {173--194},
title = {{Bilinear programming: an exact algorithm}},
url = {http://link.springer.com/article/10.1007/BF01593787},
volume = {12},
year = {1977}
}
@article{Rust1987,
annote = {From Duplicate 1 ( Optimal replacement of {\{}GMC{\}} bus engines: An empirical model of {\{}Harold Zurcher{\}} - Rust, John )
},
author = {Rust, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rust - 1987 - Optimal replacement of {\{}GMC{\}} bus engines An empirical model of {\{}Harold Zurcher{\}}.pdf:pdf},
journal = {Econometrica},
pages = {999--1033},
title = {{Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher}},
volume = {55},
year = {1987}
}
@article{Hyvarinen2000a,
abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.},
author = {Hyv{\"{a}}rinen, a and Oja, E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyv{\"{a}}rinen, Oja - 2000 - Independent component analysis algorithms and applications.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Artifacts,Brain,Brain: physiology,Humans,Magnetoencephalography,Neural Networks (Computer),Normal Distribution},
number = {4-5},
pages = {411--30},
pmid = {10946390},
title = {{Independent component analysis: algorithms and applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10946390},
volume = {13},
year = {2000}
}
@book{Strang2010,
author = {Strang, Gilbert},
doi = {10.1016/B978-0-12-387000-1.01001-9},
edition = {4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strang - 2010 - Linear Algebra and Its Applications.pdf:pdf},
isbn = {0-03-010567-6},
keywords = {Linear Algebra,Matrix Analysis},
pages = {1--497},
title = {{Linear Algebra and Its Applications}},
url = {papers2://publication/uuid/CB55F899-1C5B-4337-A8D2-187559F06F97},
year = {2010}
}
@misc{Bagnell2003,
address = {Pittsburgh, PA},
author = {Bagnell, James and Schneider, Jeff},
institution = {Robotics Institute, Carnegie Mellon University},
month = {nov},
title = {{Policy Search in Reproducing Kernel Hilbert Space}},
year = {2003}
}
@article{Lindquist2010,
author = {Lindquist, John L. and Evans, Sean P. and Shapiro, Charles a. and Knezevic, Stevan Z.},
doi = {10.1614/WT-09-070.1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lindquist et al. - 2010 - Effect of Nitrogen Addition and Weed Interference on Soil Nitrogen and Corn Nitrogen Nutrition.pdf:pdf},
issn = {0890-037X},
journal = {Weed Technology},
keywords = {chlorophyll,de recursos disponibles para,duration of weed interference,interplant competition,la,nitrogen,nitrogen uptake,nutrition index,porque reduce la cantidad,rdida indirecta del cultivo,resource acquisition,su crecimiento},
month = {jan},
number = {1},
pages = {50--58},
title = {{Effect of Nitrogen Addition and Weed Interference on Soil Nitrogen and Corn Nitrogen Nutrition}},
url = {http://www.bioone.org/doi/abs/10.1614/WT-09-070.1},
volume = {24},
year = {2010}
}
@inproceedings{Hallak2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1502.03255v1},
author = {Hallak, Assaf and Schnitzler, Francois and Mann, Timothy and Mannor, Shie},
booktitle = {International Conference on Machine Learning},
eprint = {arXiv:1502.03255v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hallak et al. - 2015 - Off-policy Model-based Learning under Unknown Factored Dynamics.pdf:pdf},
pages = {711--719},
title = {{Off-policy Model-based Learning under Unknown Factored Dynamics}},
url = {http://jmlr.org/proceedings/papers/v37/hallak15.html},
volume = {37},
year = {2015}
}
@inproceedings{Iancu2015a,
author = {Delage, Erick and Iancu, Dan A.},
booktitle = {INFORMS Tutorials in Operations Research},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delage, Iancu - 2015 - Robust multistage decision making.pdf:pdf},
isbn = {9780984337880},
pages = {19--46},
title = {{Robust multistage decision making}},
year = {2015}
}
@article{Feinberg2014,
author = {Feinberg, Eugene a. and Huang, Jefferson and Scherrer, Bruno},
doi = {10.1016/j.orl.2014.07.006},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinberg, Huang, Scherrer - 2014 - Modified policy iteration algorithms are not strongly polynomial for discounted dynamic programming.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {markov decision process,modified policy iteration},
month = {sep},
number = {6-7},
pages = {429--431},
publisher = {Elsevier B.V.},
title = {{Modified policy iteration algorithms are not strongly polynomial for discounted dynamic programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167637714001072},
volume = {42},
year = {2014}
}
@article{Brown2007,
author = {Brown, David B.},
doi = {10.1016/j.orl.2007.01.001},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown - 2007 - Large deviations bounds for estimating conditional value-at-risk.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {conditional value-at-risk,convex risk measure,estimation,large deviations,optimized certainty equivalent},
month = {nov},
number = {6},
pages = {722--730},
title = {{Large deviations bounds for estimating conditional value-at-risk}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167637707000077},
volume = {35},
year = {2007}
}
@article{Silver2010,
abstract = {This paper introduces a Monte-Carlo algorithm for online planning in large POMDPs. The algorithm combines a Monte-Carlo update of the agent's belief state with a Monte-Carlo tree search from the current belief state. The new algorithm, POMCP, has two important properties. First, Monte- Carlo sampling is used to break the curse of dimensionality both during belief state updates and during planning. Second, only a black box simulator of the POMDP is required, rather than explicit probability distributions. These properties enable POMCP to plan e ectively in signi cantly larger POMDPs than has previously been possible. We demonstrate its effectiveness in three large POMDPs. We scale up a well-known benchmark problem, rocksample, by several orders of magnitude. We also introduce two challenging new POMDPs: 10 X 10 battleship and partially observable PacMan, with approximately 10{\^{}}18 and 10{\^{}}56 states respectively. Our Monte- Carlo planning algorithm achieved a high level of performance with no prior knowledge, and was also able to exploit simple domain knowledge to achieve better results with less search. POMCP is the rst general purpose planner to achieve high performance in such large and unfactored POMDPs.},
author = {Silver, D and Veness, J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silver, Veness - 2010 - Monte-Carlo Planning in Large POMDPs.pdf:pdf},
isbn = {9781617823800},
journal = {Advances in neural information processing systems.},
pages = {2164--2172},
title = {{Monte-Carlo Planning in Large POMDPs}},
url = {http://discovery.ucl.ac.uk/1347369/},
year = {2010}
}
@article{White1996,
abstract = {In this paper we consider a homotopy deformation approach to solving Markov decision process problems by the continuous deformation of a simpler Markov decision process problem until it is identical with the original problem. Algorithms and performance bounds are given.},
annote = {From Duplicate 1 ( A homotopy approach for infinite horizon discounted Markov decision processes. - White, Douglas John )
},
author = {White, Douglas John},
journal = {Mathematical Methods of Operations Research},
pages = {353--372},
title = {{A homotopy approach for infinite horizon discounted Markov decision processes.}},
volume = {43},
year = {1996}
}
@misc{Zipkin1977,
author = {Zipkin, Paul H},
title = {{Aggregation in Linear Programming}},
year = {1977}
}
@inproceedings{Allen2008,
author = {Allen, Martin and Petrik, Marek and Zilberstein, Shlomo},
booktitle = {Conference on Artificial Intelligence (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Petrik, Zilberstein - 2008 - Interaction Structure and Dimensionality in Decentralized Problem Solving.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Petrik, Zilberstein - 2008 - Interaction Structure and Dimensionality Reduction in Decentralized MDPs.pdf:pdf},
number = {08-11},
organization = {Computer Science Department, University of Massachussetts},
pages = {1440--1441},
title = {{Interaction structure and dimensionality in decentralized problem solving}},
url = {http://www.aaai.org/Papers/AAAI/2008/AAAI08-228.pdf},
year = {2008}
}
@article{Nguyen2011,
author = {Nguyen, N and Nasrabadi, NM and Tran, TD},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen, Nasrabadi, Tran - 2011 - Robust lasso with missing and grossly corrupted observations.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--9},
title = {{Robust lasso with missing and grossly corrupted observations}},
url = {http://papers.nips.cc/paper/4386-robust-lasso-with-missing-and-grossly-corrupted-observations},
year = {2011}
}
@article{Gmbh2010,
author = {Gmbh, Enocean},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gmbh - 2010 - EnOcean Wireless Systems – RANGE PLANNING GUIDE.pdf:pdf},
keywords = {Application Note 001: EnOcean Wireless Systems – R},
pages = {1--12},
title = {{EnOcean Wireless Systems – RANGE PLANNING GUIDE}},
year = {2010}
}
@article{Ahmed2017,
author = {Ahmed, Asrar and Jaillet, Patrick},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Jaillet - 2017 - Sampling Based Approaches for Minimizing Regret in Uncertain Markov Decision Processes ( MDPs ).pdf:pdf},
journal = {Journal of Artificial Intelligence Research (JAIR)},
pages = {229--264},
title = {{Sampling Based Approaches for Minimizing Regret in Uncertain Markov Decision Processes ( MDPs )}},
volume = {59},
year = {2017}
}
@article{Thornton1998,
abstract = {We describe a dynamic agricultural land-use model based on a Markov process and governed by a few simple decision rules. Currently, the model is purely conceptual, and was designed with one objective: to investigate the possibility of constructing top-down land-use models based on as few processes as possible that might still be useful for statistical analyses of landuse change in a region. The model appears to behave in a plausible fashion in a simulated landscape with respect to cropping patterns and the effects of initial household size on wealth distribution. If this type of simple model could be validated, the information that could be produced might be of considerable value in a wide range of applications, particularly with regard to technology adoption patterns and resultant regional production impacts.},
author = {Thornton, P. K. and Jones, P.G.},
journal = {Agricultural Systems},
number = {4},
pages = {501--521},
title = {{A conceptual approach to dynamic agricultural land-use modelling}},
volume = {57},
year = {1998}
}
@inproceedings{Chen2016,
author = {Chen, Xiangli and Ziebart, Brian D},
booktitle = {Artificial Intelligence and Statistics (AISTATS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Ziebart - 2016 - Robust Covariate Shift Regression.pdf:pdf},
pages = {1270--1279},
title = {{Robust Covariate Shift Regression}},
year = {2016}
}
@misc{Pineau2004,
author = {Pineau, Joelle},
title = {{Tractable planning under uncertainty: Exploiting structure}},
year = {2004}
}
@book{Sutton1998,
abstract = {The attached file is the second edition!},
author = {Sutton, Richard S and Barto, Andrew},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 1998 - Reinforcement learning.pdf:pdf},
publisher = {MIT Press},
title = {{Reinforcement learning: An Introduction}},
year = {1998}
}
@book{Schoelkopf1998,
editor = {Scholkopf, Bernhard and Burges, Christopher J C and Smola, Alexander J},
title = {{Advances in Kernel Methods}},
year = {1998}
}
@phdthesis{Aiello-Lammens2014,
abstract = {Ph.D. disertation},
author = {Aiello-Lammens, Matthew E.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aiello-Lammens - 2014 - Patterns and Processes of the Invasion of Frangula alnus An Integrated Model Framework.pdf:pdf},
school = {Stony Brook University},
title = {{Patterns and Processes of the Invasion of Frangula alnus: An Integrated Model Framework}},
url = {http://www.soilinfo.psu.edu/},
year = {2014}
}
@article{Becker2004,
author = {Becker, Raphen and Zilberstein, Shlomo and Lesser, Victor and Goldman, Claudia V},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker - 2004 - Solving transition independent decentralized Markov decision processes.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {423--455},
title = {{Solving transition independent decentralized Markov decision processes}},
url = {http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1207{\&}context=cs{\_}faculty{\_}pubs},
volume = {22},
year = {2004}
}
@inproceedings{Wang2008,
annote = {
        {\textless}m:bold{\textgreater}From Duplicate 1 ( {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}
          {\textless}m:italic{\textgreater}Stable Dual Dynamic Programming{\textless}/m:italic{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater} - Wang, Tao; Lizotte, Daniel; Bowling, Michael; Schuurmans, Dale ){\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Wang, Tao and Lizotte, Daniel and Bowling, Michael and Schuurmans, Dale},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - Unknown - Stable Dual Dynamic Programming.pdf:pdf},
title = {{Stable Dynamic Programming}},
year = {2008}
}
@article{Felner2004,
annote = {From Duplicate 2 ( Additive Pattern Database Heuristics - Felner, Ariel; Hanan, Sarit; Korf, Richard E )
},
author = {Felner, Ariel and Hanan, Sarit and Korf, Richard E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Felner, Hanan, Korf - 2004 - Additive Pattern Database Heuristics.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {279--318},
title = {{Additive Pattern Database Heuristics}},
volume = {22},
year = {2004}
}
@inproceedings{Degris2006,
author = {Degris, Thomas and Sigaud, Olivier and Wuillemin, Pierre-Henri},
booktitle = {International Conference of Machine Learning (ICML)},
title = {{Learning the Structure of Factored Markov Decision Processes in Reinforcement Learning Problems}},
year = {2006}
}
@article{Puterman1978,
author = {Puterman, ML and Shin, MC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman, Shin - 1978 - Modified policy iteration algorithms for discounted Markov decision problems.pdf:pdf},
journal = {Management Science},
number = {11},
pages = {1127--1137},
title = {{Modified policy iteration algorithms for discounted Markov decision problems}},
url = {http://mansci.journal.informs.org/content/24/11/1127.short},
volume = {24},
year = {1978}
}
@article{Brafman2002a,
annote = {From Duplicate 2 (R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning - Brafman, Ronen I; Tennenholtz, Moshe)

From Duplicate 2 ( R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning - Brafman, Ronen I; Tennenholtz, Moshe )
},
author = {Brafman, Ronen I and Tennenholtz, Moshe},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brafman, Tennenholtz - 2002 - R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {213--231},
title = {{R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning}},
volume = {3},
year = {2002}
}
@article{James2009,
annote = {From Duplicate 1 ( DASSO: connections between the Dantzig selector and lasso - James, Gareth M.; Radchenko, Peter; Lv, Jinchi )
},
author = {James, Gareth M. and Radchenko, Peter and Lv, Jinchi},
doi = {10.1111/j.1467-9868.2008.00668.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/James, Radchenko, Lv - 2009 - DASSO connections between the Dantzig selector and lasso.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society, Series B},
keywords = {dantzig selector,dasso,lasso,least angle regression},
month = {jan},
number = {1},
pages = {127--142},
title = {{DASSO: Connections between the Dantzig selector and lasso}},
url = {http://doi.wiley.com/10.1111/j.1467-9868.2008.00668.x},
volume = {71},
year = {2009}
}
@article{Ermon2013,
author = {Ermon, Stefano and Xue, Yexiang and Gomes, Carla and Selman, Bart},
doi = {10.1007/s10994-013-5378-z},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ermon et al. - 2013 - Learning policies for battery usage optimization in electric vehicles.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {may},
number = {1},
pages = {177--194},
title = {{Learning policies for battery usage optimization in electric vehicles}},
url = {http://link.springer.com/10.1007/s10994-013-5378-z},
volume = {92},
year = {2013}
}
@inproceedings{Gutin2016,
author = {Gutin, Eli and Farias, Vivek F.},
booktitle = {Conference on Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gutin, Farias - 2016 - Optimistic Gittins Indices.pdf:pdf},
title = {{Optimistic Gittins Indices}},
year = {2016}
}
@article{Miller2015,
abstract = {We find a subtle but substantial bias in a standard measure of the conditional dependence of present outcomes on streaks of past outcomes in sequential data. The mechanism is driven by a form of selection bias, which leads to an underestimate of the true conditional probability of a given outcome when conditioning on prior outcomes of the same kind. The biased measure has been used prominently in the literature that investigates incorrect beliefs in sequential decision making—most notably the Gambler's Fallacy and the Hot Hand Fallacy. Upon correcting for the bias, the conclusions of some prominent studies in the literature are reversed. The bias also provides a structural explanation of why the belief in the law of small numbers persists, as repeated experience with finite sequences can only reinforce these beliefs, on average.},
author = {Miller, Joshua B and Sanjurjo, Adam},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Sanjurjo - 2015 - Surprised by the Gambler's and Hot Hand Fallacies A Truth in the Law of Small Numbers.pdf:pdf},
keywords = {alternation bias,bias,finite sample bias,gambler,hot hand effect,hot hand fallacy,lacy,law of small numbers,negative recency bias,s fal-,selection,sequential data,sequential decision making,small sample bias},
pages = {1--44},
title = {{Surprised by the Gambler's and Hot Hand Fallacies? A Truth in the Law of Small Numbers}},
year = {2015}
}
@phdthesis{Madabushi1997,
author = {Madabushi, Ananth},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madabushi - 1997 - Lagrangian Relaxation Dual Approaches For Solving Large-Scale Linear Programming Problems.pdf:pdf},
keywords = {lagrangian relaxation,line search,primal recovery,subgradient},
title = {{Lagrangian Relaxation / Dual Approaches For Solving Large-Scale Linear Programming Problems}},
year = {1997}
}
@article{Golikov2004,
annote = {From Duplicate 1 ( Application of Newton's Method for Solving Large Linear Programming Problems - Golikov, A I; Evtushenko, Yu.G. G; Mollaverdi, N )
},
author = {Golikov, A I and Evtushenko, Yu.G. G and Mollaverdi, N},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golikov, Evtushenko, Mollaverdi - 2004 - Application of Newton ' s Method for Solving Large Linear Programming Problems.pdf:pdf},
journal = {Computational Mathematics and Mathematical Physics},
keywords = {lagrangian,large linear programming problems,newton,s method},
number = {9},
pages = {1484--1493},
title = {{Application of Newton's Method for Solving Large Linear Programming Problems}},
volume = {44},
year = {2004}
}
@article{Chen2005,
author = {Chen, Xin and Sim, Melvyn and Sun, Peng},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Sim, Sun - 2007 - A robust optimization perspective on stochastic programming.pdf:pdf},
journal = {Operations Research},
number = {December 2004},
pages = {0--37},
title = {{A robust optimization perspective on stochastic programming}},
url = {http://or.journal.informs.org/content/55/6/1058.short},
year = {2007}
}
@book{Many,
author = {Many},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Many - Unknown - Illinois Agronomy Handbook.pdf:pdf},
title = {{Illinois Agronomy Handbook}}
}
@incollection{Moschini2001,
abstract = {Uncertainty and risk are quintessential features of agricultural production. After a brief overview of the main sources of agricultural risk, we provide an exposition of expected utility theory and of the notion of risk aversion. This is followed by a basic analysis of agricultural production decisions under risk, including some comparative statics results from stylized models. Selected empirical topics are surveyed, with emphasis on risk analyses as they pertain to production decisions at the farm level. Risk management is then discussed, and a synthesis of hedging models is presented. We conclude with a detailed review of agricultural insurance, with emphasis on the moral hazard and adverse selection problems that arise in the context of crop insurance.},
author = {Moschini, Giancarlo and Hennessy, David a.},
booktitle = {Handbook of Agricultural Economics},
doi = {10.1016/S1574-0072(01)10005-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moschini, Hennessy - 2001 - Agricultural Production Uncertainty, Risk Aversion, and Risk Management for Agricultural producers.pdf:pdf},
isbn = {9780444507280},
issn = {15740072},
keywords = {Q12},
pages = {88--153},
title = {{Agricultural Production: Uncertainty, Risk Aversion, and Risk Management for Agricultural producers}},
url = {http://www.sciencedirect.com/science/article/pii/S1574007201100058},
volume = {1},
year = {2001}
}
@article{Chatelin1982,
author = {Chatelin, F and Miranker, W L},
journal = {Linear Algebra and Applications},
title = {{Acceleration by aggregation of successive approximation method}},
volume = {43},
year = {1982}
}
@inproceedings{Roy2003,
author = {Roy, Nicholas and Gordon, Geoffrey},
booktitle = {Uncertainty in Artificial Intelligence},
title = {{Exponential family PCA for belief compression in POMDPs}},
year = {2003}
}
@article{Xu2012,
author = {Xu, Huan and Mannor, Shie},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Mannor - 2012 - Distributionally Robust Markov Decision Processes.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {2},
pages = {288--300},
title = {{Distributionally robust Markov decision processes}},
volume = {37},
year = {2012}
}
@inproceedings{Malioutov2014,
author = {Malioutov, Dmitry and Slavov, Nikolai},
booktitle = {International Conference of Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malioutov, Slavov - 2014 - Convex Total Least Squares.pdf:pdf},
title = {{Convex Total Least Squares}},
url = {http://arxiv.org/abs/1406.0189},
year = {2014}
}
@article{Ben-Tal2013,
author = {Ben-Tal, Aharon and den Hertog, Dick and Waegenaere, Anja De and Melenberg, Bertrand and Renner, Gijs},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Tal et al. - 2013 - Robust Solutions of Optimization Problems Affected by Uncertain Probabilities Robust Solutions of Optimization P.pdf:pdf},
journal = {Management Science},
keywords = {-divergence,2011,2012,accepted december 16,advance november 9,by g{\'{e}}rard p,cachon,goodness-of-fit statistics,history,online in articles in,optimization,published,received april 20,robust optimization},
number = {2},
pages = {341--357},
title = {{Robust Solutions of Optimization Problems Affected by Uncertain Probabilities}},
volume = {59},
year = {2013}
}
@article{Hostetler2012,
author = {Hostetler, Jesse and Fern, Alan and Dietterich, Thomas},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hostetler, Fern, Dietterich - 2012 - Progressive Abstraction Refinement for Sparse Sampling.pdf:pdf},
isbn = {9780000000002},
title = {{Progressive Abstraction Refinement for Sparse Sampling}},
year = {2012}
}
@article{Ellner2006,
abstract = {Matrix projection models occupy a central role in population and conservation biology. Matrix models divide a population into discrete classes, even if the structuring trait exhibits continuous variation (e.g., body size). The integral projection model (IPM) avoids discrete classes and potential artifacts from arbitrary class divisions, facilitates parsimonious modeling based on smooth relationships between individual state and demographic performance, and can be implemented with standard matrix software. Here, we extend the IPM to species with complex demographic attributes, including dormant and active life stages, cross-classification by several attributes (e.g., size, age, and condition), and changes between discrete and continuous structure over the life cycle. We present a general model encompassing these cases, numerical methods, and theoretical results, including stable population growth and sensitivity/elasticity analysis for density-independent models, local stability analysis in density-dependent models, and optimal/evolutionarily stable strategy life-history analysis. Our presentation centers on an IPM for the thistle Onopordum illyricum based on a 6-year field study. Flowering and death probabilities are size and age dependent, and individuals also vary in a latent attribute affecting survival, but a predictively accurate IPM is completely parameterized by fitting a few regression equations. The online edition of the American Naturalist includes a zip archive of R scripts illustrating our suggested methods.A zip archive of R scripts illustrating our suggested methods is also provided.},
archivePrefix = {arXiv},
arxivId = {1547},
author = {Ellner, Stephen P. and Rees, Mark},
doi = {10.1086/499438},
eprint = {1547},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ellner, Rees - 2006 - Integral Projection Models for Species with Complex Demography.pdf:pdf},
isbn = {00030147},
issn = {0003-0147},
journal = {The American Naturalist},
keywords = {cornell,corresponding author,e-mail,edu,integral model,latent variability,matrix model,sen-,sitivity analysis,spe2,structured populations,thistle},
number = {3},
pages = {410--428},
pmid = {16673349},
title = {{Integral Projection Models for Species with Complex Demography}},
url = {http://www.journals.uchicago.edu/doi/10.1086/499438},
volume = {167},
year = {2006}
}
@article{Mahadevan2009,
author = {Mahadevan, Sridhar},
doi = {10.1561/2200000003},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahadevan - 2007 - Learning Representation and Control in Markov Decision Processes New Frontiers.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends� in Machine Learning},
number = {4},
pages = {403--565},
title = {{Learning Representation and Control: New Frontiers in Approximate Dynamic Programming}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000003},
volume = {1},
year = {2009}
}
@article{Nemirovski2006,
abstract = {. We consider a chance constrained problem, where one seeks to minimize a convex objective over solutions satisfying, with a given close to one probability, a system of randomly perturbed convex constraints. This problem may happen to be computationally intractable; our goal is to build its computationally tractable approximation, i.e., an efficiently solvable deterministic optimization program with the feasible set contained in the chance constrained problem. We construct a general class of such convex conservative approximations of the corresponding chance constrained problem. Moreover, under the assumptions that the constraints are affine in the perturbations and the entries in the perturbation vector are independent-of-each-other random variables, we build a large deviation-type approximation, referred to as Bernstein approximation, of the chance constrained problem. This approximation is convex and efficiently solvable. We propose a simulation-based scheme for bounding the optimal value in the chance constrained problem and report numerical experiments aimed at comparing the Bernstein and well-known scenario approximation approaches. Finally, we extend our construction to the case of ambiguous chance constrained problems, where the random perturbations are independent with the collection of distributions known to belong to a given convex compact set rather than to be known exactly, while the chance constraint should be satisfied for every distribution given by this set.},
author = {Nemirovski, Arkadi and Shapiro, Alexander},
doi = {10.1137/050622328},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nemirovski, Shapiro - 2006 - Convex approximations of chance constrained programs.pdf:pdf},
issn = {10526234},
journal = {SIAM Journal on Optimization},
keywords = {050622328,10,1137,90c15,90c25,90c59,ambiguous chance constrained programming,ams subject classifications,chance constraints,convex programming,doi,large deviation bounds,monte carlo,sampling,scenario generation,stochastic programming},
pages = {969--996},
title = {{Convex approximations of chance constrained programs}},
url = {http://link.aip.org/link/SJOPE8/v17/i4/p969/s1{\&}Agg=doi},
volume = {17},
year = {2006}
}
@misc{Kim2001,
author = {Kim, Sunyonga and Kojima, Masakazu},
booktitle = {Optimization Methods and Software},
doi = {10.1080/10556780108805819},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Kojima - 2001 - Second order cone programming relaxation of nonconvex quadratic optimization problems.pdf:pdf},
isbn = {1055-6788},
issn = {1055-6788},
keywords = {abstract a disadvantage of,been visiting tokyo institute,convex quadratic program,global optimization,lift-and-project convex relaxation method,non-,of technol-,primal-dual interior-point method,relaxation method for,second-order-cone program,semide nite programming,the sdp,this work was done,while this author has},
title = {{Second order cone programming relaxation of nonconvex quadratic optimization problems}},
year = {2001}
}
@inproceedings{Poupart2004,
author = {Poupart, Pascal and Boutilier, Craig},
booktitle = {Advances in Neural Information Processing Systems},
title = {{VDCBPI: an Approximate Scalable Algorithm for Large Scale POMDPs}},
year = {2004}
}
@article{Blum1992,
author = {Blum, AL and Rivest, RL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blum, Rivest - 1992 - Training a 3-node neural network is NP-complete.pdf:pdf},
journal = {Neural Networks},
title = {{Training a 3-node neural network is NP-complete}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608005800103},
year = {1992}
}
@article{Glen1987,
annote = {Thorough literature overview},
author = {Glen, J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glen - 1987 - Mathematical models in farm planning A survey.pdf:pdf},
journal = {Operations Research},
number = {5},
pages = {641--666},
title = {{Mathematical models in farm planning: A survey}},
url = {http://or.journal.informs.org/content/35/5/641.short},
volume = {35},
year = {1987}
}
@phdthesis{Woerner2010,
author = {Woerner, Stefan},
school = {ETH},
title = {{Approximate Parametric Dynamic Programing in Inventory Management}},
year = {2010}
}
@book{Shapiro2014,
abstract = {Optimization problems involving stochastic models occur in almost all areas of science and engineering, such as telecommunications, medicine, and finance. Their existence compels a need for rigorous ways of formulating, analyzing, and solving such problems. This book focuses on optimization problems involving uncertain parameters and covers the theoretical foundations and recent advances in areas where stochastic models are available. Readers will find coverage of the basic concepts of modeling these problems, including recourse actions and the nonanticipativity principle. The book also includes the theory of two-stage and multistage stochastic programming problems; the current state of the theory on chance (probabilistic) constraints, including the structure of the problems, optimality theory, and duality; and statistical inference in and risk-averse approaches to stochastic programming.},
author = {Shapiro, A. and Dentcheva, D. and Ruszczynski, A.},
doi = {http://dx.doi.org/10.1137/1.9780898718751},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro, Dentcheva, Ruszczynski - 2014 - Lectures on stochastic programming Modeling and theory.pdf:pdf},
isbn = {089871687X},
issn = {01676377},
pages = {447},
pmid = {15776329},
title = {{Lectures on stochastic programming: Modeling and theory}},
year = {2014}
}
@book{Hefferon2017,
author = {Hefferon, Jim},
edition = {3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hefferon - 2017 - Linear algebra.pdf:pdf},
title = {{Linear algebra}},
year = {2017}
}
@article{Pilanci2014a,
archivePrefix = {arXiv},
arxivId = {1411.0347v1},
author = {Pilanci, Mert and Wainwright, Martin J.},
eprint = {1411.0347v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pilanci, Wainwright - 2014 - Iterative Hessian sketch Fast and accurate solution approximation for constrained least-squares.pdf:pdf},
number = {1},
pages = {1--33},
title = {{Iterative Hessian sketch : Fast and accurate solution approximation for constrained least-squares}},
year = {2014}
}
@article{Allen2016b,
abstract = {a b s t r a c t Available online xxxx Identifying invasion risk is critical for regional prioritization of management and monitoring, however, we cur-rently lack a comprehensive assessment of the invasion risk posed by plants for the United States. We aim to quantify geographic invasion risk for currently established terrestrial invasive plants in the continental U.S. under current and future climate. We assembled a comprehensive occurrence database for 896 terrestrial inva-sive plant species from 33 regional collections of field and museum data and projected species ranges using MaxEnt species distribution models based on current (1950–2000 average) and future (2040–2060 average) cli-mate. We quantified geographic invasion risk as differences in species richness, invasion debt, range infilling, and identification of hotspots. Potential invasive plant richness was higher than observed richness, particularly in eastern temperate forests, where as many as 83{\%} of species with suitable climate have not yet established. A small percentage (median = 0.22{\%}) of species' potential ranges are currently occupied by them. With climate change, potential invasive plant richness declined by a median of 7.3{\%} by 2050. About 80{\%} of invasive plant hotspots were geographically stable with climate change, with the remaining 20{\%} shifting northward. Invasion hotspots and current invasion debt reveal extensive, ongoing risk from existing invasive plants across the U.S., particularly in the Southeast. Climate change alters the spatial distributions of focal species for monitoring and is likely to reduce overall invasion risk in many areas. Early detection and rapid response programs could be most effective in stemming the spread of invasive plant species in areas with increased risk under climate change, while areas with persistent high risk are candidates for containment and control. The areas with reduced risk are prime locations for invasion of new imports from tropical and subtropical climates, highlighting the simultaneous need for prevention strategies.},
author = {Allen, Jenica M and Bradley, Bethany A},
doi = {10.1016/j.biocon.2016.09.015},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Bradley - 2016 - Out of the weeds Reduced plant invasion risk with climate change in the continental United States.pdf:pdf},
journal = {Biological Conservation},
keywords = {Biodiversity,Conservation biology,Invasion debt,Invasive plant management,Invasive species,Species richness},
pages = {306--312},
title = {{Out of the weeds? Reduced plant invasion risk with climate change in the continental United States}},
volume = {203},
year = {2016}
}
@book{James2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1007/978-1-4614-7138-7},
eprint = {arXiv:1011.1669v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/James et al. - 2013 - An introduction to Statistical Learning.pdf:pdf},
isbn = {978-1-4614-7137-0},
issn = {0929-8673},
pmid = {10911016},
title = {{An introduction to Statistical Learning}},
year = {2013}
}
@inproceedings{Smith2005,
author = {Smith, Trey and Simmons, Reid},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Simmons - 2012 - Point-based POMDP algorithms Improved analysis and implementation.pdf:pdf},
title = {{Point-based POMDP algorithms: Improved analysis and implementation}},
url = {http://arxiv.org/abs/1207.1412},
year = {2005}
}
@book{Witha,
author = {Chailloux, Emmanuel and Manoury, Pascal and Pagano, Bruno},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chailloux, Manoury, Pagano - 2000 - Developing Applications with Objective Caml.pdf:pdf},
isbn = {2841771210},
title = {{Developing Applications with Objective Caml}},
year = {2000}
}
@article{Provost2000,
author = {Provost, Foster and Domingos, Pedro},
doi = {10.1.1.33.309},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Provost, Domingos - 2000 - Well-Trained PETs Improving probability estimation trees.pdf:pdf},
isbn = {CDER Working Paper {\#}00-04-IS},
journal = {CDER Working Paper {\#}00-04-IS},
number = {0},
pages = {1--24},
title = {{Well-Trained PETs: Improving probability estimation trees}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.309},
year = {2000}
}
@article{Candes2009,
annote = {See also the new and improved version at:


Recht, B. (2011). A simpler approach to matrix completion. The Journal of Machine Learning Research, 1–13. Retrieved from http://dl.acm.org/citation.cfm?id=2185803},
author = {Cand{\`{e}}s, EJ and Recht, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Recht - 2009 - Exact matrix completion via convex optimization.pdf:pdf},
journal = {Foundations of Computational mathematics},
keywords = {compressed sensing,convex optimization,decou-,duality in optimiza-,low-rank matrices,matrix completion,noncommutative khintchine inequality,nuclear norm minimization,pling,random matrices,tion},
number = {m},
pages = {1--49},
title = {{Exact matrix completion via convex optimization}},
url = {http://link.springer.com/article/10.1007/s10208-009-9045-5},
year = {2009}
}
@inproceedings{Madani2002,
author = {Madani, Omid},
booktitle = {AAAI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madani - 2002 - On policy iteration as a Newton's method and polynomial policy iteration algorithms.pdf:pdf},
pages = {273--278},
title = {{On policy iteration as a Newton's method and polynomial policy iteration algorithms}},
url = {http://www.aaai.org/Papers/AAAI/2002/AAAI02-042.pdf},
year = {2002}
}
@article{Paulovich2009,
abstract = {The problem of projecting multidimensional data into lower dimensions has been pursued by many researchers due to its potential application to data analysis of various kinds. This paper presents a novel multidimensional projection technique based on least square approximations. The approximations compute the coordinates of a set of projected points based on the coordinates of a reduced number of control points with defined geometry. We name the technique Least Square Projections (LSP). From an initial projection of the control points, LSP defines the positioning of their neighboring points through a numerical solution that aims at preserving a similarity relationship between the points given by a metric in mD. In order to perform the projection, a small number of distance calculations is necessary and no repositioning of the points is required to obtain a final solution with satisfactory precision. The results show the capability of the technique to form groups of points by degree of similarity in 2D. We illustrate that capability through its application to mapping collections of textual documents from varied sources, a strategic yet difficult application. LSP is faster and more accurate than other existing high quality methods, particularly where it was mostly tested, that is, for mapping text sets.},
author = {Paulovich, Fernando V and Nonato, Luis G and Minghim, Rosane and Levkowitz, Haim},
doi = {10.1109/TVCG.2007.70443},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulovich et al. - 2009 - Least square projection a fast high-precision multidimensional projection technique and its application to doc.pdf:pdf},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
keywords = {Algorithms,Computer Graphics,Databases, Factual,Documentation,Documentation: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Least-Squares Analysis,Pattern Recognition, Automated,Pattern Recognition, Automated: methods},
number = {3},
pages = {564--75},
pmid = {18369264},
title = {{Least square projection: a fast high-precision multidimensional projection technique and its application to document mapping.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18369264},
volume = {14},
year = {2009}
}
@article{Li2010b,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.0146v2},
author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
doi = {10.1145/1772690.1772758},
eprint = {arXiv:1003.0146v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2010 - A contextual-bandit approach to personalized news article recommendation.pdf:pdf},
isbn = {9781605587998},
issn = {1605587990},
journal = {Proceedings of the 19th international conference on World wide web},
keywords = {contextual bandit,exploitation dilemma,exploration,personalization,recommender sys-,tems,web service},
pages = {661--670},
title = {{A contextual-bandit approach to personalized news article recommendation}},
year = {2010}
}
@article{Juditsky2010,
author = {Juditsky, Anatoli and Karzan, Fatma Kilinc and Nemirovski, Arkadi},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Juditsky, Karzan, Nemirovski - 2010 - Verifiable conditions of l1 recovery for sparse signals with sign restrictions.pdf:pdf},
title = {{Verifiable conditions of l1 recovery for sparse signals with sign restrictions}},
year = {2010}
}
@article{Haslum2008,
author = {Haslum, Patrik and Helmert, Malte},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haslum, Helmert - 2008 - Abstraction Heuristics for Planning PDBs and Beyond.pdf:pdf},
title = {{Abstraction Heuristics for Planning : PDBs and Beyond}},
year = {2008}
}
@article{Almudevar2008,
author = {Almudevar, Anthony},
doi = {10.1137/S0363012904441520},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Almudevar - 2008 - Approximate Fixed Point Iteration with an Application to Infinite Horizon Markov Decision Processes.pdf:pdf},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
keywords = {contraction mappings,dynamic programming,fixed point,markov decision pro-},
number = {5},
pages = {2303--2347},
title = {{Approximate Fixed Point Iteration with an Application to Infinite Horizon Markov Decision Processes}},
volume = {47},
year = {2008}
}
@techreport{Lansford1983,
author = {Lansford, RR and Sammis, TS and McGuckin, JT and Deinter, R},
booktitle = {{\ldots} Research Institute Report},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lansford et al. - 1983 - Irrigated agricultural decision strategies for variable weather conditions.pdf:pdf},
title = {{Irrigated agricultural decision strategies for variable weather conditions}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Irrigated+Agricultural+Decision+Strategies+for+Variable+Weather+Conditions{\#}0},
year = {1983}
}
@book{Byrne1972,
editor = {Byrne, George D and Hall, Charles A},
title = {{Numerical solutions of systems of algebraic equations}},
year = {1972}
}
@inproceedings{Ng,
annote = {Just does common random numbers},
author = {Ng, AY and Jordan, Michael},
booktitle = {Uncertainty in Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng, Jordan - 2000 - PEGASUS A policy search method for large MDPs and POMDPs.pdf:pdf},
title = {{PEGASUS: A policy search method for large MDPs and POMDPs}},
url = {http://dl.acm.org/citation.cfm?id=2073994},
year = {2000}
}
@article{Schweitzer1985,
author = {Schweitzer, Paul J and Seidmann, Abraham},
journal = {Journal of Mathematical Analysis and Applications},
pages = {568--582},
title = {{Generalized polynomial approximations In Markovian decision processes}},
volume = {110},
year = {1985}
}
@article{Lipman1995,
author = {Lipman, BL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lipman - 1995 - Information processing and bounded rationality a survey.pdf:pdf},
journal = {Canadian Journal of Economics},
title = {{Information processing and bounded rationality: a survey}},
url = {http://www.jstor.org/stable/10.2307/136022},
year = {1995}
}
@book{Boyd2004,
address = {Cambridge},
author = {Boyd, Stephen and Vandenberghe, Lieven},
doi = {10.1017/CBO9780511804441},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd, Vandenberghe - 2004 - Convex Optimization.pdf:pdf},
isbn = {9780511804441},
publisher = {Cambridge University Press},
title = {{Convex Optimization}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511804441},
year = {2004}
}
@inproceedings{Osband2014,
abstract = {We propose randomized least-squares value iteration (RLSVI) -- a new reinforcement learning algorithm designed to explore and generalize efficiently via linearly parameterized value functions. We explain why versions of least-squares value iteration that use Boltzmann or {\$}\backslashepsilon{\$}-greedy exploration can be highly inefficient, and we present computational results that demonstrate dramatic efficiency gains enjoyed by RLSVI. Further, we establish an upper bound on the expected regret of RLSVI that demonstrates near-optimality in a tabula rasa learning context. More broadly, our results suggest that randomized value functions offer a promising approach to tackling a critical challenge in reinforcement learning: synthesizing efficient exploration and effective generalization.},
archivePrefix = {arXiv},
arxivId = {1402.0635},
author = {Osband, Ian and {Van Roy}, Benjamin and Wen, Zheng},
booktitle = {International Conference of Machine Learning},
eprint = {1402.0635},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Osband, Van Roy, Wen - 2016 - Generalization and Exploration via Randomized Value Functions.pdf:pdf},
title = {{Generalization and Exploration via Randomized Value Functions}},
url = {http://arxiv.org/abs/1402.0635},
year = {2016}
}
@article{Valtorta1984,
author = {Valtorta, M},
journal = {Information Sciences},
pages = {48--59},
title = {{A result on the computational complexity of heuristic estimates for the A* algorithm}},
volume = {34},
year = {1984}
}
@article{Farahmand2011a,
author = {Farahmand, Amir-massoud and Szepesv{\'{a}}ri, Csaba},
doi = {10.1007/s10994-011-5254-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farahmand, Szepesv{\'{a}}ri - 2011 - Model selection in reinforcement learning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farahmand, Szepesv{\'{a}}ri - 2011 - Model selection in reinforcement learning(2).pdf:pdf},
isbn = {1099401152547},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {adaptivity,complexity regularization,finite-sample bounds,model selection,off-policy learning,offline learning,reinforcement learning},
month = {jun},
number = {3},
pages = {299--332},
title = {{Model selection in reinforcement learning}},
url = {http://link.springer.com/10.1007/s10994-011-5254-7 http://www.ualberta.ca/{~}szepesva/papers/RLModelSelect.pdf{\%}5Cnhttp://link.springer.com/article/10.1007/s10994-011-5254-7},
volume = {85},
year = {2011}
}
@article{Wang2007a,
abstract = {Markov decision processes capture sequential decision making under uncertainty, where an agent must choose actions so as to optimize long term reward. The paper studies efficient reasoning mechanisms for Relational Markov Decision Processes (RMDP) where world states have an internal relational structure that can be naturally described in terms of objects and relations among them. Two contributions are presented. First, the paper develops First Order Decision Diagrams (FODD), a new compact representation for functions over relational structures, together with a set of operators to combine FODDs, and novel reduction techniques to keep the representation small. Second, the paper shows how FODDs can be used to develop solutions for RMDPs, where reasoning is performed at the abstract level and the resulting optimal policy is independent of domain size (number of objects) or instantiation. In particular, a variant of the value iteration algorithm is developed by using special operations over FODDs, and the algorithm is shown to converge to the optimal policy.},
author = {Wang, Chenggang and Joshi, Saket and Khardon, Roni},
doi = {10.1613/jair.2489},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Joshi, Khardon - 2007 - First order decision diagrams for relational MDPs.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1095--1100},
title = {{First order decision diagrams for relational MDPs}},
volume = {31},
year = {2007}
}
@article{Dudik2011,
abstract = {We address the problem of learning in an online setting where the learner repeatedly observes features, selects among a set of actions, and receives reward for the action taken. We provide the first efficient algorithm with an optimal regret. Our algorithm uses a cost sensitive classification learner as an oracle and has a running time {\$}\backslashmathrm{\{}polylog{\}}(N){\$}, where {\$}N{\$} is the number of classification rules among which the oracle might choose. This is exponentially faster than all previous algorithms that achieve optimal regret in this setting. Our formulation also enables us to create an algorithm with regret that is additive rather than multiplicative in feedback delay as in all previous work.},
archivePrefix = {arXiv},
arxivId = {1106.2369},
author = {Dudik, Miroslav and Hsu, Daniel and Kale, Satyen},
eprint = {1106.2369},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dudik, Hsu, Kale - 2011 - Efficient optimal learning for contextual bandits.pdf:pdf},
journal = {arXiv preprint arXiv: {\ldots}},
month = {jun},
title = {{Efficient optimal learning for contextual bandits}},
url = {http://arxiv.org/abs/1106.2369},
year = {2011}
}
@article{Satia1973,
abstract = {This paper examines Markovian decision processes in which the transition probabilities corresponding to alternative decisions are not known with cer- tainty. The processes are assumed to be finite-state, discrete-time, and stationary. The rewards are time discounted. Both a game-theoretic and the Bayesian formulation are considered. In the game-theoretic formula- tion, variants of a policy-iteration algorithm are provided for both the max-min and the max-max cases. An implicit enumeration algorithm is discussed for the Bayesian formulation where upper and lower bounds on the total expected discounted return are provided by the max-max and max-min optimal policies. Finally, the paper discusses asymptotically Bayes-optimal policies},
author = {Satia, JK and Lave, RE},
journal = {Operations Research},
pages = {728--740},
title = {{Markovian decision processes with uncertain transition probabilities}},
url = {http://www.jstor.org/stable/10.2307/169381},
volume = {21},
year = {1973}
}
@inproceedings{Nouri2009,
annote = {From Duplicate 1 ( 


Multi-resolution Exploration in Continuous Spaces


- Nouri, Ali; Littman, Michael L )

},
author = {Nouri, Ali and Littman, Michael L},
booktitle = {NIPS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nouri, Littman - 2009 - Multi-resolution Exploration in Continuous Spaces.pdf:pdf},
title = {{Multi-resolution Exploration in Continuous Spaces}},
year = {2009}
}
@inproceedings{Seuken2007,
author = {Seuken, Sven and Zilberstein, Shlomo},
booktitle = {International Joint Conference on Artificial Intelligence},
pages = {2009--2016},
title = {{Memory bounded dynamic programming for {\{}DEC-POMDP{\}}s}},
year = {2007}
}
@article{Ba2015,
abstract = {Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.06812v1},
author = {Ba, Jimmy and Grosse, Roger and Salakhutdinov, Ruslan and Frey, Brendan},
eprint = {arXiv:1509.06812v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ba et al. - 2015 - Learning Wake-Sleep Recurrent Attention Models.pdf:pdf},
issn = {10495258},
journal = {Nips},
keywords = {Attention Model,RNN},
pages = {1--9},
title = {{Learning Wake-Sleep Recurrent Attention Models}},
url = {http://arxiv.org/pdf/1509.06812v1.pdf},
year = {2015}
}
@incollection{Farias2006,
author = {Farias, Vivek F and {Van Roy}, Benjamin},
chapter = {6: Tetris:},
title = {{Probabilistic and Randomized Methods for Design Under Uncertainty}},
year = {2006}
}
@article{Tseng1999,
author = {Tseng, P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tseng - 1999 - Convergence and error bound for perturbation of linear programs.pdf:pdf},
journal = {Computational Optimization and Applications},
title = {{Convergence and error bound for perturbation of linear programs}},
url = {http://link.springer.com/article/10.1023/A:1008625410523},
year = {1999}
}
@inproceedings{Keller2006,
address = {New York, New York, USA},
annote = {See also:
Farahmand, A., {\&} Szepesv{\'{a}}ri, C. (2011). Model selection in reinforcement learning. Machine Learning (Vol. 85, pp. 299–332). doi:10.1007/s10994-011-5254-7Farahmand, A., {\&} Szepesv{\'{a}}ri, C. ( 

Bertsekas, D. P. D., {\&} Castanon, D. A. (1989). Adaptive aggregation methods for infinite horizon dynamic programming. IEEE Transations on Automatic Control, 34, 589–598. Retrieved from http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=24227},
author = {Keller, Philipp W. and Manor, Shie and Precup, Doina},
booktitle = {International Conference on Machine Learning},
doi = {10.1145/1143844.1143901},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keller, Manor, Precup - 2006 - Automatic basis function construction for approximate dynamic programming and reinforcement learning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keller, Mannor, Precup - 2006 - Automatic basis function construction for approximate dynamic programming and reinforcement learning.pdf:pdf},
isbn = {1595933832},
pages = {449--456},
publisher = {ACM Press},
title = {{Automatic basis function construction for approximate dynamic programming and reinforcement learning}},
url = {http://portal.acm.org/citation.cfm?doid=1143844.1143901},
year = {2006}
}
@article{Perkins2002,
author = {Perkins, Theodore J},
journal = {Journal of Machine Learning Research},
pages = {803--823},
title = {{Lyapunov design for safe reinforcement learning}},
volume = {3},
year = {2002}
}
@inproceedings{Desai2009,
author = {Desai, Vijay and Farias, Vivek and Moallemi, Ciamac},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {459--467},
title = {{A Smoothed approximate linear program}},
year = {2009}
}
@article{Shortreed2011,
abstract = {This paper highlights the role that reinforcement learning can play in the optimization of treatment policies for chronic illnesses. Before applying any off-the-shelf reinforcement learning methods in this setting, we must first tackle a number of challenges. We outline some of these challenges and present methods for overcoming them. First, we describe a multiple imputation approach to overcome the problem of missing data. Second, we discuss the use of function approximation in the context of a highly variable observation set. Finally, we discuss approaches to summarizing the evidence in the data for recommending a particular action and quantifying the uncertainty around the Q-function of the recommended policy. We present the results of applying these methods to real clinical trial data of patients with schizophrenia.},
author = {Shortreed, Susan M. and Laber, Eric and Lizotte, Daniel J. and Stroup, T. Scott and Pineau, Joelle and Murphy, Susan A.},
doi = {10.1007/s10994-010-5229-0},
file = {:home/marek/Downloads/s10994-010-5229-0.pdf:pdf},
isbn = {0885-6125 (Print)$\backslash$r0885-6125 (Linking)},
issn = {08856125},
journal = {Machine Learning},
keywords = {Fitted Q-iteration,Optimal treatment policies,Policy uncertainty},
number = {1-2},
pages = {109--136},
pmid = {21799585},
title = {{Informing sequential clinical decision-making through reinforcement learning: An empirical study}},
volume = {84},
year = {2011}
}
@inproceedings{Haslum2007,
author = {Haslum, Patrik and Botea, Adi and Helmert, Malte and Bonet, Blai and Koenig, Sven},
booktitle = {National Conference on Artificial Intelligence},
title = {{Domain-independent construction of pattern database heuristics for cost-optimal planning}},
year = {2007}
}
@inproceedings{Edelkamp2002,
author = {Edelkamp, Stefan},
booktitle = {AIPS},
title = {{Symbolic pattern databases in heuristic search planning}},
year = {2002}
}
@article{Whittle1980,
annote = {I think that this paper essentially defines a value function for the Gittins policy.

Is the gittins index of the best arm essentially the value of the process?},
author = {Whittle, P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whittle - 1980 - Multi-armed bandits and the Gittins index.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B},
number = {2},
pages = {143--149},
title = {{Multi-armed bandits and the Gittins index}},
url = {http://www.jstor.org/stable/2984953},
volume = {42},
year = {1980}
}
@article{Hernandez-Lerma2000,
author = {Hern{\'{a}}ndez-Lerma, O and Lasserre, JB},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hern{\'{a}}ndez-Lerma, Lasserre - 2000 - Zero-sum stochastic games in Borel spaces average payoff criteria.pdf:pdf},
journal = {SIAM Journal on Control and Optimization},
keywords = {90d10,90d15,93e05,ams subject classifications,average payoff,borel spaces,expected average payoff,pii,s0363012999361962,sample-path,shapley equations,zero-sum stochastic games},
number = {5},
pages = {1520--1539},
title = {{Zero-sum stochastic games in Borel spaces: average payoff criteria}},
url = {http://epubs.siam.org/doi/pdf/10.1137/S0363012999361962},
volume = {39},
year = {2000}
}
@article{Seuken2000,
author = {Seuken, Sven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seuken - 2000 - Memory-Bounded Dynamic Programming for DEC-POMDPs.pdf:pdf},
title = {{Memory-Bounded Dynamic Programming for DEC-POMDPs}},
year = {2000}
}
@article{Delage2009,
author = {Delage, E. and Mannor, S.},
doi = {10.1287/opre.1080.0685},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delage, Mannor - 2010 - Percentile Optimization for Markov Decision Processes with Parameter Uncertainty.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {aug},
number = {1},
pages = {203--213},
title = {{Percentile Optimization for Markov Decision Processes with Parameter Uncertainty}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1080.0685},
volume = {58},
year = {2010}
}
@article{James2012,
author = {James, Gareth M and Paulson, Courtney and Rusmevichientong, Paat},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/James, Paulson, Rusmevichientong - 2012 - The constrained lasso.pdf:pdf},
title = {{The constrained lasso}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.8795{\&}rep=rep1{\&}type=pdf},
year = {2012}
}
@article{Wagner2011,
abstract = {A majority of approximate dynamic programming approaches to the reinforce- ment learning problem can be categorized into greedy value function methods and value-based policy gradient methods. The former approach, although fast, is well known to be susceptible to the policy oscillation phenomenon. We take a fresh view to this phenomenon by casting a considerable subset of the former approach as a limiting special case of the latter. We explain the phenomenon in terms of this view and illustrate the underlying mechanism with artificial examples. We also use it to derive the constrained natural actor-critic algorithm that can interpolate between the aforementioned approaches. In addition, it has been suggested in the literature that the oscillation phenomenon might be subtly connected to the grossly suboptimal performance in the Tetris benchmark problem of all attempted approx- imate dynamic programming methods. We report empirical evidence against such a connection and in favor of an alternative explanation. Finally, we report scores in the Tetris problem that improve on existing dynamic programming based results.},
author = {Wagner, Paul},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wagner - 2011 - A reinterpretation of the policy oscillation phenomenon in approximate policy iteration.pdf:pdf},
isbn = {9781618395993},
journal = {Conference on Neural Information Processing Systems},
pages = {1--9},
title = {{A reinterpretation of the policy oscillation phenomenon in approximate policy iteration}},
year = {2011}
}
@article{Vandenberghe2011a,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 05. Smoothing.pdf:pdf},
issn = {1050-9135},
journal = {LECTURE NOTES},
month = {nov},
number = {11},
pages = {52--3},
title = {{05. Smoothing}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
volume = {27},
year = {2011}
}
@article{Bradley2009,
author = {Bradley, BETHANY A. and Oppenheimer, MICHAEL and Wilcove, DAVID S.},
doi = {10.1111/j.1365-2486.2008.01824.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {conservation,invasives},
mendeley-tags = {conservation,invasives},
month = {jun},
number = {6},
pages = {1511--1521},
title = {{Climate change and plant invasions: restoration opportunities ahead?}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2008.01824.x},
volume = {15},
year = {2009}
}
@article{Bocsi2016,
author = {Bocsi, Tierney and Allen, Jenica M. and Bellemare, Jesse and Kartesz, John and Nishino, Misako and Bradley, Bethany A.},
doi = {10.1111/ddi.12432},
issn = {13669516},
journal = {Diversity and Distributions},
title = {{Plants' native distributions do not reflect climatic tolerance}},
url = {http://doi.wiley.com/10.1111/ddi.12432},
volume = {Forthcomin},
year = {2016}
}
@article{Loan2000,
author = {Loan, CFV},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Loan - 2000 - The ubiquitous Kronecker product.pdf:pdf},
journal = {Journal of Computational and Applied Mathematics},
title = {{The ubiquitous Kronecker product}},
url = {http://www.sciencedirect.com/science/article/pii/S0377042700003939},
year = {2000}
}
@book{Conrad2010,
abstract = {A 2010 text for students with a background in calculus and intermediate microeconomics and a familiarity with the spreadsheet software Excel.},
author = {Conrad, Jon M},
doi = {10.1037/023990},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Conrad - 2010 - Resource Economics.pdf:pdf},
isbn = {9780521697675},
issn = {01232665},
pages = {285},
pmid = {393307},
title = {{Resource Economics}},
url = {http://books.google.com/books?id=rK69vprlJwwC{\&}pg=PA75{\&}dq=intitle:Resource+Economics+inauthor:Conrad{\&}hl={\&}cd=1{\&}source=gbs{\_}api},
year = {2010}
}
@article{Zipkin1980,
annote = {From Duplicate 2 ( Bounds for Row-Aggregation in Linear Programming - Zipkin, Paul H; Aug, No Jul )
},
author = {Zipkin, Paul H and Aug, No Jul},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zipkin, Aug - 2007 - Bounds for Row-Aggregation in Linear Programming.pdf:pdf},
journal = {Operations Research},
number = {4},
pages = {903--916},
title = {{Bounds for row-aggregation in linear programming}},
volume = {28},
year = {1980}
}
@article{Wardlow2007,
annote = {Combine MODIS and LANDSAT covers.

Argues that MODIS (at 250m) can be actually useful for some kind of crop identification. 

No specific method, just a general analysis of separability of the data.},
author = {Wardlow, B and Egbert, S and Kastens, J},
doi = {10.1016/j.rse.2006.11.021},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wardlow, Egbert, Kastens - 2007 - Analysis of time-series MODIS 250 m vegetation index data for crop classification in the U.S. Central.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
month = {jun},
number = {3},
pages = {290--310},
title = {{Analysis of time-series MODIS 250 m vegetation index data for crop classification in the U.S. Central Great Plains}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0034425706004949},
volume = {108},
year = {2007}
}
@article{Cheridito2009,
abstract = {We show that VaR (Value-at-Risk) is not time-consistent and discuss examples where this can lead to dynamically inconsistent behavior. Then we propose two time-consistent alternatives to VaR. The first one is a composition of one-period VaR's. It is time-consistent but not coherent. The second one is a composition of average VaR's. It is a time-consistent coherent risk measure. ?? 2008 Elsevier Inc. All rights reserved.},
author = {Cheridito, Patrick and Stadje, Mitja},
doi = {10.1016/j.frl.2008.10.002},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheridito, Stadje - 2009 - Time-inconsistency of VaR and time-consistent alternatives.pdf:pdf},
issn = {15446123},
journal = {Finance Research Letters},
keywords = {Composed Value-at-Risk,Composed average Value-at-Risk,Time-consistency,Value-at-Risk},
number = {1},
pages = {40--46},
title = {{Time-inconsistency of VaR and time-consistent alternatives}},
volume = {6},
year = {2009}
}
@article{Mangasarian1981,
author = {Mangasarian, O L and Journal, Siam and Aug, No},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangasarian, Journal, Aug - 2007 - Iterative Solution of Linear Programs.pdf:pdf},
journal = {SIAM Journal on Numerical Analysis},
number = {4},
pages = {606--614},
title = {{Iterative Solution of Linear Programs}},
volume = {18},
year = {1981}
}
@article{Bradley2016,
abstract = {Context Understanding and predicting the spatial patterns of species abundance is a critical need in macroecology. But, widespread abundance data are rare, and habitat models based on species occurrences are typically poor predictors of abundance. Objectives I ask whether presence-only species distribution models based on locations of high species abundance can more effectively predict abundance than models based on occurrences. Methods I created climatic suitability models for fifteen problematic, non-native, invasive plants in the continental US using each of three datasets (1) occurrence data derived from herbarium records, (2) occurrence data derived from regional expert knowledge surveys, and (3) locations of high invasive plant abundance derived from regional expert knowledge surveys. Results Models based on occurrences from regional surveys were most effective for distinguishing presence from absence. Models based on locations of high abundance were most effective for characterizing both intermediate and high ranks of abundance. Occurrence data from herbarium records were poor predictors of both presence and abundance. Conclusions This analysis suggests that climate suitable for abundant populations is predictable with species distribution modeling, but not using distribution data alone. High probability of species occurrence does not equal high probability of species abundance, suggesting environmental factors differentially influence abundance and distribution. This difference highlights the need for a macrosystems approach to regional habitat modeling to consider how local-scale processes (e.g., biotic interactions) affect regional patterns. Moreover, as abundance is critical for understanding species roles and impacts on ecosystems, large-scale surveys of quantitative or qualitative species abundance are strongly needed.},
author = {Bradley, Bethany A.},
doi = {10.1007/s10980-015-0303-4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradley - 2016 - Predicting abundance with presence-only models.pdf:pdf},
isbn = {0921-2973},
issn = {15729761},
journal = {Landscape Ecology},
keywords = {Abundance,Abundant center,Bioclimatic envelope,Climatic suitability,Ecological niche,Habitat suitability,Invasion risk,Invasive plant,Maxent,Species distribution modeling},
number = {1},
pages = {19--30},
publisher = {Springer Netherlands},
title = {{Predicting abundance with presence-only models}},
volume = {31},
year = {2016}
}
@inproceedings{Kearns2000,
annote = {From Duplicate 1 ( Approximate planning in large {\{}POMDPs{\}} via reusable trajectories - Kearns, Michael; Mansour, Vishay; Ng, Andre Y )
},
author = {Kearns, Michael and Mansour, Vishay and Ng, Andre Y},
booktitle = {{\{}A{\}}dvances in {\{}N{\}}eural {\{}I{\}}nformation {\{}P{\}}rocessing {\{}S{\}}ystems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kearns, Mansour, Ng - 2000 - Approximate planning in large {\{}POMDPs{\}} via reusable trajectories.pdf:pdf},
title = {{Approximate planning in large POMDPs via reusable trajectories}},
year = {2000}
}
@article{Goldfarb2003,
annote = {From Duplicate 1 ( Robust convex quadratically constrained programs - Goldfarb, D; Iyengar, G )
},
author = {Goldfarb, D and Iyengar, G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldfarb, Iyengar - 2003 - Robust convex quadratically constrained programs.pdf:pdf},
journal = {Mathematical Programming},
pages = {495--515},
title = {{Robust convex quadratically constrained programs}},
url = {http://link.springer.com/article/10.1007/s10107-003-0425-3},
volume = {97},
year = {2003}
}
@article{Morton1971,
author = {Morton, Thomas E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morton - 1971 - On the Asymptotic Convergence Rate of Cost Differences for Markovian Decision Processes.pdf:pdf},
journal = {Operations Research},
number = {1},
pages = {244--248},
title = {{On the Asymptotic Convergence Rate of Cost Differences for Markovian Decision Processes}},
volume = {19},
year = {1971}
}
@article{Kazienko2007,
author = {Kazienko, P and Adamski, M},
doi = {10.1016/j.ins.2007.01.002},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazienko, Adamski - 2007 - AdROSA Adaptive personalization of web advertising.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {adaptive,advertising model,commerce,electronic,multi-agent system,online advertising,personalization,recommender system,system,user interface,web advertising,web content mining,web mining,web usage mining},
month = {jun},
number = {11},
pages = {2269--2295},
title = {{AdROSA: Adaptive personalization of web advertising}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025507000229},
volume = {177},
year = {2007}
}
@article{Serrao2005,
author = {Serrao, L. and Chehab, Z. and Guezennec, Y. and Rizzoni, G.},
doi = {10.1109/VPPC.2005.1554536},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serrao et al. - 2005 - An Aging Model of Ni-MH Batteries for Hybrid Electric Vehicles.pdf:pdf},
isbn = {0-7803-9280-9},
journal = {2005 IEEE Vehicle Power and Propulsion Conference},
pages = {78--85},
publisher = {Ieee},
title = {{An Aging Model of Ni-MH Batteries for Hybrid Electric Vehicles}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1554536},
year = {2005}
}
@inproceedings{Pirotta2013,
author = {Pirotta, Matteo and Restelli, Marcello and Calandriello, Daniele},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pirotta, Restelli, Calandriello - 2013 - Safe policy iteration.pdf:pdf},
title = {{Safe policy iteration}},
year = {2013}
}
@article{Sahoo,
annote = {Very good review of the literature

Uses HMM to model changing user preferences over time

Assumes that users change over time.},
author = {Sahoo, Nachiketa},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahoo - 2012 - A Hidden Markov Model for Collaborative Filtering.pdf:pdf},
journal = {MIS Quarterly},
number = {4},
pages = {1329--1356},
title = {{A Hidden Markov Model for Collaborative Filtering}},
volume = {36},
year = {2012}
}
@book{Pearl1984,
author = {Pearl, Judea},
publisher = {Addison-Wesley, Reading, MA},
title = {{Heristics}},
year = {1984}
}
@inproceedings{Dimitrakakis2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.3651v2},
author = {Dimitrakakis, Christos},
booktitle = {Recent Advances in Reinforcement Learning. EWRL 2011},
eprint = {arXiv:1106.3651v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dimitrakakis - 2012 - Robust Bayesian reinforcement learning through tight lower bounds.pdf:pdf},
title = {{Robust Bayesian reinforcement learning through tight lower bounds}},
year = {2012}
}
@inproceedings{Shafieezadeh-Abadeh2015,
abstract = {This paper proposes a distributionally robust approach to logistic regression. We use the Wasserstein distance to construct a ball in the space of probability distributions centered at the uniform distribution on the training samples. If the radius of this ball is chosen judiciously, we can guarantee that it contains the unknown data-generating distribution with high confidence. We then formulate a distributionally robust logistic regression model that minimizes a worst-case expected logloss function, where the worst case is taken over all distributions in the Wasserstein ball. We prove that this optimization problem admits a tractable reformulation and encapsulates the classical as well as the popular regularized logistic regression problems as special cases. We further propose a distributionally robust approach based on Wasserstein balls to compute upper and lower confidence bounds on the misclassification probability of the resulting classifier. These bounds are given by the optimal values of two highly tractable linear programs. We validate our theoretical out-of-sample guarantees through simulated and empirical experiments.},
archivePrefix = {arXiv},
arxivId = {1509.09259},
author = {Shafieezadeh-Abadeh, Soroosh and Esfahani, Peyman Mohajerin and Kuhn, Daniel},
booktitle = {Proceedings on Neural Information Processing Systems (NIPS)},
eprint = {1509.09259},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shafieezadeh-Abadeh, Esfahani, Kuhn - 2015 - Distributionally Robust Logistic Regression.pdf:pdf},
issn = {10495258},
title = {{Distributionally Robust Logistic Regression}},
url = {http://arxiv.org/abs/1509.09259},
year = {2015}
}
@article{Walawalkar2007,
abstract = {Unlike markets for storable commodities, electricity markets depend on the real-time balance of supply and demand. Although much of the present-day grid operates effectively without storage, cost-effective ways of storing electrical energy can help make the grid more efficient and reliable. We investigate the economics of two emerging electric energy storage (EES) technologies: sodium sulfur batteries and flywheel energy storage systems in New York state's electricity market. The analysis indicates that there is a strong economic case for EES installations in the New York City region for applications such as energy arbitrage, and that significant opportunities exist throughout New York state for regulation services. Benefits from deferral of system upgrades may be important in the decision to deploy EES. Market barriers currently make it difficult for energy-limited EES such as flywheels to receive revenue for voltage regulation. Charging efficiency is more important to the economics of EES in a competitive electricity market than has generally been recognized. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Walawalkar, Rahul and Apt, Jay and Mancini, Rick},
doi = {10.1016/j.enpol.2006.09.005},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Walawalkar, Apt, Mancini - 2007 - Economics of electric energy storage for energy arbitrage and regulation in New York.pdf:pdf},
isbn = {4122687357},
issn = {03014215},
journal = {Energy Policy},
keywords = {Electric energy storage,Electricity markets,Restructuring},
number = {4},
pages = {2558--2568},
title = {{Economics of electric energy storage for energy arbitrage and regulation in New York}},
volume = {35},
year = {2007}
}
@inproceedings{Lam2016,
abstract = {We consider the problem of optimizing an expensive objective function when a finite budget of total evaluations is prescribed. In that context, the optimal solution strategy for Bayesian optimization can be formulated as a dynamic programming instance. This results in a complex problem with uncountable, dimension-increasing state space and an uncountable control space. We show how to approximate the solution of this dynamic programming problem using rollout, and propose rollout heuristics specifically designed for the Bayesian optimization setting. We present numerical experiments showing that the resulting algorithm for optimization with a finite budget outperforms several popular Bayesian optimization algorithms.},
author = {Lam, Remi and Willcox, Karen and Wolpert, David H.},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lam, Willcox, Wolpert - 2016 - Bayesian Optimization with a Finite Budget An Approximate Dynamic Programming Approach.pdf:pdf},
pages = {883--891},
title = {{Bayesian Optimization with a Finite Budget: An Approximate Dynamic Programming Approach}},
url = {https://papers.nips.cc/paper/6188-bayesian-optimization-with-a-finite-budget-an-approximate-dynamic-programming-approach},
year = {2016}
}
@article{Goldman2008,
author = {Goldman, Claudia V and Zilberstein, Shlomo},
journal = {Journal of Artificial Intelligence Research},
pages = {169--202},
title = {{Communication-Based Decomposition Mechanisms for Decentralized MDPs}},
volume = {32},
year = {2008}
}
@book{Bertsekas1982,
author = {Bertsekas, Dimitri P},
title = {{Constrained Optimization and Lagrange Multiplier Methods}},
year = {1982}
}
@techreport{Shakhnarovich2009,
author = {Sham and Shakhnarovich, Greg},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sham, Shakhnarovich - 2009 - The Johnson-Lindenstrauss lemma.pdf:pdf},
number = {Spring},
pages = {2--5},
title = {{The Johnson-Lindenstrauss lemma}},
volume = {35900},
year = {2009}
}
@article{Werthner2004,
abstract = {Has e-commerce passed its prime or is it just resting? While business and stock market expectations have not been fulfilled, online transactions in the travel and tourism industry are continuously increasing despite tough economic problems in this arena and fewer travelers overall. This industry is the leading application in the B2C (business-to-consumer) arena. Whereas other industries are displaying a stronger hold to tradi-tional processes, the tourism industry is witnessing an acceptance of e-commerce to the extent that the entire industry structure is changing. The Web is used not only for information gathering, but also for order-ing services. A new type of user is emerging, one who acts as his or her own travel agent and builds a personalized travel package.},
author = {Werthner, Hannes and Ricci, Francesco},
doi = {10.1145/1035134.1035141},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Werthner, Ricci - 2004 - E-Commerce and Tourism.pdf:pdf},
isbn = {00010782},
issn = {00010782},
journal = {Communications of the Acm},
number = {12},
pages = {101--105},
pmid = {4742557},
title = {{E-Commerce and Tourism}},
url = {http://www.inf.unibz.it/{~}ricci/papers/werthnercacmvers2.pdf},
volume = {47},
year = {2004}
}
@phdthesis{Wang2007,
author = {Wang, Tao},
school = {University of Alberta, Canada},
title = {{New Representations and Approximations for Sequential Decision Making}},
year = {2007}
}
@inproceedings{Dietterich2002,
author = {Dietterich, Thomas G and Wang, Xin},
booktitle = {Advances in Neural Information Processing Systems},
title = {{Batch Value Function Approximation via Support Vectors}},
year = {2002}
}
@book{Grinstead,
author = {Grinstead, CM and Snell, JL},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grinstead, Snell - 1998 - Introduction to probability.pdf:pdf},
title = {{Introduction to probability}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=7ip55ODL72wC{\&}oi=fnd{\&}pg=PA1{\&}dq=Introduction+to+Probability{\&}ots=H{\_}ubCQrDeT{\&}sig=qtQ0lD{\_}LWzopTzsLVlWHyyIJnT4},
year = {1998}
}
@article{Bach2008,
author = {Bach, FR},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bach - 2008 - Consistency of trace norm minimization.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {consistency,convex optimization,singular value decomposition,trace norm},
pages = {1019--1048},
title = {{Consistency of trace norm minimization}},
url = {http://dl.acm.org/citation.cfm?id=1390716},
volume = {8},
year = {2008}
}
@inproceedings{Helmert2008a,
author = {Helmert, Malte and Mattmuller, Robert},
booktitle = {National Conference on Artificial Intelligence},
title = {{Accuracy of Admissible Heuristic Functions in Selected Planning Domains}},
year = {2008}
}
@misc{Varshney2016,
abstract = {—Machine learning algorithms are increasingly in-fluencing our decisions and interacting with us in all parts of our daily lives. Therefore, just like for power plants, highways, and myriad other engineered sociotechnical systems, we must consider the safety of systems involving machine learning. In this paper, we first discuss the definition of safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. Then we examine dimensions, such as the choice of cost function and the appropriateness of minimizing the empirical average training cost, along which certain real-world applications may not be completely amenable to the foundational principle of modern statistical machine learning: empirical risk minimization. In particular, we note an emerging dichotomy of applications: ones in which safety is important and risk minimization is not the complete story (we name these Type A applications), and ones in which safety is not so critical and risk minimization is sufficient (we name these Type B applications). Finally, we discuss how four different strategies for achieving safety in engineering (inherently safe design, safety reserves, safe fail, and procedural safeguards) can be mapped to the machine learning context through inter-pretability and causality of predictive models, objectives beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software.},
archivePrefix = {arXiv},
arxivId = {arXiv:1601.04126v1},
author = {Varshney, Kush R},
eprint = {arXiv:1601.04126v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Varshney - 2016 - Engineering Safety in Machine Learning.pdf:pdf},
keywords = {(),arXiv:1601.04126v1},
mendeley-tags = {arXiv:1601.04126v1},
title = {{Engineering Safety in Machine Learning}},
year = {2016}
}
@incollection{Lange2012,
archivePrefix = {arXiv},
arxivId = {1502.04623},
author = {Lange, Sasche and Gabel, Thomas and Riedmiller, Martin},
booktitle = {Reinforcement Learning},
doi = {10.1038/nature14236},
eprint = {1502.04623},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lange, Gabel, Riedmiller - 2012 - Batch Reinforcement Learning.pdf:pdf},
isbn = {978-1-4799-0356-6},
issn = {0028-0836},
keywords = {deep learning,unsupervised learning},
pages = {45--73},
pmid = {25719670},
title = {{Batch Reinforcement Learning}},
url = {http://arxiv.org/abs/1507.01526{\%}5Cnhttp://dx.doi.org/10.1007/978-3-642-27645-3{\_}2{\%}5Cnhttp://arxiv.org/abs/1112.6209{\%}5Cnhttp://arxiv.org/abs/1509.06461{\%}5Cnhttp://www.arxiv.org/pdf/1509.06461.pdf{\%}5Cnhttp://arxiv.org/abs/1511.06295{\%}5Cnhttp://arxiv.org/abs/151},
year = {2012}
}
@techreport{Hult2009,
author = {Hult, H and Svensson, J},
institution = {arxiv},
title = {{Efficient calculation of risk measures by importance sampling}},
url = {http://arxiv.org/PS{\_}cache/arxiv/pdf/0909/0909.3335v1.pdf},
year = {2009}
}
@article{Das1999,
author = {Das, T. K. and Gosavi, a. and Mahadevan, S. and Marchalleck, N.},
doi = {10.1287/mnsc.45.4.560},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Das et al. - 1999 - Solving Semi-Markov Decision Problems Using Average Reward Reinforcement Learning.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
month = {apr},
number = {4},
pages = {560--574},
title = {{Solving Semi-Markov Decision Problems Using Average Reward Reinforcement Learning}},
url = {http://mansci.journal.informs.org/cgi/doi/10.1287/mnsc.45.4.560},
volume = {45},
year = {1999}
}
@article{Cervellera2007,
author = {Cervellera, Cristiano and Muselli, Marco},
doi = {10.1007/s10589-007-9054-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cervellera, Muselli - 2007 - Efficient sampling in approximate dynamic programming algorithms.pdf:pdf},
issn = {0926-6003},
journal = {Computational Optimization and Applications},
keywords = {deterministic learning,dynamic programming,low-discrepancy sequences,sample complexity,stochastic optimal control problem},
month = {jun},
number = {3},
pages = {417--443},
title = {{Efficient sampling in approximate dynamic programming algorithms}},
url = {http://link.springer.com/10.1007/s10589-007-9054-8},
volume = {38},
year = {2007}
}
@article{Ashlagi2008,
author = {Ashlagi, Itai and Monderer, Dov and Tennenholtz, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashlagi, Monderer, Tennenholtz - 2008 - On the Value of Correlation.pdf:pdf},
journal = {J. Artif. Intell. Res.(JAIR)},
number = {1974},
title = {{On the Value of Correlation.}},
url = {http://www.aaai.org/Papers/JAIR/Vol33/JAIR-3316.pdf},
year = {2008}
}
@article{Hollanders2012,
author = {Hollanders, Romain and Delvenne, Jean Charles and Jungers, Raphael M.},
doi = {10.1109/CDC.2012.6426485},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hollanders, Delvenne, Jungers - 2012 - The complexity of Policy Iteration is exponential for discounted Markov Decision Processes.pdf:pdf},
isbn = {978-1-4673-2066-5},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
pages = {5997--6002},
title = {{The complexity of Policy Iteration is exponential for discounted Markov Decision Processes}},
year = {2012}
}
@article{Zimmerman2003,
annote = {From Duplicate 2 ( Learning-Assisted Automated Planning - Zimmerman, Terry; Kambhampati, Subbarao; Back, Looking; Stock, Taking )
},
author = {Zimmerman, Terry and Kambhampati, Subbarao},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Back, Stock - 2003 - Learning-Assisted Automated Planning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zimmerman, Kambhampati - 2003 - Learning-Assisted Automated Planning Looking Back, Taking Stock, Going Forward.pdf:pdf},
journal = {AI Magazine},
keywords = {Copyright{\textcopyright} 2003 American Association for Artificia},
number = {2},
pages = {73--96},
title = {{Learning-Assisted Automated Planning: Looking Back, Taking Stock, Going Forward}},
volume = {24},
year = {2003}
}
@inproceedings{Zahavi2008,
annote = {From Duplicate 2 ( Predicting the Performance of {\{}IDA*{\}} with Conditional Distributions - Zahavi, Uzi; Felner, Ariel; Burch, Neil; Holte, Robert C )
},
author = {Zahavi, Uzi and Felner, Ariel and Burch, Neil and Holte, Robert C},
booktitle = {National Conference on AI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zahavi et al. - 2008 - Predicting the Performance of {\{}IDA{\}} with Conditional Distributions.pdf:pdf},
title = {{Predicting the Performance of {\{}IDA*{\}} with Conditional Distributions}},
year = {2008}
}
@unpublished{Lakshmanan2006,
author = {Lakshmanan, H and de Farias, D P},
title = {{Decentralized Approximate Dynamic Programming for Dynamic Networks of Agents,}},
year = {2006}
}
@inproceedings{Kalyanasundaram2002,
abstract = {Solution techniques for Markov decision problems rely on exact knowledge of the transition rates, which may be difficult or impossible to obtain. In this paper, we consider Markov decision problems with uncertain transition rates represented as compact sets. We first consider the problem of sensitivity analysis where the aim is to quantify the range of uncertainty of the average per-unit-time reward given the range of uncertainty of the transition rates. We then develop solution techniques for the problem of obtaining the max-min optimal policy, which maximizes the worst-case average per-unit-time reward. For both these problems, we develop the optimization and policy iteration solution techniques.},
author = {Kalyanasundaram, S and Chong, E K P and Shroff, N B},
booktitle = {IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2002.1184956},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalyanasundaram, Chong, Shroff - 2002 - Markov decision processes with uncertain transition rates Sensitivity and robust control.pdf:pdf},
isbn = {0780375165},
issn = {01912216},
pages = {3799--3804},
title = {{Markov decision processes with uncertain transition rates: Sensitivity and robust control}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1184956},
year = {2002}
}
@article{Pineau2006,
author = {Pineau, Joelle and Gordon, Geoffrey and Thrun, Sebastian},
institution = {McGill},
journal = {Journal of Artificial Intelligence Research},
number = {SOCS-TR-2005.4},
pages = {335--380},
title = {{Anytime point-based approximations for fast {\{}POMDP{\}} solving}},
volume = {27},
year = {2006}
}
@article{Csaji2008,
author = {Cs{\'{a}}ji, Bc and Monostori, L},
journal = {The Journal of Machine Learning Research},
keywords = {-,changing environments,markov decision processes,mdps,reinforcement learning,stochastic iterative algorithms,value function bounds,$\delta$,$\epsilon$},
pages = {1679--1709},
title = {{Value function based reinforcement learning in changing Markovian environments}},
url = {http://dl.acm.org/citation.cfm?id=1442787},
volume = {9},
year = {2008}
}
@article{Alvarez2007,
author = {Alvarez, Isabelle and Bernard, Stephan and Deffuant, Guillaume},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alvarez, Bernard, Deffuant - 2007 - Keep the decision tree and estimate the class probabilities using its decision boundary.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {decision trees,kernel methods},
number = {1},
pages = {654--659},
title = {{Keep the decision tree and estimate the class probabilities using its decision boundary}},
year = {2007}
}
@book{Litvinchev2003,
author = {Litvinchev, I and Tsurkov, Vladimir},
title = {{Aggregation in Large-Scale Optimization (Applied Optimization)}},
year = {2003}
}
@article{Kim2016,
author = {Kim, Michael Jong and Kim, Michael Jong},
keywords = {area of review,dynamic programming,entropy,failure models,games,group decisions,model ambiguity,partially observable systems,relative,robust control,stochastic,stochastic dynamic games,stochastic models,subject classifications},
number = {June},
title = {{Robust Control of Partially Observable Failing Systems Robust Control of Partially Observable Failing Systems}},
year = {2016}
}
@article{Han2013,
abstract = {An economic feasibility study of vehicle-to-grid (V2G) frequency regulation is performed in consideration of battery wear. Usually, a transaction for frequency regulation is made in terms of power capacity while the battery-wear proceeds in proportion to the absolute amount of energy transferred. In order to relate the two quantities, we first estimate the amount of transferred energy in terms of contracted power capacity, and hence regulation income, by analyzing actual regulation signals and transactions. On the other hand, the amount of transferrable energy during the life cycle of a battery is estimated analyzing some pervasive specifications for electric vehicle (EV) batteries. The expected V2G income is then estimated and compared with battery prices to judge the economic feasibility of V2G regulation. In the latter part of the paper, the assessment result is validated with actual cycle life data of an EV battery cell. As a result, it is concluded that the estimated profit exceeds current market price of EV batteries, indicating that V2G regulation is an economically feasible service.},
author = {Han, Sekyung and Han, Soohee},
doi = {10.3390/en6020748},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Han - 2013 - Economic Feasibility of V2G Frequency Regulation in Consideration of Battery Wear.pdf:pdf},
issn = {1996-1073},
journal = {Energies},
keywords = {battery cycle life,battery wear,economics,electric vehicle,frequency regulation,vehicle-to-grid},
month = {feb},
number = {2},
pages = {748--765},
title = {{Economic Feasibility of V2G Frequency Regulation in Consideration of Battery Wear}},
url = {http://www.mdpi.com/1996-1073/6/2/748/},
volume = {6},
year = {2013}
}
@article{Allen2013,
author = {Allen, Jenica M. and Leininger, Thomas J. and Hurd, James D. and Civco, Daniel L. and Gelfand, Alan E. and Silander, John A.},
doi = {10.1007/s10980-013-9916-7},
issn = {0921-2973},
journal = {Landscape Ecology},
keywords = {LULC change},
mendeley-tags = {LULC change},
month = {jul},
number = {9},
pages = {1671--1686},
title = {{Socioeconomics drive woody invasive plant richness in New England, USA through forest fragmentation}},
url = {http://link.springer.com/10.1007/s10980-013-9916-7},
volume = {28},
year = {2013}
}
@incollection{Benzi1995,
author = {Benzi, M and Sgallari, F and Spaletta, G},
booktitle = {Computations with Markov chains},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benzi, Sgallari, Spaletta - 1995 - A parallel block projection method of the Cimmino type for finite Markov chains.pdf:pdf},
title = {{A parallel block projection method of the Cimmino type for finite Markov chains}},
url = {http://link.springer.com/chapter/10.1007/978-1-4615-2241-6{\_}5},
year = {1995}
}
@article{Broder2007,
author = {Broder, Andrei and Fontoura, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Broder, Fontoura - 2007 - A semantic approach to contextual advertising.pdf:pdf},
isbn = {9781595935977},
journal = {International ACM SIGIR Conference on Research and Development in Information Retrieval},
keywords = {1,contextual advertising,from a web,matching,on the result pages,search advertising which con-,search engine,semantics,sists in placing ads,sponsored search or paid,the originating query,with ads driven by},
pages = {559--566},
title = {{A semantic approach to contextual advertising}},
url = {http://dl.acm.org/citation.cfm?id=1277837},
year = {2007}
}
@inproceedings{Kim2006,
annote = {From Duplicate 1 ( Exploiting Locality of Interaction in Networked Distributed {\{}POMDP{\}}s - Kim, Yoonheui; Nair, Ranjit; Varakantham, Pradeep; Tambe, Milind; Yokoo, Makoto )

From Duplicate 2 ( Exploiting Locality of Interaction in Networked Distributed POMDPs - Kim, Yoonheui; Nair, Ranjit; Varakantham, Pradeep; Tambe, Milind; Yokoo, Makoto )
},
author = {Kim, Yoonheui and Nair, Ranjit and Varakantham, Pradeep and Tambe, Milind and Yokoo, Makoto},
booktitle = {AAAI Spring Symposium on Distributed Planning and Scheduling},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2004 - Exploiting Locality of Interaction in Networked Distributed POMDPs.pdf:pdf},
pages = {41--48},
title = {{Exploiting Locality of Interaction in Networked Distributed POMDPs}},
year = {2006}
}
@inproceedings{McNellis2017,
author = {McNellis, Ryan and Elmachtoub, Adam and Oh, Sechan and Petrik, Marek},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McNellis et al. - 2017 - A Practical Method for Solving Contextual Bandit Problems Using Decision Trees.pdf:pdf},
title = {{A Practical Method for Solving Contextual Bandit Problems Using Decision Trees}},
year = {2017}
}
@misc{IEC2015,
title = {{Intercontinental Exchange: http://www.eia.gov/electricity/wholesale}},
url = {http://www.eia.gov/electricity/wholesale},
year = {2015}
}
@article{Calafiore2005,
author = {Calafiore, Guiuseppe and Campi, M C},
journal = {Mathematical Programming, Series A},
pages = {25--46},
title = {{Uncertain convex programs: Randomized solutions and confidence levels}},
volume = {102},
year = {2005}
}
@article{Kim2015,
abstract = {The multiarmed bandit problem is a popular framework for studying the exploration versus exploitation trade-off. Recent applications include dynamic assortment design, Internet advertising, dynamic pricing, and the control of queues. The standard mathematical formulation for a bandit problem makes the strong assumption that the decision maker has a full characterization of the joint distribution of the rewards, and that “arms” under this distribution are independent. These assumptions are not satisfied in many applications, and the out-of-sample performance of policies that optimize a misspecified model can be poor. Motivated by these concerns, we formulate a robust bandit problem in which a decision maker accounts for distrust in the nominal model by solving a worst-case problem against an adversary (“nature”) who has the ability to alter the underlying reward distribution and does so to minimize the decision maker's expected total profit. Structural properties of the optimal worst-case policy are charac...},
author = {Kim, Michael Jong and Lim, Andrew E.B.},
doi = {10.1287/mnsc.2015.2153},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Lim - 2015 - Robust Multiarmed Bandit Problems.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
keywords = {bandit problems,games against nature,model uncertainty,relative entropy,robust control},
number = {1},
pages = {264--285},
title = {{Robust Multiarmed Bandit Problems}},
url = {http://pubsonline.informs.org/doi/ref/10.1287/mnsc.2015.2153},
volume = {62},
year = {2015}
}
@article{Palosuo2011,
annote = {
        {\textless}m:bold{\textgreater}Weather data source:{\textless}/m:bold{\textgreater}
      },
author = {Palosuo, Taru and Kersebaum, Kurt Christian and Angulo, Carlos and Hlavinka, Petr and Moriondo, Marco and Olesen, J{\o}rgen E. and Patil, Ravi H. and Ruget, Fran{\c{c}}oise and Rumbaur, Christian and Tak{\'{a}}{\v{c}}, Jozef and Trnka, Miroslav and Bindi, Marco and {\c{C}}aldağ, Barış and Ewert, Frank and Ferrise, Roberto and Mirschel, Wilfried and Şaylan, Levent and {\v{S}}i{\v{s}}ka, Bernard and R{\"{o}}tter, Reimund},
doi = {10.1016/j.eja.2011.05.001},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Palosuo et al. - 2011 - Simulation of winter wheat yield and its variability in different climates of Europe A comparison of eight crop.pdf:pdf},
issn = {11610301},
journal = {European Journal of Agronomy},
keywords = {climatic variability},
month = {oct},
number = {3},
pages = {103--114},
title = {{Simulation of winter wheat yield and its variability in different climates of Europe: A comparison of eight crop growth models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1161030111000542},
volume = {35},
year = {2011}
}
@article{Pereira1985,
author = {Pereira, M V F},
journal = {Water Resource Research},
pages = {779--792},
title = {{Stochastic optimization of a multi-reservoir hydroelectric system: A decomposition approach}},
volume = {21},
year = {1985}
}
@article{Bertsimas2007,
author = {Bertsimas, Dimitris and Brown, DB and Caramanis, Constantine},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Brown, Caramanis - 2011 - Theory and applications of robust optimization.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Brown, Caramanis - 2011 - Theory and applications of robust optimization(2).pdf:pdf},
journal = {SIAM Review},
keywords = {adaptable optimization,applications of robust op-,robust optimization,robustness},
number = {3},
pages = {464--501},
title = {{Theory and applications of robust optimization}},
url = {http://epubs.siam.org/doi/abs/10.1137/080734510},
volume = {53},
year = {2011}
}
@article{Rothwell1995,
author = {Rothwell, Geoffrey and Rust, John},
journal = {EconWPA Microeconomics},
title = {{A Dynamic Programming Model of U.S. Nuclear Power Plant Operations}},
year = {1995}
}
@article{Weiss1988,
author = {Weiss, G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weiss - 1988 - Branching Bandit Processes.pdf:pdf},
journal = {Probability in the Engineering and Informational Sciences},
pages = {269--278},
title = {{Branching Bandit Processes}},
volume = {2},
year = {1988}
}
@inproceedings{Turchetta2016,
abstract = {In classical reinforcement learning, when exploring an environment, agents accept arbitrary short term loss for long term gain. This is infeasible for safety critical applications, such as robotics, where even a single unsafe action may cause system failure. In this paper, we address the problem of safely exploring finite Markov decision processes (MDP). We define safety in terms of an, a priori unknown, safety constraint that depends on states and actions. We aim to explore the MDP under this constraint, assuming that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop a novel algorithm for this task and prove that it is able to completely explore the safely reachable part of the MDP without violating the safety constraint. To achieve this, it cautiously explores safe states and actions in order to gain statistical confidence about the safety of unvisited state-action pairs from noisy observations collected while navigating the environment. Moreover, the algorithm explicitly considers reachability when exploring the MDP, ensuring that it does not get stuck in any state with no safe way out. We demonstrate our method on digital terrain models for the task of exploring an unknown map with a rover.},
archivePrefix = {arXiv},
arxivId = {1606.04753},
author = {Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
eprint = {1606.04753},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turchetta, Berkenkamp, Krause - 2016 - Safe Exploration in Finite Markov Decision Processes with Gaussian Processes.pdf:pdf},
title = {{Safe Exploration in Finite Markov Decision Processes with Gaussian Processes}},
url = {http://arxiv.org/abs/1606.04753{\%}5Cnhttp://www.arxiv.org/pdf/1606.04753.pdf},
year = {2016}
}
@article{Mangasarian2004,
author = {Mangasarian, O L},
journal = {Journal of Optimization Theory and Applications},
pages = {1--18},
title = {{A Newton Method for Linear Programming}},
volume = {121},
year = {2004}
}
@techreport{Lattimore2016,
abstract = {Stochastic linear bandits are a natural and simple generalisation of finite-armed bandits with numerous practical applications. Cur-rent approaches focus on generalising existing techniques for finite-armed bandits, notably the optimism principle and Thompson sam-pling. While prior work has mostly been in the worst-case setting, we analyse the asymptotic instance-dependent regret and show matching upper and lower bounds on what is achiev-able. Surprisingly, our results show that no al-gorithm based on optimism or Thompson sam-pling will ever achieve the optimal rate, and indeed, can be arbitrarily far from optimal, even in very simple cases. This is a disturb-ing result because these techniques are stan-dard tools that are widely used for sequential optimisation. For example, for generalised lin-ear bandits and reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {arXiv:1610.04491v1},
author = {Lattimore, Tor and Szepesv{\'{a}}ri, Csaba},
booktitle = {arXiv:1610.04491v1},
eprint = {arXiv:1610.04491v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lattimore, Szepesv{\'{a}}ri - 2016 - The End of Optimism An Asymptotic Analysis of Finite-Armed Linear Bandits.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lattimore, Szepesv{\'{a}}ri - 2016 - The End of Optimism An Asymptotic Analysis of Finite-Armed Linear Bandits(2).pdf:pdf},
keywords = {keyword1 key2 key3},
title = {{The End of Optimism? An Asymptotic Analysis of Finite-Armed Linear Bandits}},
year = {2016}
}
@techreport{Allen2000,
author = {Allen, Rick},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen - 2000 - Calibration for the Watermark 200SS soil water potential sensor to fit the 7-19-96 “Calibration{\#} 3” table from Irrome.pdf:pdf},
institution = {University of Idaho},
pages = {18--21},
title = {{Calibration for the Watermark 200SS soil water potential sensor to fit the 7-19-96 “Calibration{\#} 3” table from Irrometer}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Calibration+for+the+Watermark+200SS+Soil+Water+Potential+Sensor+to+fit+the+7-19-96+“+Calibration+{\#}+3+”+Table+from+Irrometer{\%}230 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Calibration+for+the+watermark+200ss+soil+water+potential+sensor+to+fit+the+7-19-96+“calibration{\#}+3”+table+from+Irrometer{\%}230},
year = {2000}
}
@inproceedings{Mahadevan2006,
author = {Mahadevan, Sridhar and Maggioni, Mauro and Ferguson, Kimberly and Osentoski, Sarah},
booktitle = {National Conference on Artificial Intelligence},
title = {{Learning Representation and Control in Continuous {\{}M{\}}arkov Decision Processes}},
year = {2006}
}
@inproceedings{Petrik2010,
author = {Petrik, Marek and Taylor, Gavin and Parr, Ron and Zilberstein, Shlomo},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik et al. - 2010 - Feature selection using regularization in approximate linear programs for Markov decision processes.pdf:pdf},
title = {{Feature selection using regularization in approximate linear programs for Markov decision processes}},
url = {http://arxiv.org/abs/1005.1860},
year = {2010}
}
@article{Drenick1992,
author = {Drenick, R F},
journal = {Journal of Optimization Theory and Applications},
pages = {459--486},
title = {{Multilinear programming: Duality theories}},
volume = {72},
year = {1992}
}
@inproceedings{Emery-Montemerlo2004,
annote = {From Duplicate 2 ( Approximate solutions for partially observable stochastic games with common payoffs - Emery-Montemerlo, R; Gordon, G; Schneider, J; Thrun, S )
},
author = {Emery-Montemerlo, R and Gordon, G and Schneider, J and Thrun, S},
booktitle = {International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Emery-Montemerlo et al. - 2004 - Approximate solutions for partially observable stochastic games with common payoffs.pdf:pdf},
pages = {136--143},
title = {{Approximate solutions for partially observable stochastic games with common payoffs}},
url = {citeseer.ist.psu.edu/703537.html},
year = {2004}
}
@article{Cai2011,
author = {Cai, Ruohong and Bergstrom, JC and Mullen, JD and Wetzstein, ME},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2011 - A dynamic optimal crop rotation model in acreage response.pdf:pdf},
title = {{A dynamic optimal crop rotation model in acreage response}},
url = {http://ageconsearch.umn.edu/bitstream/103949/2/FS11-02.pdf},
year = {2011}
}
@misc{Allen1990,
author = {Allen, Rb},
booktitle = {Handbook of human-computer interaction},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen - 1997 - Mental Models and User Models.pdf:pdf},
title = {{Mental Models and User Models}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=WuQbERgXR10C{\&}oi=fnd{\&}pg=PA49{\&}dq=Mental+Models+and+User+Models{\&}ots=-{\_}yBgIOIlT{\&}sig=5U5rtr8BuxaN-a4-X6X4EpVQEO0},
year = {1997}
}
@misc{Casella2002,
abstract = {This book builds theoretical statistics from the first principles$\backslash$nof probability theory. Starting from the basics of probability, the$\backslash$nauthors develop the theory of statistical inference using techniques,$\backslash$ndefinitions, and concepts that are statistical and are natural extensions$\backslash$nand consequences of previous concepts. Intended for first-year graduate$\backslash$nstudents, this book can be used for students majoring in statistics$\backslash$nwho have a solid mathematics background. It can also be used in a$\backslash$nway that stresses the more practical uses of statistical theory,$\backslash$nbeing more concerned with understanding basic statistical concepts$\backslash$nand deriving reasonable statistical procedures for a variety of situations,$\backslash$nand less concerned with formal optimality investigations.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Casella, George and Berger, Roger L.},
doi = {10.1057/pt.2010.23},
eprint = {9605103},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casella, Berger - 2002 - Statistical inference.pdf:pdf},
isbn = {0534119581},
issn = {0307-4463},
pages = {660 pages},
pmid = {20927031},
primaryClass = {cs},
title = {{Statistical inference}},
year = {2002}
}
@article{Antos2008,
author = {Antos, Andr{\'{a}}s and Szepesv{\'{a}}ri, Csaba and Munos, R{\'{e}}mi},
journal = {Machine Learning},
month = {apr},
number = {1},
pages = {89--129},
title = {{Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path}},
volume = {71},
year = {2008}
}
@article{Rosberg1983,
author = {Rosberg, Z and Introduction, I},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Introduction - Unknown - Optimal Decentralized Control in a Multiaccess Channel with Partial Information.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
pages = {187--193},
title = {{Optimal decentralized control in a multiaccess channel with partial information}},
volume = {28},
year = {1983}
}
@article{Rust1997,
author = {Rust, John},
journal = {Econometrica},
pages = {487--516},
title = {{Using randomization to break the curse of dimensionality}},
volume = {65},
year = {1997}
}
@inproceedings{Powell2005,
author = {Powell, Warren B},
booktitle = {Winter Simulation Conference},
title = {{The optimizing simulator: Merging simulation and optimization using approximate dynamic programming}},
year = {2005}
}
@article{Taylor2008,
author = {Taylor, Jonathan and Precup, Doina and Panangaden, Prakash},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taylor, Precup, Panangaden - 2008 - Bounding Performance Loss in Approximate MDP Homomorphisms.pdf:pdf},
isbn = {9781605609492},
journal = {Advances in Neural Information Processing Systems (NIPS) 21},
pages = {1649--1656},
title = {{Bounding Performance Loss in Approximate MDP Homomorphisms}},
url = {http://books.nips.cc/papers/files/nips21/NIPS2008{\_}0971.pdf},
year = {2008}
}
@inproceedings{Ferns2004,
author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
pages = {162--169},
title = {{Metrics for finite {\{}M{\}}arkov decision processes}},
year = {2004}
}
@article{Moura2010,
author = {Moura, Scott J. and Stein, Jeffrey L. and Fathy, Hosam K.},
doi = {10.1115/DSCC2010-4089},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moura, Stein, Fathy - 2010 - Battery-Health Conscious Power Management for Plug-In Hybrid Electric Vehicles via Stochastic Control.pdf:pdf},
isbn = {978-0-7918-4417-5},
journal = {ASME 2010 Dynamic Systems and Control Conference, Volume 1},
pages = {615--624},
publisher = {Asme},
title = {{Battery-Health Conscious Power Management for Plug-In Hybrid Electric Vehicles via Stochastic Control}},
url = {http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=1613504},
year = {2010}
}
@article{Vershynin2014,
annote = {A high-dimensional take on learning theory

An interesting difference from the statistical learning theory: 
the focus is on the error in x and not on the error on f(x) 
That is the question is what is the probability that the solution that is comuted is close to the true one, and not necessarily what is the quality of the computed solution with respect to the optimal one.},
archivePrefix = {arXiv},
arxivId = {arXiv:1405.5103v1},
author = {Vershynin, Roman},
eprint = {arXiv:1405.5103v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vershynin - 2014 - Estimation in high dimensions a geometric perspective.pdf:pdf},
pages = {1--54},
title = {{Estimation in high dimensions: a geometric perspective}},
year = {2014}
}
@inproceedings{Petrik2012,
author = {Petrik, Marek},
booktitle = {International Conference of Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2012 - Approximate dynamic programming by minimizing distributionally robust bounds.pdf:pdf},
title = {{Approximate dynamic programming by minimizing distributionally robust bounds}},
url = {http://arxiv.org/abs/1205.1782},
year = {2012}
}
@book{Ruppert2003,
address = {Cambridge},
author = {Ruppert, David and Wand, M. P. and Carroll, R. J.},
doi = {10.1017/CBO9780511755453},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruppert, Wand, Carroll - 2003 - Semiparametric Regression.pdf:pdf},
isbn = {9780511755453},
publisher = {Cambridge University Press},
title = {{Semiparametric Regression}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511755453},
year = {2003}
}
@article{Thompson2005,
author = {Thompson, R.B. and Gallardo, M. and Ag{\"{u}}era, T. and Valdez, L.C. and Fern{\'{a}}ndez, M.D.},
doi = {10.1007/s00271-005-0009-5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thompson et al. - 2005 - Evaluation of the Watermark sensor for use with drip irrigated vegetable crops.pdf:pdf},
isbn = {3495001549},
issn = {0342-7188},
journal = {Irrigation Science},
month = {nov},
number = {3},
pages = {185--202},
title = {{Evaluation of the Watermark sensor for use with drip irrigated vegetable crops}},
url = {http://link.springer.com/10.1007/s00271-005-0009-5},
volume = {24},
year = {2005}
}
@article{Saul2006,
author = {Saul, LK and Weinberger, KQ and Ham, JH},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saul, Weinberger, Ham - 2006 - Spectral methods for dimensionality reduction.pdf:pdf},
journal = {Semisupervised {\ldots}},
title = {{Spectral methods for dimensionality reduction}},
url = {http://www.cse.wustl.edu/{~}kilian/papers/smdr{\_}ssl05.pdf},
year = {2006}
}
@article{Rahimi2007,
author = {Rahimi, Ali and Recht, Ben},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rahimi, Recht - 2007 - Random features for large-scale kernel machines.pdf:pdf},
journal = {NIPS},
number = {1},
pages = {1--8},
title = {{Random features for large-scale kernel machines}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2007{\_}833.pdf},
year = {2007}
}
@techreport{Brockman2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1606.01540v1},
author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
eprint = {arXiv:1606.01540v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brockman et al. - 2016 - OpenAI Gym.pdf:pdf},
institution = {arXiv:1606.01540v1},
pages = {1--4},
title = {{OpenAI Gym}},
year = {2016}
}
@inproceedings{Huang2010,
author = {Huang, Pu and Subramanian, Dharmashankar and Xu, Jie},
booktitle = {Winter Simulation Conference},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Subramanian, Xu - 2010 - AN IMPORTANCE SAMPLING METHOD FOR PORTFOLIO CVaR ESTIMATION WITH GAUSSIAN COPULA MODELS.pdf:pdf},
title = {{AN IMPORTANCE SAMPLING METHOD FOR PORTFOLIO CVaR ESTIMATION WITH GAUSSIAN COPULA MODELS}},
url = {http://www.informs-sim.org/wsc10papers/258.pdf},
year = {2010}
}
@article{Delage2010,
author = {Delage, Eric and Ye, Yinyu},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delage, Ye - 2010 - Distributionally robust optimization under moment uncertainty with application to data driven problems.pdf:pdf},
journal = {Operations Research},
number = {3},
pages = {595--612},
title = {{Distributionally robust optimization under moment uncertainty with application to data driven problems}},
volume = {58},
year = {2010}
}
@article{Haviv1987,
annote = {From Duplicate 1 ( Aggregation/disaggregation methods for computing the stationary distribution of a Markov chain - Haviv, Moshe )
},
author = {Haviv, Moshe},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haviv - 1987 - Aggregationdisaggregation methods for computing the stationary distribution of a Markov chain.pdf:pdf},
journal = {SIAM Journal on Numberical Analysis},
number = {4},
pages = {952--966},
title = {{Aggregation/disaggregation methods for computing the stationary distribution of a Markov chain}},
url = {http://epubs.siam.org/doi/abs/10.1137/0724062},
volume = {24},
year = {1987}
}
@inproceedings{Rendle2010,
abstract = {Recommender systems are an important component of many websites. Two of the most popular approaches are based on matrix factorization (MF) and Markov chains (MC). MF methods learn the general taste of a user by factorizing the matrix over observed user-item preferences. On the other hand, MC methods model sequential behavior by learning a transition graph over items that is used to predict the next action based on the recent actions of a user. In this paper, we present a method bringing both approaches together. Our method is based on personalized transition graphs over un- derlying Markov chains. That means for each user an own transition matrix is learned – thus in total the method uses a transition cube. As the observations for estimating the transitions are usually very limited, our method factorizes the transition cube with a pairwise interaction model which is a special case of the Tucker Decomposition. We show that our factorized personalized MC (FPMC) model sub- sumes both a common Markov chain and the normal matrix factorization model. For learning the model parameters, we introduce an adaption of the Bayesian Personalized Ranking (BPR) framework for sequential basket data. Empirically, we show that our FPMC model outperforms both the com- mon matrix factorization and the unpersonalized MC model both learned with and without factorization. Categories},
author = {Rendle, Steffen and Freudenthaler, Christoph and Schmidt-Thieme, Lars},
booktitle = {International conference on World wide web (WWW)},
doi = {10.1145/1772690.1772773},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rendle, Freudenthaler, Schmidt-Thieme - 2010 - Factorizing personalized Markov chains for next-basket recommendation.pdf:pdf},
isbn = {9781605587998},
issn = {1469493X},
pages = {811--820},
pmid = {21975771},
title = {{Factorizing personalized Markov chains for next-basket recommendation}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772773},
year = {2010}
}
@book{B,
author = {Barber, S A},
title = {{Soil nutrient bioavailability: a mechanistic approach}},
year = {1995}
}
@article{Rogers2007a,
abstract = {This paper introduces certain nonlinear partially observable stochastic optimal control problems which are equivalent to completely observable control problems with finite-dimensional state space. In some cases the optimal control laws are analogousto linear-exponential-quadratic-Gaussian and linear-quadratic-Gaussian tracking problems. The problems discussed allow nonlinearities to enter the unobservable dynamics as gradients of potential functions. The methodology is based on explicit solutions of a modified Duncan-Mortensen-Zakai equation.},
author = {Rogers, L C G},
doi = {10.1137/050642885},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rogers - 2007 - Pathwise Stochastic Optimal Control.pdf:pdf},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
keywords = {050642885,1,10,1137,90c39,90c40,90c46,93e20,93e25,ams subject classifications,deterministic,doi,dual,dynamic programming,introduction,paper refers to this,pathwise optimization,stochastic,that,the title of this,we intend to show},
number = {3},
pages = {1116--1132},
title = {{Pathwise Stochastic Optimal Control}},
volume = {46},
year = {2007}
}
@article{Ross2008,
author = {Ross, Stephane and Pineau, Joelle and Paquet, Sebastien and Chaib-draa, Brahin},
journal = {Journal of Artificial Intelligence Research},
pages = {663--704},
title = {{Online Planning Algorithms for POMDPs}},
volume = {32},
year = {2008}
}
@article{Rubinstein2006,
author = {Rubinstein, Ariel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubinstein - 2006 - Lecture notes in microeconomic theory.pdf:pdf},
isbn = {9780691120300},
journal = {Princeton University, Princeton, NJ},
title = {{Lecture notes in microeconomic theory}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Lecture+Notes+in+Microeconomic+Theory{\#}0},
year = {2006}
}
@article{Xu2011,
annote = {A very interesting relationship to Markov sampling},
author = {Xu, Huan and Mannor, Shie},
doi = {10.1007/s10994-011-5268-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Mannor - 2011 - Robustness and generalization.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {generalization,non-iid sample,quantile loss,robust},
month = {nov},
number = {3},
pages = {391--423},
title = {{Robustness and generalization}},
url = {http://link.springer.com/10.1007/s10994-011-5268-1},
volume = {86},
year = {2011}
}
@techreport{Michigan2012,
author = {{USDA Forest Service Forest Health Staff}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/USDA Forest Service Forest Health Staff - 2012 - Glossy Buckthorn.pdf:pdf},
pages = {1},
title = {{Glossy Buckthorn}},
volume = {2},
year = {2012}
}
@article{Garc2015,
author = {Garcia, Javier and Fernandez, Fernando},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia, Fernandez - 2015 - A Comprehensive Survey on Safe Reinforcement Learning.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {reinforcement learning,risk sensitivity,safe exploration,teacher advice},
number = {1},
pages = {1437--1480},
title = {{A Comprehensive Survey on Safe Reinforcement Learning}},
volume = {16},
year = {2015}
}
@article{Altman1993,
author = {Altman, Eitan and Gaisgory, Vladimir A},
journal = {IEEE Transactions On Automatic Control},
pages = {971},
title = {{Stability and singular perturbations in constrained Markov decision problems}},
volume = {38},
year = {1993}
}
@inproceedings{Negenborn2006,
author = {Negenborn, RR R and Schutter, B De and Hellendoorn, H},
booktitle = {IEEE International Conference on Networking, Sensing and Control},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Negenborn - 2006 - Multi-agent model predictive control of transportation networks.pdf:pdf},
title = {{Multi-agent model predictive control of transportation networks}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1673161},
volume = {19},
year = {2006}
}
@article{Ipsen1998,
annote = {From Duplicate 1 ( The idea behind Krylov methods - Ipsen, Ilse C F; Meyer, Carl D )

From Duplicate 2 ( The Idea Behind Krylov Methods An Example of a Krylov Method - Ipsen, Ilse C F; Meyer, Carl D )
},
author = {Ipsen, Ilse C F and Meyer, Carl D},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ipsen, Meyer - Unknown - The Idea Behind Krylov Methods An Example of a Krylov Method.pdf:pdf},
journal = {American {\{}M{\}}athematical {\{}M{\}}onthly},
number = {10},
pages = {889--899},
title = {{The idea behind {\{}K{\}}rylov methods}},
url = {citeseer.ist.psu.edu/article/ipsen97idea.html},
volume = {105},
year = {1998}
}
@article{Bubeck2012a,
abstract = {Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the Thirties, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this survey, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.},
archivePrefix = {arXiv},
arxivId = {1204.5721},
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
doi = {10.1561/2200000024},
eprint = {1204.5721},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems(3).pdf:pdf},
isbn = {9781601986269},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000024},
volume = {5},
year = {2012}
}
@article{Ruszczynski2010,
annote = {From Duplicate 2 ( 


Risk-averse dynamic programming for Markov decision processes


- Paper, Full Length; Ruszczy{\'{n}}ski, Andrzej; Ruszczynski, Andrzej )

},
author = {Ruszczynski, Andrzej},
doi = {10.1007/s10107-010-0393-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruszczy{\'{n}}ski - 2010 - Risk-averse dynamic programming for Markov decision processes.pdf:pdf},
isbn = {1010701003933},
issn = {0025-5610},
journal = {Mathematical Programming B},
keywords = {2000,93e20,dynamic risk measures,markov risk measures,mathematics subject classification,min-max markov models,nonsmooth newton,policy iteration,s method,secondary 91a25,value iteration},
month = {jul},
number = {2},
pages = {235--261},
title = {{Risk-averse dynamic programming for Markov decision processes}},
url = {http://link.springer.com/10.1007/s10107-010-0393-3},
volume = {125},
year = {2010}
}
@article{Stich2012,
author = {Stich, Sebastian and Eth, Z},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stich, Eth - 2012 - The Heavy Ball Method.pdf:pdf},
journal = {Arxiv},
title = {{The Heavy Ball Method}},
year = {2012}
}
@book{Fink2003,
author = {Fink, Gernot A.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fink - 2003 - Markov Models for Pattern Recognition.pdf:pdf},
isbn = {9783540717669},
title = {{Markov Models for Pattern Recognition}},
year = {2003}
}
@inproceedings{Edelkamp2001,
author = {Edelkamp, Stefan},
booktitle = {ECP},
title = {{Planning with pattern databases}},
year = {2001}
}
@inproceedings{Littman1995,
annote = {From Duplicate 1 ( On the Complexity of Solving Markov Decision Problems - Littman, Michael L; Dean, Thomas; Kaelbling, Leslie Pack )
},
author = {Littman, Michael L and Dean, Thomas and Kaelbling, Leslie Pack},
booktitle = {Uncertainty in Artificial Intelligence},
pages = {394--402},
title = {{On the Complexity of Solving Markov Decision Problems}},
year = {1995}
}
@article{Singh1996,
abstract = {Crop yield is mainly dependent on weather, soil and technological inputs. Yield forecasting models have been developed mainly using multiple regression techniques based on biometrical characters of the plants and/or weather parameters. Matiset al. (1985) proposed another approach of crop yield modelling using Markov Chain theory based on biometrical characters. The integration of remote sensing with other technologies has provided an immense scope to improve upon the existing crop yield models. In the present study, multi date spectral data during crop growth period was used in Markov Chain Model to forecast wheat yield. The results indicate that the use of spectral data near the maximum vegetative growth of wheat crop improves the efficiency and reliability of yield forecast about a month before its actual harvest.},
author = {Singh, Randhir and Ibrahim, A Ei},
journal = {Journal of the Indian Society of Remote Sensing},
number = {3},
pages = {145--152},
title = {{Use of spectral data in Markov chain model for crop yield forecasting}},
volume = {24},
year = {1996}
}
@book{Minoux1986,
author = {Minoux, M},
title = {{Mathematical Programming: Theory and Algorithms}},
year = {1986}
}
@article{Leite2008,
annote = {Image preprocessing 
- Dark-object subtraction
- Conversion to real reflectance values

Improved classification from 84{\%} to 91{\%} using multiple spectra 

States in the HMM: 4
The transition probabilities may be season-dependent


Leite, P. B. C., Feitosa, R. Q., Formaggio, A. R., da Costa, G. A. O. P., Pakzad, K., {\&} Sanches, I. D. (2011). Hidden Markov Models for crop recognition in remote sensing image sequences. Pattern Recognition Letters, 32(1), 19–26. doi:10.1016/j.patrec.2010.02.008},
author = {Leite, P. B. C. and Feitosa, R. Q. and Formaggio, a. R. and Costa, G. a. O. P. and Pakzad, K. and Sanches, I. D. a.},
doi = {10.1109/SIBGRAPI.2008.26},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leite et al. - 2008 - Crop Type Recognition Based on Hidden Markov Models of Plant Phenology.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leite et al. - 2008 - Crop Type Recognition Based on Hidden Markov Models of Plant Phenology(2).pdf:pdf},
isbn = {978-0-7695-3358-2},
journal = {2008 XXI Brazilian Symposium on Computer Graphics and Image Processing},
month = {oct},
pages = {27--34},
publisher = {Ieee},
title = {{Crop Type Recognition Based on Hidden Markov Models of Plant Phenology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4654140},
year = {2008}
}
@article{Qi1994,
annote = {This paper introduces the Modified Soil Adjusted Index (MSAVI)},
author = {Qi, J. and Chehbouni, a. and a.R. Huete and Kerr, Y.H. and Sorooshian, S.},
doi = {10.1016/0034-4257(94)90134-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - 1994 - A modified soil adjusted vegetation index.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
month = {may},
number = {2},
pages = {119--126},
title = {{A modified soil adjusted vegetation index}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0034425794901341},
volume = {48},
year = {1994}
}
@inproceedings{Parr2008,
author = {Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakefield, Christopher and Littman, Michael L},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parr et al. - 2008 - An analysis of linear models, linear value function approximation, and feature selection for reinforcement learning.pdf:pdf},
title = {{An analysis of linear models, linear value function approximation, and feature selection for reinforcement learning}},
year = {2008}
}
@book{Shapiro2009,
author = {Shapiro, Alexander and Dentcheva, Darinka and Ruszczynski, Andrzej},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro, Dentcheva, Ruszczynski - Unknown - LECTURES ON S TOCHASTIC P ROGRAMMING AND.pdf:pdf},
isbn = {9780898716870},
publisher = {SIAM},
title = {{Lectures on Stochastic Programming}},
year = {2009}
}
@article{Audet1999,
author = {Audet, Charles and Hansen, Pierre and Jaumard, Brigitte and Savard, Gilles},
doi = {10.1007/s101070050072},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Audet et al. - 1999 - A symmetrical linear maxmin approach to disjoint bilinear programming.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {branch and bound algorithm,disjoint bilinear problem,global,linear maxmin problem},
month = {aug},
number = {3},
pages = {573--592},
title = {{A symmetrical linear maxmin approach to disjoint bilinear programming}},
url = {http://link.springer.com/10.1007/s101070050072},
volume = {85},
year = {1999}
}
@article{Kretchmar,
author = {Kretchmar, R Matthew and Young, Peter M and Anderson, Charles W and Hittle, Douglas C and Anderson, Michael L and Tu, Jilin and Delnero, Christopher C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kretchmar et al. - Unknown - Robust Reinforcement Learning Control.pdf:pdf},
title = {{Robust Reinforcement Learning Control}}
}
@article{Letham2010,
author = {Letham, Benjamin and Rudin, Cynthia and Mccormick, Tyler H and Madigan, David},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Letham et al. - 2010 - An Interpretable Stroke Prediction Model Using Rules and Bayesian Analysis.pdf:pdf},
isbn = {9781577356288},
keywords = {AAAI Technical Report WS-13-17},
number = {609},
pages = {65--67},
title = {{An Interpretable Stroke Prediction Model Using Rules and Bayesian Analysis}},
year = {2010}
}
@article{American2017,
author = {Hall, Darwin C. and Norgaard, Richard B.},
doi = {10.1093/ajae/aaql08},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall, Norgaard - 1973 - On the Timing and Application of Pesticides.pdf:pdf},
journal = {American Journal of Agricultural Economics},
keywords = {agricultural sector models,behave,between the way farmers,competitive markets,gaining,in the risk case,inear programming models are,linear programming,overestimation of the returns,programs,response and agricultural investment,risk,to investment},
number = {2},
pages = {198--201},
title = {{On the Timing and Application of Pesticides}},
volume = {55},
year = {1973}
}
@article{Puterman1979,
author = {Puterman, Martin L},
journal = {Management Science},
title = {{Modified policy iteration algorithms for discounted {\{}M{\}}arkov decision problems}},
volume = {24},
year = {1979}
}
@article{Goldman2004,
annote = {From Duplicate 1 ( Decentralized control of cooperative systems: categorization and complexity analysis - Goldman, Claudia V; Zilberstein, Shlomo )
},
author = {Goldman, Claudia V and Zilberstein, Shlomo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldman, Zilberstein - 2004 - Decentralized control of cooperative systems categorization and complexity analysis.pdf:pdf},
journal = {Journal of {\{}A{\}}rtificial {\{}I{\}}ntelligence {\{}R{\}}esearch},
pages = {143--174},
title = {{Decentralized control of cooperative systems: categorization and complexity analysis}},
volume = {22},
year = {2004}
}
@article{Knapp1991,
abstract = {A state-space model for perennial crop supply response is developed. New plantings and removals depend on the existing age structure of the crop and expected values for future prices and other exogenous variables. Acreage in individual age categories evolves depending upon existing acreage, new plantings, and removals. The Kalman filter and an iterative parameter search provide maximum-likelihood estimates of the unknown parameters and age group acreages from observed data on total acreage and production. An empirical application for alfalfa shows that existing acreage has differential impacts on new plantings and removals depending upon age.},
author = {Knapp, Keith C. and Konyar, Kazim},
journal = {American J. of Agricultural Economics},
number = {3},
pages = {841--849},
title = {{Perennial crop supply response: a Kalman filter approach}},
volume = {73},
year = {1991}
}
@article{Boyd2007,
author = {Boyd, S and Kim, SJ and Vandenberghe, L and Hassibi, A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd et al. - 2007 - A tutorial on geometric programming.pdf:pdf},
journal = {Optimization and {\ldots}},
pages = {1--69},
title = {{A tutorial on geometric programming}},
url = {http://link.springer.com/article/10.1007/s11081-007-9001-7},
volume = {90095},
year = {2007}
}
@article{Mendelssohn1982,
abstract = {An iterative aggregation procedure is described for solving large scale, finite state, finite action Markov decision processes (MDPs). At each iteration, an aggregate master problem and a sequence of smaller subproblems are solved. The weights used to form the aggregate master problem are based on the estimates from the previous iteration. Each subproblem is a finite state, finite action MDP with a reduced state space and unequal row sums. Global convergence of the algorithm is proven under very weak assumptions. The proof relates this technique to other iterative methods that have been sug- gested for general linear programs},
annote = {From Duplicate 1 ( An iterative aggregation procedure for Markov decision processes - Mendelssohn, Roy )

From Duplicate 2 ( An iterative aggregation procedure for Markov decision processes - Mendelssohn, Roy )

From Duplicate 2 ( An iterative aggregation procedure for Markov decision processes - Mendelssohn, Roy )







From Duplicate 2 ( An iterative aggregation procedure for Markov decision processes - Mendelssohn, R )
},
author = {Mendelssohn, Roy},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendelssohn - 1982 - An iterative aggregation procedure for Markov decision processes.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mendelssohn - 1982 - An iterative aggregation procedure for Markov decision processes(2).pdf:pdf},
journal = {Operations Research},
number = {1},
pages = {62--73},
title = {{An iterative aggregation procedure for Markov decision processes}},
url = {http://or.journal.informs.org/content/30/1/62.short},
volume = {30},
year = {1982}
}
@article{Jiang,
author = {Jiang, Ruiwei and Zhang, Muhong and Li, Guang and Guan, Yongpei},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - Unknown - Benders Decomposition for the Two-Stage Security Constrained Robust Unit Commitment Problem.pdf:pdf},
keywords = {benders decomposition,exact separation,ity limits,mixed integer programming,transmission capac-,unit commitment},
title = {{Benders Decomposition for the Two-Stage Security Constrained Robust Unit Commitment Problem}}
}
@book{Osborne1994,
author = {Osborne, Martin J and Rubinstein, Ariel},
booktitle = {Proceeding of the {\{}IEEE{\}} {\{}C{\}}onference on {\{}D{\}}ecision and {\{}C{\}}ontrol},
title = {{A course in game theory}},
year = {1994}
}
@article{Hauskrecht2000,
author = {Hauskrecht, Milos},
journal = {Journal of Artificial Intelligence Research},
pages = {33--94},
title = {{Value-function approximation for partially observable Markov decision processes}},
volume = {13},
year = {2000}
}
@inproceedings{Abe2010,
address = {New York, New York, USA},
author = {Abe, Naoki and Kowalczyk, Melissa and Domick, Mark and Gardinier, Timothy and Melville, Prem and Pendus, Cezar and Reddy, Chandan K. and Jensen, David L. and Thomas, Vince P. and Bennett, James J. and Anderson, Gary F. and Cooley, Brent R.},
booktitle = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/1835804.1835817},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abe et al. - 2010 - Optimizing debt collections using constrained reinforcement learning.pdf:pdf},
isbn = {9781450300551},
publisher = {ACM Press},
title = {{Optimizing debt collections using constrained reinforcement learning}},
url = {http://dl.acm.org/citation.cfm?doid=1835804.1835817},
year = {2010}
}
@inproceedings{Kalyanakrishnan2007,
abstract = {Reinforcement learning is a paradigm under which an agent seeks to improve its policy by making learning updates based on the experiences it gathers through interaction with the environment. Model-free algorithms perform updates solely bas ed on observed experiences. By contrast, model-based algorithms learn a model of the environment that effectively simulates its dynamics. The model may be used to simulate experiences or to plan into the future, potentially expediting the learning process. This paper presents a model-based reinforcement learning approach for Keepaway, a complex, continuous, stochastic, multiagent subtask of RoboCup simulated soccer. First, we propose the design of an environmental model that is partly learned based on the agent's experiences. This model is then coupled with the reinforcement learning algorithm to learn an action selection policy. We evaluate our method through empirical comparisons with model-free approaches that have been previously applied successfully to this task. Results demonstrate significant gains in the learning speed and asymptotic performance of our method. We also show that the learned model can be used effectively as part of a planning-based approach with a hand-coded policy.},
author = {Kalyanakrishnan, Shivaram and Stone, Peter and Liu, Yaxin},
booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
doi = {10.1007/978-3-540-68847-1_15},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalyanakrishnan, Stone, Liu - 2007 - Model-based reinforcement learning in a complex domain.pdf:pdf},
isbn = {3540688463},
issn = {03029743},
keywords = {evolution and adaptation,learning,perception and ac-},
pages = {650--657},
title = {{Model-based reinforcement learning in a complex domain}},
year = {2007}
}
@inproceedings{Petrik2007b,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2004 - Anytime Coordination Using Separable Bilinear Programs.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2007 - Anytime coordination using separable bilinear programs.pdf:pdf},
pages = {750--755},
title = {{Anytime coordination using separable bilinear programs}},
url = {http://www.aaai.org/Papers/AAAI/2007/AAAI07-119.pdf},
year = {2007}
}
@inproceedings{Kumar2015,
author = {Kumar, Akshat and Zilberstein, Shlomo},
booktitle = {International Conference on Automated Planning and Scheduling (ICAPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Zilberstein - 2015 - History-Based Controller Design and Optimization for Partially Observable MDPs.pdf:pdf},
pages = {156--164},
title = {{History-Based Controller Design and Optimization for Partially Observable MDPs}},
year = {2015}
}
@article{Shapiro2011,
annote = {From Duplicate 2 ( Analysis of stochastic dual dynamic programming method - Shapiro, Alexander )
},
author = {Shapiro, Alexander},
doi = {10.1016/j.ejor.2010.08.007},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro - 2011 - Analysis of stochastic dual dynamic programming method.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {algorithm,ashapiro,atlanta,average approximation method,award dms-0914785 and,e-mail,edu,gatech,georgia 30332-0205,georgia institute of technology,isye,monte carlo sampling,risk averse optimization,sample,school of industrial and,stochastic dual dynamic programming,stochastic programming,supported by the nsf,systems engineering,this research was partly,usa},
month = {feb},
number = {1},
pages = {63--72},
title = {{Analysis of stochastic dual dynamic programming method}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377221710005448},
volume = {209},
year = {2011}
}
@article{Woodruff2014,
abstract = {Computational Advertising, popularly known as online advertising or Web advertising, refers to finding the most relevant ads matching a particular context on the Web. The context depends on the type of advertising and could mean — content where the ad is shown, the user who is viewing the ad or the social network of the user. Computational Advertising (CA) is a scientific sub-discipline at the intersection of information retrieval, statistical modeling, machine learning, optimization, large scale search and text analysis. The core problem addressed in Computational Advertising is of match-making between the ads and the context.CA is prevalent in three major forms on the Web. One of the forms involves showing textual ads relevant to a query on the search page, known as Sponsored Search. On the other hand, showing textual ads relevant to a third party webpage content is known as Contextual Advertising. The third form of advertising also deals with the placement of ads on third party Web pages, but the ads in this form are rich multimedia ads — image, video, audio, flash. The business model with rich media ads is slightly different from the ones with textual ads. These ads are also called banner ads, and this form of advertising is known as Display Advertising.Both Sponsored Search and Contextual Advertising involve retrieving relevant ads for different types of content (query and Web page). As ads are short and are mainly written to attract the user, retrieval of ads pose challenges like vocabulary mismatch between the query/content and the ad. Also, as the user's probability of examining an ad decreases with the position of the ad in the ranked list, it is imperative to keep the best ads at the top positions. Display Advertising poses several challenges including modeling user behaviour and noisy page content and bid optimization on the advertiser's side. Additionally, online advertising faces challenges like false bidding, click spam and ad spam. These challenges are prevalent in all forms of advertising. There has been a lot of research work published in different areas of CA in the last one and a half decade. The focus of this survey is to discuss the problems and solutions pertaining to the information retrieval, machine learning and statistics domain of CA. This survey covers techniques and approaches that deal with several issues mentioned above.Research in Computational Advertising has evolved over time and currently continues both in traditional areas (vocabulary mismatch, query rewriting, click prediction) and recently identified areas (user targeting, mobile advertising, social advertising). In this study, we predominantly focus on the problems and solutions proposed in traditional areas in detail and briefly cover the emerging areas in the latter half of the survey. To facilitate future research, a discussion of available resources, list of public benchmark datasets and future directions of work is also provided in the end.},
author = {Woodruff, David P.},
doi = {10.1561/0400000060},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Woodruff - 2014 - Sketching as a Tool for Numerical Linear Algebra.pdf:pdf},
isbn = {9781601988331},
issn = {1551-305X},
journal = {Foundations and Trends{\textregistered} in Theoretical Computer Science},
number = {1-2},
pages = {1--157},
title = {{Sketching as a Tool for Numerical Linear Algebra}},
url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-060},
volume = {10},
year = {2014}
}
@article{Agarwal2014,
abstract = {We present a new algorithm for the contextual bandit learning problem, where the learner repeatedly takes one of {\$}K{\$} actions in response to the observed context, and observes the reward only for that chosen action. Our method assumes access to an oracle for solving fully supervised cost-sensitive classification problems and achieves the statistically optimal regret guarantee with only {\$}\backslashtilde{\{}O{\}}(\backslashsqrt{\{}KT/\backslashlog N{\}}){\$} oracle calls across all {\$}T{\$} rounds, where {\$}N{\$} is the number of policies in the policy class we compete against. By doing so, we obtain the most practical contextual bandit learning algorithm amongst approaches that work for general policy classes. We further conduct a proof-of-concept experiment which demonstrates the excellent computational and prediction performance of (an online variant of) our algorithm relative to several baselines.},
archivePrefix = {arXiv},
arxivId = {1402.0555},
author = {Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert E.},
doi = {10.1613/jair.301},
eprint = {1402.0555},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agarwal et al. - 2014 - Taming the Monster A Fast and Simple Algorithm for Contextual Bandits.pdf:pdf},
isbn = {9781634393973},
issn = {10769757},
journal = {Journal of Machine Learning Research},
number = {i},
pages = {1--28},
pmid = {17255001},
title = {{Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits}},
url = {http://arxiv.org/abs/1402.0555},
volume = {32},
year = {2014}
}
@book{Ben-david2014,
author = {Ben-david, Shai and Shalev-Shwartz, Shai},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-david, Shalev-Shwartz - 2014 - Understanding-Machine-Learning-Theory-Algorithms.pdf:pdf},
isbn = {9781107057135},
pages = {1--20},
title = {{Understanding-Machine-Learning-Theory-Algorithms}},
url = {http://www.cs.huji.ac.il/{~}shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf},
year = {2014}
}
@article{Blum1986,
author = {Blum, Manuel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blum - 1986 - Independent unbiased coin flips from a correlated biased source—a finite state Markov chain.pdf:pdf},
journal = {Combinatorica},
title = {{Independent unbiased coin flips from a correlated biased source—a finite state Markov chain}},
url = {http://link.springer.com/article/10.1007/BF02579167},
year = {1986}
}
@inproceedings{Nair2005,
author = {Nair, Ranjit and Varakantham, Pradeep and Tambe, Milind and Yokoo, Makoto},
booktitle = {National Conference on Artificial Intelligence},
title = {{Networked distributed POMDPs: A synthesis of distributed constraint optimization and POMDPs}},
year = {2005}
}
@inproceedings{Gentile2014,
abstract = {We introduce a novel algorithmic approach to content recommendation based on adaptive clustering of exploration-exploitation ("bandit") strategies. We provide a sharp regret analysis of this algorithm in a standard stochastic noise setting, demonstrate its scalability properties, and prove its effectiveness on a number of artificial and real-world datasets. Our experiments show a significant increase in prediction performance over state-of-the-art methods for bandit problems.},
archivePrefix = {arXiv},
arxivId = {1401.8257},
author = {Gentile, Claudio and Zappella, Giovanni and Com, Zappella Amazon and Li, Shuai and Zappella, Giovanni},
booktitle = {International Conference on Machine Learning},
eprint = {1401.8257},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gentile, Li, Zappella - 2014 - Online Clustering of Bandits.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gentile, Zappella, Com - 2014 - Online Clustering of Bandits.pdf:pdf},
keywords = {()},
month = {jan},
title = {{Online Clustering of Bandits}},
url = {http://arxiv.org/abs/1401.8257},
year = {2014}
}
@article{Chen2009,
author = {Chen, W. and Sim, M. and Sun, J. and Teo, C. P.},
doi = {10.1287/opre.1090.0712},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2009 - From CVaR to Uncertainty Set Implications in Joint Chance-Constrained Optimization.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {oct},
number = {2},
pages = {470--485},
title = {{From CVaR to Uncertainty Set: Implications in Joint Chance-Constrained Optimization}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1090.0712},
volume = {58},
year = {2009}
}
@book{Judd1998,
author = {Judd, K L},
publisher = {MIT Press},
title = {{Numerical methods in Economics}},
year = {1998}
}
@article{Langford2007,
abstract = {We present Epoch-Greedy, an algorithm for contextual multi-armed bandits (also known as bandits with side information). Epoch-Greedy has the following properties: 1. No knowledge of a time horizon T is necessary. 2. The regret incurred by Epoch-Greedy is controlled by a sample complexity bound for a hypothesis class. 3. The regret scales as O(T 2/3 S 1/3) or better (sometimes, much better). Here S is the complexity term in a sample complexity bound for standard supervised learning. 1},
author = {Langford, John and Zhang, Tong},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Langford, Zhang - 2007 - The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits.pdf:pdf},
isbn = {160560352X},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1--8},
title = {{The Epoch-Greedy Algorithm for Contextual Multi-armed Bandits}},
year = {2007}
}
@article{Contreras2002,
author = {Contreras, Javier and Espinola, Rosario and Nogales, F. J. and Conejo, Antonio J.},
doi = {10.1109/MPER.2002.4312577},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Contreras et al. - 2002 - ARIMA Models to Predict Next-Day Electricity Prices.pdf:pdf},
issn = {0272-1724},
journal = {IEEE Power Engineering Review},
number = {9},
pages = {57--57},
title = {{ARIMA Models to Predict Next-Day Electricity Prices}},
url = {http://ieeexplore.ieee.org/document/4312577/},
volume = {22},
year = {2002}
}
@article{Steduto2009,
author = {Steduto, P and Raes, D and Hsiao, TC and Fereres, E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steduto et al. - 2009 - AquaCrop a new model for crop prediction under water deficit conditions.pdf:pdf},
journal = {FAO, Rome},
keywords = {afin de faire face,crop modeling,d,eau est capitale dans,en conditions de limitation,en train de d{\'{e}}velopper,estimation de la production,l,la fao est,la s{\'{e}}cheresse,les environnements arides,productive des cultures herbac{\'{e}}es,qui peut {\^{e}}tre obtenue,resume,semi-arides et sujets {\'{a}},simulation de la r{\'{e}}ponse,un logiciel pour la,water productivity,water stress,yield simulation,{\'{a}} cette exigence,{\'{a}} la},
number = {80},
pages = {285--292},
title = {{AquaCrop: a new model for crop prediction under water deficit conditions}},
url = {http://om.ciheam.org/om/pdf/a80/00800453.pdf},
volume = {33},
year = {2009}
}
@article{Topsøe2000,
abstract = {Inequalities which connect information divergence with other$\backslash$nmeasures of discrimination or distance between probability distributions$\backslash$nare used in information theory and its applications to mathematical$\backslash$nstatistics, ergodic theory, and other scientific fields. We suggest new$\backslash$ninequalities of this type, often based on underlying identities. As a$\backslash$nconsequence, we obtain certain improvements of the well-known Pinsker$\backslash$ninequality. Our study depends on two measures of discrimination, called$\backslash$ncapacitory discrimination and triangular discrimination. The discussion$\backslash$ncontains references to related research and comparison with other$\backslash$nmeasures of discrimination, e.g., Ali-Silvey-Csiszar (1996, 1966)$\backslash$ndivergences and, in particular, the Hellinger distance},
author = {Tops{\o}e, Flamming},
doi = {10.1109/18.850703},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tops{\o}e - 2000 - Some inequalities for information divergence and related measures of discrimination.pdf:pdf},
isbn = {00189448 (ISSN)},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {capacitory discrimination,information divergence,ity,pinsker,s inequal-,triangular discrimination},
number = {4},
pages = {1602--1609},
title = {{Some inequalities for information divergence and related measures of discrimination}},
volume = {46},
year = {2000}
}
@inproceedings{Feraud2015,
abstract = {To address the contextual bandit problem, we propose online decision tree algorithms. The analysis of proposed algorithms is based on the sample complexity needed to find the optimal decision stump. Then, the decision stumps are assembled in a decision tree, KMD-Tree, and in a random collection of decision trees, KMD-Forest. We show that the proposed algorithms are optimal up to a factor {\$}\backslashlog 1/\backslashDelta{\$}. The dependence of the sample complexity upon the number of contextual variables is logarithmic. The computational cost of the proposed algorithm with respect to the time horizon is linear. These analytical results allow the proposed algorithms to be efficient in real applications, where the number of events to process is huge, and where we expect that some contextual variables, chosen from a large set, have potentially non-linear dependencies with the rewards. When KMD-Trees are assembled into a KMD-Forest, the analysis is done against a strong reference, the Random Forest built knowing the joint distribution of contexts and rewards. We show that the expected dependent regret bound against this strong reference is logarithmic with respect to the time horizon. In the experiments done to illustrate the theoretical analysis, KMD-Tree and KMD-Forest obtain promising results in comparison with state-of-the-art algorithms.},
archivePrefix = {arXiv},
arxivId = {1504.06952},
author = {F{\'{e}}raud, Rapha{\"{e}}l and Allesiardo, Robin and Urvoy, Tanguy and Cl{\'{e}}rot, Fabrice},
booktitle = {AISTATS},
eprint = {1504.06952},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/F{\'{e}}raud et al. - 2016 - Random Forest for the Contextual Bandit Problem.pdf:pdf},
keywords = {contextual bandit,multi-armed bandits,online decision,random forest,sample complexity,tree},
title = {{Random Forest for the Contextual Bandit Problem}},
url = {http://arxiv.org/abs/1504.06952},
year = {2016}
}
@article{El2008,
author = {El, Laurent and Eecs, Ghaoui and Berkeley, U C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/El, Eecs, Berkeley - 2008 - Robustness and Regularization An Optimization Perspective.pdf:pdf},
title = {{Robustness and Regularization : An Optimization Perspective}},
year = {2008}
}
@article{Aras2010,
author = {Aras, Raghav and Dutech, Alain},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aras, Dutech - 2010 - An Investigation into Mathematical Programming for Finite Horizon Decentralized POMDPs.pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {329--396},
title = {{An Investigation into Mathematical Programming for Finite Horizon Decentralized POMDPs}},
volume = {37},
year = {2010}
}
@article{Stoll2005,
author = {Stoll, B.},
doi = {10.1109/IGARSS.2005.1525877},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stoll - 2005 - SARvi a vegetation index based on AirSAR data for south pacific volcanic islands vegetation mapping.pdf:pdf},
isbn = {0-7803-9050-4},
journal = {Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.},
keywords = {areas thanks to the,c-vv g,classification,figure 1,jpl-airsar,l-hh,l-hv b,ndvi,polarimetric properties of the,r,sarvi,tubuai sar composite,vegetation,vegetation index,vegetation mapping},
pages = {4331--4334},
publisher = {Ieee},
title = {{SARvi: a vegetation index based on AirSAR data for south pacific volcanic islands vegetation mapping}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1525877},
volume = {6},
year = {2005}
}
@article{Poskitt1996,
author = {Poskitt, DS and Chung, SH},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poskitt, Chung - 1996 - Markov chain models, time series analysis and extreme value theory.pdf:pdf},
journal = {Advances in Applied Probability},
number = {2},
pages = {405--425},
title = {{Markov chain models, time series analysis and extreme value theory}},
url = {http://www.jstor.org/stable/10.2307/1428065},
volume = {28},
year = {1996}
}
@article{Lovejoy1991,
author = {Lovejoy, William S},
journal = {Operations Research},
pages = {162--175},
title = {{Computationally feasible bounds for partially observed Markov decision processes}},
volume = {39},
year = {1991}
}
@article{Castro2010a,
author = {Castro, Pablo Samuel and Precup, Doina},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro, Precup - 2010 - Smarter Sampling in Model-Based Bayesian Reinforcement Learning.pdf:pdf},
journal = {Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2010. LNAI},
pages = {200--2014},
title = {{Smarter Sampling in Model-Based Bayesian Reinforcement Learning}},
volume = {6321},
year = {2010}
}
@article{Mulvey1995,
author = {Mulvey, JM and Ruszczy{\'{n}}ski, A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mulvey, Ruszczy{\'{n}}ski - 1995 - A new scenario decomposition method for large-scale stochastic optimization.pdf:pdf},
journal = {Operations research},
number = {3},
pages = {477--490},
title = {{A new scenario decomposition method for large-scale stochastic optimization}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.43.3.477},
volume = {43},
year = {1995}
}
@article{Chen2013,
address = {Paris, France},
author = {Chen, Peng and Lu, Lu},
doi = {10.2991/isca-13.2013.51},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Lu - 2013 - Markov Decision Process Parallel Value Iteration Algorithm On GPU.pdf:pdf},
isbn = {978-90786-77-85-7},
journal = {Proceedings of the 2013 International Conference on Information Science and Computer Applications (ISCA 2013)},
keywords = {based on markov decision,gpu,markov decision process,mdp,opencl,out of play model,parallel algorithm,process,the best,this paper defines an},
pages = {299--304},
publisher = {Atlantis Press},
title = {{Markov Decision Process Parallel Value Iteration Algorithm On GPU}},
url = {http://www.atlantis-press.com/php/paper-details.php?id=9597},
year = {2013}
}
@inproceedings{Maillard,
author = {Maillard, Odalric-ambrym and Mannor, Shie},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillard, Mannor - 2014 - Latent bandits.pdf:pdf},
title = {{Latent bandits}},
year = {2014}
}
@inproceedings{Edelkamp2006,
author = {Edelkamp, Stefan},
booktitle = {Workshop on Model Checking and Artificial Intelligence},
title = {{Automated creation of pattern database search heuristics}},
year = {2006}
}
@inproceedings{Li2007,
author = {Li, Baohua and Si, Jennie},
booktitle = {Neural Networks},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Si - 2007 - Approximate Robust Policy Iteration for Discounted Infinite-Horizon Markov Decision Processes with Uncertain Stationary.pdf:pdf},
pages = {2052--2057},
title = {{Approximate Robust Policy Iteration for Discounted Infinite-Horizon Markov Decision Processes with Uncertain Stationary Parametric Transition Matrices}},
year = {2007}
}
@article{Martelli1977,
author = {Martelli, A},
journal = {Artificial Intelligence},
pages = {1--13},
title = {{On the complexity of admissible search algorithms}},
volume = {8},
year = {1977}
}
@article{Fonteneau2009,
author = {Fonteneau, Raphael and Murphy, Susan and Wehenkel, Louis and Ernst, Damien},
doi = {10.1109/ADPRL.2009.4927534},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fonteneau et al. - 2009 - Inferring bounds on the performance of a control policy from a sample of trajectories.pdf:pdf},
isbn = {978-1-4244-2761-1},
journal = {IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning},
month = {mar},
pages = {117--123},
publisher = {Ieee},
title = {{Inferring bounds on the performance of a control policy from a sample of trajectories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4927534},
year = {2009}
}
@techreport{ETS2016,
author = {ETS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ETS - 2016 - GRE Scores.pdf:pdf},
pages = {2016},
title = {{GRE Scores}},
year = {2016}
}
@inproceedings{Chades2007,
author = {Chades, I and Martin, T G and Curtis, J M R and Barreto, C},
booktitle = {International Congress on Modelling and Simulation},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chades et al. - 2007 - Managing Interacting Species A Reinforcement Learning Decision Theoretic Approach.pdf:pdf},
keywords = {decision theory,predator-prey,reinforcement learning},
pages = {2209--2215},
title = {{Managing Interacting Species : A Reinforcement Learning Decision Theoretic Approach}},
year = {2007}
}
@article{Haboudane2004,
abstract = {A growing number of studies have focused on evaluating spectral indices in terms of their sensitivity to vegetation biophysical parameters, as well as to external factors affecting canopy reflectance. In this context, leaf and canopy radiative transfer models are valuable for modeling and understanding the behavior of such indices. In the present work, PROSPECT and SAILH models have been used to simulate a wide range of crop canopy reflectances in an attempt to study the sensitivity of a set of vegetation indices to green leaf area index (LAI), and to modify some of them in order to enhance their responsivity to LAI variations. The aim of the paper was to present a method for minimizing the effect of leaf chlorophyll content on the prediction of green LAI, and to develop new algorithms that adequately predict the LAI of crop canopies. Analyses based on both simulated and real hyperspectral data were carried out to compare performances of existing vegetation indices (Normalized Difference Vegetation Index [NDVI], Renormalized Difference Vegetation Index [RDVI], Modified Simple Ratio [MSR], Soil-Adjusted Vegetation Index [SAVI], Soil and Atmospherically Resistant Vegetation Index [SARVI], MSAVI, Triangular Vegetation Index [TVI], and Modified Chlorophyll Absorption Ratio Index [MCARI]) and to design new ones (MTVI1, MCARI1, MTVI2, and MCARI2) that are both less sensitive to chlorophyll content variations and linearly related to green LAI. Thorough analyses showed that the above existing vegetation indices were either sensitive to chlorophyll concentration changes or affected by saturation at high LAI levels. Conversely, two of the spectral indices developed as a part of this study, a modified triangular vegetation index (MTVI2) and a modified chlorophyll absorption ratio index (MCARI2), proved to be the best predictors of green LAI. Related predictive algorithms were tested on CASI (Compact Airborne Spectrographic Imager) hyperspectral images and, then, validated using ground truth measurements. The latter were collected simultaneously with image acquisition for different crop types (soybean, corn, and wheat), at different growth stages, and under various fertilization treatments. Prediction power analysis of proposed algorithms based on MCARI2 and MTVI2 resulted in agreements between modeled and ground measurement of non-destructive LAI, with coefficients of determination (r2) being 0.98 for soybean, 0.89 for corn, and 0.74 for wheat. The corresponding RMSE for LAI were estimated at 0.28, 0.46, and 0.85, respectively.},
annote = {Leaf area index observations can be influenced by the chlorophyll content of the leaf. },
author = {Haboudane, Driss and Miller, John R. and Pattey, Elizabeth and Zarco-Tejada, Pablo J. and Strachan, Ian B.},
doi = {10.1016/j.rse.2003.12.013},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haboudane et al. - 2004 - Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies Modeling and v.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {chlorophyll content,green lai,hyperspectral,precision agriculture,prediction algorithms,spectral indices},
month = {apr},
number = {3},
pages = {337--352},
title = {{Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of precision agriculture}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0034425704000264},
volume = {90},
year = {2004}
}
@techreport{Pekelis2016,
abstract = {Optimizely is moving away from traditional, fixed horizon hypothesis testing to sequential testing and replacing Type I error control with false discovery rate (FDR) control. This will enable users to confidently check experiments as often as they like, not need to know an effect size in advance, and test as many variations and goals as desired without worrying about hidden sources of error. Read on to understand why, how, and what new tradeoffs exist.},
author = {Pekelis, Leo and Walsh, David and Johari, Ramesh},
booktitle = {Optimizely whitepaper},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pekelis, Walsh, Johari - 2016 - The New Stats Engine (Optimizely).pdf:pdf},
pages = {1--18},
title = {{The New Stats Engine (Optimizely)}},
url = {http://pages.optimizely.com/rs/optimizely/images/stats{\_}engine{\_}technical{\_}paper.pdf},
year = {2016}
}
@article{Matis1985,
abstract = {This study proposes a methodology for forecasting crop yields at intermediate times in the growing season using Markov chain theory. A Markov chain is constructed, based on historical data, to provide forecast distributions of crop yield for various crop and soil moisture condition classes at selected times prior to harvest. Expected yield and the associated standard error are obtained for each condition class. The methodology is compared to a regression approach in which the independent variables are the various crop and soil moisture conditions. The Markov chain approach requires less stringent assumptions and provides more information than the regression approach. However, the potential loss of precision in the forecast using this approach requires separate evaluation for each application. A data base created by the CERES-Maize model, which simulates the growth and development of a corn crop, is used to demonstrate the development of the forecast yield distributions using the Markov chain approach.},
author = {Matis, J. H. and Saito, T. and Grant, W. E. and Iwig, W. C. and Ritchie, J. T.},
journal = {Agricultural Systems},
number = {3},
pages = {171--187},
title = {{A Markov chain approach to crop yield forecasting}},
volume = {18},
year = {1985}
}
@article{Zipkin1978,
annote = {From Duplicate 2 ( Bounds on the Effect of Aggregating Variables in Linear Programs - Zipkin, Paul H; Apr, No Mar )
},
author = {Zipkin, Paul H and Apr, No Mar},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zipkin, Apr - 2007 - Bounds on the Effect of Aggregating Variables in Linear Programs.pdf:pdf},
journal = {Operations Research},
number = {2},
pages = {403--418},
title = {{Bounds on the effect of aggregating variables in linear programs}},
volume = {28},
year = {1978}
}
@inproceedings{Gratch1992,
author = {Gratch, Jonathan and DeJong, Gerald},
booktitle = {National conference on Artificial intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gratch, DeJong - 1992 - COMPOSER a probabilistic solution to the utility problem in speed-up learning.pdf:pdf},
isbn = {0-262-51063-4},
pages = {235--240},
title = {{COMPOSER: a probabilistic solution to the utility problem in speed-up learning}},
year = {1992}
}
@article{Pinar1996,
author = {Pinar, Mustafa C},
journal = {Mathematical Methods of Operations Research},
number = {3},
pages = {345--370},
title = {{Linear programming via a quadratic penalty function}},
volume = {44},
year = {1996}
}
@inproceedings{De2016,
abstract = {We examined the sequence of decision problems that are encountered in the game of Tetris and found that most of the problems are easy in the following sense: One can choose well among the available actions without knowing an evaluation function that scores well in the game. This is a consequence of three conditions that are preva-lent in the game: simple dominance, cumulative dominance, and noncompensation. These condi-tions can be exploited to develop faster and more effective learning algorithms. In addition, they allow certain types of domain knowledge to be incorporated with ease into a learning algorithm. Among the sequential decision problems we en-counter, it is unlikely that Tetris is unique or rare in having these properties.},
author = {De, Ozgur@mpib-Berlin Mpg and Algorta, Sim{\'{o}}n and Kothiyal, Amit and Simsek, Ozgur and Algorta, Sim{\'{o}}n and Kothiyal, Amit},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De et al. - 2016 - Why Most Decisions Are Easy in Tetris—And Perhaps in Other Sequential Decision Problems, As Well.pdf:pdf},
isbn = {9781510829008},
pages = {1757--1765},
title = {{Why Most Decisions Are Easy in Tetris—And Perhaps in Other Sequential Decision Problems, As Well}},
volume = {48},
year = {2016}
}
@article{Bhatnagar2009,
abstract = {We present four new reinforcement learning algorithms based on actor-critic, natural-gradient and function-approximation ideas, and we provide their convergence proofs. Actor-critic reinforcement learning methods are online approximations to policy iteration in which the value-function parameters are estimated using temporal difference learning and the policy parameters are updated by stochastic gradient descent. Methods based on policy gradients in this way are of special interest because of their compatibility with function-approximation methods, which are needed to handle large or infinite state spaces. The use of temporal difference learning in this way is of special interest because in many applications it dramatically reduces the variance of the gradient estimates. The use of the natural gradient is of interest because it can produce better conditioned parameterizations and has been shown to further reduce variance in some cases. Our results extend prior two-timescale convergence results for actor-critic methods by Konda and Tsitsiklis by using temporal difference learning in the actor and by incorporating natural gradients. Our results extend prior empirical studies of natural actor-critic methods by Peters, Vijayakumar and Schaal by providing the first convergence proofs and the first fully incremental algorithms. {\textcopyright} 2009 Elsevier Ltd.},
author = {Bhatnagar, Shalabh and Sutton, Richard S. and Ghavamzadeh, Mohammad and Lee, Mark},
doi = {10.1016/j.automatica.2009.07.008},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhatnagar et al. - 2009 - Natural actor-critic algorithms.pdf:pdf},
isbn = {0005-1098},
issn = {00051098},
journal = {Automatica},
keywords = {Actor-critic reinforcement learning algorithms,Approximate dynamic programming,Function approximation,Natural gradient,Policy-gradient methods,Temporal difference learning,Two-timescale stochastic approximation},
number = {11},
pages = {2471--2482},
publisher = {Elsevier Ltd},
title = {{Natural actor-critic algorithms}},
url = {http://dx.doi.org/10.1016/j.automatica.2009.07.008},
volume = {45},
year = {2009}
}
@article{Al-Kaisi2003,
author = {Al-Kaisi, MM and Yin, Xinhua},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Kaisi, Yin - 2003 - Effects of nitrogen rate, irrigation rate, and plant population on corn yield and water use efficiency.pdf:pdf},
journal = {Agronomy journal},
pages = {1475--1482},
title = {{Effects of nitrogen rate, irrigation rate, and plant population on corn yield and water use efficiency}},
url = {https://dl.sciencesocieties.org/publications/aj/abstracts/95/6/1475},
volume = {95},
year = {2003}
}
@book{Rubinstein1997,
author = {Rubinstein, Ariel},
title = {{Modeling bounded rationality}},
year = {1997}
}
@article{Kumar2006,
author = {Kumar, D Nagesh and Raju, KS and Ashok, B},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Raju, Ashok - 2006 - Optimal reservoir operation for irrigation of multiple crops using genetic algorithms.pdf:pdf},
journal = {Journal of irrigation and {\ldots}},
number = {April},
pages = {123--129},
title = {{Optimal reservoir operation for irrigation of multiple crops using genetic algorithms}},
url = {http://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-9437(2006)132:2(123)},
year = {2006}
}
@article{McQueen1966,
annote = {From Duplicate 1 ( A modified dynamic programming method for Markovian decision problems - Mcqueen, J )
},
author = {Mcqueen, J},
journal = {Journal of Mathematical Analysis and Applications},
title = {{A modified dynamic programming method for {\{}M{\}}arkovian decision problems}},
volume = {14},
year = {1966}
}
@article{Wiesemann2013,
author = {Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Berc},
doi = {10.1287/moor.1120.0540},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiesemann, Kuhn, Rustem - 2013 - Robust Markov decision processes.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {1,an x -valued,by,denoted by $\chi$,denotes the probability simplex,distribution m,if p,in r x,m,m x for all,markov decision processes,notation for a finite,random variable $\chi$ has,robust optimisation,semidefinite programming,set x,x,$\chi$},
number = {1},
pages = {153--183},
title = {{Robust Markov decision processes}},
url = {http://mor.journal.informs.org/cgi/doi/10.1287/moor.1120.0540},
volume = {38},
year = {2013}
}
@article{Rosenkranz2007,
author = {Rosenkranz, Christian A and Kohler, Uwe and Liska, Jean Louis},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenkranz, Kohler, Liska - 2007 - Modern battery systems for plug-in hybrid electric vehicles.pdf:pdf},
journal = {Power},
keywords = {batteries,battery systems,li-ion,plug-in,sprinter},
title = {{Modern battery systems for plug-in hybrid electric vehicles}},
url = {http://www.lifepo4.info/Battery{\_}study/Batteries/Modern{\_}Battery{\_}Systems{\_}for{\_}Plug{\_}In{\_}Hybrid{\_}Vehicles.pdf},
year = {2007}
}
@article{Boggs1995,
annote = {Approximate the objective function locally using a quadratic approximation of the lagrangian with an estimate of the dual variables

Solve the quadratic program, and update dual variables, for example using the Quadratic program dual values

Repeat.

Good local convregence, but the global convergence could be more complicated.

Interior point methods are generally superior when the second derivatives are available (According to a talk by Philip E. Gill)},
author = {Boggs, PT and Tolle, JW},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boggs, Tolle - 1995 - Sequential quadratic programming.pdf:pdf},
journal = {Acta numerica},
pages = {1--52},
title = {{Sequential quadratic programming}},
url = {http://journals.cambridge.org/abstract{\_}S0962492900002518},
year = {1995}
}
@inproceedings{Abe2004,
author = {Abe, Naoki and Zadrozny, Bianca and Langford, John},
booktitle = {ACM Conference on Knowledge Discovery and Data Mining (KDD)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abe, Zadrozny, Langford - 2004 - An Iterative Method for Multi-class Cost-sensitive Learning.pdf:pdf},
isbn = {1581138881},
pages = {3--11},
title = {{An Iterative Method for Multi-class Cost-sensitive Learning}},
year = {2004}
}
@article{Gadat2016,
archivePrefix = {arXiv},
arxivId = {1609.04228},
author = {Gadat, S{\'{e}}bastien and Panloup, Fabien and Saadane, Sofiane},
eprint = {1609.04228},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gadat, Panloup, Saadane - 2016 - Stochastic Heavy Ball.pdf:pdf},
journal = {Arxiv},
keywords = {35h10,35p15,60g15,60j70,msc2010,primary,random dynamical systems,second-order methods,stochastic optimization algorithms},
pages = {1--39},
title = {{Stochastic Heavy Ball}},
year = {2016}
}
@article{Tsuchiya1992,
author = {Tsuchiya, Takashi},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsuchiya - 1992 - Global convergence property of the affine scaling methods for primal degenerate linear programming problems.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {3},
pages = {527--557},
title = {{Global convergence property of the affine scaling methods for primal degenerate linear programming problems}},
url = {http://mor.journal.informs.org/content/17/3/527.short},
volume = {17},
year = {1992}
}
@article{Westphan2003,
author = {Westphan, Michael I and Pickett, Marcus and Getz, Wayne M and Possingham, Hugh P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Westphan et al. - 2003 - The Use of Stochastic Dynamic Programming in Optimal Landscape Reconstruction for Metapopulations.pdf:pdf},
journal = {Ecological Applications},
number = {2},
pages = {543--555},
title = {{The Use of Stochastic Dynamic Programming in Optimal Landscape Reconstruction for Metapopulations}},
volume = {13},
year = {2003}
}
@unpublished{Petrik2010xx,
annote = {In Preparation},
author = {Petrik, Marek},
title = {{Linear Dynamic Programs}}
}
@inproceedings{Russo2014,
abstract = {We propose information-directed sampling -- a new algorithm for online optimization problems in which a decision-maker must balance between exploration and exploitation while learning from partial feedback. Each action is sampled in a manner that minimizes the ratio between squared expected single-period regret and a measure of information gain: the mutual information between the optimal action and the next observation. We establish an expected regret bound for information-directed sampling that applies across a very general class of models and scales with the entropy of the optimal action distribution. For the widely studied Bernoulli, Gaussian, and linear bandit problems, we demonstrate simulation performance surpassing popular approaches, including upper confidence bound algorithms, Thompson sampling, and the knowledge gradient algorithm. Further, we present simple analytic examples illustrating that, due to the way it measures information gain, information-directed sampling can dramatically outperform upper confidence bound algorithms and Thompson sampling.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.2609v5},
author = {Russo, Daniel and {Van Roy}, Benjamin},
booktitle = {Neural Information Processing Systems (NIPS)},
doi = {10.1287/moor.2014.0650},
eprint = {arXiv:1301.2609v5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russo, Van Roy - 2014 - Learning to Optimize via Information-Directed Sampling.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russo, Van Roy - 2016 - Learning to Optimize via Information-Directed Sampling.pdf:pdf},
isbn = {0364-765X},
issn = {15265471},
keywords = {Computer Science - Learning},
pmid = {28028460},
title = {{Learning to Optimize via Information-Directed Sampling}},
url = {http://arxiv.org/abs/1403.5556{\%}5Cnfiles/28/Russo ? Van Roy - 2014 - Learning to Optimize via Information-Directed Samp.pdf{\%}5Cnfiles/29/1403.html http://dx.doi.org/10.1287/moor.2014.0650},
year = {2014}
}
@techreport{Guigues2009,
author = {Guigues, Vincent and Sagastizabal, Claudia},
institution = {Optimization Online},
title = {{Risk averse feasible policies for stochastic linear programming}},
year = {2009}
}
@article{Phillips2006,
abstract = {The availability of detailed environmental data, together with inexpensive and powerful computers, has fueled a rapid increase in predictive modeling of species environmental requirements and geographic distributions. For some species, detailed presence/absence occurrence data are available, allowing the use of a variety of standard statistical techniques. However, absence data are not available for most species. In this paper, we introduce the use of the maximum entropy method (Maxent) for modeling species geographic distributions with presence-only data. Maxent is a general-purpose machine learning method with a simple and precise mathematical formulation, and it has a number of aspects that make it well-suited for species distribution modeling. In order to investigate the efficacy of the method, here we perform a continental-scale case study using two Neotropical mammals: a lowland species of sloth, Bradypus variegatus, and a small montane murid rodent, Microryzomys minutus. We compared Maxent predictions with those of a commonly used presence-only modeling method, the Genetic Algorithm for Rule-Set Prediction (GARP). We made predictions on 10 random subsets of the occurrence records for both species, and then used the remaining localities for testing. Both algorithms provided reasonable estimates of the species' range, far superior to the shaded outline maps available in field guides. All models were significantly better than random in both binomial tests of omission and receiver operating characteristic (ROC) analyses. The area under the ROC curve (AUC) was almost always higher for Maxent, indicating better discrimination of suitable versus unsuitable areas for the species. The Maxent modeling approach can be used in its present form for many applications with presence-only datasets, and merits further research and development.},
author = {Phillips, Steven J. and Anderson, Robert P. and Schapire, Robert E.},
doi = {10.1016/j.ecolmodel.2005.03.026},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Anderson, Schapire - 2006 - Maximum entropy modeling of species geographic distributions.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Distribution,MaxEnt,Maximum entropy,Modeling,Niche,Range,SDMs},
mendeley-tags = {MaxEnt,SDMs},
month = {jan},
number = {3-4},
pages = {231--259},
title = {{Maximum entropy modeling of species geographic distributions}},
url = {http://www.sciencedirect.com/science/article/pii/S030438000500267X},
volume = {190},
year = {2006}
}
@article{Ramadass2003,
author = {Ramadass, P. and Haran, Bala and White, Ralph and Popov, Branko N.},
doi = {10.1016/S0378-7753(03)00531-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramadass et al. - 2003 - Mathematical modeling of the capacity fade of Li-ion cells.pdf:pdf},
isbn = {1803777826},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {capacity fade model,cycle life,li-ion batteries,semi-empirical model},
month = {sep},
number = {2},
pages = {230--240},
title = {{Mathematical modeling of the capacity fade of Li-ion cells}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378775303005317},
volume = {123},
year = {2003}
}
@incollection{Hernandez-Lerma2001,
author = {Hernandez-Lerma, Onesimo and Lasserre, Jean B},
booktitle = {Handbook of Markov Decision Processes: Methods and Applications},
editor = {{In E. Feinberg And A. Shwartz}},
publisher = {Kluwer},
title = {{The linear programming approach}},
year = {2001}
}
@article{Interface2002a,
annote = {Order of pins:

- blue
- blue
- yellow, volts out
- green, frequency out
- red, power 
- black, common


Voltage to OHM conversion data (pg 6 table):

ohms = [ 0, 1, 2, 3, 4, 6, 8,12, 16, 24, 32, 48, 64, 96,
128, 192, 256, 384, 512, 768,
1024, 1536, 2048, 3072, 4096, 6144, 8192, 
12288, 16384, 24576, 32768, 49152, 65536, 98304,
131072, 196608, 262144, 10000000] 

millivolts = [1707, 1704, 1702, 1699, 1697, 1691, 1686, 1676, 1666, 1645, 1625, 
1588, 1552, 1485, 1426, 1320, 1230, 1089, 980, 828, 726, 596, 517, 427, 377,
323, 295, 265, 250, 234, 226, 218, 214, 210, 208, 206, 205,
201]

Resistance to moisture:
ohms{\_}moisture = [550,1000,1100,2000,6000,9200,12200,15575,28075]
kpa = [0,9,10,15,35,55,75,100,200]


Compensated resistance (temperature in C):
R{\_}raw * ( 1 + 0.018 * (t - 24))},
author = {Interface, Electrical and Sensors, Gypsum Block},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Interface, Sensors - 2002 - Electrical Interface for Watermark™ or Gypsum Block Sensors(2).pdf:pdf},
number = {510},
pages = {1--15},
title = {{Electrical Interface for Watermark™ or Gypsum Block Sensors.}},
year = {2002}
}
@book{Smola2014,
abstract = {The machine learning field, which can be briefly defined as enabling computers make successful predictions using past experiences, has exhibited an impressive development recently with the help of the rapid increase in the storage capacity and processing power of computers. Together with many other disciplines, machine learning methods have been widely employed in bioinformatics. The difficulties and cost of biological analyses have led to the development of sophisticated machine learning approaches for this application area. In this chapter, we first review the fundamental concepts of machine learning such as feature assessment, unsupervised versus supervised learning and types of classification. Then, we point out the main issues of designing machine learning experiments and their performance evaluation. Finally, we introduce some supervised learning methods.},
archivePrefix = {arXiv},
arxivId = {0904.3664v1},
author = {Smola, Alex and Vishwanathan, S.V.N.},
booktitle = {Methods in Molecular Biology},
doi = {10.1007/978-1-62703-748-8-7},
eprint = {0904.3664v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smola, Vishwanathan - 2014 - Introduction to machine learning.pdf:pdf},
isbn = {9781627037471},
issn = {10643745},
keywords = {Classification,Clustering,Dimensionality reduction,Machine learning,Model complexity,Model evaluation,Performance metrics,Regression,Supervised learning,Unsupervised learning},
pages = {105--128},
pmid = {24272434},
title = {{Introduction to machine learning}},
volume = {1107},
year = {2014}
}
@inproceedings{Pires2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1602.06346v2},
author = {Pires, Bernardo Avila and Szepesvari, Csaba},
booktitle = {Conference on Learning Theory (COLT)},
eprint = {arXiv:1602.06346v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pires, Szepesvari - 2016 - Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models.pdf:pdf},
title = {{Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models}},
year = {2016}
}
@article{Petrik2016a,
author = {Petrik, Marek and {Mohammad Ghavamzadeh} and Chow, Yinlam},
journal = {Advances in Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Mohammad Ghavamzadeh, Chow - 2016 - Safe Policy Improvement by Minimizing Robust Baseline Regret.pdf:pdf},
title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
year = {2016}
}
@book{Bishop2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, Christopher M},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2013 - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
number = {9},
pages = {1689--1699},
pmid = {25246403},
title = {{Pattern Recognition and Machine Learning}},
volume = {53},
year = {2013}
}
@phdthesis{Cant2006a,
author = {Cant, Lindsey},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cant - 2006 - LIFE-SAVING DECISIONS A Model for Optimal Blood Inventory Management.pdf:pdf},
title = {{LIFE-SAVING DECISIONS : A Model for Optimal Blood Inventory Management}},
year = {2006}
}
@article{NeilC.TurnerabCorrespondingauthorcontactinformationE-mailthecorrespondingauthor,
abstract = {Global warming is widely predicted to decrease crop yields in tropical, sub-tropical and Mediterranean climatic regions as a result of a speeding up of phenological development and shortening of the time to maturity. We used a well-tested simulation model, APSIM-Sorghum, to evaluate the impact of temperatures +1 °C, +2 °C, +3 °C, +4 °C and +5 °C above current temperatures measured over the past ∼50 years at four sites in eastern and southern Africa, namely, Katumani and Makindu in Kenya, Chitala in Malawi and Beitbridge in Zimbabwe, on the yield, aboveground biomass, transpiration and soil evaporation of short-, medium- and long-duration sorghum [Sorghum bicolor (L.) Moench] cultivars given, 0, 20, 40, and 80 kg nitrogen (N) ha−1. When fertilized with 80 kg N ha−1, warming temperatures decreased average yields at Chitala and Beitbridge and yields were unchanged at Makindu and Katumani, but with no added fertilizer average yields increased with increase in temperature at all sites except the hottest and driest site, Beitbridge, where the simulated yields decreased with increasing temperature. Simulation of the changes in soil organic carbon showed that the higher temperatures increased the rate of loss of soil organic carbon and increased nitrogen uptake at all except the driest and hottest site. A micro-dose (20 kg N ha−1) of added nitrogen increased the simulated yields by an average of 19{\%} at Beitbridge, 36{\%} at Makindu, 59{\%} at Katumani and 72{\%} at Chitala, considerably greater than any increase from increased temperatures. The use of longer-duration cultivars and lower or higher populations could not consistently be used to overcome any reductions in yield from warming temperatures. We conclude that low-input, small-holder farmers will not immediately have reduced sorghum yields as a consequence of global warming, but micro-dosing with nitrogen fertilizer will significantly increase yields even in the hottest and driest locations.},
author = {Turner, Neil C. and Rao, K.P.C.},
journal = {Agricultural Systems},
pages = {53--62},
title = {{Simulation analysis of factors affecting sorghum yield at selected sites in eastern and southern Africa, with emphasis on increasing temperatures}},
volume = {121},
year = {2013}
}
@article{Laurent2005,
author = {Laurent, Monique and Rendl, Franz},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laurent, Rendl - 2005 - Semidefinite programming and integer programming.pdf:pdf},
journal = {Handbooks in Operations Research and Management {\ldots}},
title = {{Semidefinite programming and integer programming}},
url = {http://www.sciencedirect.com/science/article/pii/S0927050705120088},
year = {2005}
}
@article{Papadimitriou1987,
annote = {From Duplicate 1 ( The complexity of Markov decision processes - Papadimitriou, Christos H; Tsitsiklis, John )
},
author = {Papadimitriou, Christos H and Tsitsiklis, John},
journal = {Mathematics of Operations Research},
pages = {441--450},
title = {{The complexity of Markov decision processes}},
volume = {12},
year = {1987}
}
@article{Auer2002,
abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we showthat the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support},
author = {Auer, Peter and Cesa-bianchi, Nicolo and Fischer, Paul},
doi = {10.1023/A:1013689704352},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Auer, Cesa-bianchi, Fischer - 2002 - Finite time analysis of the multiarmed bandit problem.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {adaptive allocation rules,bandit problems,finite horizon regret},
number = {2-3},
pages = {235--256},
title = {{Finite time analysis of the multiarmed bandit problem}},
volume = {47},
year = {2002}
}
@article{Philpott2008,
author = {Philpott, A B and Guan, Z},
journal = {Operations Research Letters},
pages = {450--455},
title = {{On the convergence of stochastic dual dynamic programming and related methods}},
volume = {36},
year = {2008}
}
@article{Chukoskie2013,
abstract = {Survival depends on successfully foraging for food, for which evolution has selected diverse behaviors in different species. Humans forage not only for food, but also for information. We decide where to look over 170,000 times per day, approximately three times per wakeful second. The frequency of these saccadic eye movements belies the complexity underlying each individual choice. Experience factors into the choice of where to look and can be invoked to rapidly redirect gaze in a context and task-appropriate manner. However, remarkably little is known about how individuals learn to direct their gaze given the current context and task. We designed a task in which participants search a novel scene for a target whose location was drawn stochastically on each trial from a fixed prior distribution. The target was invisible on a blank screen, and the participants were rewarded when they fixated the hidden target location. In just a few trials, participants rapidly found the hidden targets by looking near previously rewarded locations and avoiding previously unrewarded locations. Learning trajectories were well characterized by a simple reinforcement-learning (RL) model that maintained and continually updated a reward map of locations. The RL model made further predictions concerning sensitivity to recent experience that were confirmed by the data. The asymptotic performance of both the participants and the RL model approached optimal performance characterized by an ideal-observer theory. These two complementary levels of explanation show how experience in a novel environment drives visual search in humans and may extend to other forms of search such as animal foraging.},
author = {Chukoskie, Leanne and Snider, Joseph and Mozer, Michael C and Krauzlis, Richard J and Sejnowski, Terrence J},
doi = {10.1073/pnas.1301216110},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chukoskie et al. - 2013 - Learning where to look for a hidden target.pdf:pdf},
isbn = {0027-8424},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Animals,Biological,Female,Humans,Male,Models,Problem Solving,Problem Solving: physiology,Problem-Based Learning,Visual Perception,Visual Perception: physiology},
pages = {10438--45},
pmid = {23754404},
title = {{Learning where to look for a hidden target.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3690606{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110 Suppl },
year = {2013}
}
@inproceedings{Ravindran2003,
author = {Ravindran, Balaraman and Barto, Andrew G},
booktitle = {International Joint Conference on Artificial Intelligence},
title = {{{\{}SMDP{\}} homomorphisms: An algebraic approach to abstraction in semi-{\{}M{\}}arkov decision processes}},
year = {2003}
}
@article{Wani2013,
author = {Wani, Mushtaq A. and Wani, J. A. and Bhat, M. A. and Kirmani, N. A. and Wani, Zahid M. and Bhat, Shaista Nazir},
journal = {Journal of the Indian Society of Remote Sensing},
number = {2},
title = {{Mapping of Soil Micronutrients in Kashmir Agricultural Landscape Using Ordinary Kriging and Indicator Approach}},
volume = {41},
year = {2013}
}
@techreport{Zhao2012,
author = {Zhao, Xiaoting},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao - 2012 - Bayesian Contextual Multi-armed Bandits.pdf:pdf},
pages = {1--33},
title = {{Bayesian Contextual Multi-armed Bandits}},
year = {2012}
}
@incollection{Holte2005,
author = {Holte, Robert C and Grajkowski, Jeffery and Tanner, Brian},
booktitle = {Abstraction, Reformulation and Approximation},
pages = {121--133},
title = {{Hierarchical Heuristic Search Revisited}},
year = {2005}
}
@article{Tolk1999,
author = {Tolk, J. A. and Howell, T. A. and Evett., S. R.},
journal = {Soil and Tillage Research},
number = {2},
pages = {137--147},
title = {{Effect of mulch, irrigation, and soil type on water use and yield of maize}},
volume = {50},
year = {1999}
}
@article{Lafferty,
author = {Lafferty, John and Wasserman, Larry and Zhou, Shuheng},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Lafferty, Wasserman - Unknown - Compressed Regression.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lafferty, Wasserman, Zhou - Unknown - Compressed Regression.pdf:pdf},
pages = {1--8},
title = {{Compressed Regression}}
}
@article{Maillard2009,
annote = {Bounds the approximation error when features are compressed using a random matrix projection.},
author = {Maillard, OA and Munos, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maillard, Munos - 2009 - Compressed Least-Squares Regression.pdf:pdf},
journal = {Neural Information Processing Systems (NIPS)},
pages = {1--10},
title = {{Compressed Least-Squares Regression.}},
url = {https://papers.nips.cc/paper/3698-compressed-least-squares-regression.pdf},
volume = {2009},
year = {2009}
}
@misc{Gelman1998,
abstract = {We present several classroom demonstrations that have sparked student involvement in our undergraduate course in decision theory and Bayesian statistics. Some of the demonstrations involve student participation, while others are essentially lectures with extra class discussion.},
author = {Gelman, Andrew},
booktitle = {The American Statistician},
doi = {10.2307/2685476},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman - 1998 - Some Class-Participation Demonstrations for Decision Theory and Bayesian Statistics.pdf:pdf},
issn = {00031305},
keywords = {Calibration Probabilty Utility Expected{\_}Value},
number = {2},
pages = {167--174},
title = {{Some Class-Participation Demonstrations for Decision Theory and Bayesian Statistics}},
volume = {52},
year = {1998}
}
@article{Kumar,
author = {Kumar, M.P. and Torr, P.H.S. and Zisserman, a.},
doi = {10.1109/CVPR.2006.283},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar, Torr, Zisserman - Unknown - Solving Markov Random Fields using Second Order Cone Programming Relaxations.pdf:pdf},
isbn = {0-7695-2597-0},
journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 1 (CVPR'06)},
pages = {1045--1052},
publisher = {Ieee},
title = {{Solving Markov Random Fields using Second Order Cone Programming Relaxations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640866},
volume = {1}
}
@article{Stolle2002,
author = {Stolle, Martin and Precup, Doina},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stolle, Precup - 2002 - Learning options in reinforcement learning.pdf:pdf},
journal = {Lecture Notes in Computer Science},
pages = {212--223},
title = {{Learning options in reinforcement learning}},
volume = {2371},
year = {2002}
}
@article{Gittins1979,
author = {Gittins, JC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gittins - 1979 - Bandit processes and dynamic allocation indices.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B},
keywords = {bandit processes,dynamic allocation},
number = {2},
pages = {148--177},
title = {{Bandit processes and dynamic allocation indices}},
url = {http://www.jstor.org/stable/10.2307/2985029},
volume = {41},
year = {1979}
}
@misc{Bertsimas2014a,
abstract = {Sparsity is a key driver in modern statistical problems, from linear regression via the Lasso to matrix regression with nuclear norm penalties in matrix completion and beyond. In stark contrast to sparsity motivations for such problems, it is known in the field of robust optimization that a variety of vector regression problems, such as Lasso which appears as a loss function plus a regularization penalty, can arise by simply immunizing a nominal problem (with only a loss function) to uncertainty in the data. Such a robustification offers an explanation for why some linear regression methods perform well in the face of noise, even when these methods do not produce reliably sparse solutions. In this paper we deepen and extend the understanding of the connection between robustification and regularization in regression problems. Specifically, (a) in the context of linear regression, we characterize under which conditions on the model of uncertainty used and on the loss function penalties robustification and regularization are equivalent; (b) we show how to tractably robustify median regression problems; and (c) we extend the characterization of robustification and regularization to matrix regression problems (matrix completion and Principal Component Analysis).},
archivePrefix = {arXiv},
arxivId = {1411.6160},
author = {Bertsimas, Dimitris and Copenhaver, Martin S.},
eprint = {1411.6160},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Copenhaver - 2014 - Characterization of the equivalence of robustification and regularization in linear, median, and matrix r.pdf:pdf},
keywords = {arXiv:1411.6160},
mendeley-tags = {arXiv:1411.6160},
title = {{Characterization of the equivalence of robustification and regularization in linear, median, and matrix regression}},
url = {http://arxiv.org/abs/1411.6160},
year = {2014}
}
@inproceedings{Gong2006,
annote = {From Duplicate 2 ( A pseudospectral method for the optimal constrol of constrained feedback linearizable systems - Gong, Qi; Kang, Wei; Ross, I Michael )
},
author = {Gong, Qi and Kang, Wei and Ross, I Michael},
booktitle = {{\{}IEEE{\}} Transactions on Automatic Control},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gong, Kang, Ross - 2006 - A pseudospectral method for the optimal constrol of constrained feedback linearizable systems.pdf:pdf},
number = {7},
title = {{A pseudospectral method for the optimal constrol of constrained feedback linearizable systems}},
volume = {51},
year = {2006}
}
@inproceedings{Nair2004,
author = {Nair, Ranjit and Roth, Maayan and Yokoo, Makoto and Tambe, Milind},
booktitle = {International Joint Conference on Agents and Multiagent Systems (AAMAS)},
pages = {1098--1105},
title = {{Communication for Improving Policy Computation in Distributed POMDPs}},
url = {citeseer.ist.psu.edu/nair04communication.html},
year = {2004}
}
@article{Iancu2014,
abstract = {This paper formalizes and adapts the well-known concept of Pareto$\backslash$nefficiency in the context of the popular robust optimization (RO)$\backslash$nmethodology for linear optimization problems. We argue that the$\backslash$nclassical RO paradigm need not produce solutions that possess the$\backslash$nassociated property of Pareto optimality, and we illustrate via examples$\backslash$nhow this could lead to inefficiencies and suboptimal performance in$\backslash$npractice. We provide a basic theoretical characterization of Pareto$\backslash$nrobustly optimal (PRO) solutions and extend the RO framework by$\backslash$nproposing practical methods that verify Pareto optimality and generate$\backslash$nsolutions that are PRO. Critically important, our methodology involves$\backslash$nsolving optimization problems that are of the same complexity as the$\backslash$nunderlying robust problems; hence, the potential improvements from our$\backslash$nframework come at essentially limited extra computational cost. We$\backslash$nperform numerical experiments drawn from three different application$\backslash$nareas (portfolio optimization, inventory management, and project$\backslash$nmanagement), which demonstrate that PRO solutions have a significant$\backslash$npotential upside compared with solutions obtained using classical RO$\backslash$nmethods.},
archivePrefix = {arXiv},
arxivId = {arXiv:1308.4616v3},
author = {Iancu, Dan A. and Trichakis, Nikolaos},
doi = {10.1287/mnsc.2013.1753},
eprint = {arXiv:1308.4616v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iancu, Trichakis - 2014 - Pareto Efficiency in Robust Optimization.pdf:pdf},
isbn = {0025-1909},
issn = {0025-1909},
journal = {Management Science},
keywords = {2012,2013,accepted march 5,advance september 16,by g{\'{e}}rard p,cachon,history,linear programming,online in articles in,optimization,pareto optimality,published,received august 1,robust optimization},
number = {1},
pages = {130--147},
pmid = {28028460},
title = {{Pareto Efficiency in Robust Optimization}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.2013.1753},
volume = {60},
year = {2014}
}
@inproceedings{Ghavamzadeh2011,
abstract = {We consider the problem of reinforcement learning in high-dimensional spaces when the number of features is bigger than the number of samples. In particular, we study the least-squares temporal difference (LSTD) learning algorithm when a space of low dimension is generated with a random projection from a highdimensional space. We provide a thorough theoretical analysis of the LSTD with random projections and derive performance bounds for the resulting algorithm. We also show how the error of LSTD with random projections is propagated through the iterations of a policy iteration algorithm and provide a performance bound for the resulting least-squares policy iteration (LSPI) algorithm.},
author = {Ghavamzadeh, Mohammad and Lazaric, Alessandro and Maillard, Odalric-Ambrym and Munos, R{\'{e}}mi},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghavamzadeh et al. - 2010 - LSTD with Random Projections.pdf:pdf},
isbn = {9781617823800},
keywords = {Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
title = {{LSTD with Random Projections}},
url = {http://eprints.pascal-network.org/archive/00007417/},
year = {2010}
}
@article{Lozano2008,
abstract = {In practical applications of classification, there are often varying costs associated with different types of misclassification (e.g. fraud detection, anomaly detection and medical diag- nosis), motivating the need for the so-called ”cost-sensitive” classification. In this paper, we introduce a family of novel boosting methods for cost-sensitive classification by applying the theory of gradient boosting to p-norm based cost functionals, and establish theoretical guarantees as well as their empirical advantage over existing algorithms.},
author = {Lozano, AC and Abe, Naoki},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lozano, Abe - 2008 - Cost-sensitive Boosting with p-norm Loss Functionsand its Applications.pdf:pdf},
journal = {12},
pages = {1--10},
title = {{Cost-sensitive Boosting with p-norm Loss Functionsand its Applications}},
url = {https://qir.kyushu-u.ac.jp/dspace/handle/2324/13302},
year = {2008}
}
@article{Givan2003,
author = {Givan, Robert and Dean, Thomas and Greig, Matthew},
journal = {Artificial Intelligence},
pages = {163--223},
title = {{Equivalence notions and model minimization in {\{}M{\}}arkov decision processes}},
volume = {147},
year = {2003}
}
@article{Todorov2008,
author = {Todorov, Emanuel},
doi = {10.1109/CDC.2008.4739438},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todorov - 2008 - General duality between optimal control and estimation.pdf:pdf},
isbn = {978-1-4244-3123-6},
journal = {2008 47th IEEE Conference on Decision and Control},
keywords = {Estimation,Stochastic optimal control},
number = {5},
pages = {4286--4292},
publisher = {Ieee},
title = {{General duality between optimal control and estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4739438},
year = {2008}
}
@article{Follmer2011a,
abstract = {We study a coherent version of the entropic risk measure, both in the law-invariant case and in a situation of model ambiguity. In particular, we discuss its behavior under the pooling of independent risks and its connection with a classical and a robust large deviations bound.},
author = {F{\"{o}}llmer, Hans and Knispel, Thomas},
doi = {10.1142/S0219493711003334},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/F{\"{o}}llmer, Knispel - 2011 - Entropic Risk Measures Coherence Vs. Convexity, Model Ambiguity and Robust Large Deviations.pdf:pdf},
issn = {0219-4937},
journal = {Stochastics and Dynamics},
keywords = {2010,60f10,62p05,91b16,91b30,ams subject classification,large deviations,model ambiguity,premium principles,risk measures},
number = {02n03},
pages = {333--351},
title = {{Entropic Risk Measures: Coherence Vs. Convexity, Model Ambiguity and Robust Large Deviations}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0219493711003334},
volume = {11},
year = {2011}
}
@article{Dasgupta2003,
author = {Dasgupta, Sanjoy and Gupta, Anupam},
doi = {10.1002/rsa.10073},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dasgupta, Gupta - 2003 - An elementary proof of a theorem of Johnson and Lindenstrauss.pdf:pdf},
issn = {1042-9832},
journal = {Random Structures and Algorithms},
month = {jan},
number = {1},
pages = {60--65},
title = {{An elementary proof of a theorem of Johnson and Lindenstrauss}},
url = {http://doi.wiley.com/10.1002/rsa.10073},
volume = {22},
year = {2003}
}
@article{Rust2001,
author = {Rust, J and Traub, J F and Wozniakowski, H},
journal = {Econometrica},
title = {{Is there a curse of dimensionality for contraction fixed points in the worst case?}},
volume = {?? Forthco},
year = {2001}
}
@book{Si2004,
author = {Si, Jennie and Barto, Andy and Powell, Warren and Wunsch, Donald},
title = {{Handbook of Learning and Approximate Dynamic Programming}},
year = {2004}
}
@inproceedings{Delage2007,
abstract = {Markov decision processes are an effective tool in modeling decision-making$\backslash$nin uncertain dynamic environments. Since the parameters of these$\backslash$nmodels are typically estimated from data, learned from experience,$\backslash$nor designed by hand, it is not surprising that the actual performance$\backslash$nof a chosen strategy often significantly differs from the designer's$\backslash$ninitial expectations due to unavoidable model uncertainty. In this$\backslash$npaper, we present a percentile criterion that captures the trade-off$\backslash$nbetween optimistic and pessimistic points of view on MDP with parameter$\backslash$nuncertainty. We describe tractable methods that take parameter uncertainty$\backslash$ninto account in the process of decision making. Finally, we propose$\backslash$na cost-effective exploration strategy when it is possible to invest$\backslash$n(money, time or computation efforts) in actions that will reduce$\backslash$nthe uncertainty in the parameters.},
author = {Delage, Erick and Mannor, Shie},
booktitle = {International Conference of Machine Learning (ICML)},
doi = {http://doi.acm.org/10.1145/1273496.1273525},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delage, Edu, Mannor - 2007 - Percentile Optimization in Uncertain Markov Decision Processes with Application to Efficient Exploration.pdf:pdf},
isbn = {978-1-59593-793-3},
pages = {225--232},
title = {{Percentile optimization in uncertain Markov decision processes with application to efficient exploration}},
year = {2007}
}
@inproceedings{Li2008,
author = {Li, Lihong and Littman, Michael L and Walsh, Thomas J},
booktitle = {International Conference on Machine Learning},
title = {{Knows what it knows: A framework for self-aware learning}},
year = {2008}
}
@article{Wang2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1307.6279v3},
author = {Wang, Zizhuo and Glynn, Peter W},
eprint = {arXiv:1307.6279v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Glynn - 2016 - Likelihood Robust Optimization for Data-driven Problems.pdf:pdf},
journal = {Computational Management Science},
number = {2},
pages = {241--261},
title = {{Likelihood Robust Optimization for Data-driven Problems}},
volume = {13},
year = {2016}
}
@article{Schuurmans2001,
author = {Schuurmans, D and Patrascu, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schuurmans, Patrascu - 2001 - Direct value-approximation for factored MDPs.pdf:pdf},
journal = {NIPS},
title = {{Direct value-approximation for factored MDPs.}},
url = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/CN14.ps.gz},
year = {2001}
}
@misc{Eddmaps2016,
title = {{EDDMapS. 2016. Early Detection {\&} Distribution Mapping System. The University of Georgia - Center for Invasive Species and Ecosystem Health}},
urldate = {2011-06-20},
year = {2016}
}
@inproceedings{Gashnig1977,
author = {Gashnig, J},
booktitle = {International Joint Conference on AI},
title = {{Exactly how good are heuristics? Toward a realistic predictive theory of best-first search}},
year = {1977}
}
@inproceedings{Petrik2016b,
abstract = {An important problem in sequential decision-making under uncertainty is to use limited data to compute a safe policy, i.e., a policy that is guaranteed to perform at least as well as a given baseline strategy. In this paper, we develop and analyze a new model-based approach to compute a safe policy when we have access to an inaccurate dynamics model of the system with known accuracy guarantees. Our proposed robust method uses this (inaccurate) model to directly minimize the (negative) regret w.r.t. the baseline policy. Contrary to the existing approaches, minimizing the regret allows one to improve the baseline policy in states with accurate dynamics and seamlessly fall back to the baseline policy, otherwise. We show that our formulation is NP-hard and propose an approximate algorithm. Our empirical results on several domains show that even this relatively simple approximate algorithm can significantly outperform standard approaches.},
archivePrefix = {arXiv},
arxivId = {1607.03842},
author = {Petrik, Marek and Chow, Yinlam and Ghavamzadeh, Mohammad},
booktitle = {ICML Workshop on Reliable Machine Learning in the Wild},
eprint = {1607.03842},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Chow, Ghavamzadeh - 2016 - Safe Policy Improvement by Minimizing Robust Baseline Regret.pdf:pdf},
pages = {1--25},
pmid = {2625008024985752158},
title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
url = {http://arxiv.org/abs/1607.03842},
year = {2016}
}
@article{Whitt1978,
annote = {From Duplicate 1 ( Approximations of dynamic programs - Whitt, Ward )
},
author = {Whitt, Ward},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whitt - 1978 - Approximations of dynamic programs.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {3},
pages = {231--243},
title = {{Approximations of dynamic programs}},
volume = {3},
year = {1978}
}
@article{Chen2004,
annote = {Inventory and price optimization with fixed costs.

An interesting question is whether the optimal selling price is a nonincreasing function of the initial inventory level, as is the case for a similar model with no fixed cost; see Federgruen and Heching (1999). Unfortunately, this property does not hold for our model.},
author = {Chen, Xin and Simchi-Levi, David},
doi = {10.1287/opre.1040.0127},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Simchi-Levi - 2004 - Coordinating Inventory Control and Pricing Strategies with Random Demand and Fixed Ordering Cost The Finite H.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {dec},
number = {6},
pages = {887--896},
title = {{Coordinating Inventory Control and Pricing Strategies with Random Demand and Fixed Ordering Cost: The Finite Horizon Case}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1040.0127},
volume = {52},
year = {2004}
}
@inproceedings{rudin2014algorithms,
author = {Rudin, Cynthia},
booktitle = {International Conference on Knowledge Discovery and Data Mining (KDD)},
organization = {ACM},
pages = {1519},
title = {{Algorithms for interpretable machine learning}},
year = {2014}
}
@inproceedings{Kolter2009,
annote = {From Duplicate 2 ( Regularization and Feature Selection in Least-Squares Temporal Difference Learning - Ng, Andrew Y )
},
author = {Ng, Andrew Y and Kolter, J Zico},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng - 2009 - Regularization and Feature Selection in Least-Squares Temporal Difference Learning.pdf:pdf},
title = {{Regularization and feature selection in least-squares temporal difference learning}},
year = {2009}
}
@inproceedings{Ribeiro1996,
author = {Ribeiro, Carlos H C and Szepesvari, Csaba},
booktitle = {International Conference on Intelligent and Cognitive Systems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ribeiro, Szepesvari - 1996 - SPATIAL SPREADING OF ACTION VALUES IN Q-LEARNING I . INTRODUCTION.pdf:pdf},
pages = {32--36},
title = {{SPATIAL SPREADING OF ACTION VALUES IN Q-LEARNING I . INTRODUCTION}},
year = {1996}
}
@article{Kakade2002,
author = {Kakade, Sham and Langford, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade, Langford - 2002 - Approximately Optimal Approximate Reinforcement Learning.pdf:pdf},
journal = {Proceedings of the 19th International Conference on Machine Learning},
pages = {267--274},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
url = {http://www.cs.cmu.edu/afs/cs/Web/People/jcl/papers/aoarl/Final.pdf},
year = {2002}
}
@article{Hillestad1980,
author = {Hillestad, Richard J and Jacobsen, Stephen E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hillestad, Jacobsen - 1980 - Applied Mathematics and Optimization Reverse Convex Programming.pdf:pdf},
journal = {Applied Mathematics and Optimization},
number = {1},
pages = {63--78},
title = {{Applied Mathematics and Optimization Reverse Convex Programming}},
volume = {6},
year = {1980}
}
@article{Rusmevichientong2010a,
author = {Rusmevichientong, Paat and Tsitsiklis, John N.},
doi = {10.1287/moor.1100.0446},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusmevichientong, Tsitsiklis - 2010 - Linearly Parameterized Bandits.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {62f35,62l12,93e35,adaptive control,applications,control,dynamic programming and optimal,ms subject classification,msc2000 subject classification,multi-armed bandit,or,parametric model,primary,secondary,statistics},
month = {may},
number = {2},
pages = {395--411},
title = {{Linearly Parameterized Bandits}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1100.0446},
volume = {35},
year = {2010}
}
@inproceedings{Petrik2009c,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Robust value function approximation using bilinear programming}},
year = {2009}
}
@book{FrancoisBrunDanielWallachDavidMakowski2006,
annote = {Relevant Contents 

Two forms of crop models
Evaluating crop models
Uncertainty ans sensitivity analysis for crop models
Parameter estimation for crop models
Data assimilation with crop models
Representing and optimizing management decisions with crop models
Using crop models for multiple fields

Parameterization and evaluation of a corn crop model
Evaluation of a model for kiwifruit
Sensitivity and uncertainty analysis of a static denitrification model
Model of nitrogen transport
Application of Kalman filters to soil carbon estimation

analyzing and improving corn irrigation strategies with MODERATO: corn crop model and a decision model},
author = {{Francois Brun, Daniel Wallach, David Makowski}, James W. Jones},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Francois Brun, Daniel Wallach, David Makowski - 2006 - Working with Dynamic Crop Models Evaluation, Analysis, Parameterization, and Appl.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Francois Brun, Daniel Wallach, David Makowski - 2006 - Working with Dynamic Crop Models Evaluation, Analysis, Parameterization, and A(2).pdf:pdf},
title = {{Working with Dynamic Crop Models: Evaluation, Analysis, Parameterization, and Applications}},
year = {2006}
}
@article{Desai2012,
annote = {From Duplicate 2 ( Approximate Dynamic Programming via a Smoothed Linear Program - Desai, Vijay V )
},
author = {Desai, V. V. and Farias, V. F. and Moallemi, C. C.},
doi = {10.1287/opre.1120.1044},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desai - 2009 - Approximate Dynamic Programming via a Smoothed Linear Program.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desai, Farias, Moallemi - 2012 - Approximate Dynamic Programming via a Smoothed Linear Program.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {jul},
number = {3},
pages = {655--674},
title = {{Approximate dynamic programming via a smoothed linear program}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1120.1044},
volume = {60},
year = {2012}
}
@article{Rifkin2007,
author = {Rifkin, Ryan M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - 2007 - Fenchel Duality with Auxiliary Parameters Things You Need to Know.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - 2007 - Introduction to Fenchel Duality for Machine Learning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin - 2007 - Fenchel Duality for Machine Learning , Part II A Bit More Theory.pdf:pdf},
title = {{Fenchel Duality with Auxiliary Parameters Things You Need to Know}},
year = {2007}
}
@article{Gmbh2013,
author = {Enocean},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Enocean - 2013 - EnOcean STM330 TMP.pdf:pdf},
keywords = {User Manual Scavenger Transmitter Module STM 330 /},
title = {{EnOcean STM330 TMP}},
year = {2013}
}
@article{Nogueira2016,
archivePrefix = {arXiv},
arxivId = {1602.02261},
author = {Nogueira, Rodrigo},
eprint = {1602.02261},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nogueira - 2016 - End-to-End Goal-Driven Web Navigation.pdf:pdf},
number = {Nips},
title = {{End-to-End Goal-Driven Web Navigation}},
year = {2016}
}
@article{Li2010,
author = {Li, Lihong and Littman, Michael L. and Walsh, Thomas J. and Strehl, Alexander L.},
doi = {10.1007/s10994-010-5225-4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2010 - Knows what it knows a framework for self-aware learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {nov},
number = {3},
pages = {399--443},
title = {{Knows what it knows: a framework for self-aware learning}},
url = {http://link.springer.com/10.1007/s10994-010-5225-4},
volume = {82},
year = {2010}
}
@book{Edition,
author = {Wiliams, David},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiliams - 1991 - Probability With Martingales.pdf:pdf},
isbn = {9781420079388},
title = {{Probability With Martingales}},
year = {1991}
}
@article{Lai2003,
author = {Lai, JY and Myers, RJ and Hanson, SD},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lai, Myers, Hanson - 2003 - Optimal on-farm grain storage by risk-averse farmers.pdf:pdf},
journal = {Journal of Agricultural and Resource Economics},
keywords = {grain storage,risk aversion,stochastic dynamic programming},
number = {3},
pages = {558--579},
title = {{Optimal on-farm grain storage by risk-averse farmers}},
url = {http://www.jstor.org/stable/10.2307/40987967},
volume = {28},
year = {2003}
}
@phdthesis{Larsen2013,
author = {Larsen, John Bruntse},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Larsen - 2013 - Content-based Recommender Systems.pdf:pdf},
school = {Technical University of Denmark},
title = {{Content-based Recommender Systems}},
year = {2013}
}
@article{Vila2011,
abstract = {Biological invasions cause ecological and economic impacts across the globe. However, it is unclear whether there are strong patterns in terms of their major effects, how the vulnerability of different ecosystems varies and which ecosystem services are at greatest risk. We present a global meta-analysis of 199 articles reporting 1041 field studies that in total describe the impacts of 135 alien plant taxa on resident species, communities and ecosystems. Across studies, alien plants had a significant effect in 11 of 24 different types of impact assessed. The magnitude and direction of the impact varied both within and between different types of impact. On average, abundance and diversity of the resident species decreased in invaded sites, whereas primary production and several ecosystem processes were enhanced. While alien N-fixing species had greater impacts on N-cycling variables, they did not consistently affect other impact types. The magnitude of the impacts was not significantly different between island and mainland ecosystems. Overall, alien species impacts are heterogeneous and not unidirectional even within particular impact types. Our analysis also reveals that by the time changes in nutrient cycling are detected, major impacts on plant species and communities are likely to have already occurred.},
author = {Vil{\`{a}}, Montserrat and Espinar, Jos{\'{e}} L and Hejda, Martin and Hulme, Philip E and Jaro{\v{s}}{\'{i}}k, Vojt{\v{e}}ch and Maron, John L and Pergl, Jan and Schaffner, Urs and Sun, Yan and Py{\v{s}}ek, Petr},
doi = {10.1111/j.1461-0248.2011.01628.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vil{\`{a}} et al. - 2011 - Ecological impacts of invasive alien plants a meta-analysis of their effects on species, communities and ecosystem.pdf:pdf},
issn = {1461-0248},
journal = {Ecology letters},
keywords = {Biodiversity,Ecosystem,Geography,Introduced Species,Plants,Population Density,Population Dynamics},
month = {jul},
number = {7},
pages = {702--8},
pmid = {21592274},
title = {{Ecological impacts of invasive alien plants: a meta-analysis of their effects on species, communities and ecosystems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21592274},
volume = {14},
year = {2011}
}
@article{Shani2005,
author = {Shani, Guy and Heckerman, David and Brafman, Ronen I},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shani, Heckerman, Brafman - 2005 - An MDP-based Recommender System.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1265--1295},
title = {{An MDP-based Recommender System}},
volume = {6},
year = {2005}
}
@book{G.P.Nikishkov2006,
author = {{G. P. Nikishkov}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G. P. Nikishkov - 2006 - An introduction to the finite element method.pdf:pdf},
title = {{An introduction to the finite element method}},
url = {http://asccourses.googlecode.com/svn-history/r142/trunk/CSI742/finite{\_}element{\_}method.pdf},
year = {2006}
}
@article{Auer2010,
abstract = {For undiscounted reinforcement learning in Markov decision processes (MDPs) we consider the total regret of a learning algorithm with respect to an optimal policy. In order to describe the transition structure of an MDP we propose a new parameter: An MDP has diameter D if for any pair of states s,s'  there is a policy which moves from s to s' in at most D steps (on average). We present a reinforcement learning algorithm with total regret {\~{O}}(DS√AT) after T steps for any unknown MDP with S states, A actions per state, and diameter D. A corresponding lower bound of $\Omega$(√DSAT) on the total regret of any learning algorithm is given as well.
These results are complemented by a sample complexity bound on the number of suboptimal steps taken by our algorithm. This bound can be used to achieve a (gap-dependent) regret bound that is logarithmic in T.
Finally, we also consider a setting where the MDP is allowed to change a fixed number of l times. We present a modification of our algorithm that is able to deal with this setting and show a regret bound of {\~{O}}(l1/3T2/3DS√A).},
annote = {From Duplicate 1 (Near-optimal Regret Bounds for Reinforcement Learning - Jaksch, Thomas; Ortner, Ronald; Auer, Peter)

Use expected average reward criterion},
archivePrefix = {arXiv},
arxivId = {1403.3741},
author = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
eprint = {1403.3741},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Auer, Jaksch, Ortner - 2010 - Near-optimal regret bounds for reinforcement learning.pdf:pdf},
isbn = {Technical Report No. CIT-2009-01},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Computational,Information-Theoretic Learning with,Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
number = {1},
pages = {1563--1600},
title = {{Near-optimal Regret Bounds for Reinforcement Learning}},
url = {http://eprints.pascal-network.org/archive/00007081/},
volume = {11},
year = {2010}
}
@article{Jain1992,
abstract = {Markov chain approach has been adopted to forecast sugarcane yield. Two years data (1977–78 and 1978–79) on biometrical characters and yield collected by IASRI, New Delhi under the pilot study on pre-harvest forecasting of sugarcane yield in Meerut district (U.P.) were utilised for the study. Yield forecasts at 7–8 months after planting (about 2–3 months before harvest) were very close to the observed ones, per cent deviations from observed being 4{\%} in 1978–79 and 2{\%} in 1977–78. This study thus reveals that Markov Chain method can be successfully used in crop yield forecasting.},
author = {Jain, R. C. and Agrawal, Ranjana},
journal = {Biometrical Journal},
number = {4},
pages = {501--511},
title = {{Probability Model for Crop Yield Forecasting}},
volume = {34},
year = {1992}
}
@article{Patrascu2004b,
annote = {From Duplicate 1 ( Linear approximations for factored Markov decision processes - Patrascu, Relu-Eugen )

From Duplicate 1 ( Linear approximations for factored Markov decision processes - Patrascu, RE )
},
author = {Patrascu, Relu-Eugen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patrascu - 2004 - Linear approximations for factored Markov decision processes.pdf:pdf},
institution = {University of Waterloo},
title = {{Linear approximations for factored Markov decision processes}},
url = {http://uwspace.uwaterloo.ca/handle/10012/1171},
year = {2004}
}
@article{Xu2007,
author = {Xu, Yuesheng and Zhang, Haizhang},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Zhang - 2007 - Refinable Kernels.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {dual ker-,learning with kernels,nels,refinable feature maps,refinable kernels,reproducing kernel hilbert spaces,riesz bases,wavelet-like reproducing kernels},
pages = {2083--2120},
title = {{Refinable Kernels.}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.6011{\&}rep=rep1{\&}type=pdf},
volume = {8},
year = {2007}
}
@article{Bijvank2011,
author = {Bijvank, Marco and Vis, Iris F.a.},
doi = {10.1016/j.ejor.2011.02.004},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bijvank, Vis - 2011 - Lost-sales inventory theory A review.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
month = {nov},
number = {1},
pages = {1--13},
publisher = {Elsevier B.V.},
title = {{Lost-sales inventory theory: A review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377221711001354},
volume = {215},
year = {2011}
}
@book{Bellman1957,
author = {Bellman, Richard},
title = {{Dynamic Programming}},
year = {1957}
}
@article{Littman2004,
abstract = {With the increasing reliance on game theory as a foundation for auctions and electronic commerce, efficient algorithms for computing equilibria in multiplayer general-sum games are of great theoretical and practical interest. The computational complexity of finding a Nash equilibrium for a one-shot bimatrix game is a well known open problem. This paper treats a related but distinct problem, that of finding a Nash equilibrium for an average-payoff repeated bimatrix game, and presents a polynomial-time algorithm. Our approach draws on the well known ``folk theorem'' from game theory and shows how finite-state equilibrium strategies can be found efficiently and expressed succinctly.},
author = {Littman, ML Michael L. and Stone, Peter},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Littman, Stone - 2005 - A polynomial-time Nash equilibrium algorithm for repeated games.pdf:pdf},
journal = {Decision Support Systems},
pages = {55--66},
title = {{A polynomial-time Nash equilibrium algorithm for repeated games}},
url = {http://www.sciencedirect.com/science/article/pii/S0167923604001733},
volume = {39},
year = {2005}
}
@book{French2003,
author = {French, Mark and Szepesv{\'{a}}ri, Csaba and Rogers, Eric},
title = {{Performance of Nonlinear Approximate Adaptive Controllers}},
year = {2003}
}
@inproceedings{Poupart2006a,
author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poupart et al. - 2006 - An Analytic Solution to Discrete Bayesian Reinforcement Learning.pdf:pdf},
title = {{An Analytic Solution to Discrete Bayesian Reinforcement Learning}},
year = {2006}
}
@article{Xu2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0811.1790v1},
author = {Xu, Huan and Caramanis, Constantine and Mannor, Shie and Member, Senior},
eprint = {arXiv:0811.1790v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2010 - Robust Regression and Lasso.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {7},
pages = {3561--3574},
title = {{Robust regression and Lasso}},
volume = {56},
year = {2010}
}
@article{Strehl2004,
author = {Strehl, a. L. and Littman, M. L.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Strehl, Littman - 2004 - An empirical evaluation of interval estimation for markov decision processes.pdf:pdf},
keywords = {learning theory,markov decision processes,reinforcement learning},
number = {April 2007},
pages = {128--135},
title = {{An empirical evaluation of interval estimation for markov decision processes}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1374179},
year = {2004}
}
@article{Geibel2005,
abstract = {In this paper, we consider Markov Decision Processes (MDPs) with error states. Error$\backslash$nstates are those states entering which is undesirable or dangerous. We define the risk$\backslash$nwith respect to a policy as the probability of entering such a state when the policy is$\backslash$npursued. We consider the problem of finding good policies whose risk is smaller than$\backslash$nsome user-specified threshold, and formalize it as a constrained MDP with two criteria.$\backslash$nThe first criterion corresponds to the value function originally given. We will show that$\backslash$nthe risk can be formulated as a second criterion function based on a cumulative return,$\backslash$nwhose definition is independent of the original value function. We present a model free,$\backslash$nheuristic reinforcement learning algorithm that aims at finding good deterministic policies.$\backslash$nIt is based on weighting the original value function and the risk. The weight parameter is$\backslash$nadapted in order to find a feasible solution for the constrained problem that has a good$\backslash$nperformance with respect to the value function. The algorithm was successfully applied$\backslash$nto the control of a feed tank with stochastic inflows that lies upstream of a distillation$\backslash$ncolumn. This control task was originally formulated as an optimal control problem with$\backslash$nchance constraints, and it was solved under certain assumptions on the model to obtain an$\backslash$noptimal solution. The power of our learning algorithm is that it can be used even when$\backslash$nsome of these restrictive assumptions are relaxed.},
archivePrefix = {arXiv},
arxivId = {1109.2147},
author = {Geibel, Peter and Wysotzki, Fritz},
doi = {10.1613/jair.1666},
eprint = {1109.2147},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geibel, Wysotzki - 2005 - Risk-sensitive reinforcement learning applied to control under constraints.pdf:pdf},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {81--108},
title = {{Risk-sensitive reinforcement learning applied to control under constraints}},
volume = {24},
year = {2005}
}
@article{Mannor2005,
annote = {The paper deals with a technical condition for average-reward problems.},
author = {Mannor, Shie and Tsitsiklis, John N.},
doi = {10.1287/moor.1050.0148},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannor, Tsitsiklis - 2005 - On the Empirical State-Action Frequencies in Markov Decision Processes Under General Policies.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {60b10,60f99,90c40,control,dynamic programming,empirical measure,large deviations,markov decision processes,markov finite state,markov processes,ms subject classification,msc2000 subject classification,optimal,or,primary,probability,secondary,state-action frequencies},
month = {aug},
number = {3},
pages = {545--561},
title = {{On the Empirical State-Action Frequencies in Markov Decision Processes Under General Policies}},
url = {http://mor.journal.informs.org/cgi/doi/10.1287/moor.1050.0148},
volume = {30},
year = {2005}
}
@article{Bellinghamb,
author = {Bellingham, J.S. and Tillerson, M. and Alighanbari, M. and How, J.P.},
doi = {10.1109/CDC.2002.1184270},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellingham et al. - Unknown - Cooperative path planning for multiple UAVs in dynamic and uncertain environments.pdf:pdf},
isbn = {0-7803-7516-5},
journal = {Proceedings of the 41st IEEE Conference on Decision and Control, 2002.},
pages = {2816--2822},
publisher = {Ieee},
title = {{Cooperative path planning for multiple UAVs in dynamic and uncertain environments}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1184270},
volume = {3}
}
@article{Nadarajah2014a,
abstract = {Introduced in the 1980s, value at risk has been a popular measure of financial risk. However, value at risk suffers from a number of drawbacks as measure of financial risk. An alternative measure referred to as expected shortfall was introduced in late 1990s to circumvent these drawbacks. Much theory have been developed since then. The developments have been most intensive in recent years.However, we are not aware of any comprehensive review of known estimation methods for expected shortfall. We feel it is timely that such a review is written. This paper (containing six sections and over 140 references) attempts that task with emphasis on recent developments. We expect this review to serve as a source of reference and encourage further research with respect to measures of financial risk.},
author = {Nadarajah, Saralees and Zhang, Bo and Chan, Stephen},
doi = {10.1080/14697688.2013.816767},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nadarajah, Zhang, Chan - 2014 - Estimation methods for expected shortfall.pdf:pdf},
isbn = {1469-7688},
issn = {1469-7688},
journal = {Quantitative Finance},
keywords = {expected shortfall,nonparametric methods,parametric methods,semiparametric},
number = {2},
pages = {271--291},
title = {{Estimation methods for expected shortfall}},
url = {http://www.tandfonline.com/doi/abs/10.1080/14697688.2013.816767},
volume = {14},
year = {2014}
}
@article{Slantchev2004,
author = {Slantchev, Branislav L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Slantchev - 2004 - Game Theory Preferences and Expected Utility.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Slantchev - 2004 - Game Theory Elements of Basic Models .pdf:pdf},
title = {{Game Theory : Preferences and Expected Utility}},
year = {2004}
}
@article{Flessa1999,
author = {Flessa, Steffen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flessa - 1999 - Decision support for malaria-control programmes – a system dynamics model.pdf:pdf},
journal = {Health Care Management Science},
keywords = {epidemiological model,health care policy and,malaria,management,strategic decision support,system dynamics},
number = {1},
pages = {181--191},
title = {{Decision support for malaria-control programmes – a system dynamics model}},
volume = {2},
year = {1999}
}
@article{Russo2014b,
abstract = {This paper considers the use of a simple posterior sampling algorithm to balance between exploration and exploitation when learning to optimize actions such as in multiarmed bandit problems. The algorithm, also known as Thompson Sampling and as probability matching, offers significant advantages over the popular upper confidence bound (UCB) approach, and can be applied to problems with finite or infinite action spaces and complicated relationships among action rewards. We make two theoretical contributions. The first establishes a connection between posterior sampling and UCB algorithms. This result lets us convert regret bounds developed for UCB algorithms into Bayesian regret bounds for posterior sampling. Our second theoretical contribution is a Bayesian regret bound for posterior sampling that applies broadly and can be specialized to many model classes. This bound depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB algorithm Bayesian regret bounds for specific model classes, our general bound matches the best available for linear models and is stronger than the best available for generalized linear models. Further, our analysis provides insight into performance advantages of posterior sampling, which are highlighted through simulation results that demonstrate performance surpassing recently proposed UCB algorithms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1301.2609v5},
author = {Russo, Daniel and {Van Roy}, Benjamin},
doi = {10.1287/moor.2014.0650},
eprint = {arXiv:1301.2609v5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Russo, Van Roy - 2014 - Learning to Optimize via Posterior Sampling.pdf:pdf},
isbn = {0364-765X},
issn = {15265471},
journal = {Mathematics of Operations Research},
keywords = {2013,2014,62l05,93e35,decision analysis,history,in advance april 23,ms subject classification,msc2000 subject classification,multiarmed bandits,online optimization,or,primary,published online in articles,received february 26,revised november 21,secondary,sequential,thompson sampling},
number = {4},
pages = {1221--1243},
title = {{Learning to Optimize via Posterior Sampling}},
url = {http://dx.doi.org/10.1287/moor.2014.0650},
volume = {39},
year = {2014}
}
@misc{Kakade2003,
author = {Kakade, Sham Machandranath},
title = {{On the Sample Complexity of Reinforcement Learning}},
year = {2003}
}
@article{Hale2007,
annote = {Same as Daubechies, but a bit more general, better analysis, and continuation scheme

Notes that this is forward-backward, but says those proofs don't apply because they require strict convexity (?!). Actually, after thinking about it, here's what is happening: forward-backward applies to this situation but it only says the objective value converges, and it requires strong convexity in order to say the iterates themsevesl converge. So proving convergence of iterates is novel (well, other than Daubechies' work).},
author = {Hale, Elaine T and Yin, Wotao and Zhang, Yin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hale, Yin, Zhang - 2007 - A Fixed-Point Continuation Method for l1-Regularized Minimization with Applications to Compressed Sensing.pdf:pdf},
journal = {Rice Technical report TR07-07},
keywords = {1 regularization,FPC fixed point continuation,continuation,q-linear convergence,xed point algorithm},
mendeley-tags = {FPC fixed point continuation},
number = {x},
title = {{A Fixed-Point Continuation Method for l1-Regularized Minimization with Applications to Compressed Sensing}},
year = {2007}
}
@article{Geramifard2015,
abstract = {RLPy is an object-oriented reinforcement learning framework with focus on valuefunction-based methods using linear function-approximation and discrete actions. The framework was designed for both, education and research purposes. It provides a rich library of fine-grained, easily exchangeable components for learning agents (e.g., policies or representations of value functions), facilitating recent increased specialization in reinforcement learning. RLPy is written in Python to allow fast prototyping but is also suitable for large-scale experiments by relying on optimized numerical libraries and parallelization. Code profiling, domain visualizations, and data analysis are integrated in a self-contained package available under the Modified BSD License at http://acl.mit.edu/rlpy. All these properties allow users to compare various RL algorithms with little effort.},
author = {Geramifard, Alborz and Klein, Robert H. and Dann, Christoph and Dabney, William and How, Jonathan P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Geramifard et al. - 2015 - RLPy A value-function-based reinforcement learning framework for education and research.pdf:pdf},
issn = {15337928},
journal = {The Journal of Machine Learning Research},
keywords = {empirical evaluation,open source,reinforcement learning,value-function},
number = {1},
pages = {1573--1578},
title = {{RLPy: A value-function-based reinforcement learning framework for education and research}},
url = {http://jmlr.org/papers/v16/geramifard15a.html},
volume = {16},
year = {2015}
}
@article{Golini2012,
author = {Golini, Natalia},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golini - 2012 - Bayesian modeling of presence-only data.pdf:pdf},
number = {2009},
pages = {1--4},
title = {{Bayesian modeling of presence-only data}},
year = {2012}
}
@article{Merow2016,
author = {Merow, Cory and Allen, Jenica M. and Aiello-Lammens, Matthew E. and {Silander Jr}, John. A.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merow et al. - 2016 - Improving niche and range estimates with Maxent and point process models by integrating spatially explicit informa.pdf:pdf},
journal = {Global Ecology and Biogeography},
pages = {1022--1036},
title = {{Improving niche and range estimates with Maxent and point process models by integrating spatially explicit information}},
volume = {25},
year = {2016}
}
@article{Dietterich2000,
author = {Dietterich, Thomas G},
journal = {Journal of Artificial Intelligence Research},
pages = {227--303},
title = {{Hierarchical reinforcement learning with {\{}MAXQ{\}} value function decomposition}},
volume = {13},
year = {2000}
}
@inproceedings{Becker2003,
annote = {From Duplicate 1 ( Transition-independent decentralized Markov decision processes - Becker, Raphen; Lesser, Victor; Zilberstein, Shlomo )
},
author = {Becker, Raphen and Zilberstein, Shlomo and Lesser, Victor},
booktitle = {International Joint Conference on Autonomous Agents and Multi Agent Systems (AAMAS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker, Lesser, Zilberstein - 2004 - Decentralized Markov decision processes with event-driven interactions.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker, Zilberstein, Lesser - 2003 - Transition-independent decentralized Markov decision processes.pdf:pdf},
pages = {41--48},
title = {{Transition-independent decentralized Markov decision processes}},
year = {2003}
}
@article{Parikh2013,
author = {Parikh, Neal and Boyd, Stephen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parikh, Boyd - 2013 - Proximal algorithms.pdf:pdf},
journal = {Foundations and Trends in Optimization},
number = {3},
pages = {123--231},
title = {{Proximal algorithms}},
url = {http://www.stanford.edu/{~}boyd/papers/pdf/prox{\_}algs.pdf},
volume = {1},
year = {2013}
}
@article{Neyman1998b,
author = {Neyman, Abraham and Sorin, Sylvain},
doi = {10.1007/s001820050066},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neyman, Sorin - 1998 - Equilibria in repeated games of incomplete information The general symmetric case.pdf:pdf},
issn = {0020-7276},
journal = {International Journal of Game Theory},
keywords = {information,repeated games of incomplete,stochastic games},
month = {aug},
number = {2},
pages = {201--210},
title = {{Equilibria in repeated games of incomplete information: The general symmetric case}},
url = {http://link.springer.com/10.1007/s001820050066},
volume = {27},
year = {1998}
}
@article{Kakade2003a,
author = {Kakade, S and Kearns, Michael and Langford, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade, Kearns, Langford - 2003 - Exploration in metric state spaces.pdf:pdf},
journal = {ICML},
title = {{Exploration in metric state spaces}},
url = {http://www.aaai.org/Papers/ICML/2003/ICML03-042.pdf},
year = {2003}
}
@inproceedings{Zrihem2016,
abstract = {Deep Reinforcement Learning (DRL) is a trending field of research, showing great promise in many challenging problems such as playing Atari, solving Go and controlling robots. While DRL agents perform well in practice we are still missing the tools to analayze their performance and visualize the temporal abstractions that they learn. In this paper, we present a novel method that automatically discovers an internal Semi Markov Decision Process (SMDP) model in the Deep Q Network's (DQN) learned representation. We suggest a novel visualization method that represents the SMDP model by a directed graph and visualize it above a t-SNE map. We show how can we interpret the agent's policy and give evidence for the hierarchical state aggregation that DQNs are learning automatically. Our algorithm is fully automatic, does not require any domain specific knowledge and is evaluated by a novel likelihood based evaluation criteria.},
archivePrefix = {arXiv},
arxivId = {1606.07112},
author = {Zrihem, Nir Ben and Zahavy, Tom and Mannor, Shie},
booktitle = {ICML Workshop on Human Interpretability},
eprint = {1606.07112},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zrihem, Zahavy, Mannor - 2016 - Visualizing Dynamics from t-SNE to SEMI-MDPs.pdf:pdf},
title = {{Visualizing Dynamics: from t-SNE to SEMI-MDPs}},
url = {http://arxiv.org/abs/1606.07112},
year = {2016}
}
@article{Pereira1989,
author = {Pereira, M V F},
journal = {Electric Power and Energy Systems},
number = {3},
pages = {161--169},
title = {{Stochastic operation scheduling of large hydroelectric systems}},
volume = {11},
year = {1989}
}
@article{Meyer2008,
author = {Meyer, George E. and Neto, Jo{\~{a}}o Camargo},
doi = {10.1016/j.compag.2008.03.009},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyer, Neto - 2008 - Verification of color vegetation indices for automated crop imaging applications.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
month = {oct},
number = {2},
pages = {282--293},
title = {{Verification of color vegetation indices for automated crop imaging applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169908001063},
volume = {63},
year = {2008}
}
@article{Ruszczynski1997,
author = {Ruszczynski, Andrzej},
journal = {Mathematical Programming},
pages = {333--353},
title = {{Decomposition methods in stochastic programming}},
volume = {79},
year = {1997}
}
@article{Maes2012,
author = {Maes, Francis and Fonteneau, Raphael and Wehenkel, Louis and Ernst, Damien},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maes et al. - 2012 - Policy Search in a Space of Simple Closed-form Formulas Towards Interpretability of Reinforcement Learning.pdf:pdf},
journal = {Discovery Science},
keywords = {formula discovery,interpretability,reinforcement learning},
number = {1},
pages = {37--51},
title = {{Policy Search in a Space of Simple Closed-form Formulas: Towards Interpretability of Reinforcement Learning}},
url = {http://www.montefiore.ulg.ac.be/{~}ernst/Maes2012Ds.pdf},
volume = {7569},
year = {2012}
}
@article{Tsitsiklis1985,
author = {Tsitsiklis, J. and Athans, M.},
doi = {10.1109/TAC.1985.1103988},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis, Athans - 1985 - On the complexity of decentralized decision making and detection problems.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {may},
number = {5},
pages = {440--446},
title = {{On the complexity of decentralized decision making and detection problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1103988},
volume = {30},
year = {1985}
}
@article{Hardt2014,
annote = {From Stephen:

The complexity results apply for the underlying matrix of rank at least 3, with the target rank greater than k. The number of entries omitted is about 10{\%} of the total. 

From Stephen:
Hi Marek,
  We talked a while ago about the problem if finding the best rank-1 solution to a general least-squares problem:

min ||A(X-Y)||{\_}F
s.t. rank(X) {\textless}= 1

For the special case of A is a sampling operator, this recent paper has some hardness results:
http://arxiv.org/pdf/1402.2331v2.pdf 

Looks like most of it does NOT apply for rank(X)=1

( what about the S-lemma? ) 

Notation 
M - input matrix of rank k, bounded by c
p - fraction of entries provided 
k - rank of the input matrix 
r - desired rank of the output},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.2331v2},
author = {Hardt, Moritz and Meka, R and Raghavendra, P and Weitz, B},
eprint = {arXiv:1402.2331v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardt et al. - 2014 - Computational Limits for Matrix Completion.pdf:pdf},
journal = {arXiv preprint arXiv: {\ldots}},
title = {{Computational Limits for Matrix Completion}},
url = {http://arxiv.org/abs/1402.2331},
year = {2014}
}
@inproceedings{Yoon2007,
author = {Yoon, SungWook and Fern, Alan and Givan, Robert},
booktitle = {International Joint Conference on Artificial Intelligence},
title = {{Using Learned Policies in Heuristic-Search Planning}},
year = {2007}
}
@article{Bergez2004,
annote = {Describes a stochastic model for optimizing irrigation decisions

Mentions dynamic, but argues that it is better to search over the parameters of strategies
argue that simulation optimization is better

P2P algorithm:
More or less exhaustive search with focused subdivision

The paper has a good description of a baseline strategy},
author = {Bergez, J.-E. and Garcia, F. and Lapasse, L.},
doi = {10.1016/j.agsy.2003.07.004},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergez, Garcia, Lapasse - 2004 - A hierarchical partitioning method for optimizing irrigation strategies.pdf:pdf},
isbn = {3356173553},
issn = {0308521X},
journal = {Agricultural Systems},
month = {jun},
number = {3},
pages = {235--253},
title = {{A hierarchical partitioning method for optimizing irrigation strategies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0308521X03001367},
volume = {80},
year = {2004}
}
@article{Maruyama2005,
author = {Maruyama, Yuzo and Strawderman, William E.},
doi = {10.1214/009053605000000327},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maruyama, Strawderman - 2005 - A new class of generalized Bayes minimax ridge regression estimators.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {condition number,generalized bayes,minimax ridge estimators,minimaxity,ridge regression,short title new bayes},
month = {aug},
number = {4},
pages = {1753--1770},
title = {{A new class of generalized Bayes minimax ridge regression estimators}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.aos/1123250228/},
volume = {33},
year = {2005}
}
@article{Schutze,
author = {Sch{\"{u}}tze, Niels and Schmitz, GH},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sch{\"{u}}tze, Schmitz - Unknown - Neuro-dynamic programming as a new framework for decision support for deficit irrigation sytems.pdf:pdf},
journal = {ip-103-1-174-100.ip.secureserver. {\ldots}},
keywords = {deficit irrigation,dynamic optimization,neuro-dynamic programming},
number = {mm},
pages = {2271--2277},
title = {{Neuro-dynamic programming as a new framework for decision support for deficit irrigation sytems}},
url = {http://ip-103-1-174-100.ip.secureserver.net/MODSIM07/papers/42{\_}s3/Neuro-dynamic{\_}s3A{\_}Schutze{\_}.pdf}
}
@article{Ruszczynski2006,
abstract = {We consider optimization problems involving convex risk functions. By employing techniques of convex analysis and optimization theory in vector spaces of measurable functions, we develop new representation theorems for risk models, and optimality and duality theory for problems with convex risk functions.},
archivePrefix = {arXiv},
arxivId = {1111.0194v1},
author = {Ruszczy{\'{n}}ski, Andrzej and Shapiro, Alexander},
doi = {10.1287/moor.1050.0186},
eprint = {1111.0194v1},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {2004,2005,90c15,90c46,90c48,91b30,and november 20,convex analysis,duality,history,ms subject classification,msc2000 subject classification,or,primary,received january 31,revised january 24,risk,risk measures,secondary,stochastic optimization,stochastic programming},
number = {3},
pages = {433--452},
title = {{Optimization of Convex Risk Functions}},
volume = {31},
year = {2006}
}
@article{Swain,
author = {Swain, RE},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swain - 2008 - Evolution of the Hoover Dam Inflow Design Flood–A Study in Changing Methodologies.pdf:pdf},
journal = {Bureau of Reclamation: Historical Essays from the {\ldots}},
title = {{Evolution of the Hoover Dam Inflow Design Flood–A Study in Changing Methodologies}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=lxdkY71u6rsC{\&}oi=fnd{\&}pg=PA195{\&}dq=Evolution+of+the+Hoover+Dam+Inflow+Design+Flood+-+A+Study+in+Changing+Methodologies{\&}ots=OyKYUhygvq{\&}sig=38K7rZnQ-haRdux{\_}Ath4M9ZoLdQ},
year = {2008}
}
@article{Waring2006,
author = {Waring, R.H. and Coops, N.C. and Fan, W. and Nightingale, J.M.},
doi = {10.1016/j.rse.2006.05.007},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Waring et al. - 2006 - MODIS enhanced vegetation index predicts tree species richness across forested ecoregions in the contiguous U.S.A.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {ecoregions,federal inventory and analysis,modeling gross photosynthesis,modis evi,plots,tree diversity,united states},
month = {jul},
number = {2},
pages = {218--226},
title = {{MODIS enhanced vegetation index predicts tree species richness across forested ecoregions in the contiguous U.S.A.}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S003442570600191X},
volume = {103},
year = {2006}
}
@incollection{Saad1995,
author = {Saad, Yosef},
booktitle = {Solution Techniques for Large Scale CFD Problems},
editor = {Hasbashi, W G},
pages = {141},
title = {{Preconditioned Krylov subspace methods for CFD applications}},
url = {citeseer.ist.psu.edu/saad95preconditioned.html},
year = {1995}
}
@article{Linderoth2005,
annote = {From Duplicate 1 ( A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs - Linderoth, Jeff )
},
author = {Linderoth, Jeff},
doi = {10.1007/s10107-005-0582-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Linderoth - 2005 - A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs.pdf:pdf},
isbn = {1010700505827},
issn = {0025-5610},
journal = {Mathematical Programming, Series B},
keywords = {branch-and-,convex envelope,global optimization,nonconvex quadratic programming},
number = {2},
pages = {251--282},
title = {{A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs}},
url = {http://link.springer.com/10.1007/s10107-005-0582-7},
volume = {103},
year = {2005}
}
@article{Greenberg2009,
author = {Greenberg, Harvey J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greenberg - 2009 - Contact the author to be noti ed of updates .pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greenberg - 2009 - Contact the author to be noti ed of updates (2).pdf:pdf},
title = {{Myths and Counter-examples in Linear Programming}},
volume = {2009},
year = {2009}
}
@inproceedings{Bonet2009,
author = {Bonet, Blai and Geffner, Hector},
booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
title = {{Solving POMDPs: RTDP-Bel vs. Point-based algorithms}},
year = {2009}
}
@inproceedings{Khan2013,
abstract = {In this paper, we present a method to iteratively refine the parameters of a Markov Decision Process by leveraging constraints implied from an expert's review of the policy. We impose a constraint on the parameters of the model for every case where the expert's recommendation differs from the recommendation of the policy. We demonstrate that consistency with an expert's feedback leads to non-convex constraints on the model parameters. We refine the parameters of the model, under these constraints, by partitioning the parameter space and iteratively applying alternating optimization. We demonstrate how the approach can be applied to both flat and factored MDPs and present results based on diagnostic sessions from a manufacturing scenario.},
author = {Khan, Omar Zia and Poupart, Pascal and Agosta, John Mark},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-40988-2_11},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khan, Poupart, Agosta - 2013 - Iterative model refinement of recommender MDPs based on expert feedback.pdf:pdf},
isbn = {9783642409875},
issn = {03029743},
number = {PART 1},
pages = {162--177},
title = {{Iterative model refinement of recommender MDPs based on expert feedback}},
volume = {8188 LNAI},
year = {2013}
}
@article{Seuken2008,
author = {Seuken, Sven and Zilberstein, Shlomo},
journal = {Autonomous Agents and Multiagent Systems},
pages = {190--250},
title = {{Formal models and algorithms for decentralized decision making under uncertainty}},
volume = {17},
year = {2008}
}
@misc{Ma2011,
author = {Ma, H and Zhou, D and Liu, C and Lyu, MR and King, I},
booktitle = {Proceedings of the World Wide Web Conference},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2011 - Recommender systems with social regularization.pdf:pdf},
isbn = {9781450304931},
keywords = {all or part of,collaborative filtering,matrix factorization,or hard copies of,permission to make digital,recommender systems,social net-,social regularization,this work for,work},
title = {{Recommender systems with social regularization}},
url = {http://dl.acm.org/citation.cfm?id=1935877},
year = {2011}
}
@inproceedings{Munos2016,
abstract = {In this work, we take a fresh look at some old and new algorithms for off-policy, return-based reinforcement learning. Expressing these in a common form, we derive a novel algorithm, Retrace({\$}\backslashlambda{\$}), with three desired properties: (1) low variance; (2) safety, as it safely uses samples collected from any behaviour policy, whatever its degree of "off-policyness"; and (3) efficiency, as it makes the best use of samples collected from near on-policy behaviour policies. We analyse the contractive nature of the related operator under both off-policy policy evaluation and control settings and derive online sample-based algorithms. To our knowledge, this is the first return-based off-policy control algorithm converging a.s. to {\$}Q{\^{}}*{\$} without the GLIE assumption (Greedy in the Limit with Infinite Exploration). As a corollary, we prove the convergence of Watkins' Q({\$}\backslashlambda{\$}), which was still an open problem. We illustrate the benefits of Retrace({\$}\backslashlambda{\$}) on a standard suite of Atari 2600 games.},
archivePrefix = {arXiv},
arxivId = {1606.02647},
author = {Munos, R{\'{e}}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc G.},
booktitle = {Conference on Neural Information Processing Systems (NIPS)},
eprint = {1606.02647},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos et al. - 2016 - Safe and Efficient Off-Policy Reinforcement Learning.pdf:pdf},
title = {{Safe and Efficient Off-Policy Reinforcement Learning}},
url = {http://arxiv.org/abs/1606.02647},
year = {2016}
}
@inproceedings{Cserna2017,
abstract = {Multi-armed bandits are a quintessential machine learning problem requiring the balancing of exploration and exploitation. While there has been progress in developing algorithms with strong theoretical guarantees, there has been less focus on practical near-optimal finite-time performance. In this paper, we propose an algorithm for Bayesian multi-armed bandits that utilizes value-function-driven online planning techniques. Building on previous work on UCB and Gittins index, we introduce linearly-separable value functions that take both the expected return and the benefit of exploration into consideration to perform n-step lookahead. The algorithm enjoys a sub-linear performance guarantee and we present simulation results that confirm its strength in problems with structured priors. The simplicity and generality of our approach makes it a strong candidate for analyzing more complex multi-armed bandit problems.},
archivePrefix = {arXiv},
arxivId = {1704.03926},
author = {Cserna, Bence and Petrik, Marek and Russel, Reazul Hasan and Ruml, Wheeler},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
eprint = {1704.03926},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cserna et al. - 2017 - Value Directed Exploration in Multi-Armed Bandits with Structured Priors.pdf:pdf},
pages = {1--16},
title = {{Value Directed Exploration in Multi-Armed Bandits with Structured Priors}},
url = {http://arxiv.org/abs/1704.03926},
year = {2017}
}
@techreport{Kuleshov2014,
abstract = {Although many algorithms for the multi-armed bandit problem are well-understood theoretically, empirical confirmation of their effectiveness is generally scarce. This paper presents a thorough empirical study of the most popular multi-armed bandit algorithms. Three important observations can be made from our results. Firstly, simple heuristics such as epsilon-greedy and Boltzmann exploration outperform theoretically sound algorithms on most settings by a significant margin. Secondly, the performance of most algorithms varies dramatically with the parameters of the bandit problem. Our study identifies for each algorithm the settings where it performs well, and the settings where it performs poorly. Thirdly, the algorithms' performance relative each to other is affected only by the number of bandit arms and the variance of the rewards. This finding may guide the design of subsequent empirical evaluations. In the second part of the paper, we turn our attention to an important area of application of bandit algorithms: clinical trials. Although the design of clinical trials has been one of the principal practical problems motivating research on multi-armed bandits, bandit algorithms have never been evaluated as potential treatment allocation strategies. Using data from a real study, we simulate the outcome that a 2001-2002 clinical trial would have had if bandit algorithms had been used to allocate patients to treatments. We find that an adaptive trial would have successfully treated at least 50{\%} more patients, while significantly reducing the number of adverse effects and increasing patient retention. At the end of the trial, the best treatment could have still been identified with a high level of statistical confidence. Our findings demonstrate that bandit algorithms are attractive alternatives to current adaptive treatment allocation strategies.},
archivePrefix = {arXiv},
arxivId = {1402.6028},
author = {Kuleshov, Volodymyr and Precup, Doina},
booktitle = {arXiv:1402.6028},
doi = {10.1145/1109557.1109659},
eprint = {1402.6028},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuleshov, Precup - 2014 - Algorithms for multi-armed bandit problems.pdf:pdf},
isbn = {0-89871-605-5},
title = {{Algorithms for multi-armed bandit problems}},
url = {http://arxiv.org/abs/1402.6028},
year = {2014}
}
@article{Feinberg2012,
author = {Feinberg, Eugene A and Rothblum, Uriel G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinberg, Rothblum - 2012 - Splitting Randomized Stationary Policies in Total-Reward Markov Decision Processes.pdf:pdf},
journal = {Mathematics of Operations Research},
keywords = {toclassify},
mendeley-tags = {toclassify},
number = {1},
pages = {129--153},
title = {{Splitting Randomized Stationary Policies in Total-Reward Markov Decision Processes}},
volume = {37},
year = {2012}
}
@inproceedings{Becker2017,
author = {Becker, Stephen and Kawas, Ban and Petrik, Marek},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker, Kawas, Petrik - 2017 - Robust Partially-Compressed Least-Squares Robust Partially-Compressed Least-Squares.pdf:pdf},
title = {{Robust Partially-Compressed Least-Squares Robust Partially-Compressed Least-Squares}},
year = {2017}
}
@book{Ricci2011,
address = {Boston, MA},
author = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha},
doi = {10.1007/978-0-387-85820-3},
editor = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha and Kantor, Paul B.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ricci, Rokach, Shapira - 2011 - Recommender Systems Handbook.pdf:pdf},
isbn = {978-0-387-85819-7},
pages = {1--35},
publisher = {Springer US},
title = {{Recommender Systems Handbook}},
url = {http://link.springer.com/10.1007/978-0-387-85820-3},
year = {2011}
}
@techreport{Olsen2011,
author = {Olsen, Peder and Hershey, John and Rennie, Steven and Goel, Vaibhava and Heights, Yorktown},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olsen et al. - 2011 - A Speech Recognition Solution to an Ancient Cryptography Problem.pdf:pdf},
title = {{A Speech Recognition Solution to an Ancient Cryptography Problem}},
volume = {25109},
year = {2011}
}
@article{Tsitsiklis1994,
author = {Tsitsiklis, JN},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis - 1994 - A short proof of the Gittins index theorem.pdf:pdf},
journal = {The Annals of Applied Probability},
number = {1},
pages = {194--199},
title = {{A short proof of the Gittins index theorem}},
url = {http://www.jstor.org/stable/2245051},
volume = {4},
year = {1994}
}
@inproceedings{Helmert2008,
author = {Helmert, Malte and Roger, Gabriele},
booktitle = {National Conference on AI},
title = {{How good is almost perfect}},
year = {2008}
}
@article{Kawas2009,
author = {Kawas, Ban and Thiele, Aur{\'{e}}lie},
doi = {10.1007/s00291-008-0162-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kawas, Thiele - 2009 - A log-robust optimization approach to portfolio management.pdf:pdf},
isbn = {0029100801},
issn = {0171-6468},
journal = {OR Spectrum},
keywords = {a,b,cmmi-0757983,cmmi-0757983 and an ibm,convex optimization,faculty award,kawas,part by nsf grant,portfolio management,robust optimization,s work supported in,thiele},
month = {jan},
number = {1},
pages = {207--233},
title = {{A log-robust optimization approach to portfolio management}},
url = {http://link.springer.com/10.1007/s00291-008-0162-3},
volume = {33},
year = {2009}
}
@article{Azaria2013,
abstract = {Traditional recommender systems minimize prediction error with respect to users' choices. Recent studies have shown that recom- mender systems have a positive effect on the provider's revenue. In this paper we show that by providing a set of recommenda- tions different than the one perceived best according to user ac- ceptance rate, the recommendation system can further increase the business' utility (e.g. revenue), without any significant drop in user satisfaction. Indeed, the recommendation system designer should have in mind both the user, whose taste we need to reveal, and the business, which wants to promote specific content. We performed a large body of experiments comparing a commer- cial state-of-the-art recommendation engine with a modified rec- ommendation list, which takes into account the utility (or revenue) which the business obtains from each suggestion that is accepted by the user. We show that the modified recommendation list is more desirable for the business, as the end result gives the business a higher utility (or revenue). To study possible reduce in satisfaction by providing the user worse suggestions, we asked the users how they perceive the list of recommendation that they received. Dif- ferences in user satisfaction between the lists is negligible, and not statistically significant. We also uncover a phenomenon where movie consumers prefer watching and even paying for movies that they have already seen in the past than movies that are new to them.},
author = {Azaria, Amos and Hassidim, Avinatan and Kraus, S},
doi = {10.1145/2507157.2507162},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azaria, Hassidim, Kraus - 2013 - Movie recommender system for profit maximization.pdf:pdf},
isbn = {9781450324090},
journal = {ACM conference on Recommender systems - RecSys},
keywords = {human modeling,movies,recommender systems},
pages = {121--128},
title = {{Movie recommender system for profit maximization}},
url = {http://dl.acm.org/citation.cfm?id=2507162},
year = {2013}
}
@inproceedings{Felner2005,
author = {Felner, Ariel and Zahavi, Uzi and Schaeffer, Jonathan and Holte, Robert C},
booktitle = {International Joint Conference on AI},
title = {{Dual lookups in pattern databases}},
year = {2005}
}
@inproceedings{Wu2016,
author = {Wu, Xiaojian and Kumar, Akshat and Sheldon, Daniel and Zilberstein, Shlomo},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2016 - Robust Optimization for Tree-Structured Stochastic Network Design.pdf:pdf},
title = {{Robust Optimization for Tree-Structured Stochastic Network Design}},
year = {2016}
}
@inproceedings{Lattimore2016a,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06014v3},
author = {Lattimore, Tor},
booktitle = {Annual Conference on Learning Theory (COLT)},
eprint = {arXiv:1511.06014v3},
organization = {arXiv},
title = {{Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits}},
year = {2016}
}
@book{Train2003,
abstract = {This book describes the new generation of discrete choice methods, focusing on the many advances that are made possible by simulation. Researchers use these statistical methods to examine the choices that consumers, households, firms, and other agents make. Each of the major models is covered: logit, generalized extreme value, or GEV (including nested and cross-nested logits), probit, and mixed logit, plus a variety of specifications that build on these basics. Simulation-assisted estimation procedures are investigated and compared, including maximum simulated likelihood, method of simulated moments, and method of simulated scores. Procedures for drawing from densities are described, including variance reduction techniques such as anithetics and Halton draws. Recent advances in Bayesian procedures are explored, including the use of the Metropolis-Hastings algorithm and its variant Gibbs sampling. No other book incorporates all these fields, which have arisen in the past 20 years. The procedures are applicable in many fields, including energy, transportation, environmental studies, health, labor, and marketing.},
author = {Train, Kenneth E.},
booktitle = {Cambridge University Press},
doi = {10.1017/CBO9780511753930},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Train - 2003 - Discrete Choice Methods with Simulation.pdf:pdf},
isbn = {9780511753930},
issn = {08981221},
pages = {1--388},
pmid = {6973},
title = {{Discrete Choice Methods with Simulation}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511753930},
year = {2003}
}
@article{Solan2003a,
author = {Solan, Eilon and Vieille, Nicolas},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Solan, Vieille - 2003 - Perturbed Markov chains.pdf:pdf},
journal = {Journal of applied probability},
keywords = {60f10,60j10,conductance,perturbed markov chains,primary subject classification,secondary subject classification},
number = {03620191},
pages = {1--19},
title = {{Perturbed Markov chains}},
url = {http://projecteuclid.org/euclid.jap/1044476830},
year = {2003}
}
@article{Dietterich2013,
author = {Dietterich, Thomas G. TG and Taleghan, Majid A. and Crowley, Mark},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich, Taleghan, Crowley - 2013 - PAC optimal planning for invasive species management Improved exploration for reinforcement learn.pdf:pdf},
journal = {National Conference on Artificial Intelligence (AAAI)},
title = {{PAC optimal planning for invasive species management: Improved exploration for reinforcement learning from simulator-defined MDPs.}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/download/6478/6850},
year = {2013}
}
@inproceedings{Filippi2010,
author = {Filippi, Sarah and Cappe, Olivier and Garivier, Aurelien and Szepesv{\'{a}}ri, Csaba},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippi et al. - 2010 - Parametric Bandits The Generalized Linear Case.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippi et al. - 2010 - Parametric Bandits The Generalized Linear Case(2).pdf:pdf},
isbn = {9781617823800},
keywords = {generalized linear models,multi-armed bandit,parametric bandits,regret minimization,ucb},
title = {{Parametric Bandits: The Generalized Linear Case.}},
url = {https://papers.nips.cc/paper/4166-parametric-bandits-the-generalized-linear-case.pdf},
year = {2010}
}
@article{Mannor2016,
author = {Mannor, Shie and Mebel, Ofir and Xu, Huan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannor, Mebel, Xu - 2016 - Robust MDPs with k-rectangular uncertainty.pdf:pdf},
journal = {Mathematics of Operations Research},
keywords = {90c39,90c40,dynamic programming,markov,models,msc2000 subject classification,optimal control,primary,secondary},
number = {4},
pages = {1484--1509},
title = {{Robust MDPs with k-rectangular uncertainty}},
volume = {41},
year = {2016}
}
@inproceedings{Kakade2003a,
author = {Kakade, Sham and Kearns, Michael and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Exploration in metric spaces}},
year = {2003}
}
@article{Martin1989,
abstract = {A method is developed to determine optimal irrigation strategies for a single season using crop production functions which incorporate physically based coefficients. The relationship of yield to evapotranspiration is used to develop the yield-irrigation function. The physical parameters used in the production function can be determined from field measurements or various types of computer simulation. Using this approach, the optimal irrigated area and depth of water to apply can be related to prices, costs, and physical parameters. This pro- duces a more general solution than commonly used production functions that depend on limited experimental results. The optimal irrigation depth and irrigated area can be deter- mined for either land or water limiting conditions. The analysis also allows consideration of different irrigated and dryland crops. Three examples are analyzed to illustrate the use of the technique and to develop some general guidelines. Introduction},
author = {Martin, DL and Gilley, JR and Supalla, RJ},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin, Gilley, Supalla - 1989 - Evaluation of irrigation planning decisions.pdf:pdf},
journal = {Journal of Irrigation and Drainage Engineering},
number = {1},
pages = {58--77},
title = {{Evaluation of irrigation planning decisions}},
url = {http://ascelibrary.org/doi/abs/10.1061/(ASCE)0733-9437(1989)115:1(58)},
volume = {115},
year = {1989}
}
@article{VanDam2000,
author = {van Dam, Jos C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Dam - 2000 - Field-scale water flow and solute transport SWAP model concepts, parameter estimation and case studies.pdf:pdf},
isbn = {9058082563},
title = {{Field-scale water flow and solute transport: SWAP model concepts, parameter estimation and case studies}},
url = {http://agris.fao.org/agris-search/search.do?f=2000/NL/NL00052.xml;NL2000004511},
year = {2000}
}
@article{See2008,
annote = {From Duplicate 1 ( Robust Approximation to Multi-Period Inventory Management ∗ - See, Chuen-teck; Sim, Melvyn )
},
author = {See, Chuen-teck and Sim, Melvyn},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/See, Sim - 2010 - Robust Approximation to Multi-Period Inventory Management.pdf:pdf},
journal = {Operations Research},
number = {3},
pages = {583--594},
title = {{Robust Approximation to Multi-Period Inventory Management}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Robust+Approximation+to+Multi-Period+Inventory+Management{\#}9},
volume = {58},
year = {2010}
}
@article{Shimodaira2000,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 230710850 Improving inference shift - likelihood Article 2000 DOI : 10 . 1016 / S0378 - 3758 (00) 00115 - 4 CITATIONS 373 READS 478 1 : Hidetoshi Osaka 76 , 883 SEE All . The . Abstract A class of predictive densities is derived by weighting the observed samples in maximizing the log - likelihood function . This approach is eeective in cases such as sample surveys or design of experiments , where the observed covariate follows a diierent distribution than that in the whole population . Under misspeci{\"{y}}cation of the parametric model , the optimal choice of the weight function is asymptotically shown to be the ratio of the density function of the covariate in the population to that in the observations . This is the pseudo - maximum likelihood estima - tion of sample surveys . The optimality is de{\"{y}}ned by the expected Kullback – Leibler loss , and the optimal weight is obtained by considering the importance sampling identity . Under correct speci{\"{y}}cation of the model , however , the ordinary maximum likelihood estimate (i . e . the uniform weight) is shown to be optimal asymptotically . For moderate sample size , the situation is in between the two extreme cases , and the weight function is selected by minimizing a variant of the information criterion derived as an estimate of the expected loss . The method is also applied to a weighted version of the Bayesian predictive density . Numerical examples as well as Monte - Carlo simulations are shown for polynomial regression . A connection with the robust parametric estimation is discussed .},
author = {Shimodaira, Hidetoshi},
doi = {10.1016/S0378-3758(00)00115-4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shimodaira - 2000 - Improving predictive inference under covariate shift by weighting the log - likelihood function.pdf:pdf},
isbn = {0378-3758},
issn = {03783758},
journal = {Journal of Statistical Planning and Inference},
keywords = {62B10,62D05 Keywords,Akaike information criterion,Design of experiments,Importance sampling,Kullback – Leibler divergence,MSC,Misspeci{\"{y}}cation,Sample surveys,Weighted least squares},
pages = {227--244},
title = {{Improving predictive inference under covariate shift by weighting the log - likelihood function}},
volume = {90},
year = {2000}
}
@misc{Littman1996,
annote = {Mentions that the robust MDP (or a stochastic game) has not been formulated as a linear program.},
author = {Littman, Michael},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Littman - 1996 - Algorithms for sequential decision making.pdf:pdf},
title = {{Algorithms for sequential decision making}},
year = {1996}
}
@article{Hazan2007,
abstract = {In an online convex optimization problem a decision-maker makes a sequence of decisions, i.e., chooses a sequence of points in Euclidean space, from a fixed feasible set. After each point is chosen, it encounters a sequence of (possibly unrelated) convex cost functions. Zinkevich (ICML 2003) introduced this framework, which models many natural repeated decision-making problems and generalizes many existing problems such as Prediction from Expert Advice and Cover's Universal Portfolios. Zinkevich showed that a simple online gradient descent algorithm achieves additive regret O({\&}radic;T), for an arbitrary sequence of T convex cost functions (of bounded gradients), with respect to the best single decision in hindsight. In this paper, we give algorithms that achieve regret O(log(T)) for an arbitrary sequence of strictly convex functions (with bounded first and second derivatives). This mirrors what has been done for the special cases of prediction from expert advice by Kivinen and Warmuth (EuroCOLT 1999), and Universal Portfolios by Cover (Math. Finance 1:1-19, 1991). We propose several algorithms achieving logarithmic regret, which besides being more general are also much more efficient to implement. The main new ideas give rise to an efficient algorithm based on the Newton method for optimization, a new tool in the field. Our analysis shows a surprising connection between the natural follow-the-leader approach and the Newton method. We also analyze other algorithms, which tie together several different previous approaches including follow-the-leader, exponential weighting, Cover's algorithm and gradient descent. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Hazan, Elad and Agarwal, Amit and Kale, Satyen},
doi = {10.1007/s10994-007-5016-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Agarwal, Kale - 2007 - Logarithmic regret algorithms for online convex optimization.pdf:pdf},
isbn = {1573-0565 0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {Online learning,Online optimization,Portfolio management,Regret minimization},
number = {2-3},
pages = {169--192},
title = {{Logarithmic regret algorithms for online convex optimization}},
volume = {69},
year = {2007}
}
@article{Even-Dar2003,
author = {Even-Dar, Eyal and Mansour, Yishay},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even-Dar, Mansour - 2003 - Approximate Equivalence of Markov Decision Processes.pdf:pdf},
issn = {03029743},
journal = {Learning Theory and Kernel Machines, 16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT},
pages = {581--594},
title = {{Approximate Equivalence of Markov Decision Processes}},
year = {2003}
}
@misc{Recht2012,
author = {Recht, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Recht - 2012 - CS726 - Lyapunov analysis and the Heavy Ball Method Analysis of the Heavy Ball Method.pdf:pdf},
pages = {2--5},
title = {{CS726 - Lyapunov analysis and the Heavy Ball Method Analysis of the Heavy Ball Method}},
year = {2012}
}
@article{Goh2010a,
author = {Goh, Joel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh - 2010 - Robust Optimization Made Easy with ROME.pdf:pdf},
number = {July 2009},
pages = {1--35},
title = {{Robust Optimization Made Easy with ROME}},
year = {2010}
}
@article{Bertsekas1989,
author = {Bertsekas, Dimitri P and Castanon, David A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas, Casta{\~{n}}on - 1989 - Adaptive aggregation methods for infinite horizon dynamic programming.pdf:pdf},
journal = {IEEE Transations on Automatic Control},
number = {6},
pages = {589--598},
title = {{Adaptive aggregation methods for infinite horizon dynamic programming}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=24227},
volume = {34},
year = {1989}
}
@book{Ghallab2004,
author = {Ghallab, Malik and Nau, Dana and Traverso, Paolo},
publisher = {Morgan Kaufmann},
title = {{Automated Planning: Theory and Practice}},
year = {2004}
}
@inproceedings{Leike2016,
abstract = {We discuss a variant of Thompson sampling for nonparametric reinforcement learning in a countable classes of general stochastic environments. These environments can be non-Markov, non-ergodic, and partially observable. We show that Thompson sampling learns the environment class in the sense that (1) asymptotically its value converges to the optimal value in mean and (2) given a recoverability assumption regret is sublinear.},
archivePrefix = {arXiv},
arxivId = {1602.07905},
author = {Leike, Jan and Lattimore, Tor and Orseau, Laurent and Hutter, Marcus},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
eprint = {1602.07905},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leike et al. - 2016 - Thompson Sampling is Asymptotically Optimal in General Environments.pdf:pdf},
keywords = {asymptotic optimality,discounting,general reinforcement learning,re-,regret,sampling,thompson},
title = {{Thompson Sampling is Asymptotically Optimal in General Environments}},
url = {http://arxiv.org/abs/1602.07905},
year = {2016}
}
@book{Horst1996,
author = {Horst, Reiner and Tuy, Hoang},
title = {{Global optimization: Deterministic approaches}},
year = {1996}
}
@article{Chawla2006,
abstract = {Decision trees, a popular choice for classification, have their limitation in providing good quality probability estimates. Typically, smoothing methods such as Laplace or m-estimate are applied at the decision tree leaves to overcome the systematic bias introduced by the frequency-based estimates. An ensemble of decision trees has also been shown to help in reducing the bias and variance in the leaf estimates, resulting in better calibrated probabilistic predictions. In this work, we evaluate the calibration or quality of these estimates using various loss measures. We also examine the relationship between the quality of such estimates and resulting rank-ordering of test instances. Our results quantify the impact of smoothing in terms of the loss measures, and the coupled relationship with the AUC measure.},
author = {Chawla, N and Cieslak, David},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chawla, Cieslak - 2006 - Evaluating probability estimates from decision trees.pdf:pdf},
isbn = {1577352882},
journal = {American Association for Artificial Intelligence Workshop},
keywords = {Copyright {\textcopyright}2006, American Association for Artifici},
pages = {18--23},
title = {{Evaluating probability estimates from decision trees}},
url = {http://www.aaai.org/Papers/Workshops/2006/WS-06-06/WS06-06-005.pdf},
year = {2006}
}
@article{Thieu1988,
author = {Thieu, TV},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thieu - 1988 - A note on the solution of bilinear programming problems by reduction to concave minimization.pdf:pdf},
journal = {Mathematical Programming},
keywords = {bilinear programming problem,concave minimiz-,outer-approximation algorithm},
pages = {249--260},
title = {{A note on the solution of bilinear programming problems by reduction to concave minimization}},
url = {http://link.springer.com/article/10.1007/BF01580766},
volume = {41},
year = {1988}
}
@article{Klocke2011,
annote = {different deficit irrigation treatments

yields correlated with LAI
dry matter accumulation did not vary
water use efficiency decreased as irrigation decreased 

relative grain yield and evotranspiration has a linear dependence

there is multi-year dependence as the deficit irrigation leaves less water in the soil

Response to limited water supply:
1) reducing water application
2) growing crops that match the water supply
3) reducing the area of the crop
4) reducing the irrigated area},
author = {Klocke, N L and Currie, R S and Tomsicek, D J and Koehn, J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klocke et al. - 2011 - Corn Yield Response to Deficit Irrigation.pdf:pdf},
journal = {Transactions of the ASABE},
keywords = {and in many regions,are decreasing in,ater supplies for irrigation,corn,deficit irrigation,great plains,irrigation,irrigation management,limited irrigation,of the,ogallala aquifer,particularly from the,s,the u},
number = {3},
pages = {931--940},
title = {{Corn Yield Response to Deficit Irrigation}},
volume = {54},
year = {2011}
}
@article{JamesE.EppersonJamesE.Hook1993,
author = {{James E. Epperson, James E. Hook}, Yasmin R. Mustafa},
journal = {Agricultural Systems},
number = {1-2},
pages = {85--101},
title = {{Dynamic programming for improving irrigation scheduling strategies of maize}},
volume = {42},
year = {1993}
}
@article{Bergez2001a,
author = {Bergez, JE and Eigenraam, M and Garcia, F},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergez, Eigenraam, Garcia - 2001 - Comparison between dynamic programming and reinforcement learning a case study on maize irrigation ma.pdf:pdf},
journal = {European Conference of the European Federation for Information Technology in Agriculture},
pages = {343--348},
title = {{Comparison between dynamic programming and reinforcement learning: a case study on maize irrigation management}},
url = {http://www7.inra.fr/mia/T/garcia/Doc/Papiers/efita01b.pdf},
year = {2001}
}
@article{Analyzer2005,
author = {Decagon},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Decagon - 2005 - Decagon GS1 Operator ' S Manual.pdf:pdf},
isbn = {5093325600},
number = {10654},
title = {{Decagon GS1 Operator ' S Manual}},
year = {2005}
}
@inproceedings{Sanner2009,
annote = {From Duplicate 2 ( Bayesian Real-time Dynamic Programming - Sanner, Scott; Goetschalckx, Robby; Driessens, Kurt; Shani, Guy )
},
author = {Sanner, Scott and Goetschalckx, Robby and Driessens, Kurt and Shani, Guy},
booktitle = {Intenational Joint Conference on Artificial Intelligence (IJCAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sanner et al. - 1994 - Bayesian Real-time Dynamic Programming.pdf:pdf},
title = {{Bayesian Real-time Dynamic Programming}},
year = {2009}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei a and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
eprint = {1312.5602},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {7540},
pages = {529--533},
pmid = {25719670},
publisher = {Nature Publishing Group},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Sen2005,
author = {Sen, Suvrajeet and Sherali, Hanif D.},
doi = {10.1007/s10107-005-0592-5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sen, Sherali - 2005 - Decomposition with branch-and-cut approaches for two-stage stochastic mixed-integer programming.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {branch-and-cut,decomposition,mixed-integer programming,stochastic programming},
month = {jul},
number = {2},
pages = {203--223},
title = {{Decomposition with branch-and-cut approaches for two-stage stochastic mixed-integer programming}},
url = {http://link.springer.com/10.1007/s10107-005-0592-5},
volume = {106},
year = {2005}
}
@article{Shapiro2006,
author = {Shapiro, Alexander},
doi = {10.1016/j.orl.2005.02.003},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro - 2006 - On complexity of multistage stochastic programs.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {complexity,large deviations exponential bounds,monte carlo sampling,sample average method,stochastic programming},
month = {jan},
number = {1},
pages = {1--8},
title = {{On complexity of multistage stochastic programs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167637705000325},
volume = {34},
year = {2006}
}
@article{Ghosh2011,
author = {Ghosh, Soumyadip and Iancu, Dan a. and Katz-Rogozhnikov, Dmitriy and Phan, Dzung T. and Squillante, Mark S.},
doi = {10.1109/PES.2011.6039781},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh et al. - 2011 - Power generation management under time-varying power and demand conditions.pdf:pdf},
isbn = {978-1-4577-1000-1},
journal = {2011 IEEE Power and Energy Society General Meeting},
month = {jul},
pages = {1--7},
publisher = {Ieee},
title = {{Power generation management under time-varying power and demand conditions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6039781},
year = {2011}
}
@article{Usha2013,
abstract = {Horticulture crops play significant role in improving the productivity of land, generating employment, enhancing exports, improving economic conditions of the farmers and entrepreneurs and providing food and nutritional security to the people. For better management of the existing crops and to bring more area under horticulture crops, updated and accurate database is necessary for systematic planning and decision making. Remote sensing (RS) is an advanced tool that aids in gathering and updating information to develop scientific management plans. Many types of sensors namely microwave radiometers, laser meters, magnetic sensors and cameras collect electromagnetic information to derive accurate, large-scale information about the Earth's surface and atmosphere. Because these data and images are digital, they can easily be quantified and manipulated using computers. RS can be used in efforts to reduce the risk and minimize damage. The same data can be analyzed in different ways for different applications. A number of studies were aiming at identification of crop, area estimation, disease and pest identification, etc. using satellite data in horticulture. The potential use of RS techniques in Horticulture is briefly reviewed in order to exploit the available techniques for efficient crop management. {\textcopyright} 2013 Elsevier B.V.},
author = {Usha, K. and Singh, Bhupinder},
doi = {10.1016/j.scienta.2013.01.008},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Usha, Singh - 2013 - Potential applications of remote sensing in horticulture-A review.pdf:pdf},
isbn = {0304-4238},
issn = {03044238},
journal = {Scientia Horticulturae},
keywords = {Hyper spectral,Multispectral,NDVI,NIR,Remote sensing},
pages = {71--83},
publisher = {Elsevier B.V.},
title = {{Potential applications of remote sensing in horticulture-A review}},
url = {http://dx.doi.org/10.1016/j.scienta.2013.01.008},
volume = {153},
year = {2013}
}
@phdthesis{Bolte1997,
author = {Bolte, John P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolte - 1997 - Optimization of Seasonal Irrigation Scheduling by Genetic Algorithms.pdf:pdf},
title = {{Optimization of Seasonal Irrigation Scheduling by Genetic Algorithms}},
year = {1997}
}
@article{Martela2015,
author = {Martela, Fran{\c{c}}ois and Kelouwanib, Sousso and Dub{\'{e}}b, Yves and Agbossoua, Kodjo and Martel, Fran{\c{c}}ois and Kelouwani, Sousso and Dub{\'{e}}, Yves and Agbossou, Kodjo},
doi = {10.1016/j.jpowsour.2014.10.011},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martel et al. - 2014 - Optimal economy-based battery degradation management dynamics for fuel-cell plug-in hybrid electric vehicles.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
month = {oct},
pages = {367--381},
title = {{Optimal economy-based battery degradation management dynamics for fuel-cell plug-in hybrid electric vehicles}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378775314016206},
volume = {274},
year = {2015}
}
@article{Varaiya1985,
author = {Varaiya, PP},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Varaiya - 1985 - Extensions of the multiarmed bandit problem the discounted case.pdf:pdf},
journal = {Automatic Control, IEEE {\ldots}},
number = {May},
pages = {426--439},
title = {{Extensions of the multiarmed bandit problem: the discounted case}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1103989},
year = {1985}
}
@article{Dasgupta2009,
abstract = {We start by showing that in an active learning setting, the Perceptron algorithm needs $\Omega$(1/$\epsilon$2) labels to learn linear separators within generalization error $\epsilon$. We then present a simple active learning algorithm for this problem, which combines a modification of the Perceptron update with an adaptive filtering rule for deciding which points to query. For data distributed uniformly over the unit sphere, we show that our algorithm reaches generalization error $\epsilon$ after asking for just {\~{O}}(d log 1/$\epsilon$) labels. This exponential improvement over the usual sample complexity of supervised learning had previously been demonstrated only for the computationally more complex query-by-committee algorithm.},
author = {Dasgupta, Sanjoy},
doi = {10.1145/1577069.1577080},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dasgupta - 2009 - Analysis of Perceptron-Based Active Learning.pdf:pdf},
isbn = {3-540-26556-2},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {active learning,label complexity bounds,online learning,perceptron},
pages = {281--299},
title = {{Analysis of Perceptron-Based Active Learning}},
url = {http://portal.acm.org/citation.cfm?id=1577080{\&}dl=},
volume = {10},
year = {2009}
}
@article{Nordstrom2005,
annote = {From Duplicate 1 ( A new reward model for MDP state aggregation with application to CAC and Routing - Nordstr{\"{o}}m, Ernst; Carlstr{\"{o}}m, Jakob; Nordstrom, Ernst; Carlstrom, Jakob )
},
author = {Nordstrom, Ernst and Carlstrom, Jakob and Nordstr{\"{o}}m, Ernst and Carlstr{\"{o}}m, Jakob},
doi = {10.1002/ett.1007},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nordstr{\"{o}}m, Carlstr{\"{o}}m - 2005 - A new reward model for MDP state aggregation with application to CAC and Routing.pdf:pdf},
issn = {1124-318X},
journal = {Euro. Trans. Telecomms.},
month = {nov},
number = {6},
pages = {0},
title = {{A new reward model for MDP state aggregation with application to CAC and Routing}},
url = {http://doi.wiley.com/10.1002/ett.1007},
volume = {16},
year = {2005}
}
@book{Golub1996,
author = {Golub, Gene H and Loan, Charles F Van},
title = {{Matrix Computations}},
year = {1996}
}
@article{Rust2002,
author = {Rust, John and Traub, JF and Wozniakowski, H},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rust, Traub, Wozniakowski - 2002 - Is there a curse of dimensionality for contraction fixed points in the worst case.pdf:pdf},
journal = {Econometrica},
keywords = {computational complexity,contraction mappings,curse of dimensionality,dynamic program,quasi linear,rational expectations models,strong,tractability},
number = {1},
pages = {285--329},
title = {{Is there a curse of dimensionality for contraction fixed points in the worst case?}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1468-0262.00276/abstract},
volume = {70},
year = {2002}
}
@article{Cheridito2010,
author = {Cheridito, Patrick and Kupper, Michael},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheridito, Kupper - 2010 - Composition of Time-Consistent Dynamic Monetary Risk Measures in Discrete Time.pdf:pdf},
keywords = {dual representations,dynamic risk measures,time-consistency},
pages = {1--22},
title = {{Composition of Time-Consistent Dynamic Monetary Risk Measures in Discrete Time}},
year = {2010}
}
@inproceedings{Munos2005,
annote = {From Duplicate 1 ( Perofrmance Bounds in Lp Norm for Approximate Value Iteration - Munos, Remi )
},
author = {Munos, Remi},
booktitle = {National Conference on Artificial Intelligence (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos - Unknown - Perofrmance Bounds in Lp Norm for Approximate Value Iteration.pdf:pdf},
title = {{Performance bounds in Lp norm for approximate value iteration}},
year = {2005}
}
@article{Agrawal2011,
author = {Agrawal, Shipra and Goyal, N},
booktitle = {Annual Conference on Learning Theory (COLT)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agrawal, Goyal - 2012 - Analysis of Thompson sampling for the multi-armed bandit problem.pdf:pdf},
keywords = {bayesian algorithm,multi-armed bandit,online learning,thompson sampling},
journal = {Journal of Machine Learning},
pages = {39.1--39.26},
volume = {23},
title = {{Analysis of Thompson sampling for the multi-armed bandit problem}},
year = {2012}
}
@inproceedings{Marecki2010a,
author = {Marecki, Janusz and Varakantham, Pradeep},
booktitle = {Conference on Autonomous Agents and Multiagent Systems},
title = {{Risk-Sensitive Planning in Partially Observable Environments}},
year = {2010}
}
@misc{Yu2007,
author = {Yu, Vincent},
title = {{Approximate Dynamic Programming for Blood Inventory Management}},
year = {2007}
}
@article{Wilson2007a,
author = {Wilson, John R. U. and Richardson, David M. and Rouget, Mathieu and Procheş, Şerban and Amis, Mao A. and Henderson, Lesley and Thuiller, Wilfried},
doi = {10.1111/j.1366-9516.2006.00302.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson et al. - 2007 - Residence time and potential range crucial considerations in modelling plant invasions.pdf:pdf},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Biological invasions,South Africa.,invasive species,range size,rates of spread,residence time},
month = {jan},
number = {1},
pages = {11--22},
publisher = {Blackwell Publishing Ltd},
title = {{Residence time and potential range: crucial considerations in modelling plant invasions}},
url = {http://doi.wiley.com/10.1111/j.1366-9516.2006.00302.x},
volume = {13},
year = {2007}
}
@article{Bousquet,
author = {Bousquet, Olivier and Boucheron, Stephane St{\'{e}}phane and Lugosi, G{\'{a}}bor Gabor},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bousquet, Boucheron, Lugosi - Unknown - Introduction to Statistical Learning Theory.pdf:pdf},
journal = {Advanced Lectures on Machine Learning},
pages = {169--207},
title = {{Introduction to Statistical Learning Theory}},
volume = {3176},
year = {2004}
}
@inproceedings{Koller2001,
author = {Koller, D and Milch, B},
booktitle = {International Joint Conference on Uncertainty in Artififial Intelligence},
title = {{Multi-agent influence diagrams for representing and solving games}},
year = {2001}
}
@article{Mangasarian,
author = {Mangasarian, O L and Street, West Dayton},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangasarian, Street - Unknown - A Finite Newton Method for Classification Problems.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mangasarian, Street - Unknown - A Newton Method for Linear Programming.pdf:pdf},
number = {26},
pages = {1--17},
title = {{A Finite Newton Method for Classification Problems}}
}
@article{Karmarkar1984,
author = {Karmarkar, N},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karmarkar - 1984 - A new polynomial-time algorithm for linear programming.pdf:pdf},
journal = {Proceedings of the sixteenth annual ACM symposium {\ldots}},
pages = {302--311},
title = {{A new polynomial-time algorithm for linear programming}},
url = {http://dl.acm.org/citation.cfm?id=808695},
year = {1984}
}
@inproceedings{Hannon2010,
abstract = {Recently the world of the web has become more social and more real-time. Facebook and Twitter are perhaps the ex- emplars of a new generation of social, real-time web services and we believe these types of service provide a fertile ground for recommender systems research. In this paper we focus on one of the key features of the social web, namely the creation of relationships between users. Like recent research, we view this as an important recommendation problem—for a given user, UT which other usersmight be recommended as follow- ers/followees — but unlike other researchers we attempt to harness the real-time web as the basis for profiling and rec- ommendation. To this end we evaluate a range of different profiling and recommendation strategies, based on a large dataset of Twitter users and their tweets, to demonstrate the potential for effective and efficient followee recommen- dation.},
author = {Hannon, John and Bennett, Mike and Smyth, Barry},
booktitle = {ACM Conference on Recommender Systems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hannon, Bennett, Smyth - 2010 - Publisher Recommending Twitter Users to Follow using Content and Collaborative Filtering Approaches.pdf:pdf},
title = {{Publisher Recommending Twitter Users to Follow using Content and Collaborative Filtering Approaches}},
year = {2010}
}
@article{Ahmed2007,
author = {Ahmed, Shabbir and {\c{C}}akmak, Ulaş and Shapiro, Alexander},
doi = {10.1016/j.ejor.2006.07.016},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, {\c{C}}akmak, Shapiro - 2007 - Coherent risk measures in inventory problems.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {coherent risk measures,conditional-value-at-risk,dyn-,inventory models,mean-absolute deviation,newsvendor problem},
month = {oct},
number = {1},
pages = {226--238},
title = {{Coherent risk measures in inventory problems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377221706006497},
volume = {182},
year = {2007}
}
@article{Noori2017,
author = {Noori, Amin and Sadrnia, Mohammad Ali and Sistani, Mahamad bagher Naghibi},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Noori, Sadrnia, Sistani - 2017 - Glucose Level Control Using Temporal Difference Methods.pdf:pdf},
isbn = {9781509059638},
keywords = {- drug therapy,diabetes,difference,reinforcement learning,sarsa algorithm,temporal},
pages = {895--900},
title = {{Glucose Level Control Using Temporal Difference Methods}},
year = {2017}
}
@article{Golub1980,
author = {Golub, GH and Loan, CF Van},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golub, Loan - 1980 - An analysis of the total least squares problem.pdf:pdf},
journal = {SIAM Journal on Numerical Analysis},
number = {6},
title = {{An analysis of the total least squares problem}},
url = {http://epubs.siam.org/doi/abs/10.1137/0717073},
volume = {17},
year = {1980}
}
@article{Chen2007a,
author = {Chen, X. and Sim, M. and Simchi-Levi, D. and Sun, P.},
doi = {10.1287/opre.1070.0429},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2007 - Risk Aversion in Inventory Management.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2007 - Risk Aversion in Inventory Management(2).pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {sep},
number = {5},
pages = {828--842},
title = {{Risk Aversion in Inventory Management}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1070.0429},
volume = {55},
year = {2007}
}
@book{Hickey2008,
author = {Hickey, Jason},
booktitle = {Preprint (January 11, 2008), available at http://www. cs. {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hickey - 2008 - Introduction to Objective Caml.pdf:pdf},
title = {{Introduction to Objective Caml}},
url = {http://www.cis.upenn.edu/{~}cis120e/book.pdf},
year = {2008}
}
@inproceedings{Ooi1996,
author = {Ooi, James M and Wornell, Gregory W},
booktitle = {Proceeding of the IEEE Conference on Decision and Control},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ooi, Wornell - 1996 - Decentralized control of a multiple access broadcast channel performance bounds.pdf:pdf},
pages = {293--298},
title = {{Decentralized control of a multiple access broadcast channel: performance bounds}},
volume = {1},
year = {1996}
}
@misc{Bergez2002,
author = {Bergez, Jacques-Eric and Garcia, Frederick and Leenhardt, Delphine and Maton, Laure},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergez et al. - 2002 - Optimizing Irrigation Management at the Plot Scale to Participate at the Regional Scale Water Resource Management.pdf:pdf},
keywords = {decision rules,irrigation management,markov chain,multivariate analysis,optimisation},
title = {{Optimizing Irrigation Management at the Plot Scale to Participate at the Regional Scale Water Resource Management}},
year = {2002}
}
@article{Goh2010,
abstract = {In this paper we focus on a linear optimization problem with uncertainties, having expectations in the objective and in the set of constraints. We present a modular framework to obtain an approximate solution to the problem that is distributionally robust and more flexible than the standard technique of using linear rules. Our framework begins by first affinely extending the set of primitive uncertainties to generate new linear decision rules of larger dimensions and is therefore more flexible. Next, we develop new piecewise-linear decision rules that allow a more flexible reformulation of the original problem. The reformulated problem will generally contain terms with expectations on the positive parts of the recourse variables. Finally, we convert the uncertain linear program into a deterministic convex program by constructing distributionally robust bounds on these expectations. These bounds are constructed by first using different pieces of information on the distribution of the underlying uncertainties to develop separate bounds and next integrating them into a combined bound that is better than each of the individual bounds.},
author = {Goh, Joel and Sim, Melvyn},
doi = {10.1287/opre.1090.0795},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh, Sim - 2009 - Distributionally Robust Optimization and its Tractable Approximations.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh, Sim - 2009 - Distributionally Robust Optimization and its Tractable Approximations(2).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh, Sim - 2009 - Distributionally Robust Optimization and its Tractable Approximations(3).pdf:pdf},
isbn = {0030-364X},
issn = {0030-364X},
journal = {Operations Research},
keywords = {constraints,uncertain linear-programs,value-at-risk},
number = {4},
pages = {902--917},
title = {{Distributionally robust optimization and its tractable approximations}},
volume = {58},
year = {2010}
}
@article{Wu2001,
abstract = {Dynamic and static weed control decision rules are derived analytically and compared. The dynamic rule leads to increased farm profits and greater control of weeds and weed seeds than the static rule, while total herbicide use is unchanged. The magnitude of the differences is estimated for atrazine control of foxtail and cocklebur in corn production. Incorporating weed dynamics into weed control strategies increases farm profits between 1.0 and 1.4{\%}. (C) 2001 Elsevier Science B.V. All rights reserved.},
author = {Wu, J J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu - 2001 - Optimal weed control under static and dynamic decision rules.pdf:pdf},
isbn = {ISSN: 0169-5150},
journal = {Agricultural Economics},
keywords = {AVENA-FATUA,FARMERS,INFORMATION,KeyWords Plus,MODEL,PEST-MANAGEMENT,THRESHOLDS,WHEAT,herbicide use,weed control decision rules,weed seed dynamics},
number = {1},
pages = {119--130},
title = {{Optimal weed control under static and dynamic decision rules}},
url = {cited: 20th of dec. 2005 athttps://ejournal.csiro.au/pdflinks/05112020013226443.pdf},
volume = {25},
year = {2001}
}
@article{Horvath2012,
author = {Horv{\'{a}}th, T},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Horv{\'{a}}th - 2012 - A model of user preference learning for content-based recommender systems.pdf:pdf},
journal = {Computing and informatics},
keywords = {annotated logic programs,content-based recommender systems,induc-,tion of fuzzy and,user preference learning},
pages = {1001--1029},
title = {{A model of user preference learning for content-based recommender systems}},
url = {http://www.cai.sk/ojs/index.php/cai/article/viewArticle/46},
volume = {29},
year = {2012}
}
@book{Hastie2009,
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
booktitle = {Springer Series in Statistics},
doi = {10.1007/b94608},
edition = {2nd},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hastie, Tibshirani, Friedman - 2009 - The Elements of Statistical Learning.pdf:pdf},
isbn = {9780387848570},
issn = {03436993},
pmid = {15512507},
title = {{The Elements of Statistical Learning}},
url = {http://www.springerlink.com/index/D7X7KX6772HQ2135.pdf},
year = {2009}
}
@book{Phelps2001,
author = {Phelps, Robert R.},
booktitle = {Lecture Notes in Mathematics},
doi = {10.1007/b76887},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phelps - 2001 - Lectures on Choquet's Theorem.pdf:pdf},
isbn = {3540418342},
pages = {124},
title = {{Lectures on Choquet's Theorem}},
volume = {1757},
year = {2001}
}
@book{Sullivan2015,
abstract = {This book is designed as a broad introduction to the mathematics of Un- certainty Quantification (UQ) at the fourth year (senior) undergraduate or beginning postgraduate level. It is aimed primarily at readers from a math- ematical or statistical (rather than, say, engineering) background. The main mathematical prerequisite is familiarity with the language of linear functional analysis and measure / probability theory, and some familiarity with basic optimization theory. Chapters 2–5 of the text provide a review of this mate- rial, generally without detailed proof. The aim of this book has been to give a survey of the main objectives in the field of UQ and a few of the mathematical methods by which they can be achieved. However, this book is no exception to the old saying that books are never completed, only abandoned. There are many more UQ problems and solution methods in the world than those covered here. For any grievous omissions, I ask for your indulgence, and would be happy to receive sugges- tions for improvements. With the exception of the preliminary material on measure theory and functional analysis, this book should serve as a basis for a course comprising 30–45 hours' worth of lectures, depending upon the instructor's choices in terms of selection of topics and depth of treatment. The examples and exercises in this book aim to be simple but informative about individual components of UQ studies: practical applications almost always require some ad hoc combination of multiple techniques (e.g., Gaus- sian process regression plus quadrature plus reduced-order modelling). Such compound examples have been omitted in the interests of keeping the pre- sentation of the mathematical ideas clean, and in order to focus on examples and exercises that will be more useful to instructors and students. Each chapter concludes with a bibliography, the aim of which is threefold: to give sources for results discussed but not proved in the text; to give some historical overview and context; and, most importantly, to give students a jumping-off point for further reading and research. This has led to a large bibliography, but hopefully a more useful text for budding researchers. I would like to thank Achi Dosanjh at Springer for her stewardship of this project, and the anonymous reviewers for their thoughtful comments, which prompted many improvements to the manuscript. Frominitial conception to nearly finished product, this book has benefitted from interactions with many people: they have given support and encourage- ment, offered stimulating perspectives on the text and the field of UQ, and pointed out the inevitable typographical mistakes. In particular, I would like to thank Paul Constantine, Zach Dean, Charlie Elliott, Zydrunas Gimbutas, Calvin Khor, Ilja Klebanov, Han Cheng Lie, Milena Kremakova, David Mc- Cormick, Damon McDougall, Mike McKerns, Akil Narayan, Michael Ortiz, Houman Owhadi, Adwaye Rambojun, Asbj{\o}rn Nilsen Riseth, Clint Scovel, Colin Sparrow, Andrew Stuart, Florian Theil, Joy Tolia, Florian Wechsung, Thomas Whitaker, and Aim´ ee Williams. Finally, since the students on the 2013–14 iteration of the University of Warwick mathematics module MA4K0 Introduction to Uncertainty Quantifi- cation were curious and brave enough to be the initial ‘guinea pigs' for this material, they deserve a special note of thanks.},
author = {Sullivan, T.J.},
booktitle = {Springer},
doi = {10.1007/978-3-319-23395-6},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sullivan - 2015 - Introduction to Uncertainty Quantification.pdf:pdf},
isbn = {978-3-319-23394-9},
title = {{Introduction to Uncertainty Quantification}},
url = {http://link.springer.com/10.1007/978-3-319-23395-6},
volume = {63},
year = {2015}
}
@techreport{Unknown,
author = {Unknown},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Convergence of Series.pdf:pdf},
title = {{Convergence of Series}}
}
@inproceedings{Littman1994,
author = {Littman, Michael},
booktitle = {International Conference on Simulation of Adaptive Behavior},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Littman - 1994 - Memoryless policies Theoretical limitations and practical results.pdf:pdf},
title = {{Memoryless policies: Theoretical limitations and practical results}},
year = {1994}
}
@article{Gabriel2005a,
author = {Gabriel, SA Steven A and Garcia-Bertrand, Raquel and Sahakij, Prawat and Conejo, Antonio J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gabriel et al. - 2005 - A practical approach to approximate bilinear functions in mathematical programming problems by using Schur's dec.pdf:pdf},
journal = {Journal of the Operational Research Society},
number = {1970},
pages = {995--1004},
title = {{A practical approach to approximate bilinear functions in mathematical programming problems by using Schur's decomposition and SOS type 2 variables}},
url = {http://www.palgrave-journals.com/jors/journal/v57/n8/abs/2602052a.html},
volume = {57},
year = {2005}
}
@book{Papadimitriou1998,
author = {Papadimitriou, Christos H and Steiglitz, Kenneth},
title = {{Combinatorial Optimization}},
year = {1998}
}
@article{Carson1997,
author = {Carson, Y and Maria, a},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Carson, Maria - 1997 - Simulation optimization methods and applications.pdf:pdf},
isbn = {078034278X},
journal = {Proceedings of the 29th conference on Winter simulation},
pages = {118--126},
title = {{Simulation optimization: methods and applications}},
url = {http://dl.acm.org/citation.cfm?id=268460},
year = {1997}
}
@article{Vandenberghe2007,
author = {Vandenberghe, Lieven and Boyd, Stephen and Comanor, Katherine},
doi = {10.1137/S0036144504440543},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe, Boyd, Comanor - 2007 - Generalized Chebyshev Bounds via Semidefinite Programming.pdf:pdf},
issn = {0036-1445},
journal = {SIAM Review},
keywords = {60-08,90c22,90c25,ams subject classifications,cheby-,convex optimization,duality theory,moment problems,semidefinite programming,shev inequalities},
month = {jan},
number = {1},
pages = {52--64},
title = {{Generalized Chebyshev Bounds via Semidefinite Programming}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0036144504440543},
volume = {49},
year = {2007}
}
@article{Watkins1989,
annote = {From Duplicate 2 ( Q-learning - Watkins, Chris; Dayan, Peter )

From Duplicate 2 ( Q-learning - Watkins, Chris; Dayan, Peter )
},
author = {Watkins, Chris and Dayan, Peter},
journal = {Machine Learning},
pages = {279--292},
title = {{Q-learning}},
volume = {8},
year = {1989}
}
@article{Hardt2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1211.1056v1},
author = {Hardt, Moritz and Woodru, David P and Woodruff, David P},
eprint = {arXiv:1211.1056v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardt, Woodruff - Unknown - How Robust are Linear Sketches to Adap7ve Inputs.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardt, Woodru - 2012 - How Robust are Linear Sketches to Adaptive Inputs.pdf:pdf},
title = {{How Robust are Linear Sketches to Adaptive Inputs}},
year = {2012}
}
@article{Liu2013,
author = {Liu, X and Aberer, Karl},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Aberer - 2013 - SoCo a social network aided context-aware recommender system.pdf:pdf},
isbn = {9781450320351},
journal = {Proceedings of the World Wide Web Conference},
keywords = {context-awareness,ization,matrix factor-,recommender system,social networks},
pages = {781--791},
title = {{SoCo: a social network aided context-aware recommender system}},
url = {http://dl.acm.org/citation.cfm?id=2488457},
year = {2013}
}
@techreport{Abbasi-yadkori2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1402.6763v1},
author = {Abbasi-Yadkori, Yasin and Bartlett, Peter L and Berkeley, U C and Malek, Alan},
eprint = {arXiv:1402.6763v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abbasi-Yadkori et al. - 2014 - Linear Programming for Large-Scale Markov Decision Problems.pdf:pdf},
pages = {1--27},
title = {{Linear Programming for Large-Scale Markov Decision Problems}},
year = {2014}
}
@book{Russell2003,
author = {Russell, Stuart and Norvig, Peter},
title = {{Artificial Intelligence A Modern Approach}},
year = {2003}
}
@book{Cottle1992,
author = {Cottle, Richard W and Pang, Jong-Shi and Stone, Richard E},
title = {{The Linear Complementarity Problem}},
year = {1992}
}
@article{Lasserre1994,
author = {Lasserre, JB},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lasserre - 1994 - A new policy iteration scheme for Markov decision processes using Schweitzer's formula.pdf:pdf},
journal = {Journal of applied probability},
number = {1},
pages = {268--273},
title = {{A new policy iteration scheme for Markov decision processes using Schweitzer's formula}},
url = {http://cat.inist.fr/?aModele=afficheN{\&}cpsidt=4054244},
volume = {31},
year = {1994}
}
@article{Morton1996,
author = {Morton, D P},
journal = {Annals of Operations Research},
pages = {211--235},
title = {{An enhanced decomposition algorithm for multi-stage stochastic hydroelectric scheduling}},
volume = {64},
year = {1996}
}
@inproceedings{Ng2001,
author = {Ng, Andrew and Jordan, Michael and Weiss, Yair},
booktitle = {{\{}A{\}}dvances in {\{}N{\}}eural {\{}I{\}}nformation {\{}P{\}}rocessing {\{}S{\}}ystems},
title = {{On spectral clustering: analysis and an algorithm}},
year = {2001}
}
@article{Kazaz2004,
author = {Kazaz, Burak},
doi = {10.1287/msom.1030.0024},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazaz - 2004 - Production Planning Under Yield and Demand Uncertainty with Yield-Dependent Cost and Price.pdf:pdf},
issn = {1523-4614},
journal = {Manufacturing {\&} Service Operations Management},
keywords = {olive oil production,price,production planning,stochastic programming,yield and demand uncertainty,yield-dependent,yield-dependent cost},
month = {jul},
number = {3},
pages = {209--224},
title = {{Production Planning Under Yield and Demand Uncertainty with Yield-Dependent Cost and Price}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/msom.1030.0024},
volume = {6},
year = {2004}
}
@inproceedings{Song,
author = {Song, Linqi and Tekin, Cem and Schaar, Mihaela Van Der},
booktitle = {IEEE Transaction on Services Computing},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Tekin, Schaar - Unknown - Online Learning in Large-scale Contextual Recommender Systems.pdf:pdf},
pages = {433--445},
title = {{Online Learning in Large-scale Contextual Recommender Systems}},
url = {http://www.seas.ucla.edu/{~}linqi/recommendation.pdf},
year = {2014}
}
@inproceedings{Baird1995,
author = {Baird, Leemon C},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baird - 1995 - Residual Algorithms Reinforcement Learning with Function Approximation.pdf:pdf},
pages = {30--37},
title = {{Residual Algorithms: Reinforcement Learning with Function Approximation}},
url = {citeseer.ist.psu.edu/baird95residual.html},
year = {1995}
}
@article{Kleywegt2002,
annote = {
        {\textless}m:bold{\textgreater}From Duplicate 1 ( {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}
          {\textless}m:italic{\textgreater}Dynamic programming approximations for a stochastic inventory routing problem{\textless}/m:italic{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater} - Kleywegt, Anton J; Nori, Vija S; Savelsbergh, Martin W P ){\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Kleywegt, Anton J and Nori, Vija S and Savelsbergh, Martin W P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kleywegt, Nori, Savelsbergh - 2002 - Dynamic programming approximations for a stochastic inventory routing problem.pdf:pdf},
journal = {Transportation Science},
pages = {42--70},
title = {{Dynamic programming approximations for a stochastic inventory routing problem}},
volume = {38},
year = {2002}
}
@book{Altman1998,
author = {Altman, Eitan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Altman - 1998 - Constrained Markov Decision Processes.pdf:pdf},
title = {{Constrained Markov Decision Processes}},
year = {1998}
}
@misc{Castings,
author = {Castings, Vermont},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castings - Unknown - Vermont Castings Defiant Encore Manual.pdf:pdf},
title = {{Vermont Castings Defiant Encore Manual}}
}
@article{Aoki1968,
annote = {From Duplicate 2 ( Control of Large-Scale Dynamic Systems - Aoki, Masanao )
},
author = {Aoki, Masanao},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aoki - 1968 - Control of Large-Scale Dynamic Systems.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {3},
pages = {246--253},
title = {{Control of large-scale dynamic systems by aggregation}},
volume = {13},
year = {1968}
}
@article{Rockafellar2002,
author = {Rockafellar, R. Tyrrell and Uryasev, Stanislav},
doi = {10.1016/S0378-4266(02)00271-6},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Uryasev - 2002 - Conditional value-at-risk for general loss distributions.pdf:pdf},
issn = {03784266},
journal = {Journal of Banking and Finance},
keywords = {coherent risk measures,conditional value-at-risk,hedging,index tracking,mean shortfall,pling,portfolio optimization,risk management,risk sam-,scenarios,value-at-risk},
month = {jul},
number = {7},
pages = {1443--1471},
title = {{Conditional Value-At-Risk for General Loss Distributions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378426602002716 http://www.sciencedirect.com/science/article/pii/S0378426602002716},
volume = {26},
year = {2002}
}
@article{Boyd2010,
author = {Boyd, Stephen},
doi = {10.1561/2200000016},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000016},
volume = {3},
year = {2010}
}
@article{Sherali1980,
author = {Sherali, Hanif D and Shetty, C M},
journal = {Mathematical Programming},
pages = {14--31},
title = {{A finitely convergent algorithm for bilinear programming problems using polar cuts and disjunctive face cuts}},
url = {http://dx.doi.org/10.1007/BF01581626},
volume = {19},
year = {1980}
}
@article{Least-squares,
archivePrefix = {arXiv},
arxivId = {arXiv:1406.5986v1},
author = {Least-squares, Ordinary and Raskutti, Garvesh},
eprint = {arXiv:1406.5986v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Least-squares, Raskutti - Unknown - A Statistical Perspective on Randomized Sketching for.pdf:pdf},
title = {{A Statistical Perspective on Randomized Sketching for}}
}
@article{Boutilier2000,
author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Moises},
journal = {Artificial Intelligence},
pages = {49--107},
title = {{Stochastic dynamic programming with factored representations}},
volume = {121},
year = {2000}
}
@article{Nijbroek2003,
author = {Nijbroek, Ravic and Hoogenboom, Gerrit and Jones, James W},
doi = {10.1016/S0308-521X(02)00127-0},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nijbroek, Hoogenboom, Jones - 2003 - Optimizing irrigation management for a spatially variable soybean field.pdf:pdf},
isbn = {1770228721},
issn = {0308521X},
journal = {Agricultural Systems},
month = {apr},
number = {1},
pages = {359--377},
title = {{Optimizing irrigation management for a spatially variable soybean field}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0308521X02001270},
volume = {76},
year = {2003}
}
@article{Ben-Tal2010,
author = {Ben-Tal, Aharon and Bertsimas, Dmitris and Brown, David B.},
doi = {10.1287/opre.1100.0821},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Tal, Bertsimas, Brown - 2010 - A Soft Robust Model for Optimization Under Ambiguity.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
number = {4},
pages = {1220--1234},
title = {{A Soft Robust Model for Optimization Under Ambiguity}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1100.0821},
volume = {58},
year = {2010}
}
@incollection{Serin1995,
annote = {Touches on the issue of interpretability and observation of components.

Actions of a policy depend only on a subset of states 

Very similar to learning finite state controllers for POMDPS. In fact the setting here is a POMDP.},
author = {Serin, Yasemin and Kulkarni, VG},
booktitle = {Computations with Markov Chains},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serin, Kulkarni - 1995 - Implementable policies discounted cost case.pdf:pdf},
pages = {283--306},
title = {{Implementable policies: discounted cost case}},
url = {http://link.springer.com/chapter/10.1007/978-1-4615-2241-6{\_}17},
year = {1995}
}
@article{Elith2011,
abstract = {Abstract MaxEnt is a program for modelling species distributions from presence-only species records. This paper is written for ecologists and describes the MaxEnt model from a statistical perspective, making explicit links between the structure of the model, decisions required in producing a modelled distribution, and knowledge about the species and the data that might affect those decisions. To begin we discuss the characteristics of presence-only data, highlighting implications for modelling distributions. We particularly focus on the problems of sample bias and lack of information on species prevalence. The keystone of the paper is a new statistical explanation of MaxEnt which shows that the model minimizes the relative entropy between two probability densities (one estimated from the presence data and one, from the landscape) defined in covariate space. For many users, this viewpoint is likely to be a more accessible way to understand the model than previous ones that rely on machine learning concepts. We then step through a detailed explanation of MaxEnt describing key components (e.g. covariates and features, and definition of the landscape extent), the mechanics of model fitting (e.g. feature selection, constraints and regularization) and outputs. Using case studies for a Banksia species native to south-west Australia and a riverine fish, we fit models and interpret them, exploring why certain choices affect the result and what this means. The fish example illustrates use of the model with vector data for linear river segments rather than raster (gridded) data. Appropriate treatments for survey bias, unprojected data, locally restricted species, and predicting to environments outside the range of the training data are demonstrated, and new capabilities discussed. Online appendices include additional details of the model and the mathematical links between previous explanations and this one, example code and data, and further information on the case studies.},
archivePrefix = {arXiv},
arxivId = {1132},
author = {Elith, Jane and Phillips, Steven J. and Hastie, Trevor and Dud{\'{i}}k, Miroslav and Chee, Yung En and Yates, Colin J.},
doi = {10.1111/j.1472-4642.2010.00725.x},
eprint = {1132},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elith et al. - 2011 - A statistical explanation of MaxEnt for ecologists.pdf:pdf},
isbn = {1472-4642},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Absence,Ecological niche,Entropy,Machine learning,Presence-only,Species distribution model},
number = {1},
pages = {43--57},
pmid = {15204886},
title = {{A statistical explanation of MaxEnt for ecologists}},
volume = {17},
year = {2011}
}
@article{International2007,
author = {International, Pioneer Hi-bred},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/International - 2007 - Environmental Classification in Maize.pdf:pdf},
title = {{Environmental Classification in Maize}},
year = {2007}
}
@inproceedings{Weinstein2010,
author = {Weinstein, Ari and Mansley, Chris and Littman, Michael},
booktitle = {ICML Workshop on Reinforcement Learning and Search in Very Large Spaces},
title = {{Sample-based Planning for Continuous Action Markov Decision Processes}},
year = {2010}
}
@article{Bertsimas2006a,
author = {Bertsimas, Dimitris and Sim, Melvyn},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Sim - 2006 - Tractable approximations to robust conic optimization problems.pdf:pdf},
journal = {Mathematical Programming},
pages = {1--34},
title = {{Tractable approximations to robust conic optimization problems}},
url = {http://link.springer.com/article/10.1007/s10107-005-0677-1},
year = {2006}
}
@article{Smith2006a,
abstract = {Decision analysis produces measures of value such as expected net present values or expected utilities and ranks alternatives by these value estimates. Other optimization-based processes operate in a similar manner. With uncertainty and limited resources, an analysis is never perfect, so these value estimates are subject to error. We show that if we take these value estimates at face value and select accordingly, we should expect the value of the chosen alternative to be less than its estimate, even if the value estimates are unbiased. Thus, when comparing actual outcomes to value estimates, we should expect to be disappointed on average, not because of any inherent bias in the estimates themselves, but because of the optimization-based selection process. We call this phenomenon the optimizer's curse and argue that it is not well understood or appreciated in the decision analysis and management science communities. This curse may be a factor in creating skepticism in decision makers who review the results of an analysis. In this paper, we study the optimizer's curse and show that the resulting expected disappointment may be substantial. We then propose the use of Bayesian methods to adjust value estimates. These Bayesian methods can be viewed as disciplined skepticism and provide a method for avoiding this postdecision disappointment.},
author = {Smith, James E. and Winkler, Robert L.},
doi = {10.1287/mnsc.1050.0451},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Winkler - 2006 - The Optimizer's Curse Skepticism and Postdecision Surprise in Decision Analysis.pdf:pdf},
isbn = {0025-1909},
issn = {0025-1909},
journal = {Management Science},
keywords = {bayesian models,decision analysis,optimization,optimizer,postdecision surprise,s curse},
number = {3},
pages = {311--322},
pmid = {20335587},
title = {{The Optimizer's Curse: Skepticism and Postdecision Surprise in Decision Analysis}},
url = {http://econpapers.repec.org/article/inmormnsc/v{\_}3a52{\_}3ay{\_}3a2006{\_}3ai{\_}3a3{\_}3ap{\_}3a311-322.htm{\%}5Cnhttp://content.ebscohost.com/ContentServer.asp?T=P{\&}P=AN{\&}K=20335587{\&}S=R{\&}D=bah{\&}EbscoContent=dGJyMNLe80Sepq84zdnyOLCmr02ep65SsKq4TK6WxWXS{\&}ContentCustomer=dGJyMOzprk+zp},
volume = {52},
year = {2006}
}
@article{Tan1988,
author = {Tan, Tommy Chin-Chiu and {da Costa Werlang}, S�rgio Ribeiro},
journal = {Journal of Economic Theory},
title = {{The Bayesian foundations of solution concepts of games}},
year = {1988}
}
@article{Rockafellar2000,
author = {Rockafellar, R. Tyrrell and Uryasev, S.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Uryasev - 2000 - Optimization of conditional value-at-risk.pdf:pdf},
journal = {Journal of Risk},
pages = {21--41},
title = {{Optimization of conditional value-at-risk}},
volume = {2},
year = {2000}
}
@article{Hsu2010a,
abstract = {This dissertation develops and analyzes active learning algorithms for binary classification problems. In passive (non-active) learning, a learner uses a random sample of labeled examples from a fixed distribution to select a hypothesis with low error. In active learning, a learner receives only a sample of unlabeled data, but has the option to query the label of any of these data points. The hope is that the active learner needs to query the labels of just a few, carefully chosen points in order to produce a hypothesis with low error.$\backslash$nThe first part of this dissertation develops algorithms based on maintaining a version space—the set of hypotheses still in contention to be selected. The version space is specifically designed to tolerate arbitrary label noise and model mismatch in the agnostic learning model. The algorithms maintain the version space using a reduction to a special form of agnostic learning that allows for example-based constraints; this represents a computational improvement over previous methods. The generalization behavior of one of these algorithms is rigorously analyzed using a quantity called the disagreement coefficient. This algorithm is shown to have label complexity that improves over that of previous methods, and matches known label complexity lower bounds in certain cases.$\backslash$nThe second part of this dissertation develops algorithms based on simpler reductions to agnostic learning that more closely match the standard abstraction of supervised learning procedures. The generalization behavior of these algorithms are also analyzed in the agnostic learning model, and are shown to have label com- plexity similar to the version space methods. Therefore, these algorithms represent qualitative improvements over version space methods, as strict version space meth- ods can be risky to deploy in practice. The first of these algorithms is based on a relaxation of a version space method, and the second is based on an importance weighting technique. The second algorithm is also shown to automatically adapt to various noise conditions that imply a tighter label complexity analysis. Exper- iments using this algorithm are also presented to illustrate some of the promise of the method.},
author = {Hsu, Daniel},
doi = {10.1300/J122v22n03_06},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsu - 2010 - Algorithms for active learning.pdf:pdf},
isbn = {0-8247-0973-X},
issn = {0194-262X},
journal = {Active Learning},
title = {{Algorithms for active learning}},
url = {https://escholarship.org/uc/item/3hs1z568.pdf},
year = {2010}
}
@article{Ghate2013,
abstract = {Nonstationary infinite-horizon Markov decision processes (MDPs) generalize the most well-studied class of sequential decision models in operations research, namely, that of stationary MDPs, by relaxing the restrictive assumption that problem data do not change over time. Linear programming (LP) has been very successful in obtaining structural insights and devising solution methods for stationary MDPs. However, an LP approach for nonstationary MDPs is currently missing. This is because the LP formulation of a nonstationary infinite-horizon MDP includes countably infinite variables and constraints, and research on such infinite-dimensional LPs has traditionally faced several hurdles. For instance, duality results may not hold; an extreme point may not be a basic feasible solution; and in the context of a simplex algorithm, a pivot operation may require infinite data and computations, and a sequence of improving extreme points need not converge in value to optimal. In this paper, we tackle these challenges and establish (1) weak and strong duality, (2) complementary slackness, (3) a basic feasible solution characterization of extreme points, (4) a one-to-one correspondence between extreme points and deterministic Markovian policies, and (5) we devise a simplex algorithm for an infinite-dimensional LP formulation of nonstationary infinite-horizon MDPs. Pivots in this simplex algorithm use finite data, perform finite computations, and generate a sequence of improving extreme points that converges in value to optimal. Moreover, this sequence of extreme points gets arbitrarily close to the set of optimal extreme points. We also prove that decisions prescribed by these extreme points are eventually exactly optimal in all states of the nonstationary infinite-horizon MDP in early periods.},
author = {Ghate, Archis and Smith, Robert L.},
doi = {10.1287/opre.1120.1121},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghate, Smith - 2013 - A Linear Programming Approach to Nonstationary Infinite-Horizon Markov Decision Processes.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
number = {January 2015},
pages = {413--425},
title = {{A Linear Programming Approach to Nonstationary Infinite-Horizon Markov Decision Processes}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1120.1121},
volume = {61},
year = {2013}
}
@inproceedings{Littman2002,
author = {Littman, Michael and Sutton, Richard and Singh, Satinder},
booktitle = {Advances in Neural Information Processing Systems},
title = {{Predictive Representations of State}},
year = {2002}
}
@book{Kolobov2012,
author = {Kolobov, Mausam and Kolobov, Andrey},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolobov, Kolobov - 2012 - Planning with Markov Decision Processes.pdf:pdf},
isbn = {9781608458868},
title = {{Planning with Markov Decision Processes}},
year = {2012}
}
@inproceedings{Mcmahan2005,
author = {Mcmahan, H Brendan and Gordon, Geoffrey J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mcmahan, Gordon - 2005 - Bounded Real-Time Dynamic Programming RTDP with monotone upper bounds and performance guarantees.pdf:pdf},
title = {{Bounded Real-Time Dynamic Programming : RTDP with monotone upper bounds and performance guarantees}},
year = {2005}
}
@techreport{Braziunas2003,
author = {Braziunas, Darius},
institution = {University of Toronto},
title = {{POMDP solution methods}},
year = {2003}
}
@article{Anonymous2013,
annote = {undoubtedly writen by Xiao and Zhang

This deals with estimating the strong convexity parameter (it's an alternative to "restarts"). Also, it has a continuation scheme that they prove will sometimes give fast convergence. But's all contingent on some conditions on the operator...

Here's my ICML review for it:

Review of "An Adaptive Accelerated Proximal Gradient Method and its Homotopy Continuation for Sparse Optimization."
Initially I was skeptical of the paper because there have been two many papers on this topic and most results are now very incremental. However, by the end of the paper, I had a more favorable view. The paper covers several different results, the mathematics are good, and the writing is considerably better than average. The complexity results seem rigorous and this is refreshing. The numerical example is chosen to be slightly more difficult than is typical. Also, the authors' implementation of FISTA (using line search, homotopy, etc.) is fair, in comparison to many authors who just use plain FISTA and, of course, find that plain FISTA is not competitive.

However, there are still flaws with the paper. The algorithm does not perform significantly better than FISTA with restart. The method, especially the homotopy variant, has quite a few parameters. The result for l1-LS with the restricted eigenvalue condition depends on very strong RIP-like conditions (stronger than RIP in fact!), so it's not clear how often this applies. If lambda{\_}{\{}tgt{\}} is such that this holds, the problem is basically not ill-conditioned, so changing from O(kappa) to O(sqrt(kappa)) is not as good as it sounds like.

Furthermore, this topic is extremely well researched and inevitably, the authors have missed some (rather significant) relevant references. It's not fun to run a lot of numerical comparisons, but if the authors want to write yet another paper about a fast solver for l1-LS problems, they should do the comparisons.

Specific comments:

- Section 2, you attribute the composite gradient mapping to Nesterov 2013. This is misleading since it comes from ideas about 10 years earlier. Nesterov's technical report and FISTA both contain this idea (FISTA may have in fact been the first paper to have acceleration with the proximal term), so change the citation to an earlier paper otherwise the reader will think this technique was introduced in 2013.

- For which functions Psi is condition (11) easy to check? For Psi = l1, this is easy, but what about other cases, especially if Psi is not separable?

- Section 4 asks a lot of the reader. Even assumption 1 looks quite complicated.

- "Our O(sqrt(kappa)ln(1/eps)) complexity of the APG homotopy method is the best known result for solving the l1-LS problem in the high-d case". Well, yes, but you have strong assumptions. You could also say that under the assumption that algorithm X converges in 1 step, it has the best known complexity result!

- In the plots, you've added a few symbols to the lines to help distinguish them in B{\&}W, which is very nice (since I printed this out B{\&}W), but they do not show up in the legend. A trick to do this in Matlab: assuming you've plotted the main line (that has values for every k), instead of adding a new line series that is sub-sampled and has markers but no line style, you can add a new line series that has markers and a line style, but set the points you don't want to show up to the value -Inf, and on a semilogy plot they will not show up. You can now add this line series to the legend instead of the original.

- Missing references and solvers:

-- "PARNES: a rapidly convergent..." by Gu, Lim and Wu. This shows linear convergence under similar restricted eigenvalue conditions


-- "An adaptive accelerated first-order method for convex optimization" by Monteiro, Ortiz and Svaiter. They adaptively estimate constants as well.

-- "Fine tuning Nesterov's steepest descent algorithm for differentiable convex programming" by Gonzaga and Karas. They have an adaptive procedure for estimating a strong convexity constant.

-- FPC-Active Set is a refinement of Hale/Yin/Zhang's earlier work on FPC, and it is much faster due to an active set scheme.

-- "A quasi-Newton proximal splitting method" by Becker and Fadili doesn't exploit strong convexity but it is a fast solver for these problems. Additionally, they compare to other fast solvers (e.g., PSSas by Schmidt, L-BFGS-B), so you could use their results to pick the fastest solvers to compare to.

-- Finally, since Nesterov already suggested an adaptive scheme to estimate mu{\_}f and provided complexity bounds, it seems logical to try this experimentally.

Not all of the above methods have code, but many of them do, so they should be included in a test.

The numerical experiment doesn't seem to actually be that ill-conditioned, since it can be solved to high accuracy in under 2000 iterations. There are some ill-conditioned matrices that require {\textgreater} 10{\^{}}4 iterations with first-order methods so it would be interesting to try these. Or, ill-conditioned matrices that arise in applications that use 1l (e.g., a blur operator) would be interesting.},
author = {Anonymous},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anonymous - 2013 - An Adaptive Accelerated Proximal Gradient Method and its Homotopy Continuation for Sparse Optimization.pdf:pdf},
journal = {ICML '14, submitted},
title = {{An Adaptive Accelerated Proximal Gradient Method and its Homotopy Continuation for Sparse Optimization}},
year = {2013}
}
@article{Moreno-Amat2015,
abstract = {Maximum entropy modeling (Maxent) is a widely used algorithm for predicting species distributions across space and time. Properly assessing the uncertainty in such predictions is non-trivial and requires validation with independent datasets. Notably, model complexity (number of model parameters) remains a major concern in relation to overfitting and, hence, transferability of Maxent models. An emerging approach is to validate the cross-temporal transferability of model predictions using paleoecological data. In this study, we assess the effect of model complexity on the performance of Maxent projections across time using two European plant species (Alnus glutinosa (L.) Gaertn. and Corylus avellana L.) with an extensive late Quaternary fossil record in Spain as a study case. We fit 110 models with different levels of complexity under present time and tested model performance using AUC (area under the receiver operating characteristic curve) and AICc (corrected Akaike Information Criterion) through the standard procedure of randomly partitioning current occurrence data. We then compared these results to an independent validation by projecting the models to mid-Holocene (6000 years before present) climatic conditions in Spain to assess their ability to predict fossil pollen presence–absence and abundance. We find that calibrating Maxent models with default settings result in the generation of overly complex models. While model performance increased with model complexity when predicting current distributions, it was higher with intermediate complexity when predicting mid-Holocene distributions. Hence, models of intermediate complexity resulted in the best trade-off to predict species distributions across time. Reliable temporal model transferability is especially relevant for forecasting species distributions under future climate change. Consequently, species-specific model tuning should be used to find the best modeling settings to control for complexity, notably with paleoecological data to independently validate model projections. For cross-temporal projections of species distributions for which paleoecological data is not available, models of intermediate complexity should be selected.},
author = {Moreno-Amat, Elena and Mateo, Rub{\'{e}}n G. and Nieto-Lugilde, Diego and Morueta-Holme, Naia and Svenning, Jens-Christian and Garc{\'{i}}a-Amorena, Ignacio},
doi = {10.1016/j.ecolmodel.2015.05.035},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreno-Amat et al. - 2015 - Impact of model complexity on cross-temporal transferability in Maxent species distribution models An assess.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Alnus glutinosa,Corylus avellana,Model validation,Pollen fossil,Species distribution model,$\beta$-Multiplier},
month = {sep},
pages = {308--317},
title = {{Impact of model complexity on cross-temporal transferability in Maxent species distribution models: An assessment using paleobotanical data}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380015002483},
volume = {312},
year = {2015}
}
@inproceedings{Tamar2014a,
author = {Tamar, Aviv and Mannor, Shie and Xu, Huan},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar, Mannor, Xu - 2014 - Scaling Up Robust MDPs using Function Approximation.pdf:pdf},
title = {{Scaling Up Robust MDPs using Function Approximation}},
year = {2014}
}
@techreport{Seuken2005,
annote = {From Duplicate 1 ( Formal Models and Algorithms for Decentralized Control of Multiple Agents - Seuken, Sven; Zilberstein, Shlomo )
},
author = {Seuken, Sven and Zilberstein, Shlomo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seuken, Zilberstein - 2005 - Formal Models and Algorithms for Decentralized Control of Multiple Agents.pdf:pdf},
institution = {Computer Science Department, University of Massachusetts},
number = {2005-068},
title = {{Formal Models and Algorithms for Decentralized Control of Multiple Agents}},
year = {2005}
}
@book{Cover1991,
author = {Cover, TM and Thomas, JA},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cover, Thomas - 2012 - Elements of information theory.pdf:pdf},
isbn = {0471062596},
title = {{Elements of information theory}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=VWq5GG6ycxMC{\&}oi=fnd{\&}pg=PT10{\&}dq=Elements+of+Information+Theory{\&}ots=bWbjL{\_}VaRS{\&}sig=gDruJ4Os9AkFn4FzQggI1TVIoUM},
year = {2012}
}
@inproceedings{Maggioni2006,
annote = {From Duplicate 1 ( 


Fast direct policy evaluation using multiscale analysis of Markov diffusion processes


- Maggioni, Mauro; Mahadevan, Sridhar )

},
author = {Maggioni, Mauro and Mahadevan, Sridhar},
booktitle = {International Conference on Machine Learning},
doi = {http://doi.acm.org/10.1145/1143844.1143920},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maggioni, Mahadevan - 2006 - Fast direct policy evaluation using multiscale analysis of Markov diffusion processes.pdf:pdf},
isbn = {1-59593-383-2},
pages = {601--608},
publisher = {ACM Press},
title = {{Fast direct policy evaluation using multiscale analysis of Markov diffusion processes}},
year = {2006}
}
@article{Klabjan2007,
author = {Klabjan, D. and Adelman, D.},
doi = {10.1287/moor.1070.0252},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klabjan, Adelman - 2007 - An Infinite-Dimensional Linear Programming Algorithm for Deterministic Semi-Markov Decision Processes on Borel.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {90c40,90c90,algorithms,approximate dynamic programming,deterministic semi-markov decision processes,dynamic,infinite,infinite dimensional,ms subject classification,msc2000 subject classification,or,primary,programming,ridge function approximations,secondary,semi-infinite linear programming algorithms},
month = {aug},
number = {3},
pages = {528--550},
title = {{An Infinite-Dimensional Linear Programming Algorithm for Deterministic Semi-Markov Decision Processes on Borel Spaces}},
url = {http://mor.journal.informs.org/cgi/doi/10.1287/moor.1070.0252},
volume = {32},
year = {2007}
}
@misc{Shaw,
author = {Shaw, W Douglass},
booktitle = {Encyclopedia of Environmental and Resource Economics},
doi = {http://dx.doi.org/10.1016/B978-0-12-375067-9.00145-5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shaw - 2016 - Environmental and Natural Resource Economics Decisions under Risk and Uncertainty.pdf:pdf},
isbn = {978-0-08-096452-2},
title = {{Environmental and Natural Resource Economics: Decisions under Risk and Uncertainty}},
year = {2016}
}
@article{Jackson2004,
author = {Jackson, T},
doi = {10.1016/j.rse.2003.10.021},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jackson - 2004 - Vegetation water content mapping using Landsat data derived normalized difference water index for corn and soybeans.pdf:pdf},
issn = {00344257},
journal = {Remote Sensing of Environment},
keywords = {landsat,ndwi,vegetation water content},
month = {sep},
number = {4},
pages = {475--482},
title = {{Vegetation water content mapping using Landsat data derived normalized difference water index for corn and soybeans}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0034425703003353},
volume = {92},
year = {2004}
}
@article{Farias2000,
author = {{Van Roy}, Benjamin and de Farias, Daniela P},
journal = {Journal of Optimization Theory and Applications},
title = {{On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning}},
volume = {105},
year = {2000}
}
@article{Bontemps2000,
author = {Bontemps, C and Couture, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bontemps, Couture - 2000 - Dynamics and uncertainty in irrigation management.pdf:pdf},
journal = {Cahiers d'Economie et sociologie Rurales},
number = {April},
pages = {1--17},
title = {{Dynamics and uncertainty in irrigation management}},
url = {http://www.cabdirect.org/abstracts/20013107928.html},
year = {2000}
}
@phdthesis{Gordon1999,
author = {Gordon, Geoffrey J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon - 1999 - Approximate solutions to Markov decision processes.pdf:pdf},
school = {CMU},
title = {{Approximate solutions to Markov decision processes}},
year = {1999}
}
@inproceedings{Tamar2014,
archivePrefix = {arXiv},
arxivId = {1404.3862},
author = {Tamar, Aviv and Glassner, Yonatan and Mannor, Shie},
booktitle = {AAAI Conference on Artificial Intelligence},
eprint = {1404.3862},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tamar, Glassner, Mannor - 2014 - Optimizing the CVaR via Sampling.pdf:pdf},
isbn = {9781577357025},
keywords = {Novel Machine Learning Algorithms Track},
pages = {2993--2999},
title = {{Optimizing the CVaR via Sampling}},
url = {http://arxiv.org/abs/1404.3862},
year = {2014}
}
@inproceedings{Kumar2014,
author = {Kumar, Akshat and Singh, Arambam James and Varakantham, Pradeep and Sheldon, Daniel},
booktitle = {AAAI Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2014 - Robust Decision Making For Stochastic Network Design.pdf:pdf},
title = {{Robust Decision Making For Stochastic Network Design}},
year = {2014}
}
@article{Spaan2005,
author = {Spaan, Matthijs T J and Vlassis, Nikos},
journal = {Journal of Artificial Intelligence Research},
pages = {195--220},
title = {{Perseus: Randomized Point-based Value Iteration for POMDPs}},
volume = {24},
year = {2005}
}
@article{Ernst2005,
abstract = {Reinforcement learning aims to determine an optimal control policy from interaction with a system or from observations gathered from a system. In batch mode, it can be achieved by approximating the so-called Q-function based on a set of four-tuples (xt, ut , rt, xt+1) where xt denotes the system state at time t, ut the control action taken, rt the instantaneous reward obtained and xt+1 the successor state of the system, and by determining the control policy from this Q-function. The Q-function approximation may be obtained from the limit of a sequence of (batch mode) supervised learning problems. Within this framework we describe the use of several classical tree-based supervised learning methods (CART, Kd-tree, tree bagging) and two newly proposed ensemble algorithms, namely extremely and totally randomized trees. We study their performances on several examples and find that the ensemble methods based on regression trees perform well in extracting relevant information about the optimal control policy from sets of four-tuples. In particular, the totally randomized trees give good results while ensuring the convergence of the sequence, whereas by relaxing the convergence constraint even better accuracy results are provided by the extremely randomized trees.},
author = {Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ernst, Geurts, Wehenkel - 2005 - Tree-Based Batch Mode Reinforcement Learning.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {batch mode reinforcement learning,ensemble methods,fitted value iteration,learning,optimal control,regression trees,supervised},
number = {1},
pages = {503--556},
pmid = {8013595514229294023},
title = {{Tree-Based Batch Mode Reinforcement Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.7705{\&}rep=rep1{\&}type=pdf},
volume = {6},
year = {2005}
}
@article{Rifkin2007,
annote = {From Duplicate 1 ( 


Value Regularization and Fenchel Duality


- Rifkin, Ryan M; Lippert, Ross A )

},
author = {Rifkin, Ruyan M Ryan M and Lippert, Ross A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rifkin, Lippert - 2007 - Value Regularization and Fenchel Duality.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {convex analysis,duality,kernel learning,kernel machines,optimization},
pages = {441--479},
title = {{Value regularization and Fenchel duality}},
volume = {8},
year = {2007}
}
@article{Ledoux2005,
author = {Ledoux, James},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ledoux - 2005 - Recursive filters for partially observable finite Markov chains.pdf:pdf},
journal = {Journal of applied probability},
keywords = {d-bmap,hidden markov chain,time-inhomogeneous markov chain},
number = {October 2004},
pages = {684--697},
title = {{Recursive filters for partially observable finite Markov chains}},
url = {http://projecteuclid.org/euclid.jap/1127322020},
volume = {697},
year = {2005}
}
@article{Spielman2001,
abstract = {We introduce the smoothed analysis of algorithms, which is a hybrid of the worst-case and average-case analysis of algorithms. In smoothed analysis, we measure the maximum over inputs of the expected performance of an algorithm under small random perturbations of that input. We measure this performance in terms of both the input size and the magnitude of the perturbations. We show that the simplex algorithm has polynomial smoothed complexity.},
archivePrefix = {arXiv},
arxivId = {cs.DS/0111050},
author = {Spielman, Daniel a. and Teng, Shang-Hua},
eprint = {0111050},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 2001 - Smoothed Analysis of Algorithms Why the Simplex Algorithm Usually Takes Polynomial Time.pdf:pdf},
month = {nov},
primaryClass = {cs.DS},
title = {{Smoothed Analysis of Algorithms: Why the Simplex Algorithm Usually Takes Polynomial Time}},
url = {http://arxiv.org/abs/cs.DS/0111050},
year = {2001}
}
@article{Yudovina2014,
author = {Yudovina, Elena and Michailidis, George},
doi = {10.1109/TAC.2014.2346089},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yudovina, Michailidis - 2014 - Socially Optimal Charging Strategies for Electric Vehicles.pdf:pdf},
isbn = {9823010102},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
number = {c},
pages = {1--6},
title = {{Socially Optimal Charging Strategies for Electric Vehicles}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6873288},
volume = {9286},
year = {2014}
}
@article{Feinberg2014a,
author = {Feinberg, Eugene A and Huang, Jefferson},
doi = {10.1016/j.orl.2013.12.011},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Feinberg, Huang - 2014 - The value iteration algorithm is not strongly polynomial for discounted dynamic programming.pdf:pdf},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {markov decision process},
month = {mar},
number = {2},
pages = {130--131},
publisher = {Elsevier B.V.},
title = {{The value iteration algorithm is not strongly polynomial for discounted dynamic programming}},
url = {http://dx.doi.org/10.1016/j.orl.2013.12.011 http://linkinghub.elsevier.com/retrieve/pii/S0167637714000029},
volume = {42},
year = {2014}
}
@inproceedings{Saha2009,
author = {Saha, Bhaskar and Goebel, Kai},
booktitle = {Annual Conference of the Prognostics and Health Management Society},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saha, Goebel - 2009 - Modeling Li-ion battery capacity depletion in a particle filtering framework.pdf:pdf},
pages = {1--10},
title = {{Modeling Li-ion battery capacity depletion in a particle filtering framework}},
url = {https://www.phmsociety.org/sites/phmsociety.org/files/phm{\_}submission/2009/phmc{\_}09{\_}38.pdf},
year = {2009}
}
@article{Whittle1988,
abstract = {We consider a population of n projects which in general continue to evolve whether in operation or not (although by different rules). It is desired to choose the projects in operation at each instant of time so as to maximise the expected rate of reward, under a constraint upon the expected number of projects in operation. The Lagrange multiplier associated with this constraint defines an index which reduces to the Gittins index when projects not being operated are static. If one is constrained to operate m projects exactly then arguments are advanced to support the conjecture that, for m and n large in constant ratio, the policy of operating the m projects of largest current index is nearly optimal. The index is evaluated for some particular projects.},
author = {Whittle, P.},
doi = {10.2307/3214163},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Whittle - 1988 - Restless Bandits Activity Allocation in a Changing World.pdf:pdf},
isbn = {00219002},
issn = {00219002},
journal = {Journal of Applied Probability},
keywords = {Gittins index,Indexability,Mulit-armed Bandits,Sequential Scheduling,Stimulating Prices},
number = {1988},
pages = {287},
title = {{Restless Bandits: Activity Allocation in a Changing World}},
url = {http://www.jstor.org/stable/3214163?origin=crossref},
volume = {25},
year = {1988}
}
@unpublished{Weissman2003xx,
annote = {From Duplicate 2 ( Inequalities for the {\$}L{\_}1{\$} deviation of the empirical distribution - Weissman, Tsachy; Ordentlich, Erik; Seroussi, Gadiel; Verdu, Sergio; Weinberger, Marcelo J )
},
author = {Weissman, Tsachy and Ordentlich, Erik and Seroussi, Gadiel and Verdu, Sergio and Weinberger, Marcelo J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weissman et al. - 2003 - Inequalities for the {\$}L{\_}1{\$} deviation of the empirical distribution.pdf:pdf},
month = {jun},
title = {{Inequalities for the L{\_}1 deviation of the empirical distribution}},
year = {2003}
}
@article{Vet-mote1997,
author = {Vet-mote, Eric F and Deuzc, Jean Luc},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vet-mote, Deuzc - 1997 - Second Simulation of the Satellite Signal in the Solar Spectrum , 6s An Overview.pdf:pdf},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
number = {3},
pages = {675--686},
title = {{Second Simulation of the Satellite Signal in the Solar Spectrum , 6s : An Overview}},
volume = {35},
year = {1997}
}
@article{USDA,
abstract = {The purpose of this study is to identify areas of the country that have the highest potential for sediment and nutrient loss from farm fields, wind erosion, and soil quality degradation - areas of the country that would likely benefit the most from conservation practices. To accomplish this, the National Nutrient Loss and Soil Carbon (NNLSC) database was constructed using the 1997 NRI to represent cropland land use patterns and resource conditions. The modeling results reported in this study were obtained using a system of databases and models built by the U.S. Department of Agriculture (USDA) Natural Resources Conservation Service (NRCS) and the Blackland Research Center, Texas Agricultural Experiment Station (TAES) during 2000 to 2004. The spatial distribution of the model outputs is shown in maps to identify areas of the country with the greatest potential for loss of soil and nutrients from farm fields and for changes in soil organic carbon as an indicator of the potential for deteriorating soil quality. This report is the first in a series of reports on the Cropland National Assessment component of the Conservation Effects Assessment Project (CEAP). CEAP is a multi-agency effort initiated in 2003 by five USDA agencies (NRCS, ARS, NIFA (previously CSREES), FSA, and NASS) to estimate the environmental effects of conservation practices (Mausbach and Dedrick 2004 (PDF; 0.4 MB)). The purpose of the project is to quantify the benefits and effects of conservation practices. The project has three principal components: the watershed assessment studies component, designed primarily to measure the effects of conservation practices at the watershed scale, the national assessments, designed to provide estimates of the benefits of conservation practices for reporting at the national and regional levels, and literature syntheses and bibliographies. Subsequent CEAP reports on cropland will expand and extend the results presented in this first report and conduct analyses for each major water resource region in the continental U.S. Significant refinements are currently underway in the models and modeling systems used to estimate effects. Results in these forthcoming CEAP reports are expected to differ somewhat from results reported in the present study, benefiting from improved model routines, better information on farming activities, and a fuller accounting of conservation practices.},
author = {(USDA), NRCS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(2).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(3).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(4).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(5).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(6).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(7).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/(USDA) - Unknown - Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon(8).pdf:pdf},
title = {{Model Simulation of Soil Loss, Nutrient Loss and Soil Organic Carbon}},
url = {http://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/technical/?cid=nrcs143{\_}014128}
}
@article{Lall2011,
author = {Lall, Sanjay},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lall - 2011 - Sums of Squares.pdf:pdf},
title = {{Sums of Squares}},
year = {2011}
}
@inproceedings{Petrik2015,
author = {Petrik, Marek and Wu, Xiaojian},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Wu - 2015 - Optimal Threshold Control for Energy Arbitrage with Degradable Battery Storage.pdf:pdf},
isbn = {9780000000002},
pages = {692--701},
title = {{Optimal Threshold Control for Energy Arbitrage with Degradable Battery Storage}},
year = {2015}
}
@book{Bertsekas1996a,
author = {Bertsekas, DP and Shreve, SE},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas, Shreve - 1978 - Stochastic optimal control The discrete time case.pdf:pdf},
title = {{Stochastic optimal control: The discrete time case}},
url = {http://saba.kntu.ac.ir/eecd/taghirad/E books/TOC/Stochastic Control.pdf},
year = {1978}
}
@article{Rusmevichientong2010b,
abstract = {We consider an assortment optimization problem where a retailer chooses$\backslash$nan assortment of products that maximizes the profit subject to a$\backslash$ncapacity constraint. The demand is represented by a multinomial logit$\backslash$nchoice model. We consider both the static and dynamic optimization$\backslash$nproblems. In the static problem, we assume that the parameters of$\backslash$nthe logit model are known in advance; we then develop a simple algorithm$\backslash$nfor computing a profit-maximizing assortment based on the geometry$\backslash$nof lines in the plane and derive structural properties of the optimal$\backslash$nassortment. For the dynamic problem, the parameters of the logit$\backslash$nmodel are unknown and must be estimated from data. By exploiting$\backslash$nthe structural properties found for the static problem, we develop$\backslash$nan adaptive policy that learns the unknown parameters from past data$\backslash$nand at the same time optimizes the profit. Numerical experiments$\backslash$nbased on sales data from an online retailer indicate that our policy$\backslash$nperforms well.},
annote = {From Duplicate 3 (Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint - Rusmevichientong, P.; Shen, Z.-J. M.; Shmoys, D. B.)

It is interesting that the regret is logarithmic.

The main theorem is Thm 3.4},
author = {Rusmevichientong, P. and Shen, Z.-J. M. and Shmoys, D. B.},
doi = {10.1287/opre.1100.0866},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusmevichientong, Shen, Shmoys - 2010 - Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusmevichientong, Shen, Shmoys - 2010 - Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint(2).pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {dec},
number = {6},
pages = {1666--1680},
title = {{Dynamic Assortment Optimization with a Multinomial Logit Choice Model and Capacity Constraint}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1100.0866},
volume = {58},
year = {2010}
}
@article{Zadorojniy2005,
author = {Zadorojniy, Alexander and Shwartz, Adam},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zadorojniy, Shwartz - 2005 - Robustness of policies in constrained Markov decision processes.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
title = {{Robustness of policies in constrained Markov decision processes}},
year = {2005}
}
@article{Eldar2008,
author = {Eldar, Yonina C. and Beck, Amir and Teboulle, Marc},
doi = {10.1109/TSP.2007.908945},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eldar, Beck, Teboulle - 2008 - A Minimax Chebyshev Estimator for Bounded Error Estimation.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = {apr},
number = {4},
pages = {1388--1397},
title = {{A Minimax Chebyshev Estimator for Bounded Error Estimation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4471880},
volume = {56},
year = {2008}
}
@article{Bagnell2001a,
author = {Bagnell, JA and Schneider, JG},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bagnell, Schneider - 2001 - Autonomous helicopter control using reinforcement learning policy search methods.pdf:pdf},
journal = {Robotics and Automation, 2001. {\ldots}},
title = {{Autonomous helicopter control using reinforcement learning policy search methods}},
url = {citeseer.ist.psu.edu/bagnell01autonomous.html http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=932842},
volume = {0},
year = {2001}
}
@article{Rockafellar1976,
author = {Rockafellar, RT},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar - 1976 - Augmented Lagrangians and applications of the proximal point algorithm in convex programming.pdf:pdf},
journal = {Mathematics of operations research},
number = {2},
title = {{Augmented Lagrangians and applications of the proximal point algorithm in convex programming}},
url = {http://mor.journal.informs.org/content/1/2/97.short},
volume = {1},
year = {1976}
}
@book{Pearson2002,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Pearson, Neil D.},
booktitle = {Journal of Chemical Information and Modeling},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearson - 2002 - Risk Budgeting Protfolio problem solving with Value at Risk.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
number = {9},
pmid = {25246403},
title = {{Risk Budgeting: Protfolio problem solving with Value at Risk}},
volume = {53},
year = {2002}
}
@article{Castellazzi2008,
author = {Castellazzi, M.S. and Wood, G.a. and Burgess, P.J. and Morris, J. and Conrad, K.F. and Perry, J.N.},
doi = {10.1016/j.agsy.2007.10.006},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castellazzi et al. - 2008 - A systematic representation of crop rotations.pdf:pdf},
issn = {0308521X},
journal = {Agricultural Systems},
keywords = {crop rotation,crop temporal arrangement,landscape simulation,long-term crop proportions,stochastic modelling,transition matrix},
month = {apr},
number = {1-2},
pages = {26--33},
title = {{A systematic representation of crop rotations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0308521X07001096},
volume = {97},
year = {2008}
}
@article{Mendelssohn1980,
author = {Mendelssohn, Roy},
journal = {Operations Research},
pages = {1450--1453},
title = {{Improved bounds for aggregated linear programs}},
volume = {28},
year = {1980}
}
@inproceedings{Prashanth2013,
author = {Prashanth, L.A. and Ghavamzadeh, Mohammad},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prashanth, Ghavamzadeh - 2013 - Actor-critic algorithms for risk-sensitive MDPs.pdf:pdf},
pages = {252--260},
title = {{Actor-critic algorithms for risk-sensitive MDPs}},
year = {2013}
}
@article{Monahan1982,
author = {Monahan, George E},
journal = {Management science},
pages = {1--16},
title = {{A survey of partially observable Markov decision processes: theory, models, and algorithms}},
volume = {28},
year = {1982}
}
@article{Tramer2016,
archivePrefix = {arXiv},
arxivId = {1609.02943},
author = {Tram{\`{e}}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael and Ristenpart, Thomas},
eprint = {1609.02943},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tram{\`{e}}r et al. - 2016 - Stealing Machine Learning Models via Prediction APIs.pdf:pdf},
isbn = {9781931971324},
journal = {Usenix Security},
number = {Ml},
title = {{Stealing Machine Learning Models via Prediction APIs}},
year = {2016}
}
@phdthesis{Pengqian2016,
author = {Pengqian, Yu},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pengqian - 2016 - Risk-averse And Ambiguity-Averse Markov Decision Processes.pdf:pdf},
title = {{Risk-averse And Ambiguity-Averse Markov Decision Processes}},
year = {2016}
}
@article{Kbs2017,
abstract = {Controlling invasive species is a highly complex problem. The intricacy of the problem stems from the nonlinearity that is inherent in biological systems, consequently impeding researchers to obtain timely and cost-efficient treatment strategies over a planning horizon. To cope with the complexity of the invasive species problem, we develop a mixed-integer programming (MIP) model that handles the problem as a full dynamic optimization model and solves it to optimality for the first time. We demonstrate the applicability of the model on a case study of sericea (Lespedeza cuneata) infestation by optimizing a spatially explicit model on a heterogeneous 10-by-10 grid landscape for a seven-year time period. We evaluate the solution quality of five different linearization methods that are used to obtain the MIP model. We also compare the model with its mixed-integer nonlinear programming (MINLP) equivalent and nonlinear programming (NLP) relaxation in terms of solution quality. The computational superiority and realism of the proposed MIP model demonstrate that our model has the potential to constitute the basis for future decision-support tools in invasive species management.},
author = {Kıbış, Eyy{\"{u}}b Y. and B{\"{u}}y{\"{u}}ktahtakın, Esra},
doi = {10.1016/j.ejor.2016.09.049},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kıbış, B{\"{u}}y{\"{u}}ktahtakın - 2017 - Optimizing invasive species management A mixed-integer linear programming approach.pdf:pdf},
isbn = {3169783742},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {(S) Complexity theory,Big-M,Linearization,Mixed-integer programming (MIP),Spatially explicit large-scale optimization},
number = {1},
pages = {308--321},
title = {{Optimizing invasive species management: A mixed-integer linear programming approach}},
volume = {259},
year = {2017}
}
@inproceedings{Yan1993,
author = {Yan, H and Luh, PB},
booktitle = {Power Systems, IEEE {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Luh - 1993 - Scheduling of hydrothermal power systems.pdf:pdf},
title = {{Scheduling of hydrothermal power systems}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=260857},
year = {1993}
}
@inproceedings{Chapman1991,
author = {Chapman, David and Kaelbling, Leslie Pack},
booktitle = {International Conference on Artificial Intelligence},
pages = {726--731},
title = {{Input generalization in delayed reinforcement learning: An algorithm and performance comparisons}},
year = {1991}
}
@article{Aurbach2000,
author = {Aurbach, Doron},
doi = {10.1016/S0378-7753(00)00431-6},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aurbach - 2000 - Review of selected electrode–solution interactions which determine the performance of Li and Li ion batteries.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {electrode,lithium,lithium ion batteries,solution interactions},
month = {aug},
number = {2},
pages = {206--218},
title = {{Review of selected electrode–solution interactions which determine the performance of Li and Li ion batteries}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378775300004316},
volume = {89},
year = {2000}
}
@article{Givan2000,
author = {Givan, Robert and Leach, Sonia and Dean, Thomas},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Givan, Leach, Dean - 2000 - Bounded-parameter Markov decision processes.pdf:pdf},
journal = {Artificial Intelligence},
number = {1},
pages = {71--109},
title = {{Bounded-parameter Markov decision processes}},
volume = {122},
year = {2000}
}
@article{Qiu1999,
author = {Qiu, Qinru and Pedram, Massoud},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu, Pedram - Unknown - Dynamic Power Management Based on Continuous-Time Markov Decision Processes.pdf:pdf},
journal = {Design automation},
number = {98},
title = {{Dynamic power management based on continuous-time Markov decision processes}},
year = {1999}
}
@article{Matis1989,
author = {Matis, J.H. and Birkett, T. and Boudreaux, D.},
doi = {10.1016/0308-521X(89)90097-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matis, Birkett, Boudreaux - 1989 - An application of the Markov chain approach to forecasting cotton yields from surveys.pdf:pdf},
issn = {0308521X},
journal = {Agricultural Systems},
month = {jan},
number = {4},
pages = {357--370},
title = {{An application of the Markov chain approach to forecasting cotton yields from surveys}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0308521X89900978},
volume = {29},
year = {1989}
}
@article{Payero2006,
author = {Payero, Jos{\'{e}} O. and Melvin, Steven R. and Irmak, Suat and Tarkalson, David},
doi = {10.1016/j.agwat.2006.01.009},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Payero et al. - 2006 - Yield response of corn to deficit irrigation in a semiarid climate.pdf:pdf},
issn = {03783774},
journal = {Agricultural Water Management},
month = {jul},
number = {1-2},
pages = {101--112},
title = {{Yield response of corn to deficit irrigation in a semiarid climate}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378377406000278},
volume = {84},
year = {2006}
}
@misc{Bubeck,
author = {Bubeck, Sebastien},
title = {{Theory of Convex Optimization for Machine Learning}}
}
@article{Hoke2011,
annote = {Two important indictors of battery life/quality:
1) energy capacity 
2) maximum power transfer
They both decrease with use.


Factors driving degradation:
1) battery temperature
2) state of charge
3) depth of discharge


The cost in the paper is additive},
author = {Hoke, Anderson and Brissette, Alexander and Maksimovic, Dragan and Pratt, Annabelle and Smith, Kandler},
doi = {10.1109/VPPC.2011.6043046},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoke et al. - 2011 - Electric vehicle charge optimization including effects of lithium-ion battery degradation.pdf:pdf},
isbn = {978-1-61284-248-6},
journal = {2011 IEEE Vehicle Power and Propulsion Conference},
month = {sep},
pages = {1--8},
publisher = {Ieee},
title = {{Electric vehicle charge optimization including effects of lithium-ion battery degradation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6043046},
year = {2011}
}
@article{Ohnishi1992,
author = {Ohnishi, Masamitsu},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ohnishi - 1992 - Policy Iteration and Newton-Raphson Methods for Markov Decision Processes ander Average Cost Criterion.pdf:pdf},
journal = {Computers Math. Applic.},
number = {1},
pages = {147--155},
title = {{Policy Iteration and Newton-Raphson Methods for Markov Decision Processes ander Average Cost Criterion}},
volume = {24},
year = {1992}
}
@book{Horn1990,
author = {Horn, Roger A and Johnson, Charles R},
isbn = {0521305861},
title = {{Matrix Analysis}},
year = {1990}
}
@book{Schoemaker1980,
author = {Schoemaker, P.J.H.},
title = {{Experiments on Decisions under Risk: The Expected Utility Hypothesis}},
year = {1980}
}
@article{Singh1995a,
annote = {From Duplicate 1 ( Reinforcement learning with soft state aggregation - Singh, SP Satinder P; Jaakkola, Tommi; Jordan, Michael I )

From Duplicate 2 ( Reinforcement learning with soft state aggregation - Singh, SP; Jaakkola, T; Jordan, MI )





From Duplicate 2 ( Reinforcement learning with soft state aggregation - Singh, SP Satinder P; Jaakkola, Tommi; Jordan, Michael I )

From Duplicate 1 ( Reinforcement learning with soft state aggregation - Singh, SP Satinder P; Jaakkola, Tommi; Jordan, Michael I )

From Duplicate 2 ( Reinforcement learning with soft state aggregation - Singh, SP; Jaakkola, T; Jordan, MI )
},
author = {Singh, SP Satinder P and Jaakkola, Tommi and Jordan, Michael I},
editor = {Tesauro, G and Touretzky, D and Leen, T},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Jaakkola, Jordan - 1995 - Reinforcement Learning with Soft State Aggregation.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Jaakkola, Jordan - 1995 - Reinforcement learning with soft state aggregation.pdf:pdf},
journal = {Advances in neural information {\ldots}},
pages = {361--368},
publisher = {The {\{}MIT{\}} Press},
title = {{Reinforcement learning with soft state aggregation}},
url = {citeseer.ist.psu.edu/article/singh95reinforcement.html http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.6244{\&}rep=rep1{\&}type=pdf},
volume = {7},
year = {1995}
}
@article{Tsitsiklis1996,
annote = {Assuming that steady-state probabilities refer to the limiting distribution},
author = {Tsitsiklis, John N and {Van Roy}, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis, Roy - Unknown - An Analysis of Temporal-Di erence Learning with Function Approximation 1.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis, Van Roy - 1997 - An analysis of temporal-difference learning with function approximation.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {5},
pages = {674--690},
title = {{An analysis of temporal-difference learning with function approximation}},
url = {citeseer.ist.psu.edu/article/tsitsiklis96analysis.html},
volume = {42},
year = {1997}
}
@misc{Boyd,
author = {Boyd, Stephen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd - Unknown - Subgradients.pdf:pdf},
title = {{Subgradients}}
}
@inproceedings{Bhat2004,
author = {Bhat, N A R and Leyton-Brown, K},
booktitle = {International Conference on Uncretainty in Artificial Intelligence},
title = {{Computing {\{}N{\}}ash equilibria of action-graph games}},
year = {2004}
}
@misc{McCallum1995,
author = {McCallum, Andrew},
title = {{Reinforcement Learning with Selective Perception and Hidden State}},
year = {1995}
}
@inproceedings{Korf1988,
annote = {From Duplicate 1 ( Real-Time Heuristic Search : New Results * Minimin with Alpha Pruni - Korf, Richard E )
},
author = {Korf, Richard E},
booktitle = {National Conference on AI (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Korf - 1988 - Real-Time Heuristic Search New Results Minimin with Alpha Pruni.pdf:pdf},
title = {{Real-Time Heuristic Search}},
year = {1988}
}
@article{Todorov2006,
abstract = {Advances in Neural Information Processing Systems 2006 We introduce a class of MPDs which greatly simplify Reinforcement Learning. They have discrete state spaces and continuous control spaces. The controls have the effect of rescaling the transition probabilities of an underlying Markov chain. A control cost penalizing KL divergence between controlled and uncontrolled transition probabilities makes the minimization problem convex, and allows an-alytical computation of the optimal controls given the optimal value function. An exponential transformation of the optimal value function makes the minimized Bellman equation linear. Apart from their theoretical signiicance, the new MDPs enable ef approximations to traditional MDPs. Shortest path problems are approximated to arbitrary precision with largest eigenvalue problems, yielding an O (n) algorithm. Accurate approximations to generic MDPs are obtained via continuous embedding reminiscent of LP relaxation in integer programming. Off-policy learning of the optimal value function is possible without need for state-action values; the new algorithm (Z-learning) outperforms Q-learning.},
author = {Todorov, Emanuel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todorov - 2006 - Linearly-solvable Markov decision problems.pdf:pdf},
isbn = {9780262195683},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {1},
pages = {8},
title = {{Linearly-solvable Markov decision problems}},
year = {2006}
}
@article{Vazifedoust2008,
annote = {Uses SWAP model to optimize irrigation},
author = {Vazifedoust, M and Dam, JC Van},
journal = {Agricultural water Management},
pages = {89--102},
title = {{Increasing water productivity of irrigated crops under limited water supply at field scale}},
url = {http://www.sciencedirect.com/science/article/pii/S0378377407002211},
volume = {95},
year = {2008}
}
@article{Mundhenk2000,
address = {New York, NY, USA},
annote = {From Duplicate 2 ( Complexity of finite-horizon Markov decision process problems - Mundhenk, Martin; Goldsmith, Judy; Lusena, Christopher; Allender, Eric )
},
author = {Mundhenk, Martin and Goldsmith, Judy and Lusena, Christopher and Allender, Eric},
doi = {http://doi.acm.org/10.1145/347476.347480},
issn = {0004-5411},
journal = {J. {\{}ACM{\}}},
number = {4},
pages = {681--720},
publisher = {ACM Press},
title = {{Complexity of finite-horizon {\{}M{\}}arkov decision process problems}},
volume = {47},
year = {2000}
}
@article{Ben-Tal2008,
annote = {From Duplicate 1 ( Selected topics in robust optimization - Ben-Tal, Aharon; Nemirovski, Arkadi )

From Duplicate 1 ( Selected topics in robust convex optimization - Ben-Tal, Aharon; Nemirovski, Arkadi )
},
author = {Ben-Tal, Aharon and Nemirovski, Arkadi},
doi = {10.1007/s10107-006-0092-2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Tal, Nemirovski - 2007 - Selected topics in robust convex optimization.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming, Series B},
keywords = {2000,chance constraints,convex,mathematics subject classification,optimization under uncertainty,programming,robust linear control,robust optimization},
number = {1},
pages = {125--158},
title = {{Selected topics in robust optimization}},
url = {http://link.springer.com/10.1007/s10107-006-0092-2},
volume = {112},
year = {2008}
}
@phdthesis{Bethke2010,
author = {Bethke, BM},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethke - 2010 - Kernel-based approximate dynamic programming using Bellman residual elimination.pdf:pdf},
title = {{Kernel-based approximate dynamic programming using Bellman residual elimination}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=ADA528927},
year = {2010}
}
@article{Zhang2009,
author = {Zhang, D. and Adelman, D.},
doi = {10.1287/trsc.1090.0262},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Adelman - 2009 - An Approximate Dynamic Programming Approach to Network Revenue Management with Customer Choice.pdf:pdf},
issn = {0041-1655},
journal = {Transportation Science},
keywords = {2008,2009,accepted,august 2006,been done on meth-,choice behavior,december 21,dynamic programming,history,in advance june 29,network revenue management,october 2007 and june,published online in articles,received,revisions received,while substantial research has},
month = {jun},
number = {3},
pages = {381--394},
title = {{An Approximate Dynamic Programming Approach to Network Revenue Management with Customer Choice}},
url = {http://transci.journal.informs.org/cgi/doi/10.1287/trsc.1090.0262},
volume = {43},
year = {2009}
}
@article{Johns2009,
author = {Johns, Jeff and Petrik, Marek and Mahadevan, Sridhar},
doi = {10.1007/s10994-009-5128-4},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johns, Petrik, Mahadevan - 2009 - Hybrid least-squares algorithms for approximate policy evaluation.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {markov decision processes,reinforcement learning},
month = {jul},
number = {2},
pages = {243--256},
title = {{Hybrid least-squares algorithms for approximate policy evaluation}},
url = {http://link.springer.com/10.1007/s10994-009-5128-4},
volume = {76},
year = {2009}
}
@misc{Murphy2000,
author = {Murphy, K},
institution = {U.C. Berkeley},
title = {{A survey of POMDP solution techniques}},
year = {2000}
}
@article{Prince2004,
abstract = {This study examines the evidence for the effectiveness of active learning. It defines the common forms of active learning most relevant for engineering faculty and critically examines the core element of each method. It is found that there is broad but uneven support for the core elements of active, collaborative, cooperative and problem-based learning.},
author = {Prince, M},
doi = {10.1002/j.2168-9830.2004.tb00809.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prince - 2004 - Does active learning work A review of the research.pdf:pdf},
isbn = {10694730},
issn = {1069-4730},
journal = {Journal of Engineering Education},
number = {3},
pages = {223--232},
pmid = {48056773},
title = {{Does active learning work? A review of the research}},
volume = {93},
year = {2004}
}
@article{Farias2006a,
author = {Farias, Vivek F and {Van Roy}, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farias, Van Roy - 2006 - Tetris A study of randomized constraint sampling.pdf:pdf},
journal = {Probabilistic and Randomized Methods for Design {\ldots}},
title = {{Tetris: A study of randomized constraint sampling}},
url = {http://link.springer.com/chapter/10.1007/1-84628-095-8{\_}6},
year = {2006}
}
@article{Brown2010,
annote = {The penalty compares the value function that could be obtained in one state according to the original filtration versus the values obtained from the relaxed formulation.},
author = {Brown, D. B. and Smith, J. E. and Sun, P.},
doi = {10.1287/opre.1090.0796},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown, Smith, Sun - 2010 - Information Relaxations and Duality in Stochastic Dynamic Programs.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {apr},
number = {4-Part-1},
pages = {785--801},
title = {{Information Relaxations and Duality in Stochastic Dynamic Programs}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1090.0796},
volume = {58},
year = {2010}
}
@article{Hansen2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1008.0530v1},
author = {Hansen, TD and Miltersen, PB and Zwick, Uri},
eprint = {arXiv:1008.0530v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Miltersen, Zwick - 2013 - Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant dis.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Miltersen, Zwick - 2013 - Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant (2).pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Miltersen, Zwick - 2013 - Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant (3).pdf:pdf},
journal = {Journal of the ACM (JACM)},
number = {1},
pages = {1--16},
title = {{Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant discount factor}},
url = {http://dl.acm.org/citation.cfm?id=2432623 http://arxiv.org/abs/1008.0530},
volume = {60},
year = {2013}
}
@article{Tsitsiklis1996a,
annote = {Contains proofs of the best error bounds for aggregation in MDPs. 

The most interesting theorem is Theorem 3! It probably generalizes to any aggregations with equal weights (unsure about unequal weights)

There are some additional assumptions required, such as Assumption 4 and 5.

Reltionship with oblique projections of Bruno Scherrer?},
author = {Tsitsiklis, JN and {Van Roy}, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis, Van Roy - 1996 - Feature-based methods for large scale dynamic programming.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsitsiklis, Van Roy - 1996 - Feature-based methods for large scale dynamic programming(2).pdf:pdf},
journal = {Machine Learning},
title = {{Feature-based methods for large scale dynamic programming}},
url = {http://link.springer.com/article/10.1023/A:1018008221616},
year = {1996}
}
@book{Seeger2004,
abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
author = {Seeger, Matthias},
booktitle = {International journal of neural systems},
doi = {10.1142/S0129065704001899},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seeger - 2004 - Gaussian processes for machine learning.pdf:pdf},
isbn = {026218253X},
issn = {0129-0657},
keywords = {Algorithms,Artificial Intelligence,Bayes Theorem,Entropy,Linear Models,Models, Statistical,Normal Distribution,Regression Analysis,Statistics, Nonparametric},
month = {apr},
number = {2},
pages = {69--106},
pmid = {15112367},
title = {{Gaussian processes for machine learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15112367},
volume = {14},
year = {2004}
}
@article{Moore2014,
annote = {A nice model for writing applied reinforcement learning papers},
author = {Moore, BL and Pyeatt, LD and Kulkarni, V},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moore, Pyeatt, Kulkarni - 2014 - Reinforcement learning for closed-loop propofol anesthesia a study in human volunteers.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {655--696},
title = {{Reinforcement learning for closed-loop propofol anesthesia: a study in human volunteers}},
url = {http://dl.acm.org/citation.cfm?id=2627456},
volume = {15},
year = {2014}
}
@article{Zhang1997,
author = {Zhang, Nevin Lianwen and Lin, Wenju},
journal = {Journal of Artificial Intelligence Research},
pages = {199--230},
title = {{A Model Approximation Scheme for Planning in Partially Observable Stochastic Domains}},
url = {citeseer.ist.psu.edu/zhang97model.html},
volume = {7},
year = {1997}
}
@techreport{USGS2013,
author = {USGS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/USGS - 2013 - Groundwater Depletion in the United States ( 1900 – 2008 ) Scientific Investigations Report 2013 – 5079.pdf:pdf},
institution = {USGS},
title = {{Groundwater Depletion in the United States ( 1900 – 2008 ) Scientific Investigations Report 2013 – 5079}},
year = {2013}
}
@book{Murphy2012,
abstract = {Some of the most remarkable issues related to interharmonics observed from a probabilistic perspective are presented. Attention is firstly devoted to interharmonic frequency and amplitude variability. Starting from the basic mathematical and computational aspects of probabilistic harmonic models, the difficulties to include interharmonics are discussed with particular attention to the problem of the frequency resolution and of the computational burden. Then, simulation and measurement aspects are discussed, also showing some numerical and experimental results.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Murphy, Kevin},
booktitle = {Machine Learning: A Probabilistic Perspective},
doi = {10.1007/SpringerReference_35834},
eprint = {0-387-31073-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murphy - 2012 - Machine Learning A Probabilistic Perspective.pdf:pdf},
isbn = {9780262018029},
issn = {0262018020},
pmid = {20236947},
title = {{Machine Learning: A Probabilistic Perspective}},
url = {http://link.springer.com/chapter/10.1007/978-94-011-3532-0{\_}2},
year = {2012}
}
@article{Barto1994,
abstract = {Learning methods based on dynamic programming (DP) are receiving increasing attention in artificial intelligence. Researchers have argued that DP provides the appropriate basis for compiling planning results into reactive strategies for real-time control, as well as for learning such strategies when the system being controlled is incompletely known. We introduce an algorithm based on DP, which we call Real-Time DP (RTDP), by which an embedded system can improve its performance with experience. RTDP generalizes Korf's Learning-Real-Time-A* algorithm to problems involving uncertainty. We invoke results from the theory of asynchronous DP to prove that RTDP achieves optimal behavior in several different classes of problems. We also use the theory of asynchronous DP to illuminate aspects of other DP-based reinforcement learning methods such as Watkins' Q-Learning algorithm. A secondary aim of this article is to provide a bridge between AI research on real-time planning and learning and relevant concepts and algorithms from control theory.},
author = {Barto, Andrew G and Bradtke, Steven J and Singh, Satinder P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barto, Bradtke, Singh - 1995 - Learning to act using real-time dynamic programming.pdf:pdf},
journal = {Artificial Intelligence},
number = {1-2},
pages = {81--138},
title = {{Learning to act using real-time dynamic programming}},
url = {http://www.sciencedirect.com/science/article/pii/000437029400011O},
volume = {72},
year = {1995}
}
@article{Taft2013,
abstract = {This paper introduces a new benchmark, designed to test database management system (DBMS) performance on a mix of data man- agement tasks (joins, filters, etc.) and complex analytics (regres- sion, singular value decomposition, etc.) Such mixed workloads are prevalent in a number of application areas, including most sci- ence workloads and web analytics. As a specific use case, we have chosen genomics data for our benchmark, and have constructed a collection of typical tasks in this area. In addition to being repre- sentative of a mixed data management and analytics workload, this benchmark is also meant to scale to large dataset sizes and mul- tiple nodes across a cluster. Besides presenting this benchmark, we have run it on a variety of storage systems including traditional row stores, newer column stores, Hadoop, and an array DBMS. We present performance numbers on all systems on single and multiple nodes, and show that performance differs by orders of magnitude between the various solutions. In addition, we demonstrate that most platforms have scalability issues. We also test offloading the analytics onto a coprocessor. The intent of this benchmark is to focus research interest in this area; to this end, all of our data, data generators, and scripts are available on our web site.},
author = {Taft, Ebecca and Vartak, Manasi and Satish, Nadathur Rajagopalan and Sundaram, Narayanan and Madden, Samuel and Stonebraker, M},
doi = {10.1145/2588555.2595633},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taft et al. - 2013 - GenBase A Complex Analytics Genomics Benchmark.pdf:pdf},
isbn = {9781450323765},
issn = {07308078},
journal = {SIGMOD '14 Proceedings of the 2014 ACM SIGMOD international conference on Management of data},
pages = {177--188},
title = {{GenBase: A Complex Analytics Genomics Benchmark}},
url = {http://dspace.mit.edu/bitstream/handle/1721.1/82517/MIT-CSAIL-TR-2013-028.pdf?sequence=2},
year = {2013}
}
@inproceedings{Mettler1999,
annote = {From Duplicate 2 ( System Identification of Small-Size Unmanned Helicopter Dynamics - Mettler, Bernard; Tischler, Mark B; Kanade, Takeo )
},
author = {Mettler, Bernard and Tischler, Mark B and Kanade, Takeo},
booktitle = {American Helicopter Society 55th Forum},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mettler, Tischler, Kanade - 1999 - System Identification of Small-Size Unmanned Helicopter Dynamics.pdf:pdf},
title = {{System Identification of Small-Size Unmanned Helicopter Dynamics}},
year = {1999}
}
@article{Felner2007,
author = {Felner, Ariel and Korf, Richard E and Meshulam, Ram and Holte, Robert},
journal = {Journal of Artificial Intelligence Research},
pages = {213--247},
title = {{Compressed Pattern Databases}},
volume = {30},
year = {2007}
}
@article{Merow2011,
abstract = {Species distribution models are a fundamental tool in ecology, conservation biology, and biogeography and typically identify potential species distributions using static phenomenological models. We demonstrate the importance of complementing these popular models with spatially explicit, dynamic mechanistic models that link potential and realized distributions. We develop general grid-based, pattern-oriented spread models incorporating three mechanisms--plant population growth, local dispersal, and long-distance dispersal--to predict broadscale spread patterns in heterogeneous landscapes. We use the model to examine the spread of the invasive Celastrus orbiculatus (Oriental bittersweet) by Sturnus vulgaris (European starling) across northeastern North America. We find excellent quantitative agreement with historical spread records over the last century that are critically linked to the geometry of heterogeneous landscapes and each of the explanatory mechanisms considered. Spread of bittersweet before 1960 was primarily driven by high growth rates in developed and agricultural landscapes, while subsequent spread was mediated by expansion into deciduous and coniferous forests. Large, continuous patches of coniferous forests may substantially impede invasion. The success of C. orbiculatus and its potential mutualism with S. vulgaris suggest troubling predictions for the spread of other invasive, fleshy-fruited plant species across northeastern North America.},
author = {Merow, Cory and Lafleur, Nancy and {Silander Jr.}, John A. and Wilson, Adam M. and Rubega, Margaret and Silander, John a and Wilson, Adam M. and Rubega, Margaret},
doi = {10.1086/660295},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merow et al. - 2011 - Developing dynamic mechanistic species distribution models predicting bird-mediated spread of invasive plants acro.pdf:pdf},
isbn = {1537-5323 (Electronic)$\backslash$n0003-0147 (Linking)},
issn = {1537-5323},
journal = {The American naturalist},
keywords = {Animals,Biological,Celastrus,Celastrus: physiology,Ecosystem,Introduced Species,Models,New England,Population Dynamics,Population Growth,Songbirds,Songbirds: physiology,Symbiosis},
month = {jul},
number = {1},
pages = {30--43},
pmid = {21670575},
title = {{Developing dynamic mechanistic species distribution models: predicting bird-mediated spread of invasive plants across northeastern North America.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21670575 http://www.journals.uchicago.edu/doi/10.1086/660295},
volume = {178},
year = {2011}
}
@techreport{Tian2004,
author = {Tian, Guoqiang},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tian - 2004 - Lecture Notes Microeconomic Theory Department of Economics.pdf:pdf},
title = {{Lecture Notes Microeconomic Theory Department of Economics}},
volume = {77843},
year = {2004}
}
@article{Xu2009a,
author = {Xu, Huan and Caramanis, Constantine and Mannor, Shie},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu - Unknown - Robustness and Regularization of Support Vector Machines.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {generalization,kernel,regularization,robustness,support vector machine},
pages = {1485--1510},
title = {{Robustness and Regularization of Support Vector Machines}},
volume = {10},
year = {2009}
}
@article{Bubeck2012,
abstract = {Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the Thirties, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this survey, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.},
archivePrefix = {arXiv},
arxivId = {1204.5721},
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
doi = {10.1561/2200000024},
eprint = {1204.5721},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems(2).pdf:pdf},
isbn = {9781601986269},
issn = {9781601986269},
journal = {Foundations and Trends in Machine Learning},
month = {apr},
number = {1},
pages = {1--122},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
url = {http://arxiv.org/abs/1204.5721 http://arxiv.org/abs/1204.5721v2{\%}5Cnpapers3://publication/uuid/FD8C90A4-1651-4BB5-9123-D84384F10271},
volume = {5},
year = {2012}
}
@article{Diuk2008,
abstract = {Rich representations in reinforcement learning have been studied for the purpose of enabling generalization and making learning feasible in large state spaces. We introduce Object-Oriented MDPs (OO-MDPs), a representation based on objects and their interactions, which is a natural way of modeling environments and offers important generalization opportunities. We introduce a learning algorithm for deterministic OO-MDPs and prove a polynomial bound on its sample complexity. We illustrate the performance gains of our representation and algorithm in the wellknown Taxi domain, plus a real-life videogame.},
author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
doi = {10.1145/1390156.1390187},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diuk, Cohen, Littman - 2008 - An object-oriented representation for efficient reinforcement learning(2).pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {240--247},
pmid = {847163450},
title = {{An object-oriented representation for efficient reinforcement learning}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390187},
year = {2008}
}
@phdthesis{Cheng1988,
author = {Cheng, H T},
school = {University of British Columbia},
title = {{Algorithms for Partially Observable Markov Decision Processes}},
year = {1988}
}
@article{Bronson2002,
author = {Bronson, K and Nesmith, D M and Xu, W},
journal = {Crop Science},
number = {June 2001},
pages = {1564--1576},
title = {{Spatial and Temporal Variability of Corn Growth and Grain Yield : Implications for Site-Specific Farming}},
volume = {1576},
year = {2002}
}
@article{Bastiaanssen2000,
author = {Bastiaanssen, WGM and Molden, DJ and Makin, IW},
doi = {10.1016/S0378-3774(00)00080-9},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bastiaanssen, Molden, Makin - 2000 - Remote sensing for irrigated agriculture examples from research and possible applications.pdf:pdf},
issn = {03783774},
journal = {Agricultural water management},
keywords = {ciency,crop yield,irrigated farming,land management,remote sensing,water resources management,water rights,water use ef},
month = {dec},
number = {2},
pages = {137--155},
title = {{Remote sensing for irrigated agriculture: examples from research and possible applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378377400000809 http://www.sciencedirect.com/science/article/pii/S0378377400000809},
volume = {46},
year = {2000}
}
@inproceedings{Poupart2001,
author = {Poupart, Pascal and Boutilier, Craig},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
title = {{Value-Directed Belief State Approximation for POMDPs}},
year = {2001}
}
@article{Wilcove1998,
abstract = {Habitat loss is the single greatest threat to biodiversity, followed by the spread of alien species},
author = {Wilcove, David S. and Rothstein, David and Dubow, Jason and Phillips, Ali and Losos, Elizabeth},
doi = {10.2307/1313420},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcove et al. - 1998 - Quantifying threats to imperiled species in the United States.pdf:pdf},
isbn = {0006-3568},
issn = {00063568},
journal = {BioScience},
number = {8},
pages = {607--615},
pmid = {3029},
title = {{Quantifying threats to imperiled species in the United States}},
volume = {48},
year = {1998}
}
@article{Ahmed2004,
author = {Ahmed, Shabbir and Guan, Yongpei},
doi = {10.1007/s10107-004-0515-x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed, Guan - 2004 - The inverse optimal value problem.pdf:pdf},
isbn = {1010700405},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {bilinear programming,complexity,inverse optimization,linear programming},
month = {may},
number = {1},
pages = {91--110},
title = {{The inverse optimal value problem}},
url = {http://link.springer.com/10.1007/s10107-004-0515-x},
volume = {102},
year = {2004}
}
@inproceedings{Ling2004,
abstract = {We propose a simple, novel and yet effective method for building and testing decision trees that minimizes the sum of the misclassification and test costs. More specifically, we first put forward an original and simple splitting criterion for attribute selection in tree building. Our tree- building algorithm has many desirable properties for a cost-sensitive learning system that must account for both types of costs. Then, assuming that the test cases may have a large number of missing values, we design several intelligent test strategies that can suggest ways of obtaining the missing values at a cost in order to minimize the total cost. We experimentally compare these strategies and C4.5, and demonstrate that our new algorithms significantly outperform C4.5 and its variations. In addition, our algorithm's complexity is similar to that of C4.5, and is much lower than that of previous work. Our work is useful for many diagnostic tasks which must factor in the misclassification and test costs for obtaining missing information.},
author = {Ling, Charles X. and Yang, Qiang and Wang, Jianning and Zhang, Shichao},
booktitle = {International Conference on Machine Learning (ICML)},
doi = {10.1145/1015330.1015369},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ling et al. - 2004 - Decision trees with minimal costs.pdf:pdf},
isbn = {1581138285},
title = {{Decision trees with minimal costs}},
url = {http://dl.acm.org/citation.cfm?id=1015369{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1015330.1015369},
year = {2004}
}
@article{Becker2011,
author = {Becker, SR and Cand{\`{e}}s, EJ and Grant, MC},
journal = {Mathematical Programming {\ldots}},
keywords = {algorithms,conic duality,nesterov,nuclear-,optimal first-order methods,proximal,s accelerated descent algorithms,smoothing by conjugation,the dantzig selector,the lasso},
pages = {1--49},
title = {{Templates for convex cone problems with applications to sparse signal recovery}},
url = {http://link.springer.com/article/10.1007/s12532-011-0029-5},
year = {2011}
}
@article{Kupper2006,
annote = {The paper showing that if you want time-consistence and law-invariance (coherence), you can only use an entropic measure of risk.

See Distribution-Invariant Dynamic Risk Measures by Weber for some weaker time-consistency conditions.},
author = {Kupper, Michael and Schachermayer, Walter},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kupper, Schachermayer - 2006 - Representation results for law invariant time consistent functions.pdf:pdf},
journal = {Mathematics and Financial Economics},
keywords = {certainty equivalent,dynamic risk mea-,law invariance,skorohod embedding theorem,sures,time consistency},
number = {2},
pages = {419--441},
title = {{Representation results for law invariant time consistent functions}},
url = {http://link.springer.com/article/10.1007/s11579-009-0019-9},
volume = {16},
year = {2006}
}
@inproceedings{McMahan2005,
author = {McMahan, H Brendan and Likhachev, M and Gordon, G J},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Bounded real-time dynamic programming: {\{}RTDP{\}} with monotone upper bounds and performance guarantees}},
year = {2005}
}
@techreport{Guigues2011a,
author = {Guigues, Vincent and Romisch, Werner},
institution = {Optimization Online},
title = {{Sampling-based decomposition methods for risk-averse multistage stochastic programs}},
year = {2011}
}
@article{Velusamy2008,
author = {Velusamy, Sudha and Gopal, Lakshmi and Bhatnagar, Shalabh and Varadarajan, Sridhar},
doi = {10.1007/s00530-008-0117-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Velusamy et al. - 2008 - An efficient ad recommendation system for TV programs.pdf:pdf},
issn = {0942-4962},
journal = {Multimedia Systems},
number = {2},
pages = {73--87},
title = {{An efficient ad recommendation system for TV programs}},
url = {http://link.springer.com/10.1007/s00530-008-0117-1},
volume = {14},
year = {2008}
}
@article{Becker2013,
author = {Becker, Stephen},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker - 2013 - Proximity functions Proximal calculus.pdf:pdf},
pages = {1--8},
title = {{Proximity functions Proximal calculus}},
year = {2013}
}
@book{Burges1997,
author = {Burges, Christopher J C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burges - 1997 - A Tutorial on Support Vector Machines for Pattern Recognition.pdf:pdf},
keywords = {121-167,1998,appeared in,data mining and knowledge,discovery 2,pattern recognition,statistical learning theory,support vector machines,vc dimension},
pages = {1--43},
title = {{A Tutorial on Support Vector Machines for Pattern Recognition}},
volume = {43},
year = {1997}
}
@unpublished{Gupta2015,
author = {Gupta, Vishal},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta - 2015 - Near-Optimal Bayesian Ambiguity Sets for Distributionally Robust Optimization.pdf:pdf},
keywords = {2015,2016,and,bayesian statistics,data-driven optimization,history,it was returned for,resubmitted in oct,revision on 6 oct,robust optimization,submitted in july 2015,this paper was first},
number = {Optimization Online},
title = {{Near-Optimal Bayesian Ambiguity Sets for Distributionally Robust Optimization}},
year = {2015}
}
@book{Chung1997,
author = {Chung, Fang},
title = {{Spectral graph theory}},
year = {1997}
}
@article{Ibanez2009,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and Silander, John A. and Wilson, Adam M. and LaFleur, Nancy and Tanaka, Nobuyuki and Tsuyama, Ikutaro},
doi = {10.1890/07-2095.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {SDM,climate change: bayes},
mendeley-tags = {SDM,climate change: bayes},
month = {mar},
number = {2},
pages = {359--375},
title = {{Multivariate forecasts of potential distributions of invasive plant species}},
url = {http://doi.wiley.com/10.1890/07-2095.1},
volume = {19},
year = {2009}
}
@article{Junghanns2001,
author = {Junghanns, Andreas and Schaeffer, Jonathan},
journal = {Artificial Intelligence},
pages = {219--251},
title = {{Sokoban: Enhancing general single-agent search methods using domain knowledge}},
volume = {129},
year = {2001}
}
@inproceedings{Bylander1997,
author = {Bylander, Tom},
booktitle = {National Conference on Artificial Intelligence},
pages = {694--699},
title = {{A Linear Programming Heuristic for Optimal Planning}},
year = {1997}
}
@article{Gabrel2014,
author = {Gabrel, Virginie and Murat, C{\'{e}}cile and Thiele, Aur{\'{e}}lie},
doi = {10.1016/j.ejor.2013.09.036},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gabrel, Murat, Thiele - 2014 - Recent advances in robust optimization An overview.pdf:pdf},
issn = {0377-2217},
journal = {European Journal of Operational Research},
number = {3},
pages = {471--483},
publisher = {Elsevier B.V.},
title = {{Recent advances in robust optimization : An overview}},
url = {http://dx.doi.org/10.1016/j.ejor.2013.09.036},
volume = {235},
year = {2014}
}
@inproceedings{Roberts2002,
annote = {From Duplicate 1 ( Low-Cost Flight Control System for a Small Autonomous Helicopter - Roberts, Jonathan M; Corke, Peter I; Buskey, Gregg )
},
author = {Roberts, Jonathan M and Corke, Peter I and Buskey, Gregg},
booktitle = {Australasian Conference on Robotics and Automation},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roberts, Corke, Buskey - 2002 - Low-Cost Flight Control System for a Small Autonomous Helicopter.pdf:pdf},
number = {November},
pages = {27--29},
title = {{Low-cost flight control for a small autonomous helicopter}},
year = {2002}
}
@article{Aravkin2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1406.1089v1},
author = {Aravkin, Aleksandr and Becker, Stephen and Cevher, V and Olsen, Peder},
eprint = {arXiv:1406.1089v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aravkin et al. - 2014 - A variational approach to stable principal component pursuit.pdf:pdf},
journal = {arXiv preprint arXiv:1406.1089},
pages = {1--10},
title = {{A variational approach to stable principal component pursuit}},
url = {http://arxiv.org/abs/1406.1089},
year = {2014}
}
@article{Meidani2013,
abstract = {A stochastic model is proposed for fluctuations in electricity demand that are associated with individual user's consumption choices. Electricity consumption is modeled as a function of social activities of consumers. The dynamics of these activities are modeled as a Markov chain. Markov models are simplified models that capture the stochasticity to the unmodeled dynamics typically attributed to white noise disturbances. Additional uncertainties are also accrued in the process of calibrating the transition rates of these chains from finite samples. In this paper, these uncertainties are accounted for by considering random transition matrices. Such formalism can also reflect the fluctuations in the environment in which the chain evolves. We also discuss a third interpretation where uncertain transitions, in a multiscale setting, reflect the fine-resolution information that is lost in the process of state aggregation. As numerical demonstration, we study the activity modeling of a heterogeneous population. Activity uncertainties are propagated onto the energy demand. Demand uncertainties, in turn, are propagated onto a global performance metric. Such uncertainty management framework bridges between the actual drivers of the energy consumption and the system health. Subsequent decisions can be robustly supported based on the results of the quantitative model proposed in this paper.?? 2013 Elsevier B.V. All rights reserved.},
author = {Meidani, Hadi and Ghanem, Roger},
doi = {10.1016/j.enbuild.2013.02.020},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meidani, Ghanem - 2013 - Multiscale Markov models with random transitions for energy demand management.pdf:pdf},
isbn = {0378-7788},
issn = {03787788},
journal = {Energy and Buildings},
keywords = {Demand management,Markov chain,Random transition matrices,Smart Grid,Uncertainty quantification},
pages = {267--274},
publisher = {Elsevier B.V.},
title = {{Multiscale Markov models with random transitions for energy demand management}},
url = {http://dx.doi.org/10.1016/j.enbuild.2013.02.020},
volume = {61},
year = {2013}
}
@article{McEneaney2004i,
author = {McEneaney, W.M.},
doi = {10.1109/CDC.2004.1429246},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McEneaney - 2004 - Certainty equivalence for imperfect information finite state-space stochastic games.pdf:pdf},
isbn = {0-7803-8682-5},
journal = {2004 43rd IEEE Conference on Decision and Control (CDC) (IEEE Cat. No.04CH37601)},
pages = {3467--3472 Vol.4},
publisher = {Ieee},
title = {{Certainty equivalence for imperfect information finite state-space stochastic games}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1429246},
year = {2004}
}
@article{Even-Dar2009,
abstract = {We consider a Markov decision process (MDP) setting in which the reward function is allowed to change after each time step (possibly in an adversarial manner), yet the dynamics remain fixed. Similar to the experts setting, we address the question of how well an agent can do when compared to the reward achieved under the best stationary policy over time. We provide efficient algorithms, which have regret bounds with no dependence on the size of state space. Instead, these bounds depend only on a certain horizon time of the process and logarithmically on the number of actions.},
author = {Even-Dar, E. and Kakade, Sham. M. and Mansour, Y.},
doi = {10.1287/moor.1090.0396},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even-Dar, Kakade, Mansour - 2009 - Online Markov Decision Processes.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {2006,2008,2009,68q32,68t05,90c40,dynamic programming,finite state,history,in advance july 22,markov,markov decision process,ms subject classification,msc2000 subject classification,no-regret algorithms,optimal control,or,primary,published online in articles,received august 16,revised september 29,secondary},
number = {3},
pages = {726--736},
title = {{Online Markov Decision Processes}},
volume = {34},
year = {2009}
}
@misc{Rotter2008,
author = {Rotter, Reimund},
number = {November},
pages = {19--20},
title = {{Models of crop growth. Crop growth simulation model WOFOST}},
year = {2008}
}
@inproceedings{Daskalaki2013,
abstract = {Artificial pancreas is in the forefront of research towards the automatic insulin infusion for patients with type 1 diabetes. Due to the high inter- and intra-variability of the diabetic population, the need for personalized approaches has been raised. This study presents an adaptive, patient-specific control strategy for glucose regulation based on reinforcement learning and more specifically on the Actor-Critic (AC) learning approach. The control algorithm provides daily updates of the basal rate and insulin-to-carbohydrate (IC) ratio in order to optimize glucose regulation. A method for the automatic and personalized initialization of the control algorithm is designed based on the estimation of the transfer entropy (TE) between insulin and glucose signals. The algorithm has been evaluated in silico in adults, adolescents and children for 10 days. Three scenarios of initialization to i) zero values, ii) random values and iii) TE-based values have been comparatively assessed. The results have shown that when the TE-based initialization is used, the algorithm achieves faster learning with 98{\%}, 90{\%} and 73{\%} in the A+B zones of the Control Variability Grid Analysis for adults, adolescents and children respectively after five days compared to 95{\%}, 78{\%}, 41{\%} for random initialization and 93{\%}, 88{\%}, 41{\%} for zero initial values. Furthermore, in the case of children, the daily Low Blood Glucose Index reduces much faster when the TE-based tuning is applied. The results imply that automatic and personalized tuning based on TE reduces the learning period and improves the overall performance of the AC algorithm.},
author = {Daskalaki, Elena and Diem, Peter and Mougiakakou, Stavroula G},
booktitle = {Conference of the IEEE Engineering in Medicine and Biology Society.},
doi = {10.1109/EMBC.2013.6610293},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daskalaki, Diem, Mougiakakou - 2013 - Personalized tuning of a reinforcement learning control algorithm for glucose regulation.pdf:pdf},
isbn = {978-1-4577-0216-7},
issn = {1557-170X},
keywords = {Artificial organs (incl heart,kidney,liver,panc},
pages = {3487--90},
pmid = {24110480},
title = {{Personalized tuning of a reinforcement learning control algorithm for glucose regulation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24110480},
year = {2013}
}
@inproceedings{Scherrer2010,
author = {Scherrer, Bruno},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Should one compute the Temporal Difference fix point or minimize the {\{}Bellman{\}} Residual?}},
year = {2010}
}
@article{William1989,
author = {William, W},
journal = {SIAM Review},
keywords = {1,65-02,65f05,ams,concerning various applications of,expo-,history,matrix perturbations,matrix updates,mos,response to gene golub,s suggestion that an,sherman-morrison,sitory paper be prepared,subject classifications,the sherman-morrison,this paper is in,woodbury},
number = {2},
pages = {221--239},
title = {{Updating inverse of a Matrix}},
volume = {31},
year = {1989}
}
@misc{Fiorio2013,
author = {Fiorio, Christophe},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fiorio - 2013 - Algorithm2E Package for Algorithms.pdf:pdf},
number = {c},
pages = {1998--2013},
title = {{Algorithm2E: Package for Algorithms}},
volume = {0},
year = {2013}
}
@article{HIJMANS2006,
author = {Hijmans, ROBERT J. and Graham, CATHERINE H.},
doi = {10.1111/j.1365-2486.2006.01256.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hijmans, Graham - 2006 - The ability of climate envelope models to predict the effect of climate change on species distributions.pdf:pdf},
issn = {1354-1013},
journal = {Global Change Biology},
keywords = {GAM,bioclim,climate change,domain,envelope models,maxent,species distributions},
month = {dec},
number = {12},
pages = {2272--2281},
publisher = {Blackwell Publishing Ltd},
title = {{The ability of climate envelope models to predict the effect of climate change on species distributions}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2006.01256.x},
volume = {12},
year = {2006}
}
@phdthesis{Bernstein2005a,
author = {Bernstein, Daniel S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernstein - 2005 - COMPLEXITY ANALYSIS AND OPTIMAL ALGORITHMS FOR DECENTRALIZED DECISION MAKING.pdf:pdf},
number = {September},
title = {{COMPLEXITY ANALYSIS AND OPTIMAL ALGORITHMS FOR DECENTRALIZED DECISION MAKING}},
year = {2005}
}
@article{Duchi2010,
abstract = {The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. It arises in various application domains, including distributed tracking and localization, multi-agent co-ordination, estimation in sensor networks, and large-scale optimization in machine learning. We develop and analyze distributed algorithms based on dual averaging of subgradients, and we provide sharp bounds on their convergence rates as a function of the network size and topology. Our method of analysis allows for a clear separation between the convergence of the optimization algorithm itself and the effects of communication constraints arising from the network structure. In particular, we show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network. The sharpness of this prediction is confirmed both by theoretical lower bounds and simulations for various networks. Our approach includes both the cases of deterministic optimization and communication, as well as problems with stochastic optimization and/or communication.},
archivePrefix = {arXiv},
arxivId = {1005.2012},
author = {Duchi, John and Agarwal, Alekh and Wainwright, Martin},
doi = {10.1109/TAC.2011.2161027},
eprint = {1005.2012},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duchi, Agarwal, Wainwright - 2010 - Dual Averaging for Distributed Optimization Convergence Analysis and Network Scaling.pdf:pdf},
issn = {0018-9286},
pages = {1--15},
title = {{Dual Averaging for Distributed Optimization: Convergence Analysis and Network Scaling}},
url = {http://arxiv.org/abs/1005.2012 http://dx.doi.org/10.1109/TAC.2011.2161027},
year = {2010}
}
@article{Peterson2010,
abstract = {The effects of combined driving and vehicle-to-grid (V2G) usage on the lifetime performance of relevant commercial Li-ion cells were studied. We derived a nominal realistic driving schedule based on aggregating driving survey data and the Urban Dynamometer Driving Schedule, and used a vehicle physics model to create a daily battery duty cycle. Different degrees of continuous discharge were imposed on the cells to mimic afternoon V2G use to displace grid electricity. The loss of battery capacity was quantified as a function of driving days as well as a function of integrated capacity and energy processed by the cells. The cells tested showed promising capacity fade performance: more than 95{\%} of the original cell capacity remains after thousands of driving days worth of use. Statistical analyses indicate that rapid vehicle motive cycling degraded the cells more than slower, V2G galvanostatic cycling. These data are intended to inform an economic model. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Peterson, Scott B. and Apt, Jay and Whitacre, J. F.},
doi = {10.1016/j.jpowsour.2009.10.010},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peterson, Apt, Whitacre - 2010 - Lithium-ion battery cell degradation resulting from realistic vehicle and vehicle-to-grid utilization.pdf:pdf},
isbn = {0378-7753},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {A123 systems,Battery degradation,Li-ion battery,LiFePO4,PHEV,Vehicle battery testing profile,Vehicle-to-grid},
pages = {2385--2392},
title = {{Lithium-ion battery cell degradation resulting from realistic vehicle and vehicle-to-grid utilization}},
volume = {195},
year = {2010}
}
@book{Filar1996,
author = {Filar, Jerzy and Vrieze, Koos},
publisher = {Springer},
title = {{Competitive Markov Decision Processes}},
url = {http://dl.acm.org/citation.cfm?id=248676},
year = {1997}
}
@article{Perkins2000,
annote = {From Duplicate 1 ( Lyapunov-Constrained Action Sets for Reinforcement Learning - Perkins, Theodore J; Barto, Andrew G )
},
author = {Perkins, Theodore J and Barto, Andrew G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perkins, Barto - 2000 - Lyapunov-Constrained Action Sets for Reinforcement Learning.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perkins, Barto - Unknown - Lyapunov Design for Safe Reinforcement Learning Control.pdf:pdf},
title = {{Lyapunov-Constrained Action Sets for Reinforcement Learning}},
year = {2000}
}
@article{DeVore2008c,
author = {DeVore, Ronald a.},
doi = {10.1017/S0962492900002816},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/DeVore - 2008 - Nonlinear approximation.pdf:pdf},
issn = {0962-4929},
journal = {Acta Numerica},
month = {nov},
pages = {51},
title = {{Nonlinear approximation}},
url = {http://www.journals.cambridge.org/abstract{\_}S0962492900002816},
volume = {7},
year = {2008}
}
@book{Vapnik1999,
author = {Vapnik, Vladimir},
publisher = {Springer},
title = {{The Nature of Statistical Learning Theory}},
year = {1999}
}
@article{Bostrom2007,
abstract = {For both single probability estimation trees (PETs) and ensembles of such trees, commonly employed class probability estimates correct the observed relative class frequencies in each leaf to avoid anomalies caused by small sample sizes. The effect of such corrections in random forests of PETs is investigated, and the use of the relative class frequency is compared to using two corrected estimates, the Laplace estimate and the m-estimate. An experiment with 34 dataseis from the UCI repository shows that estimating class probabilities using relative class frequency clearly outperforms both using the Laplace estimate and the m-estimate with respect to accuracy, area under the ROC curve (AUC) and Brier score. Hence, in contrast to what is commonly employed for PETs and ensembles of PETs, these results strongly suggest that a non-corrected probability estimate should be used in random forests of PETs. The experiment further shows that learning random forests of PETs using relative class frequency significantly outperforms learning random forests of classification trees (i.e., trees for which only an unweighted vote on the most probable class is counted) with respect to both accuracy and AUC, but that the latter is clearly ahead of the former with respect to Brier score. {\textcopyright} 2007 IEEE.},
author = {Bostr{\"{o}}m, Henrik},
doi = {10.1109/ICMLA.2007.45},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bostr{\"{o}}m - 2007 - Estimating class probabilities in random forests.pdf:pdf},
isbn = {0769530699},
journal = {International Conference on Machine Learning and Applications},
pages = {211--216},
title = {{Estimating class probabilities in random forests}},
year = {2007}
}
@book{Sugiyama2012,
author = {Sugiyama, M and Kawanabe, M},
publisher = {MIT Press},
title = {{Machine Learning in Non-stationary Environments: Introduction to Covariate Shift Adaptation.}},
year = {2012}
}
@inproceedings{Boyan1998,
annote = {From Duplicate 2 ( 









Least-Squares Temporal Difference Learning









- Boyan, Justin A )



},
author = {Boyan, Justin A},
booktitle = {Proc. 16th International Conf. on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyan - 1998 - Least-Squares Temporal Difference Learning.pdf:pdf},
organization = {Carnegie Mellon University},
pages = {49--56},
title = {{Least-Squares Temporal Difference Learning}},
url = {citeseer.ist.psu.edu/article/boyan99leastsquares.html},
year = {1998}
}
@article{Skrondal2007,
abstract = {Latent variable modelling has gradually become an integral part of mainstream statistics and is currently used for a multitude of applications in different subject areas. Examples of ‘traditional' latent variable models include latent class models, item–response models, common factor models, structural equation models, mixed or random effects models and covariate measurement error models. Although latent variables have widely different interpretations in different settings, the models have a very similar mathematical structure. This has been the impetus for the formulation of general modelling frameworks which accommodate a wide range of models. Recent developments include multilevel structural equation models with both continuous and discrete latent variables, multiprocess models and nonlinear latent variable models. [ABSTRACT FROM AUTHOR] Copyright of Scandinavian Journal of Statistics is the property of Wiley-Blackwell and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Skrondal, Anders and Rabe-Hesketh, Sophia},
doi = {10.1111/j.1467-9469.2007.00573.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Skrondal, Rabe-Hesketh - 2007 - Latent variable modelling A survey.pdf:pdf},
isbn = {03036898},
issn = {03036898},
journal = {Scandinavian Journal of Statistics},
keywords = {Factor analysis,GLLAMM,Item-response theory,Latent class,Latent trait,Latent variable,Measurement error,Mixed effects model,Multilevel model,Random effect,Structural equation model},
number = {4},
pages = {712--745},
pmid = {27649872},
title = {{Latent variable modelling: A survey}},
volume = {34},
year = {2007}
}
@book{Follmer2011,
author = {Follmer, Hans and Schied, Alexander},
edition = {3rd},
publisher = {Walter de Gruyter},
title = {{Stochastic Finance: An Introduction in Discrete Time}},
year = {2011}
}
@article{Rodriguez2009,
author = {Rodr{\'{i}}guez, Sara V. and Albornoz, Victor M. and Pl{\`{a}}, Llu{\'{i}}s M.},
doi = {10.1007/s11750-009-0087-2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rodr{\'{i}}guez, Albornoz, Pl{\`{a}} - 2009 - A two-stage stochastic programming model for scheduling replacements in sow farms.pdf:pdf},
issn = {1134-5764},
journal = {Top},
keywords = {planning,replacement,sow herd,stochastic programming},
month = {apr},
number = {1},
pages = {171--189},
title = {{A two-stage stochastic programming model for scheduling replacements in sow farms}},
url = {http://link.springer.com/10.1007/s11750-009-0087-2},
volume = {17},
year = {2009}
}
@misc{Nikovski2003,
author = {Nikovski, Daniel and Brand, Matthew},
institution = {Mitsubishi Electric Research Laboratories},
title = {{Non-Linear Stochastic Control in Continuous State Spaces by Exact Integration in Bellman's Equations}},
year = {2003}
}
@article{Newlands2010,
author = {Newlands, NK and Townley-Smith, L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newlands, Townley-Smith - 2010 - PREDICTING ENERGY CROP YIELD USING BAYESIAN NETWORKS.pdf:pdf},
journal = {Proceedings of the Fifth IASTED {\ldots}},
keywords = {agriculture,bayesian networks,climate,energy,learn-},
pages = {106--112},
title = {{PREDICTING ENERGY CROP YIELD USING BAYESIAN NETWORKS}},
url = {http://www.actapress.com/PDFViewer.aspx?paperId=43006},
year = {2010}
}
@article{Wolpert1996,
annote = {No free lunch},
author = {Wolpert, DH},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolpert - 1996 - The lack of a priori distinctions between learning algorithms.ps:ps},
journal = {Neural computation},
title = {{The lack of a priori distinctions between learning algorithms}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1996.8.7.1341},
year = {1996}
}
@article{Loffler2008,
author = {L{\"{o}}ffler, Maarten and Kreveld, Marc Van},
doi = {10.1007/s00453-008-9174-2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{o}}ffler, Kreveld - 2008 - Largest and Smallest Convex Hulls for Imprecise Points.pdf:pdf},
journal = {Algorithmica},
keywords = {computational geometry,convex hulls,data imprecision,imprecision},
title = {{Largest and Smallest Convex Hulls for Imprecise Points}},
year = {2008}
}
@book{Care2006,
author = {Tsay, Ruey},
booktitle = {Wiley},
doi = {10.1002/0471264105},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsay - 2005 - Analysis of Financial Time Series.pdf:pdf},
isbn = {978-0470414354},
issn = {0040-1706},
pmid = {10118702},
title = {{Analysis of Financial Time Series}},
url = {http://pubs.amstat.org/doi/abs/10.1198/tech.2006.s405},
year = {2005}
}
@article{Wolpert1996,
author = {Wolpert, David},
journal = {Neural Computation},
pages = {1341--1390},
title = {{The lack of apriori distinctions between learning algorithms}},
volume = {8},
year = {1996}
}
@article{Ancuti2011a,
author = {Ancuti, Cosmin and Hermans, Chris and Bekaert, Philippe},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ancuti, Hermans, Bekaert - 2011 - A fast semi-inverse approach to detect and remove the haze from a single image.pdf:pdf},
journal = {Computer Vision–ACCV {\ldots}},
title = {{A fast semi-inverse approach to detect and remove the haze from a single image}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-19309-5{\_}39},
year = {2011}
}
@book{Bertsimas2017,
author = {Bertsimas, Dimitris and Kallus, Nathan and Gupta, Vishal},
booktitle = {Mathematical Programming},
doi = {10.1007/s10107-017-1125-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Kallus, Gupta - 2017 - Data-driven robust optimization.pdf:pdf},
isbn = {1010701711258},
issn = {1436-4646},
keywords = {Robust optimization,Data-driven optimization,Chanc,chance-constraints,data-driven optimization,robust optimization},
publisher = {Springer Berlin Heidelberg},
title = {{Data-driven robust optimization}},
year = {2017}
}
@book{Rockafellar2009,
abstract = {Variational transition state analysis was performed on the barrierless phenyl + O2 and phenoxy + O association reactions. In addition, we also calculated rate constants for the related vinyl radical (C2H3) + O2 and vinoxy radical (C2H3O) + O reactions and provided rate constant estimates for analogous reactions in substituted aromatic systems. Potential energy scans along the dissociating C-OO and CO-O bonds (with consideration of C-OO internal rotation) were obtained at the O3LYP/6-31G(d) density functional theory level. The CO-O and C-OO bond scission reactions were observed to be barrierless, in both phenyl and vinyl systems. Potential energy wells were scaled by G3B3 reaction enthalpies to obtain accurate activation enthalpies. Frequency calculations were performed for all reactants and products and at points along the potential energy surfaces, allowing us to evaluate thermochemical properties as a function of temperature according to the principles of statistical mechanics and the rigid rotor harmonic oscillator (RRHO) approximation. The low-frequency vibrational modes corresponding to R-OO internal rotation were omitted from the RRHO analysis and replaced with a hindered internal rotor analysis using O3LYP/6-31G(d) rotor potentials. Rate constants were calculated as a function of temperature (300-2000 K) and position from activation entropies and enthalpies, according to canonical transition state theory; these rate constants were minimized with respect to position to obtain variational rate constants as a function of temperature. For the phenyl + O2 reaction, we identified the transition state to be located at a C-OO bond length of between 2.56 and 2.16 A (300-2000 K), while for the phenoxy + O reaction, the transition state was located at a CO-O bond length of 2.00-1.90 A. Variational rate constants were fit to a three-parameter form of the Arrhenius equation, and for the phenyl + O2 association reaction, we found k(T) = 1.860 x 1013T-0.217 exp(0.358/T) (with k in cm3 mol-1 s-1 and T in K); this rate equation provides good agreement with low-temperature experimental measurements of the phenyl + O2 rate constant. Preliminary results were presented for a correlation between activation energy (or reaction enthalpy) and pre-exponential factor for heterolytic O-O bond scission reactions.},
author = {Rockafellar, R. Tyrrell and Wets, Roger J-B},
doi = {10.1021/jp7118845},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Wets - 2009 - Variational analysis.pdf:pdf},
isbn = {1089-5639},
issn = {10895639},
pmid = {18348555},
title = {{Variational analysis}},
year = {2009}
}
@article{Gelman2008,
author = {Gelman, Andrew},
doi = {10.1198/000313008X330829},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gelman - 2008 - Teaching Bayes to Graduate Students in Political Science, Sociology, Public Health, Education, Economics, {\ldots}.pdf:pdf},
isbn = {0003-1305},
issn = {0003-1305},
journal = {The American Statistician},
number = {3},
pages = {202--205},
title = {{Teaching Bayes to Graduate Students in Political Science, Sociology, Public Health, Education, Economics, {\ldots}}},
url = {http://www.tandfonline.com/doi/abs/10.1198/000313008X330829},
volume = {62},
year = {2008}
}
@article{Eitzinger2004,
annote = {
        {\textless}m:bold{\textgreater}The weather model used: {\textless}/m:bold{\textgreater}It is not clear where the weather data comes from.},
author = {Eitzinger, J. and Trnka, M. and H{\"{o}}sch, J. and {\v{Z}}alud, Z. and Dubrovsk{\'{y}}, M.},
doi = {10.1016/j.ecolmodel.2003.08.012},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eitzinger et al. - 2004 - Comparison of CERES, WOFOST and SWAP models in simulating soil water content during growing season under diffe.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {ecological modeling,model evaluation,soil water balance,spring barley,winter wheat},
month = {jan},
number = {3},
pages = {223--246},
title = {{Comparison of CERES, WOFOST and SWAP models in simulating soil water content during growing season under different soil conditions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0304380003003351},
volume = {171},
year = {2004}
}
@article{Blum2006,
author = {Blum, Ben and Shelton, Christian and Koller, Daphne},
journal = {Journal of Artificial Intelligence Research},
pages = {457--502},
title = {{A continuation method for {\{}N{\}}ash equilibria in structured games}},
volume = {25},
year = {2006}
}
@techreport{Welch2006,
author = {Welch, Greg and Bishop, Gary},
pages = {1--16},
title = {{An Introduction to the Kalman Filter}},
year = {2006}
}
@article{Laan1987,
author = {der Laan, G Van},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laan - 1987 - Simplicial variable dimension algorithms for solving the nonlinear complementarity problem on a product of unit simplices.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {3},
pages = {377--398},
title = {{Simplicial variable dimension algorithms for solving the nonlinear complementarity problem on a product of unit simplices using a general labelling}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.12.3.377},
volume = {12},
year = {1987}
}
@article{Ben-Tal2009a,
abstract = {In the paper we consider the chance-constrained version of an affinely perturbed linear matrix inequality (LMI) constraint, assuming the primitive perturbations to be independent with light-tail distributions (e.g., bounded or Gaussian). Constraints of this type, playing a central role in chance-constrained linear/conic quadratic/semidefinite programming, are typically computationally intractable. The goal of this paper is to develop a tractable approximation to these chance constraints. Our approximation is based on measure concentration results and is given by an explicit system of LMIs. Thus, the approximation is computationally tractable; moreover, it is also safe, meaning that a feasible solution of the approximation is feasible for the chance constraint.},
author = {Ben-Tal, Aharon and Nemirovski, Arkadi},
doi = {10.1287/moor.1080.0352},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {2006,2007 and august 13,2008,60f10,90c15,90c22,90c25,chance constraints,convex programming,history,linear matrix inequalities,mathematics,matrices,measure concentration,ms subject classification,msc2000 subject classification,or,primary,programming,received november 20,revised october 19,secondary,stochastic},
number = {1},
pages = {1--25},
title = {{On Safe Tractable Approximations of Chance-Constrained Linear Matrix Inequalities}},
volume = {34},
year = {2009}
}
@article{Aggarwal2009,
abstract = {The main methodologies used in electricity price forecasting have been reviewed in this paper. The following price-forecasting techniques have been covered: (i) stochastic time series, (ii) causal models, and (iii) artificial intelligence based models. The quantitative analysis of the work done by various authors has been presented based on (a) time horizon for prediction, (b) input variables, (c) output variables, (d) results, (e) data points used for analysis, (f) preprocessing technique employed, and (g) architecture of the model. The results have been presented in the form of tables for ease of comparison. Classification of various price-influencing factors used by different researchers has been done and put for reference. Application of various models as applied to different electricity markets is also presented for consideration. ?? 2008 Elsevier Ltd. All rights reserved.},
author = {Aggarwal, Sanjeev Kumar and Saini, Lalit Mohan and Kumar, Ashwani},
doi = {10.1016/j.ijepes.2008.09.003},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Saini, Kumar - 2009 - Electricity price forecasting in deregulated markets A review and evaluation.pdf:pdf},
isbn = {0142-0615},
issn = {01420615},
journal = {International Journal of Electrical Power and Energy Systems},
keywords = {Deregulated markets,Neural networks,Price forecasting,Regression models,Stochastic time series},
number = {1},
pages = {13--22},
publisher = {Elsevier Ltd},
title = {{Electricity price forecasting in deregulated markets: A review and evaluation}},
url = {http://dx.doi.org/10.1016/j.ijepes.2008.09.003},
volume = {31},
year = {2009}
}
@article{Lobell2003,
annote = {Predicts yields},
author = {Lobell, D.B. and Asner, G.P.},
doi = {10.1109/TGRS.2003.812909},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lobell, Asner - 2003 - Comparison of Earth Observing-1 ALI and Landsat ETM for Crop Identification and Yield Prediction in Mexico.pdf:pdf},
issn = {0196-2892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
month = {jun},
number = {6},
pages = {1277--1282},
title = {{Comparison of Earth Observing-1 ALI and Landsat ETM+ for Crop Identification and Yield Prediction in Mexico}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1220235},
volume = {41},
year = {2003}
}
@book{Tao2012,
author = {Tao, Terence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tao - 2012 - Topics in random matrix theory.pdf:pdf},
title = {{Topics in random matrix theory}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Hjq{\_}JHLNPT0C{\&}oi=fnd{\&}pg=PR9{\&}dq=Topics+in+random+matrix+theory{\&}ots=DNB7qf-oAd{\&}sig={\_}IajImkMb4VX7iExdpjtS{\_}jp3-E},
year = {2012}
}
@inproceedings{Wolpert1997,
annote = {From Duplicate 2 ( No free lunch theorems for optimization - Wolpert, D.H.; Macready, W.G. )
},
author = {Wolpert, D.H. David and MacReady, W.G. William},
booktitle = {IEEE Transations on Evolutionary Computation},
doi = {10.1109/4235.585893},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolpert, Macready - 1997 - No free lunch theorems for optimization.pdf:pdf},
issn = {1089778X},
month = {apr},
number = {1},
pages = {67--82},
title = {{No free lunch theorems for optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=585893},
volume = {1},
year = {1997}
}
@inproceedings{Thomas2015,
author = {Thomas, Philip S. and Teocharous, Georgios and Ghavamzadeh, Mohammad},
booktitle = {Annual Conference of the AAAI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas, Teocharous, Ghavamzadeh - 2015 - High Confidence Off-Policy Evaluation.pdf:pdf},
title = {{High Confidence Off-Policy Evaluation}},
year = {2015}
}
@article{O'Donoghue2012,
abstract = {In this paper we demonstrate a simple heuristic adaptive restart technique that can dramatically improve the convergence rate of accelerated gradient schemes. The analysis of the technique relies on the observation that these schemes exhibit two modes of behavior depending on how much momentum is applied. In what we refer to as the 'high momentum' regime the iterates generated by an accelerated gradient scheme exhibit a periodic behavior, where the period is proportional to the square root of the local condition number of the objective function. This suggests a restart technique whereby we reset the momentum whenever we observe periodic behavior. We provide analysis to show that in many cases adaptively restarting allows us to recover the optimal rate of convergence with no prior knowledge of function parameters.},
archivePrefix = {arXiv},
arxivId = {1204.3982},
author = {O'Donoghue, Brendan and Candes, Emmanuel},
eprint = {1204.3982},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Donoghue, Candes - 2012 - Adaptive Restart for Accelerated Gradient Schemes.pdf:pdf},
month = {apr},
pages = {17},
title = {{Adaptive Restart for Accelerated Gradient Schemes}},
url = {http://arxiv.org/abs/1204.3982},
year = {2012}
}
@article{Polyak1964,
annote = {The original paper describing the heavy ball method},
author = {Polyak, B.T.},
doi = {10.1016/0041-5553(64)90137-5},
issn = {00415553},
journal = {USSR Computational Mathematics and Mathematical Physics},
month = {jan},
number = {5},
pages = {1--17},
title = {{SOME METHODS OF SPEEDING UP THE CONVERGENCE OF ITERATION METHODS}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0041555364901375},
volume = {4},
year = {1964}
}
@article{Chapelle2011,
abstract = {Thompson sampling is one of oldest heuristic to address the exploration ex- ploitation trade-off, but it is surprisingly unpopular in the literature. We present here some empirical results using Thompson sampling on simulated and real data, and show that it is highly competitive. And since this heuristic is very easy to implement, we argue that it should be part of the standard baselines to compare against.},
author = {Chapelle, Olivier and Li, Lihong},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chapelle, Li - 2011 - An Empirical Evaluation of Thompson Sampling.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems},
pages = {2249----2257},
title = {{An Empirical Evaluation of Thompson Sampling}},
url = {http://explo.cs.ucl.ac.uk/wp-content/uploads/2011/05/An-Empirical-Evaluation-of-Thompson-Sampling-Chapelle-Li-2011.pdf},
year = {2011}
}
@inproceedings{Mannor2012,
author = {Mannor, Shie and Mebel, O and Xu, H},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mannor, Mebel, Xu - 2012 - Lightning does not strike twice Robust MDPs with coupled uncertainty.pdf:pdf},
title = {{Lightning does not strike twice: Robust MDPs with coupled uncertainty}},
url = {http://arxiv.org/abs/1206.4643},
year = {2012}
}
@article{Howell1996,
author = {Howell, T A},
keywords = {automation,drainage,evaporation,irrigation control,models,plant water status,runoff,soil water,transpiration},
pages = {21--33},
title = {{Irrigation Scheduling Research And Its Impact on Water Use}},
year = {1996}
}
@techreport{Mount2011,
abstract = {As our colleague so aptly demonstrated ( http://www.win-vector.com/blog/2011/09/the-simpler- derivation-of-logistic-regression/ (link) ) there is one derivation of Logistic Regression that is particularly beautiful. It is not as general as that found in Agresti[Agresti, 1990] (which deals with generalized linear models in their full generality), but gets to the important balance equations very quickly. We will pursue this further to re-derive multi-category logistic regression in both its standard (sigmoid) phrasing and also in its equivalent maximum entropy clothing. It is well known that logistic regression and maximum entropy modeling are equivalent (for example see [Klein and Manning, 2003])- but we will show that the simpler derivation already given is a very good way to demonstrate the equivalence (and points out that logistic regression is actually special- not just one of many equivalent GLMs).},
author = {Mount, John},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mount - 2011 - The equivalence of logistic regression and maximum entropy models.pdf:pdf},
institution = {Win-Vector},
number = {1},
pages = {1--8},
title = {{The equivalence of logistic regression and maximum entropy models}},
url = {http://www.win-vector.com/dfiles/LogisticRegressionMaxEnt.pdf},
year = {2011}
}
@inproceedings{Hoey2005,
author = {Hoey, Jesse and Poupart, Pascal},
booktitle = {International Joint Conference on Artificial Intelligence},
title = {{Solving POMDPs with Continuous or Large Discrete Observation Spaces}},
year = {2005}
}
@misc{Jensen2007,
author = {Jensen, John R.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jensen - 2007 - Remote Sensing of Vegetation.pdf:pdf},
pages = {1--33},
title = {{Remote Sensing of Vegetation}},
year = {2007}
}
@inproceedings{Brunskill2014,
author = {Brunskill, Emma and Com, Lihongli Microsoft},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brunskill, Com - 2014 - PAC-inspired Option Discovery in Lifelong Reinforcement Learning.pdf:pdf},
title = {{PAC-inspired Option Discovery in Lifelong Reinforcement Learning}},
year = {2014}
}
@article{Bertsimas2004,
author = {Bertsimas, Dimitris and Pachamanova, D and Sim, Melvyn},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Pachamanova, Sim - 2004 - Robust linear optimization under general norms.pdf:pdf},
journal = {Operations Research Letters},
pages = {1--12},
title = {{Robust linear optimization under general norms}},
url = {http://www.sciencedirect.com/science/article/pii/S0167637704000082},
year = {2004}
}
@article{Vakhutinsky1979,
annote = {From Duplicate 1 ( Iterative Aggregation--A New Approach to the Solution of Large-Scale Problems - Vakhutinsky, I Y; Dudkin, L M; Ryvkin, A A; Jul, No )
},
author = {Vakhutinsky, I Y and Dudkin, L M and Ryvkin, A A and Jul, No},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vakhutinsky et al. - 2007 - Iterative Aggregation--A New Approach to the Solution of Large-Scale Problems.pdf:pdf},
journal = {Econometrica},
number = {4},
pages = {821--841},
title = {{Iterative Aggregation--A New Approach to the Solution of Large-Scale Problems}},
volume = {47},
year = {1979}
}
@misc{Livingston2012,
author = {Livingston, Michael and Roberts, MJ and Zhang, Yue},
booktitle = {North Carolina State University, {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Livingston, Roberts, Zhang - 2012 - Optimal sequential plantings of corn and soybeans under price uncertainty.pdf:pdf},
number = {November},
title = {{Optimal sequential plantings of corn and soybeans under price uncertainty}},
url = {http://www4.ncsu.edu/unity/lockers/users/v/vukina/AG{\_}ECO{\_}Workshop/Fall{\_}2012/Yue{\_}Zhang.pdf http://www2.hawaii.edu/{~}mjrobert/main/Working{\_}Papers{\_}files/AJAE{\_}revise.pdf},
year = {2012}
}
@inproceedings{Petrik2016,
author = {Petrik, Marek and Luss, Ronny},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Luss - 2016 - Interpretable Policies for Dynamic Product Recommendations.pdf:pdf},
title = {{Interpretable Policies for Dynamic Product Recommendations}},
year = {2016}
}
@book{Howard1960,
annote = {From Duplicate 2 ( Dynamic Programming and Markov Processes - Howard, Ron A )
},
author = {Howard, Ron A},
publisher = {MIT Press},
title = {{Dynamic Programming and Markov Processes}},
year = {1960}
}
@article{Audibert2009,
abstract = {Algorithms based on upper confidence bounds for balancing exploration and exploitation are gaining popularity since they are easy to implement, efficient and effective. This paper considers a variant of the basic algorithm for the stochastic, multi-armed bandit problem that takes into account the empirical variance of the different arms. In earlier experimental works, such algorithms were found to outperform the competing algorithms. We provide the first analysis of the expected regret for such algorithms. As expected, our results show that the algorithm that uses the variance estimates has a major advantage over its alternatives that do not use such estimates provided that the variances of the payoffs of the suboptimal arms are low. We also prove that the regret concentrates only at a polynomial rate. This holds for all the upper confidence bound based algorithms and for all bandit problems except those special ones where with probability one the payoff obtained by pulling the optimal arm is larger than the expected payoff for the second best arm. Hence, although upper confidence bound bandit algorithms achieve logarithmic expected regret rates, they might not be suitable for a risk-averse decision maker. We illustrate some of the results by computer simulations. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Audibert, Jean Yves and Munos, R{\'{e}}mi and Szepesv{\'{a}}ri, Csaba},
doi = {10.1016/j.tcs.2009.01.016},
isbn = {0304-3975},
issn = {03043975},
journal = {Theoretical Computer Science},
keywords = {Bernstein's inequality,Exploration-exploitation tradeoff,High-probability bound,Multi-armed bandits,Risk analysis},
number = {19},
pages = {1876--1902},
title = {{Exploration-exploitation tradeoff using variance estimates in multi-armed bandits}},
volume = {410},
year = {2009}
}
@article{Ghavamzadeh2015,
abstract = {Bayesian methods for machine learning have been widely investigated, yielding principled methods for incorporating prior information into inference algorithms. In this survey, we provide an in-depth review of the role of Bayesian methods for the reinforcement learning (RL) paradigm. The major incentives for incorporating Bayesian reasoning in RL are: 1) it provides an elegant approach to action-selection (exploration/ exploitation) as a function of the uncertainty in learning; and 2) it provides a machinery to incorporate prior knowledge into the algorithms. We first discuss models and methods for Bayesian inference in the simple single-step Bandit model. We then review the extensive recent literature on Bayesian methods for model-based RL, where prior information can be expressed on the parameters of the Markov model. We also present Bayesian methods for model-free RL, where priors are expressed over the value function or policy class. The objective of the paper is to provide a comprehensive survey on Bayesian RL algorithms and their theoretical and empirical properties.},
archivePrefix = {arXiv},
arxivId = {1405.4980},
author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
doi = {10.1561/2200000049},
eprint = {1405.4980},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghavamzadeh et al. - 2015 - Bayesian Reinforcement Learning A Survey.pdf:pdf},
isbn = {2200000049},
issn = {1935-8237},
journal = {Foundations and Trends in Machine Learning},
keywords = {Reinforcement learning},
number = {5-6},
pages = {359--483},
title = {{Bayesian Reinforcement Learning: A Survey}},
url = {http://www.nowpublishers.com/article/Details/MAL-049},
volume = {8},
year = {2015}
}
@article{Sridharan2002,
abstract = {We study the use of the reinforcement learning algorithm$\backslash$nQ-learning with regression tree function approximation to learn pricing$\backslash$nstrategies in a competitive marketplace of economic software agents.$\backslash$nQ-learning is an algorithm for learning to estimate the long-term$\backslash$nexpected reward for a given state-action pair. In the case of a$\backslash$nstationary environment with a lookup table representing the Q-function,$\backslash$nthe learning procedure is guaranteed to converge to an optimal policy.$\backslash$nHowever, utilizing Q-learning in multi-agent systems presents special$\backslash$nchallenges. The simultaneous adaptation of multiple agents creates a$\backslash$nnon-stationary environment for each agent, hence there are no$\backslash$ntheoretical guarantees of convergence or optimality. Also, large$\backslash$nmulti-agent systems may have state spaces too large to represent with$\backslash$nlookup tables, necessitating the use of function approximation},
author = {Sridharan, M. and Tesauro, G.},
doi = {10.1109/ICMAS.2000.858518},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sridharan, Tesauro - 2002 - Multi-agent Q-learning and regression trees for automated pricing decisions.pdf:pdf},
isbn = {0-7695-0625-9},
journal = {Proceedings Fourth International Conference on MultiAgent Systems},
pages = {447--448},
title = {{Multi-agent Q-learning and regression trees for automated pricing decisions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=858518{\%}5Cnhttp://link.springer.com/chapter/10.1007/978-1-4615-1107-6{\_}11{\%}5Cnhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=858518},
year = {2002}
}
@incollection{Chakravorty2014,
author = {Chakravorty, Jhelum and Mahajan, Aditya},
booktitle = {Methods and Applications of Statistics in Clinical Trials},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakravorty, Mahajan - 2014 - Multi-Armed Bandits, Gittins Index, and Its Calculation.pdf:pdf},
pages = {416--435},
title = {{Multi-Armed Bandits, Gittins Index, and Its Calculation}},
year = {2014}
}
@article{Newlands2014,
abstract = {We present a novel forecasting method for generating agricultural crop yield forecasts at the seasonal and regional-scale, integrating agroclimate variables and remotely- sensed indices. The method devises a multivariate statistical model to compute bias and uncertainty in forecasted yield at the Census of Agricultural Region (CAR) scale across the Canadian Prairies. The method uses robust variable-selection to select the best predictors within spatial subregions. Markov-Chain Monte Carlo (MCMC) simulation and random forest-tree machine learning techniques are then integrated to generate sequential forecasts through the growing season. Cross-validation of the model was performed by hindcasting/backcasting and comparing forecasts against available historical data (1987–2011) for spring wheat (Triticum aestivum L.). The model was also validated for the 2012 growing season by comparing forecast skill at the CAR, provincial and Canadian Prairie region scales against available statistical survey data. Mean percent departures between wheat yield forecastedwere under-estimated by 1–4{\%} in mid-season and over-estimated by 1{\%} at the end of the growing season. This integrated methodology offers a consistent, generalizable approach for sequentially forecasting crop yield at the regional-scale. It provides a statistically robust, yet flexible way to concurrently adjust to data-rich and data-sparse situations, adaptively select different predictors of yield to changing levels of environmental uncertainty, and to update forecasts sequentially so as to incorporate new data as it becomes available. This integrated method also provides additional statistical support for assessing the accuracy and reliability of model-based crop yield forecasts in time and space. Keywords:},
author = {Newlands, Nathaniel K. and Zamar, David S. and Kouadio, Louis a. and Zhang, Yinsuo and Chipanshi, Aston and Potgieter, Andries and Toure, Souleymane and Hill, Harvey S. J.},
doi = {10.3389/fenvs.2014.00017},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Newlands et al. - 2014 - An integrated, probabilistic model for improved seasonal forecasting of agricultural crop yield under environme.pdf:pdf},
issn = {2296-665X},
journal = {Frontiers in Environmental Science},
keywords = {Bayesian,agriculture,bayesian,climate,crop yield,foreca,forecasting,regional,uncertainty},
number = {June},
pages = {1--21},
title = {{An integrated, probabilistic model for improved seasonal forecasting of agricultural crop yield under environmental uncertainty}},
url = {http://www.frontiersin.org/Interdisciplinary{\_}Climate{\_}Studies/10.3389/fenvs.2014.00017/abstract},
volume = {2},
year = {2014}
}
@article{Govindan2003e,
author = {Govindan, Srihari and Wilson, Robert},
doi = {10.1016/S0022-0531(03)00005-X},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Govindan, Wilson - 2003 - A global Newton method to compute Nash equilibria.pdf:pdf},
issn = {00220531},
journal = {Journal of Economic Theory},
keywords = {algorithm,global newton method,homotopy,nash equilibrium,noncooperative game},
month = {may},
number = {1},
pages = {65--86},
title = {{A global Newton method to compute Nash equilibria}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002205310300005X},
volume = {110},
year = {2003}
}
@article{Delgado2016,
abstract = {Markov Decision Processes have become the standard model for probabilistic planning. However, when applied to many practical problems, the estimates of transition probabilities are inaccurate. This may be due to conflicting elicitations from experts or insufficient state transition information. The Markov Decision Process with Imprecise Transition Probabilities (MDP-IPs) was introduced to obtain a robust policy where there is uncertainty in the transition. Although it has been proposed a symbolic dynamic programming algorithm for MDP-IPs (called SPUDD-IP) that can solve problems up to 22 state variables, in practice, solving MDP-IP problems is time-consuming. In this paper we propose efficient algorithms for a more general class of MDP-IPs, called Stochastic Shortest Path MDP-IPs (SSP MDP-IPs) that use initial state information to solve complex problems by focusing on reachable states. The (L)RTDP-IP algorithm, a (Labeled) Real Time Dynamic Programming algorithm for SSP MDP-IPs, is proposed together with three different methods for sampling the next state. It is shown here that the convergence of (L)RTDP-IP can be obtained by using any of these three methods, although the Bellman backups for this class of problems prescribe a minimax optimization. As far as we are aware, this is the first asynchronous algorithm for SSP MDP-IPs given in terms of a general set of probability constraints that requires non-linear optimization over imprecise probabilities in the Bellman backup. Our results show up to three orders of magnitude speedup for (L)RTDP-IP when compared with the SPUDD-IP algorithm.},
author = {Delgado, Karina V. and {De Barros}, Leliane N. and Dias, Daniel B. and Sanner, Scott},
doi = {10.1016/j.artint.2015.09.005},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delgado et al. - 2016 - Real-time dynamic programming for Markov decision processes with imprecise probabilities.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Markov decision process,Probabilistic planning,Robust planning},
pages = {192--223},
publisher = {Elsevier B.V.},
title = {{Real-time dynamic programming for Markov decision processes with imprecise probabilities}},
url = {http://dx.doi.org/10.1016/j.artint.2015.09.005},
volume = {230},
year = {2016}
}
@article{Boutilier,
author = {Boutilier, Craig and Reiter, Ray and Price, Bob},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boutilier, Reiter, Price - Unknown - Symbolic Dynamic Programming for First-Order MDPs The Q-function.pdf:pdf},
title = {{Symbolic Dynamic Programming for First-Order MDPs The Q-function}}
}
@article{Vandenberghe2011,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 07. Conjugate gradient method.pdf:pdf},
journal = {LECTURE NOTES},
title = {{07. Conjugate gradient method}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@phdthesis{Dudik2007,
author = {Dudik, M},
booktitle = {Maximum Entropy Density Estimation and Modeling Geographic Distribution of Species},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dudik - 2007 - Maximum entropy density estimation and modeling geographic distributions of species.pdf:pdf},
isbn = {9783907630280},
number = {September},
pages = {186},
pmid = {3232},
title = {{Maximum entropy density estimation and modeling geographic distributions of species}},
url = {ftp://128.112.136.55/techreports/2007/797.pdf},
year = {2007}
}
@inproceedings{AndrzejRus2014,
author = {Ruszczynski, Andrzej},
booktitle = {INFORMS Tutorials in Operations Research},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruszczynski - 2013 - Advances in Risk-Averse Optimization.pdf:pdf},
isbn = {9780984337842},
keywords = {decomposition methods,dynamic measures of risk,stochastic order},
pages = {168--190},
title = {{Advances in Risk-Averse Optimization}},
year = {2013}
}
@article{Hinton1989b,
author = {Hinton, Geoffrey E.},
doi = {10.1016/0004-3702(89)90049-0},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton - 1989 - Connectionist learning procedures.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
month = {sep},
number = {1-3},
pages = {185--234},
title = {{Connectionist learning procedures}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0004370289900490},
volume = {40},
year = {1989}
}
@article{Birge1989,
author = {Birge, J R and Wets, R J B},
journal = {Mathematical Programming},
pages = {131--149},
title = {{Sublinear upper bounds for stochastic programs with recourse}},
volume = {43},
year = {1989}
}
@misc{Santos2001,
author = {Santos, Manuel S and Rust, John},
title = {{Convergence Properties of Policy Iteration}},
year = {2001}
}
@article{Rogers2007,
author = {Rogers, David F and Plante, Robert D and Wong, Richard T and Evans, James R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rogers, Plante - 1991 - Aggregation and disaggregation techniques and methodology in optimization.pdf:pdf},
journal = {Operations Research},
number = {4},
pages = {553--582},
title = {{Aggregation and disaggregation techniques and methodology in optimization}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.39.4.553},
volume = {39},
year = {1991}
}
@phdthesis{Hwang2011,
author = {Hwang, D},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hwang - 2011 - Projected equation and aggregation-based approximate dynamic programming methods for Tetris.pdf:pdf},
title = {{Projected equation and aggregation-based approximate dynamic programming methods for Tetris}},
url = {http://dspace.mit.edu/handle/1721.1/66033},
year = {2011}
}
@book{Murty1997,
annote = {From Duplicate 1 ( 


Linear complementarity, linear and nonlinear programming


- Murty, Katta G )

},
author = {Murty, Katta G},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murty - 1997 - LINEAR COMPLEMENTARITY , LINEAR AND NONLINEAR PROGRAMMING Internet Edition.pdf:pdf},
title = {{Linear complementarity, linear and nonlinear programming}},
year = {1997}
}
@article{Carpara2009,
annote = {From Duplicate 2 ( Bidimensional packing by bilinear programming - Caprara, Alberto; Monaci, Michele )
},
author = {Caprara, Alberto and Monaci, Michele and Carpara, Alberto},
doi = {10.1007/s10107-007-0184-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caprara, Monaci - 2007 - Bidimensional packing by bilinear programming.pdf:pdf},
isbn = {1010700701847},
issn = {0025-5610},
journal = {Mathematical Programming Series A},
month = {aug},
number = {1},
pages = {75--108},
title = {{Bidimensional packing by bilinear programming}},
url = {http://link.springer.com/10.1007/s10107-007-0184-7},
volume = {118},
year = {2009}
}
@article{Wilf1994,
abstract = {Preface to the Second Edition many new problems and solutions, a number of improvements in the pre- sentation, and corrections. It also contains an Appendix that describes some of the features of computer algebra programs that are of particular importance in the study of generating functions. I am indebted to many people for helping to make this a better book. This edition contains several new areas of application, in chapter 4, Bruce Sagan, in particular, made many helpful suggestions as a result of a test run in his classroom. Many readers took up my offer (which is now repeated) to supply a current errata sheet and my thanks in return for any errors discovered.},
author = {Wilf, Herbert S},
doi = {10.2307/2324771},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilf - 1994 - Generatingfunctionology.pdf:pdf},
isbn = {1568812795},
issn = {00029890},
journal = {Reproduction},
pages = {231},
title = {{Generatingfunctionology}},
year = {1994}
}
@article{Blass1984,
author = {Blass, Andreas and Burris, Stanley and Sankappanavar, H. P.},
doi = {10.2307/2322184},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blass, Burris, Sankappanavar - 1984 - A Course in Universal Algebra.pdf:pdf},
issn = {00029890},
journal = {The American Mathematical Monthly},
month = {jan},
number = {1},
pages = {64},
title = {{A Course in Universal Algebra}},
url = {http://www.jstor.org/stable/2322184?origin=crossref},
volume = {91},
year = {1984}
}
@misc{Bertsimas2000,
abstract = {DIMITRIS Sloan School of Management and Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA 02139, dbertsimmit.edu},
author = {Bertsimas, Dimitris and Nino-Mora, Jose},
booktitle = {Operations Research},
doi = {10.1287/opre.48.1.80.12444},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Nino-Mora - 2000 - Restless Bandits, Linear Programming Relaxations, and a Primal-Dual Index Heuristic.pdf:pdf},
issn = {0030-364X},
number = {1},
pages = {80--90},
title = {{Restless Bandits, Linear Programming Relaxations, and a Primal-Dual Index Heuristic}},
volume = {48},
year = {2000}
}
@inproceedings{Xiao2006,
author = {Xiao, Lin and Sun, Jun and Boyd, Stephen},
booktitle = {{\{}I{\}}nternational {\{}C{\}}onference on {\{}M{\}}achine {\{}L{\}}earning},
title = {{A duality view of spectral methods for dimensionality reduction}},
year = {2006}
}
@article{Dhurandhar2014,
author = {Dhurandhar, Amit and Petrik, Marek},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhurandhar, Petrik - 2014 - Efficient and accurate methods for updating generalized linear models with multiple feature additions.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {feature selection,group lasso,lasso,linear regression,logistic regressions},
number = {1},
pages = {2607--2627},
title = {{Efficient and accurate methods for updating generalized linear models with multiple feature additions}},
url = {http://dl.acm.org/citation.cfm?id=2670332},
volume = {15},
year = {2014}
}
@article{ODonnell2012,
author = {O'Donnell, Jessica and Gallagher, Rachael V. and Wilson, Peter D. and Downey, Paul O. and Hughes, Lesley and Leishman, Michelle R.},
doi = {10.1111/j.1365-2486.2011.02537.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {SDMs,invasives},
mendeley-tags = {SDMs,invasives},
month = {feb},
number = {2},
pages = {617--629},
title = {{Invasion hotspots for non-native plants in Australia under current and future climates}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2011.02537.x},
volume = {18},
year = {2012}
}
@article{Division2005,
author = {Division, Nysdec},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Division - 2005 - Division of Water A Primer on Aquatic Plant Management in New York State April 2005 - DRAFT -.pdf:pdf},
number = {April},
title = {{Division of Water A Primer on Aquatic Plant Management in New York State April 2005 - DRAFT -}},
year = {2005}
}
@phdthesis{Asif2008,
author = {Asif, Salman},
school = {School of Electrical and Computer Engineering, Georgia Institute of Technology},
title = {{Primal Dual Pursuit: A Homotopy-method based algorithm for the {\{}Dantzig{\}} selector}},
year = {2008}
}
@article{Lavaei2012,
author = {Lavaei, Javad and Low, Steven H.},
doi = {10.1109/TPWRS.2011.2160974},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lavaei, Low - 2012 - Zero Duality Gap in Optimal Power Flow Problem.pdf:pdf},
issn = {0885-8950},
journal = {IEEE Transactions on Power Systems},
month = {feb},
number = {1},
pages = {92--107},
title = {{Zero Duality Gap in Optimal Power Flow Problem}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5971792},
volume = {27},
year = {2012}
}
@article{Elith2009,
abstract = {Species distribution models (SDMs) are numerical tools that combine observations of species occurrence or abundance with environmental estimates. They are used to gain ecological and evolutionary insights and to predict distributions across landscapes, sometimes requiring extrapolation in space and time. SDMs are now widely used across terrestrial, freshwater, and marine realms. Differences in methods between disciplines reflect both differences in species mobility and in “established use.” Model realism and robustness is influenced by selection of relevant predictors and modeling method, consideration of scale, how the interplay between environmental and geographic factors is handled, and the extent of extrapolation. Current linkages between SDM practice and ecological theory are often weak, hindering progress. Remaining challenges include: improvement of methods for modeling presence-only data and for model selection and evaluation; accounting for biotic interactions; and assessing model uncertainty.},
author = {Elith, Jane and Leathwick, John R.},
doi = {10.1146/annurev.ecolsys.110308.120159},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elith, Leathwick - 2009 - Species Distribution Models Ecological Explanation and Prediction Across Space and Time.pdf:pdf},
issn = {1543-592X},
journal = {Annual Review of Ecology, Evolution, and Systematics},
keywords = {SDM,climate change,equilibrium,invasions,niche,predict,presence-only,spatial},
language = {en},
mendeley-tags = {SDM,equilibrium},
month = {dec},
number = {1},
pages = {677--697},
publisher = {Annual Reviews},
title = {{Species Distribution Models: Ecological Explanation and Prediction Across Space and Time}},
url = {http://www.annualreviews.org.silk.library.umass.edu/eprint/HWR4cusJrXYCSPZ9sUDj/full},
volume = {40},
year = {2009}
}
@article{Parsons2009,
author = {Parsons, D.J. and Benjamin, L.R. and Clarke, J. and Ginsburg, D. and Mayes, a. and a.E. Milne and Wilkinson, D.J.},
doi = {10.1016/j.compag.2008.08.007},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parsons et al. - 2009 - Weed Manager—A model-based decision support system for weed management in arable crops.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
keywords = {decision support,dynamic programming,heuristics,models,optimisation,stochastic,weeds},
month = {mar},
number = {2},
pages = {155--167},
title = {{Weed Manager—A model-based decision support system for weed management in arable crops}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169908002019},
volume = {65},
year = {2009}
}
@article{Pilanci2014,
annote = {Does this demonstrate that sketching is better than subsampling?},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.7203v1},
author = {Pilanci, Mert and Wainwright, MJ},
eprint = {arXiv:1404.7203v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pilanci, Wainwright - 2014 - Randomized Sketches of Convex Programs with Sharp Guarantees.pdf:pdf},
journal = {arXiv preprint arXiv:1404.7203},
pages = {1--37},
title = {{Randomized Sketches of Convex Programs with Sharp Guarantees}},
url = {http://arxiv.org/abs/1404.7203},
year = {2014}
}
@article{Todd1990,
author = {Todd, MJ and Ye, Y},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Todd, Ye - 1990 - A centered projective algorithm for linear programming.pdf:pdf},
journal = {Mathematics of Operations Research},
title = {{A centered projective algorithm for linear programming}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:A+centered+projective+algorithm+for+linear+programming{\#}0},
year = {1990}
}
@article{McEneaney2004,
author = {McEneaney, William M},
journal = {Applied {\{}M{\}}athematics and {\{}O{\}}ptimization},
title = {{Some classes of imperfect information finite state-space stochastic games with finite-dimensional solutions}},
year = {2004}
}
@techreport{Slade,
archivePrefix = {arXiv},
arxivId = {arXiv:1707.09055v1},
author = {Slade, Patrick and Culbertson, Preston and Sunberg, Zachary and Kochenderfer, Mykel},
eprint = {arXiv:1707.09055v1},
file = {:home/marek/Downloads/1707.09055.pdf:pdf},
title = {{Simultaneous active parameter estimation and control using sampling-based Bayesian reinforcement learning}},
year = {2017}
}
@article{Talpaz1988,
author = {Talpaz, Hovav and Mjelde, James W},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talpaz, Mjelde - 1988 - Crop Irrigation Scheduling via Simulation-Based Experimentation.pdf:pdf},
keywords = {design matrix,experimentation,quadratic programming,response surface},
number = {1986},
pages = {184--192},
title = {{Crop Irrigation Scheduling via Simulation-Based Experimentation}},
volume = {13},
year = {1988}
}
@article{LYLE,
abstract = {Declining water tables on the Southern High Plains may reduce irrigated corn area in the region and/or cause a shift to deficit irrigated production. This research was conducted to determine optimum water management practices for low energy precision (LEPA) irrigation of corn with limited water supplies and to evaluate the prospects for deficit irrigation based on yield response. Irrigation quantities ranged from deficit to excess irrigation [0.4, 0.7, 1.0, and 1.3 BI (BI=ET-rainfall)] and were applied both alternate and every furrow at intervals of 3, 6, 9, and 12 days from 1989 through 1991. The study was conducted at Halfway, Texas, on a moderately prmeable (2.5 mm h-1) Olton loam soil. Seasonal irrigations (1.0 BI) ranged from 299 mm in 1991 to 453 mm in 1990. Highest corn grain yields were obtained with three-day and six-day irrigation intervals (11.1 Mg ha-1 each). Significant yield declines occurred for the 9-day (10.6 Mg ha-1) and 12-day (10.2 Mg ha-1) intervals. Grain yield increased with water quantity and ranged from 8.3 Mg ha-1 for the 0.4 BI treatment (147 mm average seasonal irrigation) to 12.4 Mg ha-1 for the 1.3 BI treatment (428 mm average irrigation). Applicator location (altenate vs. every furrow) had no effect on yield except for the 0.7 BI quantity treatment where alternate was greater than every furrow (P≤0.05). Water use efficiency responded significantly to water quantity (P≤0.05) with the highest occurring also at 0.7 BI (1.90 kg m-3). This research showed that irrigation quantities applied at infrequent intervals typical of furrow irrigation (9 to 12 days) can be reduced as much as 30{\%} by lowering the irrigation interval to six days or less without corn grain yield reduction. It was concluded that substantial water savings can be achieved by adopting a high frequency LEPA irrigation schedule and a moderate deficit irrigation management program (0.7 to 0.8 BI) without experiencing significant yield decline, but rather, resulting potentially in increased net returns},
author = {LYLE, W. M. and BORDOVSKY, J. P.},
issn = {0001-2351},
journal = {Transactions of the ASAE},
language = {eng},
number = {2},
pages = {455--462},
publisher = {American Society of Agricultural Engineers},
title = {{Lepa corn irrigation with limited water supplies}},
url = {http://cat.inist.fr/?aModele=afficheN{\&}cpsidt=3557817},
volume = {38}
}
@article{Chen1999,
annote = {From Duplicate 1 ( Value iteration and optimization of multiclass queueing networks - Chen, Rong-Rong; Meyn, Sean )
},
author = {Chen, Rong-Rong and Meyn, Sean},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Meyn - 1999 - Value iteration and optimization of multiclass queueing networks.pdf:pdf},
journal = {Queueing systems},
pages = {65--97},
title = {{Value iteration and optimization of multiclass queueing networks}},
volume = {32},
year = {1999}
}
@article{Federgruen1984a,
author = {Federgruen, Awi and Zipkin, Paul},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Federgruen, Zipkin - 1984 - A combined vehicle routing and inventory allocation problem.pdf:pdf},
journal = {Operations Research},
number = {5},
pages = {1019--1037},
title = {{A combined vehicle routing and inventory allocation problem}},
url = {http://or.journal.informs.org/content/32/5/1019.short},
volume = {32},
year = {1984}
}
@article{Holte1996,
author = {Holte, Robert C and Mkadmi, T and Zimmer, R M and Macdonald, A J},
journal = {Artificial Intelligence},
pages = {321--361},
title = {{Speeding up problem solving by abstraction: a graph oriented approach}},
volume = {85},
year = {1996}
}
@book{Lavine2009,
author = {Lavine, Michael},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lavine - 2005 - Introduction to statistical thought.pdf:pdf},
title = {{Introduction to statistical thought}},
url = {http://www.isds.duke.edu/courses/Fall04/sta213/book.pdf},
year = {2005}
}
@inproceedings{Petrik2012b,
author = {Petrik, Marek and Subramanian, Dharmashankar},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Subramanian - 2012 - An approximate solution method for large risk-averse Markov decision processes.pdf:pdf},
title = {{An approximate solution method for large risk-averse Markov decision processes}},
url = {http://arxiv.org/abs/1210.4901},
year = {2012}
}
@article{Mahadevan1996,
author = {Mahadevan, Sridhar},
journal = {Machine Learning},
pages = {159--195},
title = {{Average reward reinforcement learning: Foundations, algorithms, and empirical results}},
url = {citeseer.ist.psu.edu/mahadevan96average.html},
volume = {22},
year = {1996}
}
@misc{Bertsekas1997,
author = {Bertsekas, Dimitri P and Ioffe, Sergey},
institution = {LIDS},
title = {{Temporal differences-based policy iteration and applications in neuro-dynamic programming}},
year = {1997}
}
@article{Megiddo1983,
annote = {From Duplicate 1 (Linear-time algorithms for linear programming in R{\^{}}3 and related problems - Megiddo, Nimrod)

Shows how to solve LP in O(n) in dimensions 2 and 3 (and hence some quadratic programming)

better: see the recent review by Dyer, MartinMegiddo, Nimrod
Welzl, Emo

From Duplicate 2 (Linear-time algorithms for linear programming in R{\^{}}3 and related problems - Megiddo, Nimrod)

Shows how to solve LP in O(n) in dimensions 2 and 3 (and hence some quadratic programming)


better: see the recent review by Dyer, MartinMegiddo, Nimrod
Welzl, Emo},
author = {Megiddo, Nimrod},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Megiddo - 1983 - Linear-time algorithms for linear programming in R3 and related problems.pdf:pdf},
journal = {SIAM J Computing},
number = {4},
title = {{Linear-time algorithms for linear programming in R{\^{}}3 and related problems}},
volume = {12},
year = {1983}
}
@inproceedings{Harsha2011a,
author = {Harsha, Pavithra and Dahleh, Munther},
booktitle = {IEEE Conference on Decision and Control and European Control Conference},
doi = {10.1109/CDC.2011.6160862},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harsha, Dahleh - 2011 - Optimal sizing of energy storage for efficient integration of renewable energy.pdf:pdf},
isbn = {978-1-61284-801-3},
pages = {5813--5819},
title = {{Optimal sizing of energy storage for efficient integration of renewable energy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6160862},
year = {2011}
}
@article{Dutta1995,
author = {Dutta, PK},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dutta - 1995 - A folk theorem for stochastic games.pdf:pdf},
journal = {Journal of Economic Theory},
title = {{A folk theorem for stochastic games}},
url = {http://www.sciencedirect.com/science/article/pii/S0022053185710307},
year = {1995}
}
@inproceedings{Kveton2008,
author = {Kveton, Branislav and Hauskrecht, Milos},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
title = {{Partitioned Linear Programming Approximations for {\{}MDPs{\}}}},
year = {2008}
}
@article{Epenoux1963,
author = {D'Epenoux, G},
journal = {Management Science},
pages = {98--108},
title = {{A probabilistic production and inventory problem}},
volume = {10},
year = {1963}
}
@article{VanRoy2006,
annote = {Establishes tight approximation error bounds when the limiting distribution is known.




What kind of bounds would we get with the discounted occupancy frequencies?







The counterexample: Note that this example is meant for a minimization problem. Can be adapted to be the worst-case for the robust optimization.




It seems that the approximation can be even worse when an incorrect weight is chosen. That could be used as an motivation for using the robust approximation approach.




The bound in Theorem 4.1 does not generalize to "weighted" aggregations. Relevant citations:
[46] Tsitsiklis, J. N., B. Van Roy. 1996. Feature-based methods for large scale dynamic programming. Machine Learning 22 59–94
[24] Gordon, G. J. 1995. Stable function approximation in dynamic programming. Technical report CMU-CS-95-103, Carnegie Mellon University, Pittsburgh, PA.[25] Gordon, G. J. 1995. Stable function approximation in dynamic programming. Machine Learning: Proc. 12th Internat. Conf. (ICML), San Francisco, CA.
[26] Gordon, G. J. 1999. Approximate solutions to Markov decision processes. Ph.D. thesis, Carnegie Mellon University, Pittsburgh, PA.},
author = {{Van Roy}, Benjamin},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy - 2006 - Performance Loss Bounds for Approximate Value Iteration with State Aggregation.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy - 2005 - Performance Loss Bounds for Approximate Value Iteration with State Aggregation Preview of Results.pdf:pdf},
journal = {Mathematics of Operations Research},
month = {may},
number = {2},
pages = {234--244},
title = {{Performance loss bounds for approximate value iteration with state aggregation}},
volume = {31},
year = {2006}
}
@article{Queiroz2011,
author = {Queiroz, Anderson Rodrigo De},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Queiroz - 2011 - A Sampling-based Decomposition Algorithm with Application to Hydrothermal Scheduling Cut Formation and Solution Qualit.pdf:pdf},
title = {{A Sampling-based Decomposition Algorithm with Application to Hydrothermal Scheduling : Cut Formation and Solution Quality}},
year = {2011}
}
@article{Bradley2015,
abstract = {Aim Our understanding of potential ranges for native and non-native species is often based on their current geographic distributions. Non-native species have had less time than co-occurring native species to expand their ranges following introduction, so non-native ranges may under-represent suitable conditions. Therefore it is often assumed that species distribution models will predict disproportionately smaller potential ranges for non-natives than natives. We compare the distributions of native, endemic, alien and invasive plants to determine how the different range attributes of these groups might influence ecological forecasting. Location Continental USA. Methods We compared the geographic ranges of 13,575 plant species (9402 native, 2397 endemic, 1201 alien and 755 invasive) using (1) US only and (2) global distribution data from herbarium records. We calculated US longitudinal and latitudinal range extents as potential indicators of range-limiting factors, modelled potential range based on climate using principal components analysis, and calculated occupancy of potential ranges (range infilling). Results Contrary to expectations, modelled potential ranges were significantly larger for non-natives than natives, even for species with few occurrences. Distributions of native species, not invasive species, appeared strongly limited longitudinally. However, invasive plants occupied substantially less area within their climatically suitable ranges than native plants (lower range infilling). Main conclusions Invasive plant distributions were consistently broader, both climatically and geographically, than comparable native species. This suggests that invasive plant distribution models at regional scales are not underpredicting potential ranges relative to models for native species. In contrast, the comparatively limited longitudinal ranges of native species suggest a high degree of non-climatic limitation, which is likely to cause distribution models to underpredict the potential ranges of native species. Invasive plants have not achieved the degree of range infilling expected relative to natives. Thus, plants introduced to the US still have plenty of space to invade.},
author = {Bradley, Bethany A. and Early, Regan and Sorte, Cascade J B},
doi = {10.1111/geb.12275},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradley, Early, Sorte - 2015 - Space to invade Comparative range infilling and potential range of invasive and native plants.pdf:pdf},
isbn = {1466822X},
issn = {14668238},
journal = {Global Ecology and Biogeography},
keywords = {Alien,Bioclimatic envelope model,Dispersal,Ecological niche model,Equilibrium,Exotic,Introduced,Occupancy,Plant invasion},
month = {mar},
number = {3},
pages = {348--359},
title = {{Space to invade? Comparative range infilling and potential range of invasive and native plants}},
url = {http://doi.wiley.com/10.1111/geb.12275},
volume = {24},
year = {2015}
}
@article{Alarie2001a,
author = {Alarie, S and Audet, Charles and Jaumard, Brigitte and Savard, Gilles},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alarie et al. - 2001 - Concavity cuts for disjoint bilinear programming.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Audet, Jaumard, Savard - 2001 - Concavity cuts for disjoint bilinear programming.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alarie et al. - 2001 - Concavity cuts for disjoint bilinear programming(2).pdf:pdf},
isbn = {1010701002},
journal = {Mathematical Programming},
keywords = {bound algorithm,branch and,concavity cuts,disjoint bilinear programming,global optimization,linear maxmin programming},
number = {January},
pages = {373--398},
title = {{Concavity cuts for disjoint bilinear programming}},
url = {http://link.springer.com/article/10.1007/PL00011428},
volume = {398},
year = {2001}
}
@inproceedings{Phillips2004,
abstract = {We study the problem of modeling species geographic distributions, a critical problem in conservation biology. We propose the use of maximum-entropy techniques for this problem, specifically, sequential-update algorithms that can handle a very large number of features. We describe experiments comparing maxent with a standard distribution-modeling tool, called GARP, on a dataset containing observation data for North American breeding birds. We also study how well maxent performs as a function of the number of training examples and training time, analyze the use of regularization to avoid overfitting when the number of examples is small, and explore the interpretability of models constructed using maxent.},
author = {Phillips, Steven J. and Dudik, Miroslav and Schapire, Robert E.},
booktitle = {International Conference on Machine Learning (ICML)},
doi = {10.1145/1015330.1015412},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Dud{\'{i}}k, Schapire - 2004 - A maximum entropy approach to species distribution modeling.pdf:pdf},
isbn = {1581138285},
issn = {00147672},
pmid = {6379},
title = {{A maximum entropy approach to species distribution modeling}},
url = {http://portal.acm.org/citation.cfm?doid=1015330.1015412},
year = {2004}
}
@article{Brunskill2009,
annote = {From Duplicate 1 ( Provably Efficient Learning with Typed Parametric Models - Brunskill, Emma; Leffler, Bethany R; Littman, Michael L )
},
author = {Brunskill, Emma and Leffler, Bethany R and Li, Lihong and Littman, Michael L and Roy, Nicholas},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brunskill, Leffler, Littman - 2009 - Provably Efficient Learning with Typed Parametric Models.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {provably efficient learning,reinforcement learning},
pages = {1955--1988},
title = {{Provable Efficient Learning with Typed Parametric Models}},
volume = {10},
year = {2009}
}
@article{Menache2005,
author = {Menache, Ishai and Mannor, Shie and Shimkin, Nahum},
journal = {Annals of {\{}O{\}}perations {\{}R{\}}esearch},
pages = {215--238},
title = {{Basis function adaptation in temporal difference reinforcement learning}},
volume = {134},
year = {2005}
}
@article{Rennie2010,
abstract = {We have described some of the problems with modeling mixed acoustic signals in the log spectral domain using graphical models, as well as some current approaches to handling these problems for multitalker speech separation and recognition. We have also reviewed methods for inference on FHMMs (factorial hidden Markov model) and methods for handling the nonlinear interaction function in the log spectral domain. These methods are capable of separating and recognizing speech better than human listeners on the SSC task.},
author = {Rennie, Steven and Hershey, John and Olsen, Peder},
doi = {10.1109/MSP.2010.938081},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rennie, Hershey, Olsen - 2010 - Single-channel multitalker speech recognition.pdf:pdf},
isbn = {1053-5888},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {6},
pages = {66--80},
title = {{Single-channel multitalker speech recognition}},
volume = {27},
year = {2010}
}
@inproceedings{Dhurandhar2016,
abstract = {We propose a method for building an interpretable recommender system for personalizing online content and promotions. Historical data available for the system consists of customer features, provided content (promotions), and user responses. Unlike in a standard multi-class classification setting, misclassification costs depend on both recommended actions and customers. Our method transforms such a data set to a new set which can be used with standard interpretable multi-class classification algorithms. The transformation has the desirable property that minimizing the standard misclassification penalty in this new space is equivalent to minimizing the custom cost function.},
archivePrefix = {arXiv},
arxivId = {1606.05819},
author = {Dhurandhar, Amit and Oh, Sechan and Petrik, Marek},
booktitle = {CML Workshop on Human Interpretability in Machine Learning},
eprint = {1606.05819},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhurandhar, Oh, Petrik - 2016 - Building an Interpretable Recommender via Loss-Preserving Transformation.pdf:pdf},
title = {{Building an Interpretable Recommender via Loss-Preserving Transformation}},
url = {http://arxiv.org/abs/1606.05819},
year = {2016}
}
@article{Saad1997,
annote = {From Duplicate 1 ( Analysis of Augmented Krylov Subspace Methods - Saad, Yousef )
},
author = {Saad, Yousef},
doi = {10.1137/S0895479895294289},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad - 1997 - Analysis of Augmented Krylov Subspace Methods.pdf:pdf},
issn = {0895-4798},
journal = {S{\{}IAM{\}} {\{}J{\}}ournal on {\{}M{\}}atrix {\{}A{\}}nalysis and {\{}A{\}}pplications},
keywords = {1,65f,ams subject classification,block-gmres,deflated iterations,in,introduction,it has recently been,krylov methods,observed that significant improvements,pii,s0895479895294289},
month = {apr},
number = {2},
pages = {435--449},
title = {{Analysis of augmented {\{}K{\}}rylov subspace methods}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0895479895294289},
volume = {18},
year = {1997}
}
@phdthesis{Farias2002,
author = {de Farias, Daniela P},
title = {{The linear programming approach to approximate dynamic programming: Theory and application}},
year = {2002}
}
@article{Kotani2011,
abstract = {The management programs for invasive species have been proposed and implemented in many regions of the world. However, practitioners and scientists have not reached a consensus on how to control them yet. One reason is the presence of various uncertainties associated with the management. To give some guidance on this issue, we characterize the optimal strategy by developing a dynamic model of invasive species management under uncertainties. In particular, focusing on (i) growth uncertainty and (ii) measurement uncertainty, we identify how these uncertainties affect optimal strategies and value functions. Our results suggest that a rise in growth uncertainty causes the optimal strategy to involve more restrained removals and the corresponding value function to shift up. Furthermore, we also find that a rise in measurement uncertainty affects optimal policies in a highly complex manner, but their corresponding value functions generally shift down as measurement uncertainty rises. Overall, a rise in growth uncertainty can be beneficial, while a rise in measurement uncertainty brings about an adverse effect, which implies the potential gain of precisely identifying the current stock size of invasive species. ?? 2011 Elsevier Inc.},
author = {Kotani, Koji and Kakinaka, Makoto and Matsuda, Hiroyuki},
doi = {10.1016/j.mbs.2011.06.002},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kotani, Kakinaka, Matsuda - 2011 - Optimal invasive species management under multiple uncertainties.pdf:pdf},
isbn = {0025-5564},
issn = {00255564},
journal = {Mathematical Biosciences},
keywords = {Bioeconomic model,Dynamic programming,Growth uncertainty,Invasive species management,Measurement uncertainty,Value functions},
number = {1},
pages = {32--46},
pmid = {21704642},
publisher = {Elsevier Inc.},
title = {{Optimal invasive species management under multiple uncertainties}},
url = {http://dx.doi.org/10.1016/j.mbs.2011.06.002},
volume = {233},
year = {2011}
}
@inproceedings{Thomas2015a,
author = {Thomas, Philip S. and Teocharous, Georgios and Ghavamzadeh, Mohammad},
booktitle = {International Conference on Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas, Teocharous, Ghavamzadeh - 2015 - High Confidence Policy Improvement.pdf:pdf},
number = {2002},
title = {{High Confidence Policy Improvement}},
year = {2015}
}
@article{Lifshitz2014a,
author = {Lifshitz, Doron and Weiss, George},
doi = {10.1109/TAC.2014.2323136},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lifshitz, Weiss - 2014 - Optimal Control of a Capacitor-Type Energy Storage System.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lifshitz, Weiss - 2014 - Optimal Control of a Capacitor-Type Energy Storage System(2).pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
number = {1},
pages = {1--6},
title = {{Optimal Control of a Capacitor-Type Energy Storage System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6814310},
volume = {9286},
year = {2014}
}
@techreport{Zhang2017,
author = {Zhang, Yuanhui and Steimle, Lauren N and Denton, Brian T},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steimle, Denton - Unknown - Markov Decision Processes for Screening and Treatment of Chronic Diseases.pdf:pdf},
title = {{Markov Decision Processes for Screening and Treatment of Chronic Diseases}},
year = {2017}
}
@inproceedings{Tangamchit2002,
author = {Tangamchit, Poj and Dolan, John M and Koshla, Pradeep K},
booktitle = {{\{}IEEE{\}} {\{}I{\}}nternational {\{}C{\}}onference on {\{}R{\}}obotics and {\{}A{\}}utomation},
pages = {1296--1301},
title = {{The necessity of average rewards in cooperative multirobot learning}},
year = {2002}
}
@article{Buckley2014,
author = {Buckley, S. and Ettl, M. and Jain, P. and Luss, R. and Petrik, M. and Ravi, R. K. and Venkatramani, C.},
doi = {10.1147/JRD.2014.2344515},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buckley et al. - 2014 - Social media and customer behavior analytics for personalized customer engagements.pdf:pdf},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
month = {sep},
number = {5/6},
pages = {7:1--7:12},
title = {{Social media and customer behavior analytics for personalized customer engagements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6964876},
volume = {58},
year = {2014}
}
@article{Atallah2014,
author = {Atallah, Shady S. and Gomez, Miguel I. and Conrad, Jon M. and Nyrop, Jan P},
doi = {10.1093/ajae/aau032},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Atallah et al. - 2014 - A Plant-Level, Spatial, Bioeconomic Model of Plant Disease Diffusion and Control Grapevine Leafroll Disease.pdf:pdf},
journal = {American Journal of Agricultural Economics},
keywords = {bioeconomic models,c15,c63,cellular automata,computational methods,d24,disease control,grapevine leafroll disease,jel codes,spatial-dynamic processes},
number = {1},
pages = {199--218},
title = {{A Plant-Level, Spatial, Bioeconomic Model of Plant Disease Diffusion and Control: Grapevine Leafroll Disease}},
volume = {97},
year = {2014}
}
@article{Kaufmann2012,
abstract = {The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem had been open since 1933. In this paper we answer it positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret. The proof is accompanied by a numerical comparison with other optimal policies, experiments that have been lacking in the literature until now for the Bernoulli case.},
archivePrefix = {arXiv},
arxivId = {1205.4217},
author = {Kaufmann, Emilie and Korda, Nathaniel and Munos, R{\'{e}}mi},
eprint = {1205.4217},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaufmann, Korda, Munos - 2012 - Thompson Sampling An Asymptotically Optimal Finite Time Analysis.pdf:pdf},
isbn = {3642341055},
journal = {Algorithmic Learning Theory},
number = {1},
pages = {15},
title = {{Thompson Sampling: An Asymptotically Optimal Finite Time Analysis}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-34106-9{\_}18{\%}5Cnhttp://arxiv.org/abs/1205.4217{\%}5Cnhttp://arxiv.org/abs/1205.4217},
year = {2012}
}
@article{Sims1998,
author = {Sims, JT and Simard, RR and Joern, BC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sims, Simard, Joern - 1998 - Phosphorus loss in agricultural drainage Historical perspective and current research.pdf:pdf},
journal = {Journal of Environmental {\ldots}},
title = {{Phosphorus loss in agricultural drainage: Historical perspective and current research}},
url = {https://dl.sciencesocieties.org/publications/jeq/abstracts/27/2/JEQ0270020277},
year = {1998}
}
@inproceedings{Szer2006,
author = {Szer, Daniel and Charpillet, Francois},
booktitle = {National Conrence on Artificial Intelligence},
title = {{Point-based dynamic programming for {\{}DEC-POMDP{\}}s}},
year = {2006}
}
@misc{Jones2013,
author = {Jones, K. J. and Boote, J. W.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones, Boote - 2013 - Protocols for AgMIP Crop Model Improvement Teams.pdf:pdf},
title = {{Protocols for AgMIP Crop Model Improvement Teams}},
year = {2013}
}
@article{McMahan2003,
abstract = {We investigate methods for planning in a Markov Decision Process where$\backslash$nthe cost function is chosen by an adversary after we fix our policy.$\backslash$nAs a running example, we consider a robot path planning problem where$\backslash$n$\backslash$ncosts are in uenced by sensors that an adversary places in the environment.$\backslash$nWe formulate the problem as a zero-sum matrix game where rows correspond$\backslash$nto deterministic policies for the planning player and columns correspond$\backslash$nto cost vectors the adversary can select. For a fixed cost vector,$\backslash$nfast algorithms (such as value iteration) are available for solving$\backslash$nMDPs. We develop efficient algorithms for matrix games where such$\backslash$nbest response oracles exist. We show that for our path planning problem$\backslash$nthese algorithms are at least an order of magnitude faster than direct$\backslash$nsolution of the linear programming formulation.},
author = {McMahan, H Brendan and Gordon, Geoffrey J and Blum, Avrim},
doi = {10.1.1.13.9116},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McMahan, Gordon, Blum - 2003 - Planning in the Presence of Cost Functions Controlled by an Adversary.pdf:pdf},
isbn = {1-57735-189-4},
journal = {Icml},
pages = {536--543},
title = {{Planning in the Presence of Cost Functions Controlled by an Adversary}},
year = {2003}
}
@article{Lu2010,
author = {Lu, Tyler and P{\'{a}}l, D and P{\'{a}}l, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, P{\'{a}}l, P{\'{a}}l - 2010 - Contextual multi-armed bandits.pdf:pdf},
journal = {International Conference on Machine Learning},
pages = {485--492},
title = {{Contextual multi-armed bandits}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/AISTATS2010{\_}LuPP10.pdf},
volume = {9},
year = {2010}
}
@article{Vandenberghe2011f,
annote = {from http://www.ee.ucla.edu/{\~{}}vandenbe/ee236c.html{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}Spring 2010-2011 edition{\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}largely based on Stanford course:{\textless}m:underline{\textgreater}
          {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}EE364b (Convex Optimization II){\textless}/m:underline{\textgreater} at Stanford University.},
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 01. Gradient method (2011).pdf:pdf},
journal = {LECTURE NOTES},
pages = {1--25},
title = {{01. Gradient method (2011)}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@article{Konno1976,
author = {Konno, Hiroshi},
doi = {10.1007/BF01580380},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konno - 1976 - Maximization of A convex quadratic function under linear constraints.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
month = {dec},
number = {1},
pages = {117--127},
title = {{Maximization of A convex quadratic function under linear constraints}},
url = {http://link.springer.com/10.1007/BF01580380},
volume = {11},
year = {1976}
}
@book{Gittins2011,
author = {Gittins, John and Glazerbrook, Kevin and Weber, Richard},
edition = {2nd},
publisher = {John Wiley {\&} Sons},
title = {{Multi-Armed Bandit Allocation Indices}},
year = {2011}
}
@misc{Rosen1986,
author = {Rosen, J Ben},
institution = {University of Minnesota, Minneapolis},
month = {may},
title = {{Solution of general {\{}LCP{\}} by {\{}0-1{\}} Mixed integer programming}},
year = {1986}
}
@article{Farias2004a,
author = {{Van Roy}, Benjamin and Farias, Daniela Pucci De},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Roy, Farias - 2004 - A Linear Program for Bellman Error Minimization with Performance Guarantees.pdf:pdf},
pages = {1--35},
title = {{A Linear Program for Bellman Error Minimization with Performance Guarantees}},
year = {2004}
}
@article{Gottlob2000,
author = {Gottlob, Georg and Leone, Nicola and Scarcello, Francesco},
doi = {10.1016/S0004-3702(00)00078-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gottlob, Leone, Scarcello - 2000 - A comparison of structural CSP decomposition methods.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {1999,biconnected components,constraint satisfaction,cycle cutsets,decomposition methods,degree of cyclicity,has been published in,hypergraphs,hypertree width,ijcai-99,intelligence,international,joint conference on artificial,part of this work,preliminary form in the,proceedings of the sixteenth,stockholm,sweden,tractable cases,tree-clustering,treewidth},
month = {dec},
number = {2},
pages = {243--282},
title = {{A comparison of structural CSP decomposition methods}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370200000783},
volume = {124},
year = {2000}
}
@inproceedings{Rachelson2010,
annote = {Defines a notion of continuity of MDPs that is very appealing. It is more general than my definition and I think it could be sufficient in order to guarantee nice theoretical results for sampling in my algorithms.

Would be nice to verify experimentally what is the constant for some common problems.},
author = {Rachelson, Emmanuel and Lagoudakis, MG},
booktitle = {International Symposium on Artificial Intelligence and Mathematics},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rachelson, Lagoudakis - 2010 - On the locality of action domination in sequential decision making.pdf:pdf},
title = {{On the locality of action domination in sequential decision making.}},
url = {http://www.researchgate.net/publication/221186156{\_}On{\_}the{\_}locality{\_}of{\_}action{\_}domination{\_}in{\_}sequential{\_}decision{\_}making/file/9fcfd5051c4eaad94f.pdf},
year = {2010}
}
@article{Rabatel2011,
author = {Rabatel, Gilles and Gorretta, Nathalie and Labb, Sylvain},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabatel, Gorretta, Labb - 2011 - Getting NDVI Spectral Bands from a Single Standard RGB Digital Camera A Methodological Approach.pdf:pdf},
keywords = {aerial imaging,multispectral,ndvi,near-infrared band},
pages = {333--342},
title = {{Getting NDVI Spectral Bands from a Single Standard RGB Digital Camera : A Methodological Approach}},
year = {2011}
}
@article{Hauser2009,
abstract = {Virtual advisors often increase sales for those customers who find such online advice to be convenient and helpful. However, other customers take a more active role in their purchase decisions and prefer more detailed data. In general, we expect that websites are more preferred and increase sales if their characteristics (e.g., more detailed data) match customers' cognitive styles (e.g., more analytic). “Morphing” involves automatically matching the basic “look and feel” of a website, not just the content, to cognitive styles. We infer cognitive styles from clickstream data with Bayesian updating. We then balance exploration (learning how morphing affects purchase probabilities) with exploitation (maximizing short-term sales) by solving a dynamic program (partially observable Markov decision process). The solution is made feasible in real time with expected Gittins indices. We apply the Bayesian updating and dynamic programming to an experimental BT Group (formerly British Telecom) website using data from 835 priming respondents. If we had perfect information on cognitive styles, the optimal “morph” assignments would increase purchase intentions by 21{\%}. When cognitive styles are partially observable, dynamic programming does almost as well—purchase intentions can increase by almost 20{\%}. If implemented system-wide, such increases represent approximately {\$}80 million in additional revenue.},
author = {Hauser, John R. and Urban, Glen L. and Liberali, Guilherme and Braun, Michael},
doi = {10.1287/mksc.1080.0459},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hauser et al. - 2009 - Website Morphing.pdf:pdf},
isbn = {07322399},
issn = {0732-2399},
journal = {Marketing Science},
keywords = {Bayesian methods,Internet marketing,automated marketing,clickstream analysis,cognitive styles,dynamic programming,telecommunications,website design},
number = {2},
pages = {202--223},
pmid = {40400771},
title = {{Website Morphing}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/mksc.1080.0459},
volume = {28},
year = {2009}
}
@article{20142014,
abstract = {Grant Proposal Guide},
author = {2016, NSF},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/2016 - 2016 - Proposal And Award Policy and Procedure.pdf:pdf},
pages = {80},
title = {{Proposal And Award Policy and Procedure}},
year = {2016}
}
@book{YuriiNesterov2004,
author = {{Yurii Nesterov}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yurii Nesterov - 2004 - Introductory Lectures on Convex Optimization.pdf:pdf},
title = {{Introductory Lectures on Convex Optimization}},
year = {2004}
}
@inproceedings{Domingos1999,
author = {Domingos, Pedro},
booktitle = {Proceedings of ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {10.1145/312129.312220},
isbn = {1581131437},
pages = {155--164},
title = {{MetaCost: A general method for making classifiers cost-sensitive}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312220},
year = {1999}
}
@article{Wardlow2002,
author = {Wardlow, BD and Tadesse, T and Brown, JF and Gu, Y},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wardlow et al. - 2002 - The Vegetation Drought Response Index (VegDRI) A New Drought Monitoring Approach for Vegetation.pdf:pdf},
journal = {drought.gov},
title = {{The Vegetation Drought Response Index (VegDRI): A New Drought Monitoring Approach for Vegetation}},
url = {http://www.drought.gov/workshops/remotesensing/abstracts/brian{\_}wardlow2.pdf},
year = {2002}
}
@article{Farahmand2016,
author = {Farahmand, Amir-massoud and Nikovski, Daniel N},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Farahmand, Nikovski - 2016 - Value-Aware Loss Function for Model Learning in Reinforcement Learning.pdf:pdf},
title = {{Value-Aware Loss Function for Model Learning in Reinforcement Learning}},
url = {https://ewrl.files.wordpress.com/2016/11/ewrl13-2016-submission{\_}32.pdf},
volume = {54},
year = {2016}
}
@misc{St,
author = {Many},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Many - 2015 - Lake George Map.pdf:pdf},
title = {{Lake George Map}},
year = {2015}
}
@article{Massart,
author = {Massart, Pascal},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Massart - 1990 - The tight constant in the dvoretzky-kiefer-wolfowitz inequality.pdf:pdf},
journal = {The Annals of Probability},
number = {3},
pages = {1269--1283},
title = {{The tight constant in the dvoretzky-kiefer-wolfowitz inequality}},
volume = {18},
year = {1990}
}
@article{Yu2008,
author = {Yu, Jia Yuan and Mannor, Shie and Shimkin, Nahum},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Mannor, Shimkin - 2008 - Markov Decision Processes with Arbitrary Reward Processes.pdf:pdf},
journal = {Mathematics of Operations Research},
keywords = {1,90c99,93e99,been a topic of,dynamic programming,introduction no-regret algorithms for,markov decision processes,markov processes,ms subject classification,msc2000 subject classification,much in-,no-regret algorithms,online decision problems have,online learning,or,primary,secondary,stochastic games},
pages = {268--281},
title = {{Markov Decision Processes with Arbitrary Reward Processes}},
year = {2008}
}
@article{Jornsten1995,
author = {Jornsten, K and Leisten, R},
journal = {European Journal of Operations Research},
pages = {120--141},
title = {{Decomposition and iterative aggregation in hierarchical and decentralized planning structures}},
volume = {86},
year = {1995}
}
@article{Bernstein2010,
abstract = {We propose a model-based learning algorithm, the Adaptive-resolution Reinforcement Learning (ARL) algorithm, that aims to solve the online, continuous state space reinforcement learning problem in a deterministic domain. Our goal is to combine adaptive-resolution approximation schemes with efficient exploration in order to obtain fast (polynomial) learning rates. The proposed algorithm uses an adaptive approximation of the optimal value function using kernel-based averaging, going from coarse to fine kernel-based representation of the state space, which enables us to use finer resolution in the "important" areas of the state space, and coarser resolution elsewhere. We consider an online learning approach, in which we discover these important areas online, using an uncertainty intervals exploration technique. In addition, we introduce an incremental variant of the ARL (IARL), which is a more practical version of the original algorithm with reduced computational complexity at each stage. Polynomial learning rates in terms of mistake bound (in a PAC framework) are established for these algorithms, under appropriate continuity assumptions.},
author = {Bernstein, Andrey and Shimkin, Nahum},
doi = {10.1007/s10994-010-5186-7},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernstein, Shimkin - 2010 - Adaptive-resolution reinforcement learning with polynomial exploration in deterministic domains.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {Adaptive resolution,Efficient exploration,Kernel functions,Reinforcement learning},
number = {1999},
pages = {359--397},
title = {{Adaptive-resolution reinforcement learning with polynomial exploration in deterministic domains}},
volume = {81},
year = {2010}
}
@article{Papadimitriou1994,
author = {Papadimitriou, CH and Yannakakis, M},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papadimitriou, Yannakakis - 1994 - On complexity as bounded rationality.pdf:pdf},
journal = {{\ldots} -sixth annual ACM symposium on {\ldots}},
pages = {726--733},
title = {{On complexity as bounded rationality}},
url = {http://dl.acm.org/citation.cfm?id=195445},
year = {1994}
}
@inproceedings{Johns2007,
author = {Johns, Jeff and Mahadevan, Sridhar},
booktitle = {International Conference on Machine Learning},
title = {{Constructing Basis Functions from Directed Graphs for Value Function Approximation}},
year = {2007}
}
@article{Adulyasak2015,
author = {Adulyasak, Yossiri and Varakantham, Pradeep and Ahmed, Asrar and Jaillet, Patrick},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adulyasak et al. - 2015 - Solving Uncertain MDPs with Objectives that are Separable over Instantiations of Model Uncertainty.pdf:pdf},
isbn = {9781577357032},
journal = {AAAI Conference on Artificial Intelligence},
keywords = {Reasoning Under Uncertainty Track},
pages = {3454--3460},
title = {{Solving Uncertain MDPs with Objectives that are Separable over Instantiations of Model Uncertainty}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9843},
year = {2015}
}
@inproceedings{Rockafellar2014,
author = {Rockafellar, R Tyrrell and Royset, Johannes O},
booktitle = {INFORMS Tutorials in Operations Research},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockafellar, Royset - 2013 - Superquantiles and Their Applications to Risk, Random Variables, and Regression.pdf:pdf},
isbn = {9780984337842},
pages = {151--167},
title = {{Superquantiles and Their Applications to Risk, Random Variables, and Regression}},
year = {2013}
}
@article{Kloss,
author = {Kloss, Sebastian and Walser, Sabine},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kloss, Walser - Unknown - Evaluation of different crop models for estimating the petentials to increase the water use efficiency under c.pdf:pdf},
number = {0},
pages = {1--12},
title = {{Evaluation of different crop models for estimating the petentials to increase the water use efficiency under climate variability}},
volume = {49}
}
@misc{Simoncini2006,
author = {Simoncini, Valeria and Szyld, Daniel B},
institution = {Temple},
title = {{Recent camputational developments in {\{}K{\}}rylov subspace methods for linear systems}},
year = {2006}
}
@book{MacKay2003,
author = {MacKay, DJC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/MacKay - 2003 - Information theory, inference, and learning algorithms.pdf:pdf},
isbn = {0521642981},
title = {{Information theory, inference, and learning algorithms}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Information+Theory+,+Inference+,+and+Learning+Algorithms{\#}0},
year = {2003}
}
@article{Sutton1996,
abstract = {On large problems, reinforcement learning systems must use parame- terized function approximators such as neural networks in order to gen- eralize between similar situations and actions. In these cases there are no strong theoretical results on the accuracy of convergence, and com- putational results have been mixed. In particular, Boyan and Moore reported at last year'smeeting a series of negative results in attempting to apply dynamic programming together with function approximation to simple control problems with continuous state spaces. In this paper, we present positive results for all the control tasks they attempted, and for one that is significantly larger. The most important differences are that we used sparse-coarse-coded function approximators (CMACs) whereas they used mostly global function approximators, and that we learned online whereas they learned offline. Boyan and Moore and others have suggested that the problems they encountered could be solved by using actual outcomes (“rollouts”), as in classical Monte Carlo methods, and as in the TD($\lambda$) algorithm when $\lambda$ = 1. However, in our experiments this always resulted in substantially poorer perfor- mance. We conclude that reinforcement learning can work robustly in conjunction with function approximators, and that there is little justification at present for avoiding the case of general $\lambda$.},
author = {Sutton, Rs},
doi = {10.1.1.51.4764},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton - 1996 - Generalization in reinforcement learning Successful examples using sparse coarse coding.pdf:pdf},
isbn = {9784907764272},
issn = {10495258},
journal = {Advances in neural information processing systems},
pages = {1038--1044},
title = {{Generalization in reinforcement learning: Successful examples using sparse coarse coding}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Generalization+in+Reinforcement+Learning:+Successful+Examples+Using+Sparse+Coarse+Coding{\#}0},
year = {1996}
}
@inproceedings{Ganeshapillai2013,
abstract = {To reduce risk, investors seek assets that have high expected return and are unlikely to move in tandem. Correlation measures are generally used to quantify the connections between equities. The 2008 financial crisis, and its aftermath, demonstrated the need for a better way to quantify these connections. We present a machine learning-based method to build a connectedness matrix to address the shortcomings of correlation in capturing events such as large losses. Our method uses an unconstrained optimization to learn this matrix, while ensuring that the resulting ma- trix is positive semi-definite. We show that this matrix can be used to build portfolios that not only “beat the market,” but also outperform optimal (i.e., minimum variance) portfolios.},
author = {Ganeshapillai, Gartheeban and Guttag, John and Lo, Andrew W.},
booktitle = {Proceedings of the 30th International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ganeshapillai, Guttag, Lo - 2013 - Learning connections in financial time series.pdf:pdf},
keywords = {finance,machine learning,portfolio,time series},
pages = {109--117},
title = {{Learning connections in financial time series}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/ganeshapillai13},
volume = {28},
year = {2013}
}
@incollection{Tewari2008,
address = {Cambridge, MA},
author = {Tewari, Ambuj and Bartlett, Peter},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {Platt, J C and Koller, D and Singer, Y and Roweis, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tewari, Bartlett - 2008 - Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs.pdf:pdf},
pages = {1505--1512},
publisher = {MIT Press},
title = {{Optimistic Linear Programming gives Logarithmic Regret for Irreducible {\{}MDPs{\}}}},
year = {2008}
}
@article{Sherali2012,
author = {Sherali, HD and Dalkiran, Evrim and Liberti, Leo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sherali, Dalkiran, Liberti - 2012 - Reduced RLT representations for nonconvex polynomial programming problems.pdf:pdf},
journal = {Journal of Global Optimization},
keywords = {baron,global optimization,polynomial programs,reduced basis techniques,reformulation-linearization technique,rlt,semidefinite cuts},
title = {{Reduced RLT representations for nonconvex polynomial programming problems}},
url = {http://link.springer.com/article/10.1007/s10898-011-9757-3},
year = {2012}
}
@article{Dzeroski2001,
author = {Dzeroski, Saso and de Raedt, Luc and Driessens, Kurt},
journal = {Machine Learning},
pages = {7--52},
title = {{Relational Reinforcement Learning}},
volume = {43},
year = {2001}
}
@article{Nguy-Robertson2012,
annote = {The estimation is based on close-range hyperspectral data.},
author = {Nguy-Robertson, Anthony and Gitelson, Anatoly and Peng, Yi and Vi{\~{n}}a, Andr{\'{e}}s and Arkebauer, Timothy and Rundquist, Donald},
doi = {10.2134/agronj2012.0065},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguy-Robertson et al. - 2012 - Green Leaf Area Index Estimation in Maize and Soybean Combining Vegetation Indices to Achieve Maximal Sen.pdf:pdf},
issn = {0002-1962},
journal = {Agronomy Journal},
number = {5},
pages = {1336},
title = {{Green Leaf Area Index Estimation in Maize and Soybean: Combining Vegetation Indices to Achieve Maximal Sensitivity}},
url = {https://www.agronomy.org/publications/aj/abstracts/104/5/1336},
volume = {104},
year = {2012}
}
@misc{Bertsekas,
author = {Bertsekas, Dmitri},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas - Unknown - Dynamic Programming and Optimal Control Vol I.pdf:pdf},
title = {{Dynamic Programming and Optimal Control Vol I}}
}
@inproceedings{Jiang2015a,
author = {Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
booktitle = {International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2015 - The Dependence of Effective Planning Horizon on Model Accuracy.pdf:pdf},
isbn = {9781450337700},
issn = {15582914},
keywords = {discount factor,over-fitting,reinforcement learning},
pages = {1181--1189},
title = {{The Dependence of Effective Planning Horizon on Model Accuracy}},
year = {2015}
}
@misc{Bertsekas2012,
author = {Bertsekas, Dimitri P.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas - 2012 - Approximate Dynamic Programming.pdf:pdf},
title = {{Approximate Dynamic Programming}},
year = {2012}
}
@article{Vedula1996,
author = {Vedula, S. and Kumar, D. Nagesh},
doi = {10.1029/95WR03110},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vedula, Kumar - 1996 - An Integrated Model for Optimal Reservoir Operation for Irrigation of Multiple Crops.pdf:pdf},
issn = {00431397},
journal = {Water Resources Research},
month = {apr},
number = {4},
pages = {1101--1108},
title = {{An Integrated Model for Optimal Reservoir Operation for Irrigation of Multiple Crops}},
url = {http://doi.wiley.com/10.1029/95WR03110},
volume = {32},
year = {1996}
}
@article{Tran2017,
abstract = {We propose Edward, a Turing-complete probabilistic programming language. Edward defines two compositional representations---random variables and inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. In addition, Edward can reuse the modeling representation as part of inference, facilitating the design of rich variational models and generative adversarial networks. For efficiency, Edward is integrated into TensorFlow, providing significant speedups over existing probabilistic systems. For example, we show on a benchmark logistic regression task that Edward is at least 35x faster than Stan and 6x faster than PyMC3. Further, Edward incurs no runtime overhead: it is as fast as handwritten TensorFlow.},
archivePrefix = {arXiv},
arxivId = {1701.03757},
author = {Tran, Dustin and Hoffman, Matthew D. and Saurous, Rif A. and Brevdo, Eugene and Murphy, Kevin and Blei, David M.},
eprint = {1701.03757},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tran et al. - 2017 - Deep Probabilistic Programming.pdf:pdf},
pages = {1--18},
title = {{Deep Probabilistic Programming}},
url = {http://arxiv.org/abs/1701.03757},
year = {2017}
}
@article{Guhaniyogi2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1303.0642v2},
author = {Guhaniyogi, Rajarshi and Dunson, David B},
eprint = {arXiv:1303.0642v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guhaniyogi, Dunson - 2013 - Bayesian Compressed Regression.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guhaniyogi, Dunson - 2013 - Bayesian Compressed Regression(2).pdf:pdf},
keywords = {compressed sensing,data compression,dimensionality reduction,large p,random projection,small n,sparsity,sufficient dimension reduction},
pages = {1--28},
title = {{Bayesian Compressed Regression}},
year = {2013}
}
@article{Baransi2014,
author = {Baransi, Akram and Maillard, Odalric-ambrym and Mannor, Shie and Baransi, Akram and Maillard, Odalric-ambrym and Ban-, Shie Mannor Sub-sampling Multi-armed},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baransi et al. - 2014 - Sub-sampling for Multi-armed Bandits.pdf:pdf},
title = {{Sub-sampling for Multi-armed Bandits}},
year = {2014}
}
@book{Sharipov2004,
author = {Sharipov, R},
booktitle = {arXiv preprint math/0403252},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharipov - 2004 - Quick introduction to tensor analysis.pdf:pdf},
title = {{Quick introduction to tensor analysis}},
url = {http://arxiv.org/abs/math/0403252},
year = {2004}
}
@article{Wu2011,
abstract = {The EM algorithm is a special case of a more general algorithm called the MM algorithm. Specific MM algorithms often have nothing to do with missing data. The first M step of an MM algorithm creates a surrogate function that is optimized in the second M step. In minimization, MM stands for majorize--minimize; in maximization, it stands for minorize--maximize. This two-step process always drives the objective function in the right direction. Construction of MM algorithms relies on recognizing and manipulating inequalities rather than calculating conditional expectations. This survey walks the reader through the construction of several specific MM algorithms. The potential of the MM algorithm in solving high-dimensional optimization and estimation problems is its most attractive feature. Our applications to random graph models, discriminant analysis and image restoration showcase this ability.},
archivePrefix = {arXiv},
arxivId = {1104.2203},
author = {Wu, Tong Tong and Lange, Kenneth},
doi = {10.1214/08-STS264},
eprint = {1104.2203},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Lange - 2011 - The MM Alternative to EM.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,inequalities,iterative majorization,maximum likelihood,penalization},
number = {4},
pages = {492--505},
title = {{The MM Alternative to EM}},
url = {http://arxiv.org/abs/1104.2203},
volume = {25},
year = {2011}
}
@inproceedings{Boutilier1995,
address = {San Francisco},
author = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Moise's},
booktitle = {International Joint Conference on Artificial Intelligence},
editor = {Mellish, Chris},
pages = {1104--1111},
title = {{Exploiting Structure in Policy Construction}},
url = {citeseer.ist.psu.edu/boutilier95exploiting.html},
year = {1995}
}
@article{Miller2011,
annote = {From Duplicate 1 ( Risk-averse two-stage stochastic linear programming: modeling and decomposition - Miller, Naomi; Ruszczy{\'{n}}ski, A )
},
author = {Miller, Naomi and Ruszczynski, Andrzej and Ruszczy{\'{n}}ski, A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Ruszczy{\'{n}}ski - 2011 - Risk-averse two-stage stochastic linear programming modeling and decomposition.pdf:pdf},
journal = {Operations Research},
pages = {125--132},
title = {{Risk-Averse Two-Stage Stochastic Linear Programming: Modeling and Decomposition}},
url = {http://or.journal.informs.org/content/59/1/125.short},
volume = {59},
year = {2011}
}
@book{Press2007,
author = {Press, William H and Teukolky, Saul A and Vetterling, William T},
editor = {3},
title = {{Numerical Recipes}},
year = {2007}
}
@book{Vanderbei2001,
annote = {From Duplicate 2 ( 


Linear Programming: Foundations and Extensions


- Vanderbei, Robert J )

},
author = {Vanderbei, Robert J},
edition = {2nd},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbei - 2001 - Linear Programming Foundations and Extensions.pdf:pdf},
publisher = {Springer},
title = {{Linear Programming: Foundations and Extensions}},
year = {2001}
}
@inproceedings{Zadrozny2003,
author = {Zadrozny, Bianca and Langford, John and Abe, Naoki},
booktitle = {International Conference on Data Mining (ICDM)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zadrozny, Langford, Abe - 2003 - Cost-Sensitive Learning by Cost-Proportionate Example Weighting.pdf:pdf},
pages = {435--442},
title = {{Cost-Sensitive Learning by Cost-Proportionate Example Weighting}},
year = {2003}
}
@article{George2006,
annote = {From Duplicate 1 ( Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming - George, Abraham P; Powell, Warren B )
},
author = {George, Abraham P and Powell, Warren B},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/George, Powell - 2006 - Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming.pdf:pdf},
journal = {Machine Learning},
number = {1},
pages = {167--198},
title = {{Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming}},
volume = {65},
year = {2006}
}
@article{Kiesel2013,
author = {Kiesel, Scott and Burns, Ethan and Ruml, Wheeler and Benton, J and Kreimendahl, Frank},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kiesel et al. - 2013 - Open World Planning for Robots via Hindsight Optimization.pdf:pdf},
journal = {ICAPS Planning and Robotics Workshop},
pages = {1--7},
title = {{Open World Planning for Robots via Hindsight Optimization}},
year = {2013}
}
@book{Sutton2016,
abstract = {CiteSeerX - Scientific documents that cite the following paper: Reinforcement learning: An introduction, chapter 11},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 2006 - Reinforcement Learning An Introduction.pdf:pdf},
author = {Sutton, Richard S and Barto, Andrew},
keywords = {Artificial intelligence,Cybernetics,Signal process},
pmid = {18255791},
publisher = {MIT Press},
title = {{Reinforcement Learning: An Introduction (Second Edition)}},
year = {2006}
}
@article{Megiddo1984,
author = {Megiddo, Nimrod},
doi = {10.1145/2422.322418},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Megiddo - 1984 - Linear programming in linear time when the dimension is fixed.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM (JACM)},
month = {jan},
number = {1},
pages = {114--127},
title = {{Linear programming in linear time when the dimension is fixed}},
url = {http://portal.acm.org/citation.cfm?doid=2422.322418 http://dl.acm.org/citation.cfm?id=322418},
volume = {31},
year = {1984}
}
@article{Shor1977,
author = {Shor, N Z},
journal = {Cybernetics},
pages = {94--96},
title = {{Cut-off method with space extension in convex programming problems}},
volume = {13},
year = {1977}
}
@article{Phillips2009,
abstract = {Most methods for modeling species distributions from occurrence records require additional data representing the range of environmental conditions in the modeled region. These data, called background or pseudo-absence data, are usually drawn at random from the entire region, whereas occurrence collection is often spatially biased toward easily accessed areas. Since the spatial bias generally results in environmental bias, the difference between occurrence collection and background sampling may lead to inaccurate models. To correct the estimation, we propose choosing background data with the same bias as occurrence data. We investigate theoretical and practical implications of this approach. Accurate information about spatial bias is usually lacking, so explicit biased sampling of background sites may not be possible. However, it is likely that an entire target group of species observed by similar methods will share similar bias. We therefore explore the use of all occurrences within a target group as bias...},
author = {Phillips, Steven J. and Dud{\'{i}}k, Miroslav and Elith, Jane and Graham, Catherine H. and Lehmann, Anthony and Leathwick, John and Ferrier, Simon},
doi = {10.1890/07-2153.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {MaxEnt,SDM,background data,niche modeling,presence-only distribution models,pseudo-absence,sample selection bias,sampling bias,species distribution modeling,target group},
language = {EN},
mendeley-tags = {MaxEnt,SDM,sampling bias},
month = {jan},
number = {1},
pages = {181--197},
publisher = {Ecological Society of America},
title = {{Sample selection bias and presence-only distribution models: implications for background and pseudo-absence data}},
url = {http://www.esajournals.org/doi/full/10.1890/07-2153.1},
volume = {19},
year = {2009}
}
@article{Puterman1982,
author = {Puterman, Martin L},
journal = {Operations Research},
title = {{Action elimination procedures for modified policy iteration}},
volume = {30},
year = {1982}
}
@misc{Jukna1996,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.3418v1},
author = {Fearnley, John},
eprint = {arXiv:1003.3418v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fearnley - 2010 - Exponential Lower Bounds for Policy Iteration.pdf:pdf},
title = {{Exponential Lower Bounds for Policy Iteration}},
year = {2010}
}
@book{Ben-Tal2009,
author = {Ben-Tal, Aharon and Ghaoui, Laurent El and Nemirovski, Arkadi},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben-Tal, Ghaoui, Nemirovski - 2009 - Robust Optimization.pdf:pdf},
publisher = {Princeton University Press},
title = {{Robust Optimization}},
year = {2009}
}
@article{Bertsimas2002,
author = {Bertsimas, Dimitris and Popescu, I},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Popescu - 2002 - On the relation between option and stock prices a convex optimization approach.pdf:pdf},
journal = {Operations Research},
number = {2},
pages = {358--374},
title = {{On the relation between option and stock prices: a convex optimization approach}},
url = {http://or.journal.informs.org/content/50/2/358.short},
volume = {50},
year = {2002}
}
@article{Barber2011,
abstract = {Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.},
author = {Barber, David},
doi = {10.1017/CBO9780511804779},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barber - 2011 - Bayesian Reasoning and Machine Learning.pdf:pdf},
isbn = {9780521518147},
issn = {9780521518147},
keywords = {Computational, Information-Theoretic Learning with,Learning/Statistics {\&} Optimisation,Theory {\&} Algorithms},
pmid = {16931139},
title = {{Bayesian Reasoning and Machine Learning}},
url = {http://eprints.pascal-network.org/archive/00007920/},
year = {2011}
}
@article{Robertson1988,
author = {Robertson, G. Philip and Huston, Michael A and Evans, Francis C},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertson, Huston, Evans - 1988 - Spatial Variability in a Successional Plan Community Patterns of Nitrogen Availability.pdf:pdf},
journal = {Ecology},
keywords = {cycling,denitrification,geostatistics,kriging,nitrification,nitrogen mineralization,nutrient,old-field succession,semivariograms,soil nitrogen,spatial variability,succession},
number = {5},
pages = {1517--1524},
title = {{Spatial Variability in a Successional Plan Community: Patterns of Nitrogen Availability}},
volume = {69},
year = {1988}
}
@inproceedings{Petrik2009b,
address = {New York, New York, USA},
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {International Conference on Machine Learning},
doi = {10.1145/1553374.1553478},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein, Bank - 2009 - Blood Management Using Approximate Linear Programming Blood Inventory Management Problem Aggregate su.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2009 - Constraint relaxation in approximate linear programs.pdf:pdf},
isbn = {9781605585161},
publisher = {ACM Press},
title = {{Constraint relaxation in approximate linear programs}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553478},
year = {2009}
}
@inproceedings{Song2016,
author = {Song, Zhao and Parr, Ronald and Liao, Xuejun and Carin, Lawrence},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2016 - Linear Feature Encoding for Reinforcement Learning.pdf:pdf},
title = {{Linear Feature Encoding for Reinforcement Learning}},
year = {2016}
}
@article{Lusena2001,
author = {Lusena, Christopher and Goldsmith, Judy and Mundhenk, Martin},
journal = {Journal of Artificial Intelligence Research},
pages = {83--103},
title = {{Nonapproximability results for partially observable Markov decision processes}},
volume = {14},
year = {2001}
}
@inproceedings{Zahavi2006,
author = {Zahavi, Uzi and Felner, Ariel and Schaeffer, Jonathan and Sturtevant, Nathan},
booktitle = {National Conference on AI},
title = {{Inconsistent heuristics}},
year = {2006}
}
@article{Brafman2003a,
author = {Brafman, Ronen I and Heckerman, David and Shani, Guy},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brafman, Heckerman, Shani - 2003 - Recommendation as a Stochastic Sequential Decision Problem.pdf:pdf},
journal = {Proceedings of the 13th International Conference on Automated Planning and Scheduling (ICAPS)},
pages = {164--173},
title = {{Recommendation as a Stochastic Sequential Decision Problem}},
year = {2003}
}
@article{Viappiani2009,
address = {New York, New York, USA},
author = {Viappiani, Paolo and Boutilier, Craig},
doi = {10.1145/1639714.1639732},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viappiani, Boutilier - 2009 - Regret-based optimal recommendation sets in conversational recommender systems.pdf:pdf},
isbn = {9781605584355},
journal = {Proceedings of the third ACM conference on Recommender systems - RecSys '09},
keywords = {critiquing,minimax,preference elicitation,recommender systems},
pages = {101},
publisher = {ACM Press},
title = {{Regret-based optimal recommendation sets in conversational recommender systems}},
url = {http://portal.acm.org/citation.cfm?doid=1639714.1639732},
year = {2009}
}
@article{Webster2006,
abstract = {Invasive exotic species pose significant challenges for natural resource managers charged with the maintenance of biological diversity and the sustainable production of forest resources. In this article, we review what is known about the biology and control of some of the most serious woody invaders of eastern forests. Based on the parallels between these invasions, we propose a working framework for integrating invasive control into forestry practices. In general, early detection and rapid response to invasions are essential. However, given that consistently effective control strategies that are broadly applicable simply do not exist for many species, adaptive management strategies will be necessary.},
author = {Webster, Christopher R. and Jenkins, Michael A. and Jose, Shibu},
isbn = {0022-1201},
issn = {00221201},
journal = {Journal of Forestry},
keywords = {alien plants,invasive exotics,invasive species,perennial weeds},
number = {7},
pages = {366--374},
title = {{Woody invaders and the challenges they pose to forest ecosystems in the eastern United States}},
url = {http://www.ingentaconnect.com/content/saf/jof/2006/00000104/00000007/art00006},
volume = {104},
year = {2006}
}
@article{Frappier2004a,
abstract = {Abstract Effects of the non-indigenous shrub Rhamnus frangula L. (glossy buckthorn) on tree recruitment, herb cover, forest floor plant species richness, and R. frangula recruitment were tested in two southeastern New Hampshire Pinus forests using a randomized complete-block field experiment. The treatment, applied in January of 2000, was the presence of well-established R. frangula populations with three levels: R. frangula absent prior to experiment (“uninvaded”), {\textgreater} 90{\%} R. frangula cover (“Rhamnus present”), and removal of {\textgreater} 90{\%} R. frangula cover (“Rhamnus removed”). After 2 years of measurements, Rhamnus present had significantly lower first-year native tree seedling density than Rhamnus removed and uninvaded plots (0.11, 0.40, and 0.40 seedlings/m2 respectively). First-year native tree seedling density in the Rhamnus removed and uninvaded treatments were similar. Neither percent herb cover nor plant species richness were significantly affected by the removal of R. frangula in the two years following t...},
author = {Frappier, Brian and Eckert, Robert T. and Lee, Thomas D.},
doi = {10.1656/1092-6194(2004)011[0333:EROTNS]2.0.CO;2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frappier, Eckert, Lee - 2004 - Experimental Removal of the Non-indigenous Shrub Rhamnus frangula (Glossy Buckthorn) Effects on Native He.pdf:pdf},
issn = {1092-6194},
journal = {Northeastern Naturalist},
number = {3},
pages = {333--342},
title = {{Experimental Removal of the Non-indigenous Shrub Rhamnus frangula (Glossy Buckthorn): Effects on Native Herbs and Woody Seedlings}},
url = {http://www.bioone.org/doi/abs/10.1656/1092-6194{\%}25282004{\%}2529011{\%}255B0333{\%}253AEROTNS{\%}255D2.0.CO{\%}253B2},
volume = {11},
year = {2004}
}
@article{Fern2006,
author = {Fern, Alan and Yoon, Sungwook and Givan, Robert},
journal = {Journal of Artificial Intelligence Research (JAIR)},
pages = {85--118},
title = {{Approximate Policy Iteration with a Policy Language Bias: Solving Relational Markov Decision Processes}},
volume = {25},
year = {2006}
}
@article{Divino2015,
abstract = {Presence-only data are referred to situations in which a censoring mechanism acts on a binary response which can be partially observed only with respect to one outcome, usually denoting the presence of an attribute of interest. A typical example is the recording of species presence in ecological surveys. In this work a Bayesian approach to the analysis of presence-only data based on a two levels scheme is presented. A probability law and a case-control design are combined to handle the double source of uncertainty: one due to censoring and the other one due to sampling. In the paper, through the use of a stratified sampling design with non-overlapping strata, a new formulation of the logistic model for presence-only data is proposed. In particular, the logistic regression with linear predictor is considered. Estimation is carried out with a new Markov Chain Monte Carlo algorithm with data augmentation, which does not require the a priori knowl- edge of the population prevalence. The performance of the new algorithm is validated by means of extensive simulation experiments using three scenarios and compar- ison with optimal benchmarks. An application to data ex- isting in literature is reported in order to discuss the model behaviour in real world situations together with the results of an original study on termites occurrences data.},
author = {Divino, Fabio and Golini, Natalia and {Jona Lasinio}, Giovanna and Penttinen, Antti},
doi = {10.1007/s00477-015-1064-y},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Divino et al. - 2015 - Bayesian logistic regression for presence-only data.pdf:pdf},
isbn = {1436-3240},
issn = {14363259},
journal = {Stochastic Environmental Research and Risk Assessment},
keywords = {Case-control design,Censored data,Data augmentation,Markov Chain Monte Carlo algorithm,Stratified sampling,Two levels scheme},
number = {6},
pages = {1721--1736},
publisher = {Springer Berlin Heidelberg},
title = {{Bayesian logistic regression for presence-only data}},
url = {http://dx.doi.org/10.1007/s00477-015-1064-y},
volume = {29},
year = {2015}
}
@article{Culberson1998,
author = {Culberson, Joseph C and Schaeffer, Jonathan},
journal = {Computational Intelligence},
pages = {318--334},
title = {{Pattern databases}},
volume = {14},
year = {1998}
}
@article{Chandraker2008,
author = {Chandraker, Manmohan and Kriegman, David},
doi = {10.1109/CVPR.2008.4587846},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chandraker, Kriegman - 2008 - Globally optimal bilinear programming for computer vision applications.pdf:pdf},
isbn = {978-1-4244-2242-5},
journal = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
month = {jun},
pages = {1--8},
publisher = {Ieee},
title = {{Globally optimal bilinear programming for computer vision applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587846},
year = {2008}
}
@article{Hansen2001,
author = {Hansen, Eric A and Zilberstein, Shlomo},
journal = {Artificial Intelligence},
pages = {35--62},
title = {{{\{}LAO{\}} *: A heuristic search algorithm that finds solutions with loops}},
volume = {129},
year = {2001}
}
@article{Duchi2008,
author = {Duchi, John and Shalev-Shwartz, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duchi, Shalev-Shwartz - 2008 - Efficient projections onto the l 1-ball for learning in high dimensions.pdf:pdf},
journal = {{\ldots} on Machine learning},
title = {{Efficient projections onto the l 1-ball for learning in high dimensions}},
url = {http://dl.acm.org/citation.cfm?id=1390191},
year = {2008}
}
@article{Boyd2007a,
abstract = {GABAergic neurons are found in all layers of cerebral cortex and display many types of non-pyramidal morphology. Most are intensely immunoreactive for neuron-specific enolase, suggesting a high rate of metabolic activity. The molecular layer and subcortical white matter are strikingly enriched in GABAergic cell bodies compared to other cortical layers. In rat, cat and monkey, many GABAergic neurons in the subcortical white matter and certain cortical layers are also immunoreactive for the neuropeptide somatostatin. Somatostatin content may define a widespread subclass of GABAergic neurons in mammalian cerebral cortex. Some may be similar in function to reticular neurons of thalamus.},
author = {Boyd, Stephen and Xiao, Lin and Mutapcic, Almir and Mattingley, Jacob},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd et al. - 2007 - Notes on Decomposition Methods.pdf:pdf},
journal = {Notes},
number = {2006},
pages = {1--36},
title = {{Notes on Decomposition Methods}},
url = {http://www.core.org.cn/mirrors/Stanford/stanford/see.stanford.edu/materials/lsocoee364b/08-decomposition{\_}notes.pdf},
volume = {D},
year = {2007}
}
@inproceedings{Abbeel2007,
author = {Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng., Andrew Y},
booktitle = {Advances in Neural Information Processing Systems},
title = {{An Application of Reinforcement Learning to Aerobatic Helicopter Flight}},
year = {2007}
}
@article{Tesauro1995,
address = {New York, NY, USA},
author = {Tesauro, Gerald},
journal = {Commun. ACM},
pages = {58--68},
title = {{Temporal difference learning and TD-Gammon}},
volume = {38},
year = {1995}
}
@book{Horn1991,
author = {Johnson, CR Charles R and Horn, RA Roger A and Johnson, CR Charles R},
booktitle = {Cambridge University},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, Horn - 1991 - Topics in matrix analysis.pdf:pdf},
title = {{Topics in Matrix Analysis}},
url = {http://pharadiy.iwiin.com/b/topics-in-matrix-analysis-by-charles-r-johnson-and-roger-a-horn.pdf},
year = {1991}
}
@article{Kim2011,
author = {Kim, J. H. and Powell, W. B.},
doi = {10.1287/opre.1110.0971},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Powell - 2011 - Optimal Energy Commitments with Storage and Intermittent Supply.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
keywords = {2009 and has been,2010,2011,and on january 6,dynamic programming,energy,history,markov decision process,may 27,revised and re-submitted on,submitted on september 4,this paper was first},
month = {dec},
number = {6},
pages = {1347--1360},
title = {{Optimal Energy Commitments with Storage and Intermittent Supply}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1110.0971},
volume = {59},
year = {2011}
}
@article{Ye2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1208.5083v1},
author = {Ye, Yinyu},
eprint = {arXiv:1208.5083v1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ye - 2010 - The simplex method is strongly polynomial for the Markov decision problem with a fixed discount rate.pdf:pdf},
isbn = {9781611972511},
journal = {Mathematics of Operations Research},
number = {1},
pages = {1--11},
title = {{The simplex method is strongly polynomial for the Markov decision problem with a fixed discount rate}},
url = {http://www.stanford.edu/{~}yyye/simplexmdp.pdf},
year = {2010}
}
@book{Forsund2009,
author = {Forsund, Finn R},
publisher = {Springer US},
title = {{Hydropower Economics}},
year = {2009}
}
@article{Andrianakis2012,
author = {Andrianakis, Ioannis and Challenor, Peter G.},
doi = {10.1016/j.csda.2012.04.020},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrianakis, Challenor - 2012 - The effect of the nugget on Gaussian process emulators of computer models.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {computer experiments},
month = {dec},
number = {12},
pages = {4215--4228},
publisher = {Elsevier B.V.},
title = {{The effect of the nugget on Gaussian process emulators of computer models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947312001879},
volume = {56},
year = {2012}
}
@article{Haskell2015,
abstract = {In classical Markov decision process (MDP) theory, we search for a policy that, say, minimizes the expected infinite horizon discounted cost. Expectation is, of course, a risk neutral measure, which does not suffice in many applications, particularly in finance. We replace the ex- pectation with a general risk functional, and call such models risk-aware MDP models. We consider minimization of such risk functionals in two cases, the expected utility framework, and conditional value-at-risk, a popular coherent risk measure. Later, we consider risk-aware MDPs wherein the risk is expressed in the constraints. This includes stochastic dominance constraints, and the classical chance-constrained optimization problems. In each case, we develop a convex analytic approach to solve such risk-aware MDPs. In most cases, we show that the problem can be formulated as an infinite-dimensional linear program (LP) in occupation measures when we augment the state space. We provide a discretization method and finite approximations for solving the resulting LPs. A strik- ing result is that the chance-constrained MDP problem can be posed as an LP via the convex analytic method.},
author = {Haskell, William B. and Jain, Rahul},
doi = {10.1137/140969221},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haskell, Jain - 2015 - A Convex Analytic Approach To Risk-Aware Markov Decision Processes.pdf:pdf},
issn = {0178-8051},
journal = {Society for Industrial and Applied Mathematics},
keywords = {10,1137,130919507,65f08,65f10,65y05,65z05,adaptivity,aggregation,ams subject classifications,dirac operator,doi,domain decomposition,lattice qcd,multigrid,multilevel,parallel computing,wilson},
number = {3},
pages = {1569--1598},
title = {{A Convex Analytic Approach To Risk-Aware Markov Decision Processes}},
volume = {53},
year = {2015}
}
@inproceedings{Viappiani2009a,
author = {Viappiani, Paolo and Boutilier, Craig},
booktitle = {National Conference on AI (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viappiani, Boutilier - 2009 - Optimal Set Recommendations Based on Regret.pdf:pdf},
title = {{Optimal Set Recommendations Based on Regret}},
url = {http://www.cs.uni-dortmund.de/nps/de/Forschung/Publikationen/Graue{\_}Reihe1/Ver{\_}{\_}ffentlichungen{\_}2009/825.pdf{\#}page=26},
year = {2009}
}
@article{Falk2011,
author = {Falk, Ruma},
doi = {10.1080/13546783.2011.613690},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Falk - 2011 - When truisms clash Coping with a counterintuitive problem concerning the notorious two-child family.pdf:pdf},
issn = {1354-6783},
journal = {Thinking {\&} Reasoning},
month = {nov},
number = {4},
pages = {353--366},
title = {{When truisms clash: Coping with a counterintuitive problem concerning the notorious two-child family}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13546783.2011.613690},
volume = {17},
year = {2011}
}
@article{Andreev2005,
abstract = {Abstract. Although Conditional Value-at-Risk has significant advantages over traditional risk measures such as Value-at-Risk, it has not been adopted by practitioners as quickly as expected. One of the reasons slowing down its progress has been the lack of simple tools for its computation. In this paper we consider calculating CVaR when the underlying asset is modelled using a diffusion process with a linear drift and prespecified marginal density. The results are summarized in two closed-form formulas which can be effortlessly applied by risk managers to calculate CVaR for a number of commonly used probability distributions. Example of calculations is included. KEY WORDS: conditional value-at-risk, coherence, risk measure, expected shortfall},
author = {Andreev, Andriy and Kanto, Antti and Malo, Pekka},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Andreev, Kanto, Malo - 2005 - Closed-Form Calculation of Cvar.pdf:pdf},
journal = {Sweedish School of Economics},
title = {{Closed-Form Calculation of Cvar}},
year = {2005}
}
@article{Megiddo1989,
author = {Megiddo, Nimrod and Shub, Michael},
journal = {Mathematics of Operations Research},
pages = {97--146},
title = {{Boundary behavior of interior point algorithms in linear programming}},
volume = {14},
year = {1989}
}
@article{Darivianakis2016,
abstract = {The cooperative energy management of aggregated buildings has recently received a great deal of interest due to substantial potential energy savings. These gains are mainly obtained in two ways: (i) Exploiting the load shifting capabilities of the cooperative buildings; (ii) Utilizing the expensive but energy efficient equipment that is commonly shared by the building community (e.g., heat pumps, batteries and photovoltaics). Several deterministic and stochastic control schemes that strive to realize these savings, have been proposed in the literature. A common difficulty with all these methods is integrating knowledge about the disturbances affecting the system. In this context, the underlying disturbance distributions are often poorly characterized based on historical data. In this paper, we address this issue by exploiting the historical data to construct families of distributions which contain these underlying distributions with high confidence. We then employ tools from data-driven robust optimization to formulate a multistage stochastic optimization problem which can be approximated by a finite-dimensional linear program. The proposed method is suitable for tackling large scale systems since its complexity grows polynomially with respect to the system variables. We demonstrate its efficacy in a numerical study, in which it is shown to outperform, in terms of energy cost savings and constraint violations, established solution techniques from the literature. We conclude this study by showing the significant energy gains that are obtained by cooperatively managing a collection of buildings with heterogeneous characteristics.},
archivePrefix = {arXiv},
arxivId = {1607.05441},
author = {Darivianakis, Georgios and Georghiou, Angelos and Smith, Roy S. and Lygeros, John},
eprint = {1607.05441},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Darivianakis et al. - 2016 - The Power of Diversity Data-Driven Robust Predictive Control for Energy Efficient Buildings and Districts.pdf:pdf},
journal = {Optimization Online},
title = {{The Power of Diversity: Data-Driven Robust Predictive Control for Energy Efficient Buildings and Districts}},
url = {http://arxiv.org/abs/1607.05441},
year = {2016}
}
@article{Cornuejols2007a,
author = {Cornu{\'{e}}jols, G{\'{e}}rard},
doi = {10.1007/s10107-006-0086-0},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cornu{\'{e}}jols - 2007 - Valid inequalities for mixed integer linear programs.pdf:pdf},
issn = {0025-5610},
journal = {Mathematical Programming},
keywords = {elementary closure,gomory cut,lift-and-project,mixed integer linear program,mixed integer rounding,polyhedra,split cut,union},
month = {jan},
number = {1},
pages = {3--44},
title = {{Valid inequalities for mixed integer linear programs}},
url = {http://link.springer.com/10.1007/s10107-006-0086-0},
volume = {112},
year = {2007}
}
@article{Jakubauskas2002,
author = {Jakubauskas, Mark E and Legates, David R and Kastens, Jude H},
doi = {10.1016/S0168-1699(02)00116-3},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jakubauskas, Legates, Kastens - 2002 - Crop identification using harmonic analysis of time-series AVHRR NDVI data.pdf:pdf},
issn = {01681699},
journal = {Computers and Electronics in Agriculture},
month = {dec},
number = {1-3},
pages = {127--139},
title = {{Crop identification using harmonic analysis of time-series AVHRR NDVI data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0168169902001163},
volume = {37},
year = {2002}
}
@inproceedings{Kansky2017,
author = {Kansky, Ken and Silver, Tom and Miguel, Eldawy and Lou, Xinghua},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kansky et al. - 2017 - Schema Networks Zero-shot Transfer with a Generative Causal Model of Intuitive Physics.pdf:pdf},
title = {{Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics}},
year = {2017}
}
@article{Graves1982,
author = {Graves, SC},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves - 1982 - Using Lagrangean techniques to solve hierarchical production planning problems.pdf:pdf},
journal = {Management Science},
number = {3},
title = {{Using Lagrangean techniques to solve hierarchical production planning problems}},
url = {http://mansci.journal.informs.org/content/28/3/260.short},
year = {1982}
}
@book{Puterman2005,
annote = {Page offset: +17 pages},
author = {Puterman, Martin L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman - 2005 - Markov decision processes Discrete stochastic dynamic programming.pdf:pdf},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Markov decision processes: Discrete stochastic dynamic programming}},
year = {2005}
}
@inproceedings{Dean1997,
author = {Dean, Thomas and Givan, Robert and Leach, Sonia M},
booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI)},
title = {{Model reduction techniques for computing approximately optimal solutions for {\{}M{\}}arkov decision problems}},
year = {1997}
}
@article{Fernandez2015,
abstract = {Species distribution modeling is widely applied to predict invasive species distributions and species range shifts under climate change. Accurate predictions depend upon meeting the assumption that ecological niches are conserved, i.e., spatially or temporally transferable. Here we present a multi-taxon comparative analysis of niche conservatism using biological invasion events well documented in natural history museum collections. Our goal is to assess spatial transferability of the climatic niche of a range of noxious terrestrial invasive species using two complementary approaches. First we compare species' native versus invasive ranges in environmental space using two distinct methods, Principal Components Analysis and Mahalanobis distance. Second we compare species' native versus invaded ranges in geographic space as estimated using the species distribution modeling technique Maxent and the comparative index Hellinger's I. We find that species exhibit a range of responses, from almost complete transferability, in which the invaded niches completely overlap with the native niches, to a complete dissociation between native and invaded ranges. Intermediate responses included expansion of dimension attributable to either temperature or precipitation derived variables, as well as niche expansion in multiple dimensions. We conclude that the ecological niche in the native range is generally a poor predictor of invaded range and, by analogy, the ecological niche may be a poor predictor of range shifts under climate change. We suggest that assessing dimensions of niche transferability prior to standard species distribution modeling may improve the understanding of species' dynamics in the invaded range.},
author = {Fern{\'{a}}ndez, Miguel and Hamilton, Healy},
doi = {10.1371/journal.pone.0119891},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern{\'{a}}ndez, Hamilton - 2015 - Ecological niche transferability using invasive species as a case study.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
number = {3},
pmid = {25785858},
publisher = {Public Library of Science},
title = {{Ecological niche transferability using invasive species as a case study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25785858 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4364959},
volume = {10},
year = {2015}
}
@techreport{Johnston2011,
author = {Johnston, Ryan Z. and Matlock, Marty D.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnston, Matlock - 2011 - Geospatial Climate Data.pdf:pdf},
institution = {University of Arkansas},
title = {{Geospatial Climate Data}},
url = {https://www.agriskmanagementforum.org/sites/agriskmanagementforum.org/files/Documents/Geospatial Climate Data 2011.pdf},
year = {2011}
}
@article{Bubeck2012b,
abstract = {Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the Thirties, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this survey, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.},
archivePrefix = {arXiv},
arxivId = {1204.5721},
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
doi = {10.1561/2200000024},
eprint = {1204.5721},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems(4).pdf:pdf},
isbn = {9781601986269},
issn = {9781601986269},
journal = {arXiv.org},
keywords = {()},
pages = {138},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
url = {http://arxiv.org/abs/1204.5721v2{\%}5Cnpapers3://publication/uuid/FD8C90A4-1651-4BB5-9123-D84384F10271},
volume = {cs.LG},
year = {2012}
}
@article{Guigues2013,
author = {Guigues, Vincent},
doi = {10.1007/s10589-013-9584-1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guigues - 2013 - SDDP for some interstage dependent risk-averse problems and application to hydro-thermal planning.pdf:pdf},
issn = {0926-6003},
journal = {Computational Optimization and Applications},
keywords = {algorithms and,and phrases,averse optimization and decomposition,carlo sampling,interstage dependency and monte,stochastic programming and risk},
month = {jul},
pages = {1--26},
title = {{SDDP for some interstage dependent risk-averse problems and application to hydro-thermal planning}},
url = {http://link.springer.com/10.1007/s10589-013-9584-1},
year = {2013}
}
@article{Eep2013,
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - EnOcean Equipment Profiles.pdf:pdf},
pages = {1--127},
title = {{EnOcean Equipment Profiles}},
year = {2013}
}
@article{Bront2009,
author = {Bront, J. J. M. and Mendez-Diaz, I. and Vulcano, G.},
doi = {10.1287/opre.1080.0567},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bront, Mendez-Diaz, Vulcano - 2009 - A Column Generation Algorithm for Choice-Based Network Revenue Management.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {mar},
number = {3},
pages = {769--784},
title = {{A Column Generation Algorithm for Choice-Based Network Revenue Management}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1080.0567},
volume = {57},
year = {2009}
}
@article{Wingate2005,
annote = {From Duplicate 1 ( 


Prioritization methods for accelerating MDP solvers


- Wingate, David; Seppi, Kevin D )

},
author = {Wingate, David and Seppi, Kevin D},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wingate, Seppi - 2005 - Prioritization methods for accelerating MDP solvers.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {851--881},
title = {{Prioritization methods for accelerating MDP solvers}},
volume = {6},
year = {2005}
}
@article{Kling2017,
abstract = {State variables in many renewable resource management problems, such as the abundance of a fish stock, are imperfectly observed over time. In systems characterized by state uncertainty, decision makers often invest in monitoring to learn about the level of a stock. We develop a stochastic bioeconomic model of marine invasive species management under state uncertainty. The decision maker in our model simultaneously evaluates optimal investment in monitoring and population control. Using a recently-devised method for solving continuous-state Partially Observable Markov Decision Processes (POMDPs), we find that the ability to learn through monitoring can alter the role of population control in the optimal policy function, for example by reducing control intensity in favor of monitoring. Optimal monitoring depends on the management context, including in our application lionfish population structure. The rich transient dynamics of our model depend critically on the relationship between the initial conditions for information and invader abundance.},
author = {Kling, David M. and Sanchirico, James N. and Fackler, Paul L.},
doi = {10.1016/j.jeem.2017.01.001},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kling, Sanchirico, Fackler - 2017 - Optimal monitoring and control under state uncertainty Application to lionfish management.pdf:pdf},
issn = {10960449},
journal = {Journal of Environmental Economics and Management},
keywords = {Bioeconomics,Invasive species,Lionfish,Monitoring,Partially observable Markov decision process,State uncertainty},
pages = {223--245},
publisher = {Elsevier Inc.},
title = {{Optimal monitoring and control under state uncertainty: Application to lionfish management}},
url = {http://dx.doi.org/10.1016/j.jeem.2017.01.001},
volume = {84},
year = {2017}
}
@book{Bienstock2002,
annote = {From Duplicate 1 ( Potential function methods for approximately solving linear programming problems: Theory and practice - Bienstock, Daniel )

From Duplicate 1 ( Potential Function Methods for Problems : Theory and Practice - Bienstock, Daniel )
And Duplicate 3 ( Potential Function Methods for Problems : Theory and Practice - Bienstock, Daniel )
},
author = {Bienstock, Daniel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bienstock - 2001 - Potential Function Methods for Problems Theory and Practice.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bienstock - 2001 - Potential Function Methods for Problems Theory and Practice(2).pdf:pdf},
title = {{Potential Function Methods for Approximately Solving Linear Programming Problems: Theory and Practice}},
year = {2002}
}
@article{Adler2012,
author = {Adler, Ilan},
doi = {10.1007/s00182-012-0328-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adler - 2012 - The equivalence of linear programs and zero-sum games.pdf:pdf},
issn = {0020-7276},
journal = {International Journal of Game Theory},
keywords = {farkas,lemma,linear programming,minimax theorem,strong duality,theorem,villes,zero-sum games},
month = {apr},
number = {1},
pages = {165--177},
title = {{The equivalence of linear programs and zero-sum games}},
url = {http://link.springer.com/10.1007/s00182-012-0328-8},
volume = {42},
year = {2012}
}
@article{Recht2011,
annote = {References the paper that introduces the coherence of matrices. The smallest coherence that can be achieved is 1.

An incoherent matrix may be hard to estimate from samples because a single point may be missing and there is no way to recover it.},
archivePrefix = {arXiv},
arxivId = {arXiv:0910.0651v2},
author = {Recht, Benjamin},
eprint = {arXiv:0910.0651v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Recht - 2011 - A simpler approach to matrix completion.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {compressed sensing,convex optimization,low-rank matrices,matrices,matrix completion,nuclear norm minimization,operator chernoff bound,random},
pages = {1--13},
title = {{A simpler approach to matrix completion}},
url = {http://dl.acm.org/citation.cfm?id=2185803},
year = {2011}
}
@article{Vandenberghe2012,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2012 - 01. Gradient method (2012).pdf:pdf},
journal = {LECTURE NOTES},
title = {{01. Gradient method (2012)}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2012}
}
@techreport{Spielman2004,
author = {Spielman, Daniel A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman - 2004 - Spectral Graph Theory and its Applications.pdf:pdf},
title = {{Spectral Graph Theory and its Applications}},
year = {2004}
}
@article{Ferris2017,
author = {Ferris, Jody L and Ferris, Jody L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferris, Ferris - 2017 - Data Privacy and Protection in the Agriculture Industry Is Federal Regulation Necessary.pdf:pdf},
isbn = {140188105X},
journal = {Minnesota Journal of Law, Science {\&} Technology},
number = {1},
title = {{Data Privacy and Protection in the Agriculture Industry: Is Federal Regulation Necessary?}},
volume = {18},
year = {2017}
}
@article{Jornsten1994a,
author = {Jornsten, K and Leisten, R},
journal = {European Journal of Operations Research},
pages = {175--191},
title = {{Aggregation and decomposition for multi-divisional linear programs}},
volume = {72},
year = {1994}
}
@article{Hung2005,
abstract = {Nowadays, Electronic Commerce (EC) provides a new gateway for customers shopping online. One of the most significant advantages offered by online shops is convenience. Online shopping is no longer a time-consuming task and, in fact, is an energy-saving activity. Therefore, shortening customers' product searching time is the key to an online shop's success. In order to serve customers instantly and efficiently, it is essential to recognize each customer's unique and particular needs and recommend a personalized shopping list. In this paper, we construct a recommendation system based on a modified product taxonomy and customer classification to identify customers' shopping behavior: product addictive, brand addictive or a hybrid addictive. By analyzing each customer's preferred brand or product, our proposed system can recommend products to customers either at the general or at the specific levels.},
author = {Hung, Lun-ping},
journal = {Expert Systems with Applications},
number = {2},
pages = {383--392},
title = {{A personalized recommendation system based on product taxonomy for one-to-one marketing online}},
volume = {29},
year = {2005}
}
@article{Leite2011,
annote = {Leite, P. B. C., Feitosa, R. Q., Formaggio, a. R., Costa, G. a. O. P., Pakzad, K., {\&} Sanches, I. D. a. (2008). Crop Type Recognition Based on Hidden Markov Models of Plant Phenology. {\textless}m:italic{\textgreater}2008 XXI Brazilian Symposium on Computer Graphics and Image Processing{\textless}/m:italic{\textgreater}, 27–34. doi:10.1109/SIBGRAPI.2008.26},
author = {Leite, Paula Beatriz Cerqueira and Feitosa, Raul Queiroz and Formaggio, Ant{\^{o}}nio Roberto and da Costa, Gilson Alexandre Ostwald Pedro and Pakzad, Kian and Sanches, Ieda Del'Arco},
doi = {10.1016/j.patrec.2010.02.008},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Leite et al. - 2011 - Hidden Markov Models for crop recognition in remote sensing image sequences.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {hidden markov models},
month = {jan},
number = {1},
pages = {19--26},
publisher = {Elsevier B.V.},
title = {{Hidden Markov Models for crop recognition in remote sensing image sequences}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865510000656},
volume = {32},
year = {2011}
}
@article{Chapman2002,
abstract = {BACKGROUND AND OBJECTIVES: The Blood Stocks Management Scheme (BSMS) has been established as a joint venture between the National Blood Service (NBS) in England and North Wales and participating hospitals to monitor the blood supply chain.

MATERIALS AND METHODS: Stock and wastage data are submitted to a web-based data-management system, facilitating continuous and complete red cell data collection and 'real time' data extraction.

RESULTS: The data-management system enables peer review of performance in respect of stock holding levels and red cell wastage.

CONCLUSIONS: The BSMS has developed an innovative web-based data-management system that enables data collection and benchmarking of practice, which should drive changes in stock management practice, therefore optimizing the use of donated blood.},
author = {Chapman, J F and Cook, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chapman, Cook - 2002 - The Blood Stocks Management Scheme, a partnership venture between the National Blood Service of England and North.pdf:pdf},
issn = {0042-9007},
journal = {Vox sanguinis},
keywords = {Automatic Data Processing,Blood Banks,Blood Banks: methods,Blood Banks: organization {\&} administration,Blood Group Antigens,Data Collection,England,Health Resources,Hospitals,Humans,Information Storage and Retrieval,Internet,Management Information Systems,Wales},
month = {oct},
number = {3},
pages = {239--46},
pmid = {12366766},
title = {{The Blood Stocks Management Scheme, a partnership venture between the National Blood Service of England and North Wales and participating hospitals for maximizing blood supply chain management.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12366766},
volume = {83},
year = {2002}
}
@article{Munos2006,
author = {Munos, R{\'{e}}mi},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos - 2006 - Geometric variance reduction in Markov chains application to value function and gradient estimation.pdf:pdf},
journal = {The Journal of Machine Learning Research},
pages = {413--427},
title = {{Geometric variance reduction in Markov chains: application to value function and gradient estimation}},
url = {http://dl.acm.org/citation.cfm?id=1248561},
volume = {7},
year = {2006}
}
@incollection{Auer2009,
author = {Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
booktitle = {Advances in Neural Information Processing Systems 21},
editor = {Koller, D and Schuurmans, D and Bengio, Y and Bottou, L},
title = {{Near-optimal Regret Bounds for Reinforcement Learning}},
year = {2009}
}
@article{Boutsidis2009,
abstract = {Constrained least-squares regression problems, such as the Nonnegative Least Squares (NNLS) problem, where the variables are restricted to take only nonnegative values, often arise in applications. Motivated by the recent development of the fast Johnson-Lindestrauss transform, we present a fast random projection type approximation algorithm for the NNLS problem. Our algorithm employs a randomized Hadamard transform to construct a much smaller NNLS problem and solves this smaller problem using a standard NNLS solver. We prove that our approach finds a nonnegative solution vector that, with high probability, is close to the optimum nonnegative solution in a relative error approximation sense. We experimentally evaluate our approach on a large collection of term-document data and verify that it does offer considerable speedups without a significant loss in accuracy. Our analysis is based on a novel random projection type result that might be of independent interest. In particular, given a tall and thin matrix ?? ??? Rn ?? d (n ??? d) and a vector y ??? Rd, we prove that the Euclidean length of ?? y can be estimated very accurately by the Euclidean length of over(??, ???) y, where over(??, ???) consists of a small subset of (appropriately rescaled) rows of ??. ?? 2009 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0812.4547},
author = {Boutsidis, Christos and Drineas, Petros},
doi = {10.1016/j.laa.2009.03.026},
eprint = {0812.4547},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boutsidis, Drineas - 2009 - Random projections for the nonnegative least-squares problem.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and Its Applications},
keywords = {Hadamard transform,Non negative least-squares,Random projections,Randomized algorithm,Sampling},
number = {5-7},
pages = {760--771},
title = {{Random projections for the nonnegative least-squares problem}},
volume = {431},
year = {2009}
}
@inproceedings{Petrik2008a,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {International Conference on Automated Planning and Scheduling (ICAPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2008 - Learning Heuristic Functions through Approximate Linear Programming.pdf:pdf},
title = {{Learning heuristic functions through approximate linear programming}},
url = {http://www.aaai.org/Papers/ICAPS/2008/ICAPS08-031.pdf},
year = {2008}
}
@article{Kozlov1979,
author = {Kozlov, M K and Tarasov, S P and Khachiyan, L G},
journal = {Sov. {\{}M{\}}ath., {\{}D{\}}okl. 20, 1108-1111 (1979); translation from {\{}D{\}}okl. {\{}A{\}}kad. {\{}N{\}}auk {\{}SSSR{\}}},
pages = {1049--1051},
title = {{Polynomial solvability of quadratic programming}},
volume = {248},
year = {1979}
}
@misc{Rozloznik1996,
author = {Rozloznik, Miroslav},
title = {{Numerical stability of the {\{}GMRES{\}} method}},
year = {1996}
}
@inproceedings{Bellemare2012,
author = {Bellemare, MG and Veness, Joel and Bowling, Michael},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellemare, Veness, Bowling - 2012 - Sketch-Based Linear Value Function Approximation.pdf:pdf},
pages = {1--9},
title = {{Sketch-Based Linear Value Function Approximation.}},
url = {https://papers.nips.cc/paper/4540-sketch-based-linear-value-function-approximation.pdf},
year = {2012}
}
@article{Iyengar2005,
abstract = {In this paper we propose a robust formulation for discrete time dynamic programming (DP). The objective of the robust formulation is to systematically mitigate the sensitivity of the DP optimal policy to ambiguity in the underlying transition probabilities. The ambiguity is modeled by associating a set of conditional measures with each state-action pair. Consequently, in the robust formulation each policy has a set of measures associated with it. We prove that when this set of measures has a certain "rectangularity" property, all of the main results for finite and infinite horizon DP extend to natural robust counterparts. We discuss techniques from Nilim and El Ghaoui [17] for constructing suitable sets of conditional measures that allow one to efficiently solve for the optimal robust policy. We also show that robust DP is equivalent to stochastic zero-sum games with perfect information.},
annote = {Does the value function of the optimal policy dominate the value functions of all other policies?},
author = {Iyengar, Garud N.},
doi = {10.1287/moor.1040.0129},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iyengar - 2005 - Robust Dynamic Programming.pdf:pdf},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {90c25,90c39,90c40,90c47,ambiguity,decision analysis-risk,dynamic programming,markov decision processes,ms subject classification,msc2000 subject classification,optimal control,or,primary,probability-markov processes,robust optimization,secondary},
number = {2},
pages = {257--280},
publisher = {INFORMS},
title = {{Robust dynamic programming}},
url = {http://mor.journal.informs.org/content/30/2/257.short http://mor.journal.informs.org/cgi/doi/10.1287/moor.1040.0129},
volume = {30},
year = {2005}
}
@inproceedings{Munos2003,
annote = {From Duplicate 2 ( 


Error bounds for approximate policy iteration


- Munos, R{\'{e}}mi )




From Duplicate 1 ( 


Error bounds for approximate policy iteration


- Munos, R{\'{e}}mi )




From Duplicate 2 ( 


Error Bounds for Approximate Value Iteration


- Munos, R{\'{e}}mi )

},
author = {Munos, R{\'{e}}mi},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos - Unknown - Error Bounds for Approximate Value Iteration.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munos - 2003 - Error bounds for approximate policy iteration.pdf:pdf},
pages = {560--567},
title = {{Error bounds for approximate policy iteration}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/icml2003{\_}Munos03.pdf},
year = {2003}
}
@article{Kakade2001a,
author = {Kakade, S},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade - 2001 - Optimizing average reward using discounted rewards.pdf:pdf},
journal = {Computational Learning Theory},
title = {{Optimizing average reward using discounted rewards}},
url = {http://link.springer.com/chapter/10.1007/3-540-44581-1{\_}40},
year = {2001}
}
@article{Bean1987a,
annote = {From Duplicate 1 ( 


Aggregation in Dynamic Programming


- Bean, James C; Birge, John R; Smith, Robert L )

},
author = {Bean, JC James C and Birge, John R JR and Smith, RL Robert L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bean, Birge, Smith - 1987 - Aggregation in dynamic programming.pdf:pdf},
journal = {Operations Research},
number = {2},
pages = {215--220},
title = {{Aggregation in dynamic programming}},
url = {http://or.journal.informs.org/content/35/2/215.short},
volume = {35},
year = {1987}
}
@article{Ibanez2009a,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and {Silander Jr}, John. A. and Allen, Jenica M. and Treanor, Sarah A. and Wilson, Adam},
doi = {10.1111/j.1365-2664.2009.01736.x},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {SDMs,abundance,climate change},
mendeley-tags = {SDMs,abundance,climate change},
month = {nov},
number = {6},
pages = {1219--1228},
title = {{Identifying hotspots for plant invasions and forecasting focal points of further spread}},
url = {http://doi.wiley.com/10.1111/j.1365-2664.2009.01736.x},
volume = {46},
year = {2009}
}
@article{HsuDanielShamM.KakadeandTongZhang2008,
author = {{Hsu, Daniel, Sham M. Kakade, and Tong Zhang} and Hsu, Daniel},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsu, Daniel, Sham M. Kakade, and Tong Zhang, Hsu - 2008 - A spectral algorithm for learning hidden markov models.pdf:pdf},
journal = {arXiv preprint arXiv:0811.4413},
title = {{A spectral algorithm for learning hidden markov models.}},
year = {2008}
}
@book{Saad1995a,
annote = {From Duplicate 2 ( Preconditioned Krylov subspace methods for the numerical solution of Markov chains - Saad, Yousef )
},
author = {Saad, Yousef},
booktitle = {Computations with Markov Chains},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad - 1995 - Preconditioned Krylov subspace methods for the numerical solution of Markov chains.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saad - 1995 - Preconditioned Krylov subspace methods for the numerical solution of Markov chains(2).pdf:pdf},
pages = {49--64},
title = {{Preconditioned Krylov subspace methods for the numerical solution of Markov chains}},
url = {http://link.springer.com/chapter/10.1007/978-1-4615-2241-6{\_}4 http://books.google.com/books?hl=en{\&}lr={\&}id=5aTg5SrbeCcC{\&}oi=fnd{\&}pg=PR3{\&}dq=Numerical+Solutions+of+Markov+Chains{\&}ots=req8K0hDGB{\&}sig=PrlEOvxd4y0VMqEvSEZk9MiYECQ},
year = {1995}
}
@article{Moldovan2012,
abstract = {In environments with uncertain dynamics exploration is necessary to learn how to perform well. Existing reinforcement learning algorithms provide strong exploration guarantees, but they tend to rely on an ergodicity assumption. The essence of ergodicity is that any state is eventually reachable from any other state by following a suitable policy. This assumption allows for exploration algorithms that operate by simply favoring states that have rarely been visited before. For most physical systems this assumption is impractical as the systems would break before any reasonable exploration has taken place, i.e., most physical systems don't satisfy the ergodicity assumption. In this paper we address the need for safe exploration methods in Markov decision processes. We first propose a general formulation of safety through ergodicity. We show that imposing safety by restricting attention to the resulting set of guaranteed safe policies is NP-hard. We then present an efficient algorithm for guaranteed safe, but potentially suboptimal, exploration. At the core is an optimization formulation in which the constraints restrict attention to a subset of the guaranteed safe policies and the objective favors exploration policies. Our framework is compatible with the majority of previously proposed exploration methods, which rely on an exploration bonus. Our experiments, which include a Martian terrain exploration problem, show that our method is able to explore better than classical exploration methods.},
archivePrefix = {arXiv},
arxivId = {1205.4810},
author = {Moldovan, Teodor Mihai and Abbeel, Pieter},
eprint = {1205.4810},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moldovan, Abbeel - 2012 - Safe Exploration in Markov Decision Processes.pdf:pdf},
isbn = {978-1-4503-1285-1},
journal = {Conference on Neural Information Processing Systems (NIPS)},
keywords = {ICML,exploration,machine learning,safe,safety},
number = {Nips},
title = {{Safe Exploration in Markov Decision Processes}},
url = {http://arxiv.org/abs/1205.4810},
year = {2012}
}
@article{Ong2015,
abstract = {We propose a novel value function approximation technique for Markov decision processes. We consider the problem of compactly representing the state-action value function using a low-rank and sparse matrix model. The problem is to decompose a matrix that encodes the true value function into low-rank and sparse components, and we achieve this using Robust Principal Component Analysis (PCA). Under minimal assumptions, this Robust PCA problem can be solved exactly via the Principal Component Pursuit convex optimization problem. We experiment the procedure on several examples and demonstrate that our method yields approximations essentially identical to the true function.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.00061v1},
author = {Ong, Hao Yi},
eprint = {arXiv:1509.00061v1},
journal = {arXiv},
title = {{Value Function Approximation via Low Rank Models}},
year = {2015}
}
@article{Buyuktahtakn2011,
abstract = {A dynamic model of controlling invasive weeds is first developed which is a large scale, nonlinear 0-1 integer programming problem. This model is then applied for the case of control of the invasive grass, Pennisetum ciliare (buffelgrass), in the Arizona desert. The large size of the problem makes the application of direct optimization methods impossible, instead the most frequently suggested strategies were analyzed and their consequences compared. The model is more advanced and complex than those examined in earlier studies. ?? 2011 Elsevier Ltd. All rights reserved.},
author = {Buyuktahtakn, I. Esra and Feng, Zhuo and Frisvold, George and Szidarovszky, Ferenc and Olsson, Aaryn},
doi = {10.1016/j.camwa.2011.08.037},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buyuktahtakn et al. - 2011 - A dynamic model of controlling invasive species.pdf:pdf},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {Biological invasion,Integer programming,Invasive species,Non-native species,Optimal control},
number = {9},
pages = {3326--3333},
publisher = {Elsevier Ltd},
title = {{A dynamic model of controlling invasive species}},
url = {http://dx.doi.org/10.1016/j.camwa.2011.08.037},
volume = {62},
year = {2011}
}
@inproceedings{Price2005,
author = {Price, Bob and Messinger, Paul R},
booktitle = {National Conference on AI (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Price, Messinger - 2005 - Optimal Recommendation Sets Covering Uncertainty over User Preferences.pdf:pdf},
pages = {541--548},
title = {{Optimal Recommendation Sets : Covering Uncertainty over User Preferences}},
year = {2005}
}
@article{Miller2012,
author = {Miller, G. and Weatherwax, M. and Gardinier, T. and Abe, N. and Melville, P. and Pendus, C. and Jensen, D. and Reddy, C. K. and Thomas, V. and Bennett, J. and Anderson, G. and Cooley, B.},
doi = {10.1287/inte.1110.0618},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller et al. - 2012 - Tax Collections Optimization for New York State.pdf:pdf},
issn = {0092-2102},
journal = {Interfaces},
keywords = {data analysis,decision support systems,dynamic programming,tax policy},
number = {1},
pages = {74--84},
title = {{Tax Collections Optimization for New York State}},
volume = {42},
year = {2012}
}
@article{Ritter1976,
author = {Konno, H},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konno - 1976 - A cutting plane algorithm for solving bilinear programs.pdf:pdf},
journal = {Mathematical Programming},
pages = {14--27},
title = {{A cutting plane algorithm for solving bilinear programs}},
url = {http://link.springer.com/article/10.1007/BF01580367},
volume = {11},
year = {1976}
}
@incollection{Feinberg2002,
chapter = {16},
editor = {Feinberg, Eugene A and Shwartz, Adam},
pages = {489--536},
publisher = {Kluwer},
title = {{Handbook of Markov decision processes}},
year = {2002}
}
@inproceedings{Maei2009,
author = {Maei, Hamid and Szepesvari, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Rich},
booktitle = {Advances in Neural Information Processing Systems 22},
editor = {Bengio, Y and Schuurmans, D and Lafferty, J and Williams, C K I and Culotta, A},
pages = {1204--1212},
title = {{Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation}},
year = {2009}
}
@inproceedings{Boutilier2016,
author = {Boutilier, Craig and Lu, Tyler},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boutilier, Lu - 2016 - Budget Allocation using Weakly Coupled, Constrained Markov Decision Processes.pdf:pdf},
title = {{Budget Allocation using Weakly Coupled, Constrained Markov Decision Processes}},
year = {2016}
}
@article{Ermoliev1997,
author = {Ermoliev, Y M and Kryazhimskii, A V and Ruszczynski, A},
journal = {Mathematical Programming},
pages = {353--372},
title = {{Constraint aggregation principle in convex optimization}},
volume = {76},
year = {1997}
}
@article{Philpott2012,
annote = {From Duplicate 1 ( Dynamic sampling algorithms for multi-stage stochastic programs with risk aversion - Philpott, A B; Matos, V L De )
},
author = {Philpott, A B and de Matos, V and Matos, V L De},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Philpott, Matos - 2011 - Dynamic sampling algorithms for multi-stage stochastic programs with risk aversion.pdf:pdf},
institution = {Optimization Online},
journal = {European Journal of Operations Research},
number = {2},
pages = {470--483},
title = {{Dynamic sampling algorithms for multi-stage stochastic programs with risk aversion}},
volume = {218},
year = {2012}
}
@inproceedings{Zortea2012,
author = {Zortea, Maciel and Salberg, Artn-Borre and Trier, Oivind Due},
booktitle = {Proceedings of the 4th GEOBIA},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zortea, Salberg, Trier - 2012 - OBJECT-BASED CLOUD AND CLOUD SHADOW DETECTION IN LANDSAT IMAGES FOR TROPICAL FOREST MONITORING.pdf:pdf},
keywords = {classification,cloud detection,landsat,segmentation,shadows},
pages = {326--331},
title = {{OBJECT-BASED CLOUD AND CLOUD SHADOW DETECTION IN LANDSAT IMAGES FOR TROPICAL FOREST MONITORING}},
url = {http://publications.nr.no/1338297956/Zortea-Salberg-Trier{\_}GEOBIA-2012.pdf},
year = {2012}
}
@inproceedings{Even-dar2002,
author = {Even-dar, Eyal and Kakade, Sham. M. and Mansour, Yishay},
booktitle = {NIPS},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even-dar, Kakade, Mansour - 2002 - Experts in a Markov Decision Process.pdf:pdf},
title = {{Experts in a Markov Decision Process}},
year = {2002}
}
@article{Jornsten1994,
author = {Jornsten, K and Leisten, R},
journal = {Optimization},
pages = {251--268},
title = {{Gradient schemes in iterative aggregation procedures for variable-aggregated {\{}LP{\}}-problems}},
volume = {30},
year = {1994}
}
@article{VandeVen2011,
author = {{Van de Ven}, Peter and Hegde, Nidhi and Massoulie, Laurent and Salonidis, Theodoros},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van de Ven et al. - 2011 - Optimal Control of Residential Energy Storage Under Price Fluctuations.pdf:pdf},
isbn = {9781612081366},
journal = {ENERGY 2011, The First International Conference on Smart Grids, Green Communications and IT Energy-aware Technologies},
pages = {159--162},
title = {{Optimal Control of Residential Energy Storage Under Price Fluctuations}},
year = {2011}
}
@book{C.Helm2000,
author = {Helmberg, C.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Helmberg - 2000 - Semidefinite Programming for Combinatorial Optimization.pdf:pdf},
number = {October},
title = {{Semidefinite Programming for Combinatorial Optimization}},
volume = {34},
year = {2000}
}
@article{Dantzig1991,
author = {Dantzig, GB and Infanger, Gerd},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dantzig, Infanger - 1991 - Large-scale stochastic linear programs Importance sampling and Benders decomposition.pdf:pdf},
journal = {Computational and applied mathematics},
title = {{Large-scale stochastic linear programs: Importance sampling and Benders decomposition}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=ADA234962},
year = {1991}
}
@article{Kleywegt1999,
annote = {
        {\textless}m:bold{\textgreater}From Duplicate 1 ( {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}
          {\textless}m:italic{\textgreater}The stochastic inventory routing problem with direct deliveries{\textless}/m:italic{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater}{\textless}/m:bold{\textgreater}
        {\textless}m:bold{\textgreater} - Kleywegt, Anton J; Nori, Vija S; Savelsbergh, Martin W P ){\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}/m:bold{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
        {\textless}m:linebreak{\textgreater}{\textless}/m:linebreak{\textgreater}
      },
author = {Kleywegt, Anton J and Nori, Vija S and Savelsbergh, Martin W P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kleywegt, Nori, Savelsbergh - 1999 - The stochastic inventory routing problem with direct deliveries.pdf:pdf},
journal = {Transportation Science},
pages = {94--118},
title = {{The stochastic inventory routing problem with direct deliveries}},
volume = {36},
year = {1999}
}
@article{Vanderbei1995,
author = {Vanderbei, RJ},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbei - 1995 - Affine-scaling trajectories associated with a semi-infinite linear program.pdf:pdf},
journal = {Mathematics of operations research},
number = {1},
pages = {163--174},
title = {{Affine-scaling trajectories associated with a semi-infinite linear program}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Affine-Scaling+Trajectories+Associated+with+a+Semi-Infinite+Linear+Program{\#}0},
volume = {20},
year = {1995}
}
@inproceedings{Schied2006,
author = {Schied, Alexander},
booktitle = {Symposium on Probability and Stochastic Processes},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schied - 2004 - Risk measures and robust optimization problems.pdf:pdf},
title = {{Risk measures and robust optimization problems}},
year = {2004}
}
@inproceedings{Weinberger2006,
author = {Weinberger, Kilian Q and Saul, Lawrence K},
booktitle = {National Conference on Artificial Intelligence},
title = {{An introduction to nonlinear dimensionality reduction by maximum variance unfolding}},
year = {2006}
}
@inproceedings{Asmuth2009a,
author = {Asmuth, John and Li, Lihong and Littman, Michael L. and Nouri, Ali and Wingate, David},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asmuth et al. - 2009 - A Bayesian Sampling Approach to Exploration in Reinforcement Learning.pdf:pdf},
title = {{A Bayesian Sampling Approach to Exploration in Reinforcement Learning}},
year = {2009}
}
@inproceedings{Meleau1999,
author = {Meleau, N and Kim, K E and Kaelbling, L P and Cassandra, A R},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
title = {{Solving POMDPs by searching the space of finite policies}},
year = {1999}
}
@article{Peters2006,
annote = {Nice basic overview of the state of the art in gradient methods.},
author = {Peters, Jan and Schaal, Stefan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peters, Schaal - 2006 - Policy gradient methods for robotics.pdf:pdf},
journal = {Intelligent Robots and Systems, 2006 IEEE/ {\ldots}},
title = {{Policy gradient methods for robotics}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4058714},
year = {2006}
}
@article{Farias2004b,
author = {de Farias, D P and {Van Roy}, Benjamin},
doi = {10.1287/moor.1040.0094},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Farias, Van Roy - 2004 - On constraint sampling in the linear programming approach to approximate dynamic programming.pdf:pdf},
journal = {Mathematics of operations research},
number = {3},
pages = {462--478},
title = {{On constraint sampling in the linear programming approach to approximate dynamic programming}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:On+Constraint+Sampling+in+the+Linear+Programming+Approach+to+Approximate+Dynamic+Programming{\#}0},
volume = {29},
year = {2004}
}
@article{Vandenberghe2011e,
author = {Vandenberghe, Lieven},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vandenberghe - 2011 - 02. Subgradients.pdf:pdf},
journal = {LECTURE NOTES},
pages = {1--32},
title = {{02. Subgradients}},
url = {http://www.seas.ucla.edu/{~}vandenbe/ee236c.html},
year = {2011}
}
@inproceedings{Patrascu2002,
annote = {From Duplicate 2 ( Piecewise linear value function approximation for factored MDPs - Patrascu, Relu; Poupart, Pascal; Schuurmans, Dale; Boutilier, Craig; Guestrin, Carlos )
},
author = {Patrascu, Relu and Poupart, Pascal and Schuurmans, Dale and Boutilier, Craig and Guestrin, Carlos},
booktitle = {National Conference on Artificial Intelligence (AAAI)},
title = {{Greedy linear value-approximation for factored Markov decision processes}},
year = {2002}
}
@inproceedings{Zhou2001,
author = {Zhou, Rong and Hansen, Eric A},
booktitle = {IJCAI},
pages = {707},
title = {{An Improved Grid-Based Approximation Algorithm for POMDPs}},
year = {2001}
}
@inproceedings{Chen2016,
author = {Chen, Xiangli and Monfort, Mathew and Ziebart, Brian D and Carr, Peter},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2016 - Adversarial Inverse Optimal Control for General Imitation Learning Losses and Embodiment Transfer.pdf:pdf},
title = {{Adversarial Inverse Optimal Control for General Imitation Learning Losses and Embodiment Transfer}},
year = {2016}
}
@article{Konopnicki2013,
abstract = {Print Request Permissions Save to Project In this paper, we present one possible way of analyzing social media conversional data in order to better understand customers. Ultimately, our goal is to analyze customer behavior as it is expressed in free-form conversations and extract from it commercially valuable information about the customer. In this study, we concentrate on using statistical techniques for analyzing this unstructured data at two levels: 1) at the level of the words used in the conversation and 2) by mapping those words to abstract concepts. The goal of such a statistical analysis is twofold. First, the statistically significant terms used by the users and the concepts associated with them provide insight on a user's interests that commercial services can use, for example, in order to target advertisements. In addition, knowing the evolution of a customer's interests and hobbies can be exploited commercially by retailers, media and entertainment companies, telecommunications companies, and more. In this paper, we describe a general framework for the analysis of social media data and, in turn, the application of the framework to the statistical analysis of the language of tweets.},
author = {Konopnicki, D. and {Shmueli-Scheuer, M. Cohen}, D. and Sznajder, B. and Herzig, J. and Raviv, A. and Zwerling, N. and Roitman, H. and Mass, Y.},
journal = {IBM Journal of Research and Development},
number = {3/4},
pages = {14:1 -- 14:13},
title = {{A statistical approach to mining customers' conversational data from social media}},
volume = {57},
year = {2013}
}
@book{Bertsekas1998,
author = {Bertsekas, DP},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsekas - 1998 - Network optimization continuous and discrete models.pdf:pdf},
isbn = {1886529027},
title = {{Network optimization: continuous and discrete models}},
url = {http://galletue.ing-mat.udec.cl/{~}camilo/material{\_}udec/Economia y papers/D.P.Bertsekas/Network Optimization, Continuos and Discrete Models Chapters 1,2,3,10 - D.P.Bertsekas.pdf},
year = {1998}
}
@inproceedings{Mahadevan2005a,
annote = {From Duplicate 1 ( Representation policy iteration - Mahadevan, Sridhar )
},
author = {Mahadevan, Sridhar},
booktitle = {{\{}C{\}}onference on {\{}U{\}}ncertainty in Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahadevan - 2005 - Representation policy iteration.pdf:pdf},
title = {{Representation policy iteration}},
year = {2005}
}
@inproceedings{Gilpin2006,
author = {Gilpin, Andrew and Sandholm, Tuomas},
booktitle = {ACM Conference on Electronic Commerce},
title = {{Finding Equilibria in Large Sequential Games of Imperfect Information}},
year = {2006}
}
@inproceedings{Gordon1995a,
annote = {An interesting experiment.

Uses a local weighted experiment with pictures},
author = {Gordon, Geoffrey J},
booktitle = {International Conference on Machine Learning},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon - 1995 - Stable function approximation in dynamic programming.pdf:pdf},
organization = {Carnegie Mellon University},
pages = {261--268},
title = {{Stable function approximation in dynamic programming}},
url = {citeseer.ist.psu.edu/gordon95stable.html},
year = {1995}
}
@article{Vandenberghe1996,
author = {Vandenberghe, Lieven and Boyd, Stephen},
journal = {{\{}SIAM{\}} Review},
pages = {49--95},
title = {{Semidefinite programming}},
volume = {38},
year = {1996}
}
@article{Pearce2006,
abstract = {Presence-only data, for which there is no information on locations where the species is absent, are common in both animal and plant studies. In many situations, these may be the only data available on a species. We need effective ways to use these data to explore species distribution or species use of habitat. Many analytical approaches have been used to model presence-only data, some inappropriately. We provide a synthesis and critique of statistical methods currently in use to both estimate and evaluate these models, and discuss the critical importance of study design in models where only presence can be identified Profile or envelope methods exist to characterize environmental covariates that describe the locations where organisms are found. Predictions from profile approaches are generally coarse, but may be useful when species records, environmental predictors and biological understanding are scarce. Alternatively, one can build models to contrast environmental attributes associated with known locations with a sample of random landscape locations, termed either 'pseudo-absences' or 'available'. Great care needs to be taken when selecting random landscape locations, because the way in which they are selected determines the modelling techniques that can be applied. Regression-based models can provide predictions of the relative likelihood of occurrence, and in some situations predictions of the probability of occurrence. The logistic model is frequently applied, but can rarely be used directly to estimate these models; instead, case2013control or logistic discrimination should be used depending on the sample design. Cross-validation can be used to evaluate model performance and to assess how effectively the model reflects a quantity proportional to the probability of occurrence. However, more research is needed to develop a single measure or statistic that summarizes model performance for presence-only data. Synthesis and applications. A number of statistical procedures are available to explore patterns in presence-only data; the choice among them depends on the quality of the presence-only data. Presence-only records can provide insight into the vulnerability, historical distribution and conservation status of species. Models developed using these data can inform management. Our caveat is that researchers must be mindful of study design and the biases inherent in presence data, and be cautious in the interpretation of model predictions. Journal of Applied Ecology (2006) 43, 4052013412doi: 10.1111/j.1365-2664.2005.01112.x},
author = {Pearce, Jennie L. and Boyce, Mark S.},
doi = {10.1111/j.1365-2664.2005.01112.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pearce, Boyce - 2006 - Modelling distribution and abundance with presence-only data.pdf:pdf},
isbn = {1365-2664},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {Case-control,Distribution,Habitats,Logistic discrimination,Logistic regression,Presence-only studies,Pseudo-absences,RSF,Resource selection functions,Sampling},
number = {3},
pages = {405--412},
pmid = {20791431},
title = {{Modelling distribution and abundance with presence-only data}},
volume = {43},
year = {2006}
}
@article{Shivaswamy2012,
author = {Shivaswamy, Pannaga and Joachims, Thorsten},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shivaswamy, Joachims - 2012 - Multi-armed Bandit Problems with History.pdf:pdf},
issn = {15337928},
journal = {Artificial Intelligence and Statistics (AISTATS)},
pages = {1046--1054},
title = {{Multi-armed Bandit Problems with History}},
year = {2012}
}
@article{Petrik2005,
author = {Petrik, Marek},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - Unknown - Statistically Optimal Combination of Algorithms.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2005 - Learning Parallel Portfolios of Algorithms.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - Unknown - Learning Static Parallel Portfolios of Algorithms.pdf:pdf},
pages = {1--10},
title = {{Learning parallel portfolios of algorithms}},
year = {2005}
}
@article{Merow2013,
abstract = {The MaxEnt software package is one of the most popular tools for species distribution and environmental niche modeling, with over 1000 published applications since 2006. Its popularity is likely for two reasons: 1) MaxEnt typically outperforms other methods based on predictive accuracy and 2) the software is particularly easy to use. MaxEnt users must make a number of decisions about how they should select their input data and choose from a wide variety of settings in the software package to build models from these data. The underlying basis for making these decisions is unclear in many studies, and default settings are apparently chosen, even though alternative settings are often more appropriate. In this paper, we provide a detailed explanation of how MaxEnt works and a prospectus on modeling options to enable users to make informed decisions when preparing data, choosing settings and interpreting output. We explain how the choice of background samples reflects prior assumptions, how nonlinear functions of environmental variables (features) are created and selected, how to account for environmentally biased sampling, the interpretation of the various types of model output and the challenges for model evaluation. We demonstrate MaxEnt's calculations using both simplified simulated data and occurrence data from South Africa on species of the flowering plant family Proteaceae. Throughout, we show how MaxEnt's outputs vary in response to different settings to highlight the need for making biologically motivated modeling decisions.},
author = {Merow, Cory and Smith, Matthew J. and Silander, John A.},
doi = {10.1111/j.1600-0587.2013.07872.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merow, Smith, Silander - 2013 - A practical guide to MaxEnt for modeling species' distributions What it does, and why inputs and setting.pdf:pdf},
isbn = {1600-0587},
issn = {09067590},
journal = {Ecography},
number = {10},
pages = {1058--1069},
pmid = {1921},
title = {{A practical guide to MaxEnt for modeling species' distributions: What it does, and why inputs and settings matter}},
volume = {36},
year = {2013}
}
@article{Siebert2010,
author = {Siebert, S. and Burke, J. and Faures, J. M. and Frenken, K. and Hoogeveen, J. and D{\"{o}}ll, P. and Portmann, F. T.},
doi = {10.5194/hess-14-1863-2010},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Siebert et al. - 2010 - Groundwater use for irrigation – a global inventory.pdf:pdf},
issn = {1607-7938},
journal = {Hydrology and Earth System Sciences},
month = {oct},
number = {10},
pages = {1863--1880},
title = {{Groundwater use for irrigation – a global inventory}},
url = {http://www.hydrol-earth-syst-sci.net/14/1863/2010/},
volume = {14},
year = {2010}
}
@incollection{Beliaeva2005,
author = {Beliaeva, Natalia and Zilberstein, Shlomo},
booktitle = {Abstraction, Reformulation and Approximation},
pages = {14--29},
title = {{Generating Admissible Heuristics by Abstraction for Search in Stochastic Domains}},
year = {2005}
}
@article{VanIttersum2003,
author = {van Ittersum, M.K and Leffelaar, P.a and van Keulen, H and Kropff, M.J and Bastiaans, L and Goudriaan, J},
doi = {10.1016/S1161-0301(02)00106-5},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Ittersum et al. - 2003 - On approaches and applications of the Wageningen crop models.pdf:pdf},
issn = {11610301},
journal = {European Journal of Agronomy},
keywords = {- see front matter,02,1 corresponding author,1161-0301,2002 else v ier,31-317-484892,all rights reserved,cropping systems,dpw,e-mail address,fax,http,k,m,nitrogen,nl,office,pests and diseases,pp,science b,simulation,soil water balance,v,v an ittersum,wageningen-ur,water,weeds,wur,www},
month = {jan},
number = {3-4},
pages = {201--234},
title = {{On approaches and applications of the Wageningen crop models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1161030102001065},
volume = {18},
year = {2003}
}
@article{White1992,
annote = {From Duplicate 1 ( A linear programming approach to solving bilinear programmes - White, Douglas J )
},
author = {White, Douglas J},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/White - 1992 - A linear programming approach to solving bilinear programmes.pdf:pdf},
journal = {Mathematical Programming},
month = {aug},
number = {1},
pages = {45--50},
title = {{A linear programming approach to solving bilinear programmes}},
url = {http://dx.doi.org/10.1007/BF01580892},
volume = {56},
year = {1992}
}
@techreport{YishayMansour2003,
author = {Mansour, Yishay},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mansour - 2003 - Computational Learning Theory.pdf:pdf},
title = {{Computational Learning Theory}},
year = {2003}
}
@article{Kalai1993,
author = {Kalai, E and Lehrer, E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalai, Lehrer - 1993 - Rational learning leads to Nash equilibrium.pdf:pdf},
journal = {Econometrica: Journal of the Econometric Society},
title = {{Rational learning leads to Nash equilibrium}},
url = {http://www.jstor.org/stable/2951492},
year = {1993}
}
@article{Quintana-Orti2008,
author = {Quintana-Ort{\'{i}}, ES and Geijn, RA Van De},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quintana-Ort{\'{i}}, Geijn - 2008 - Updating an LU factorization with pivoting.pdf:pdf},
journal = {ACM Transactions on Mathematical {\ldots}},
title = {{Updating an LU factorization with pivoting}},
url = {http://dl.acm.org/citation.cfm?id=1377615},
volume = {V},
year = {2008}
}
@inproceedings{Soltani2007,
abstract = {The objective of this study was to evaluate the suitability of weather data generated by the weather generators WGEN and SIMMETEO as input for crop simulation models in order to determine the best option(s) among a number of different crop management practices. Five locations across Iran with different climates were selected for the study. The wheat, maize and soybean models of the Decision Support System for Agrotechnology Transfer (DSSAT) were applied in this study, using 30 years of observed weather data and 90 years of weather data generated by WGEN and SIMMETEO. Irrespective of some significant differences between simulated yield based on observed weather data and those based on weather data generated by WGEN and SIMMETEO, a similar conclusion could be drawn about the best cultivar, planting date, plant density and irrigation threshold. It can be concluded based on the results of this study that for many DSSAT applications where only relative estimates or determination of the best option(s) rather than absolute values are required, weather data generated by either WGEN and SIMMETEO are accurate and adequate.},
author = {Soltani, Afshin and Hoogenboom, Gerrit},
booktitle = {ASIMMOD},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soltani, Hoogenboom - 2007 - Coupling Crop Simulation Models with Generated Weather Data to Assess Crop Management Options.pdf:pdf},
keywords = {decision support systems,simulation model,stochastic model,weather generation},
pages = {262--266},
title = {{Coupling Crop Simulation Models with Generated Weather Data to Assess Crop Management Options}},
year = {2007}
}
@misc{George2005,
annote = {From Duplicate 1 ( The Nomadic Trucker Problem - George, Abraham P; Powell, Warren B )
},
author = {George, Abraham P and Powell, Warren B},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/George, Powell - 2005 - The Nomadic Trucker Problem.pdf:pdf},
title = {{The Nomadic Trucker Problem}},
year = {2005}
}
@inproceedings{Marecki2013,
author = {Marecki, Janusz and Petrik, Marek and Subramanian, Dharmashankar},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marecki, Petrik, Subramanian - 2013 - Solution methods for constrained Markov decision process with continuous probability modulation.pdf:pdf},
title = {{Solution methods for constrained Markov decision process with continuous probability modulation}},
url = {http://arxiv.org/abs/1309.6857},
year = {2013}
}
@article{Yang2006,
abstract = {The objective of this paper is to provide an overview of the Hybrid-Maize software (www.hybridmaize.unl.edu, verified 28 Feb. 2006), with emphasis on its practical applications based on our own experience and feedback from users. The Hybrid-Maize model is a computer program that simulates the growth and yield of a corn crop (Zea mays L.) under nonlimiting or water-limited (rainfed or irrigated) conditions. The scientific formulations of the model and its test and validation was published elsewhere. The model can be used to (i) assess the overall site yield potential and its variability based on historical weather data, (ii) evaluate changes in attainable yield using different combinations of planting date, hybrid maturity, and plant density, (iii) analyze yield in relation to silking and maturity in a specific year, (iv) assess soil moisture status and explore options for irrigation management, and (v) conduct in-season simulations to evaluate current crop status and predict final yield at maturity as a range of yield outcome probabilities based on historical climate data for the remainder of the growing season. Three examples are provided to demonstrate practical uses of the model. The software has a user-friendly graphic interface, and includes complete documentation of model formulations, validation, user manual, and context-sensitive help system. Settings of all internal parameters are transparent and modifiable by the user. Limitations of the software for practical uses, especially with regard to water stress and plant population, are also discussed.},
author = {Yang, Haishun and Dobermann, Achim and Cassman, Kenneth G. and Walters, Daniel T.},
doi = {10.2134/agronj2005.0162},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2006 - Features, applications, and limitations of the hybrid-maize simulation model.pdf:pdf},
isbn = {1435-0645},
issn = {00021962},
journal = {Agronomy Journal},
pages = {737--748},
title = {{Features, applications, and limitations of the hybrid-maize simulation model}},
volume = {98},
year = {2006}
}
@article{Candes2008,
author = {Cand{\`{e}}s, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
doi = {10.1007/s00041-008-9045-x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Wakin, Boyd - 2008 - Enhancing Sparsity by Reweighted ℓ 1 Minimization.pdf:pdf},
issn = {1069-5869},
journal = {Journal of Fourier Analysis and Applications},
keywords = {1 -minimization,compressive sensing,dantzig selector,focuss,iterative reweighting,linear equations,sparsity,underdetermined systems of},
number = {5-6},
pages = {877--905},
title = {{Enhancing Sparsity by Reweighted ℓ 1 Minimization}},
url = {http://link.springer.com/10.1007/s00041-008-9045-x},
volume = {14},
year = {2008}
}
@article{Chakrabarti1988,
author = {Chakrabarti, P P and Ghose, S and Desarkar, S C},
journal = {Artificial Intelligence},
pages = {97--113},
title = {{Admissibility of {\{}AO{\}}* when heuristics overestimate}},
year = {1988}
}
@inproceedings{Kearns2001,
author = {Kearns, M and Littman, M L and Singh, S},
booktitle = {International Conference of Uncertainty in Artificial Intelligence},
title = {{Graphical models for game theory}},
year = {2001}
}
@article{Bonet2001,
author = {Bonet, Blai and Geffner, Hector},
journal = {Artificial Intelligence},
pages = {5--33},
title = {{Planning as heuristic search}},
volume = {129},
year = {2001}
}
@article{Puterman1979a,
author = {Puterman, Martin L and Brumelle, Shelby L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman, Brumelle - 1979 - On the convergence of policy iteration in stationary dynamic programming.pdf:pdf},
journal = {Mathematics of Operations Research},
number = {1},
pages = {60--69},
title = {{On the convergence of policy iteration in stationary dynamic programming}},
volume = {4},
year = {1979}
}
@article{Weber2006,
author = {Weber, Stefan},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weber - 2006 - Distribution-invariant dynamic risk measures.pdf:pdf},
journal = {Mathematical Finance},
keywords = {2000,91b16,91b28,91b30,capital requirement,dy-,dynamic risk measure,g11,g18,g28,jel classification,mathematics subject classification,measure convexity,measure of risk,namic consistency,shortfall risk},
number = {2},
pages = {419--442},
title = {{Distribution-invariant dynamic risk measures}},
url = {http://www.econstor.eu/handle/10419/22266},
volume = {16},
year = {2006}
}
@article{Jakubauskas2001,
author = {Jakubauskas, Mark E and Legates, David R and Kastens, Jude H},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jakubauskas, Legates, Kastens - 2001 - Harmonic analysis of time-series AVHRR NDVI data.pdf:pdf},
journal = {Photogrammetric Engineering and Remote Sensing},
number = {4},
pages = {461--470},
title = {{Harmonic analysis of time-series AVHRR NDVI data}},
volume = {67},
year = {2001}
}
@article{Szepesvari2005,
address = {New York, New York, USA},
author = {Szepesv{\'{a}}ri, Csaba and Munos, R{\'{e}}mi},
doi = {10.1145/1102351.1102462},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szepesv{\'{a}}ri, Munos - 2005 - Finite time bounds for sampling based fitted value iteration.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szepesv{\'{a}}ri, Munos - 2005 - Finite time bounds for sampling based fitted value iteration(2).pdf:pdf},
isbn = {1595931805},
journal = {Proceedings of the 22nd international conference on Machine learning - ICML '05},
keywords = {discounted markovian decision problems,fitted value iteration,generative,model,pollard,regression,reinforcement learning,s inequality,statis-,supervised learning},
pages = {880--887},
publisher = {ACM Press},
title = {{Finite time bounds for sampling based fitted value iteration}},
url = {http://dl.acm.org/citation.cfm?id=1102462 http://portal.acm.org/citation.cfm?doid=1102351.1102462},
year = {2005}
}
@inproceedings{Petrik2009,
annote = {From Duplicate 1 ( 

























Biasing Approximate Dynamic Programming with a Lower Discount Factor

























- Petrik, Marek; Scherrer, Bruno )






















From Duplicate 2 ( 

























Biasing approximate dynamic programming with a lower discount factor

























- Petrik, Marek; Scherrer, Bruno )







},
author = {Petrik, Marek and Scherrer, Bruno},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
editor = {Koller, D and Schuurmans, D and Bengio, Y and Bottou, L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Scherrer - 2009 - Biasing Approximate Dynamic Programming with a Lower Discount Factor.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Scherrer - 2008 - Biasing approximate dynamic programming with a lower discount factor.pdf:pdf},
title = {{Biasing approximate dynamic programming with a lower discount factor}},
url = {http://hal.archives-ouvertes.fr/inria-00337652/},
year = {2008}
}
@article{Trick,
annote = {From Duplicate 1 ( Spline Approximations to Value Functions: A Linear Programming Approach - Trick, Michael A; Zin, Stanley E )

From Duplicate 2 ( Spline Approximations to Value Functions: A Linear Programming Approach - Trick, Michael A; Zin, Stanley E )





From Duplicate 2 ( Spline Approximations to Value Functions: A Linear Programming Approach - Trick, Michael A; Zin, Stanley E )
},
author = {Trick, Michael A and Zin, Stanley E},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trick, Zin - Unknown - Spline Approximations to Value Functions A Linear Programming Approach.pdf:pdf},
journal = {Macroeconomic Dynamics},
pages = {255--277},
title = {{Spline Approximations to Value Functions: A Linear Programming Approach}},
url = {citeseer.ist.psu.edu/trick95spline.html},
volume = {1},
year = {1997}
}
@inproceedings{Smith2006,
author = {Smith, T and Simmons, R G},
booktitle = {National Proceedings in Artificial Intelligence (AAAI)},
title = {{Focused real-time dynamic programming}},
year = {2006}
}
@techreport{Lim2009,
author = {Lim, A.E.B and Shanthikumar, J.G. and Vahn, G.Y.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lim, Shanthikumar, Vahn - 2009 - Fragility of CVaR in portfolio optimization.pdf:pdf},
keywords = {coherent measures,conditional value-at-risk,estimation errors,expected shortfall,global,global minimum cvar,mean-cvar optimization,mean-variance op- timization,minimum variance,of risk,portfolio optimization,tailvar},
title = {{Fragility of CVaR in portfolio optimization}},
year = {2009}
}
@article{Ling2008,
abstract = {Synonyms Learning with different classification costs, cost-sensitive classification Definition Cost-Sensitive Learning is a type of learning in data mining that takes the misclassification costs (and possibly other types of cost) into consideration. The goal of this type of learning is to minimize the total cost. The key difference between cost-sensitive learning and cost-insensitive learning is that cost-sensitive learning treats the different misclassifications differently. Cost-insensitive learning does not take the misclassification costs into consideration. The goal of this type of learning is to pursue a high accuracy of classifying examples into a set of known classes. The class imbalanced datasets occurs in many real-world applications where the class distributions of data are highly imbalanced. Cost-sensitive learning is a common approach to solve this problem.},
author = {Ling, Charles X. and Sheng, Victor S.},
doi = {10.1.1.15.7095},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ling, Sheng - 2008 - Cost-sensitive learning and the class imbalance problem.pdf:pdf},
isbn = {9780387307688},
journal = {Encyclopedia of Machine Learning},
pages = {231--235},
title = {{Cost-sensitive learning and the class imbalance problem}},
url = {http://www.springer.com/computer/ai/book/978-0-387-30768-8{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.164.4418{\&}rep=rep1{\&}type=pdf},
year = {2008}
}
@book{Kaufmann1967,
author = {Kaufmann, Arnold},
title = {{Graphs, Dynamic Programming, and Finite Games}},
year = {1967}
}
@inproceedings{Viappiani2011,
annote = {Assumes the the customers do not change. Shows that there is no point to explore because the best exploitation set is also the best one for exploration. However:
-For the Bayesian model: The paper assumes that there is only one step after the choice of the product. Either the customer takes what is offered (ESU) from the set of products, or the best overall product is available to the customer.



EU - Expected utility
EUS - Expected Utility of Selection: The myopic utility of the product set
EPU - Expected Posterior Utility: 

SMR - Setwise Max Regret
MR - Max Regret
WR - Worst Case Regret},
author = {Viappiani, Paolo and Boutilier, Craig},
booktitle = {National Conference on Artificial Intelligence (AAAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viappiani, Boutilier - 2011 - Recommendation Sets and Choice Queries There Is No ExplorationExploitation Tradeoff!.pdf:pdf},
title = {{Recommendation Sets and Choice Queries: There Is No Exploration/Exploitation Tradeoff!}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/viewPDFInterstitial/3592/4103},
year = {2011}
}
@article{Even-Dar2004,
abstract = {In this paper we derive convergence rates for Q-learning. We show$\backslash$nan interesting relationship between the convergence rate and the$\backslash$nlearning rate used in Q-learning. For a polynomial learning rate,$\backslash$none which is 1/t$\omega$ at time t where $\omega$∈(1/2,1), we show that the convergence$\backslash$nrate is polynomial in 1/(1-$\gamma$), where $\gamma$ is the discount factor. In$\backslash$ncontrast we show that for a linear learning rate, one which is 1/t$\backslash$nat time t, the convergence rate has an exponential dependence on$\backslash$n1/(1-$\gamma$). In addition we show a simple example that proves this exponential$\backslash$nbehavior is inherent for linear learning rates.},
author = {Even-Dar, E and Mansour, Y},
doi = {10.1.1.28.466},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Even-Dar, Mansour - 2004 - Learning Rates for Q-Learning.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {Q-Learning,Reinforcement Learning},
pages = {1--25},
title = {{Learning Rates for Q-Learning}},
url = {http://portal.acm.org/citation.cfm?id=1005332.1005333{\#}},
volume = {5},
year = {2004}
}
@inproceedings{Li2015,
abstract = {This paper studies the off-policy evaluation prob-lem, where one aims to estimate the value of a target policy based on a sample of observations collected by another policy. We first consider the single-state, or multi-armed bandit case, estab-lish a finite-time minimax risk lower bound, and analyze the risk of three standard estimators. For the so-called regression estimator, we show that while it is asymptotically optimal, for small sam-ple sizes it may perform suboptimally compared to an ideal oracle up to a multiplicative factor that depends on the number of actions. We also show that the other two popular estimators can be ar-bitrarily worse than the optimal, even in the limit of infinitely many data points. The performance of the estimators are studied in synthetic and real problems; illustrating the methods strengths and weaknesses. We also discuss the implications of these results for off-policy evaluation problems in contextual bandits and fixed-horizon Markov decision processes.},
author = {Li, Lihong and Munos, R{\'{e}}mi and Szepesv{\'{a}}ri, Csaba},
booktitle = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Munos, Szepesv{\'{a}}ri - 2015 - Toward Minimax Off-policy Value Estimation.pdf:pdf},
title = {{Toward Minimax Off-policy Value Estimation}},
year = {2015}
}
@article{Draper1996,
abstract = {The field of computer vision has made significant advances over$\backslash$nthe past twenty years, yet we still have not developed a theoretical or$\backslash$npractical understanding of how the many components of vision are$\backslash$ncombined into coherent, functioning systems. As a result, there are few$\backslash$napplications of computer vision technology in the real world, even$\backslash$nthough the library of available computer vision techniques keeps$\backslash$ngrowing. This paper models the control of visual procedures as a Markov$\backslash$ndecision problem, and presents a version of the schema learning system$\backslash$n(SLS) that uses this model to assemble object recognition programs from$\backslash$nexisting computer vision algorithms. An example of SLS learning to$\backslash$nrecognize rooftops in aerial images is presented},
author = {Draper, B.a.},
doi = {10.1109/ICPR.1996.547241},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Draper - 1996 - Modeling object recognition as a Markov decision process.pdf:pdf},
isbn = {0-8186-7282-X},
issn = {1051-4651},
journal = {International Conference on Pattern Recognition},
pages = {95--99},
title = {{Modeling object recognition as a Markov decision process}},
volume = {4},
year = {1996}
}
@inproceedings{Poupart2008,
author = {Poupart, Pascal and Vlassis, Nikos},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poupart, Vlassis - Unknown - Model-based Bayesian Reinforcement Learning in Partially Observable Domains.pdf:pdf},
title = {{Model-based Bayesian Reinforcement Learning in Partially Observable Domains}},
year = {2008}
}
@article{Bertsimas2006,
author = {Bertsimas, Dimitris and Thiele, Aurelie},
doi = {10.1287/opre.1050.0238},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bertsimas, Thiele - 2006 - A Robust Optimization Approach to Inventory Theory.pdf:pdf},
issn = {0030-364X},
journal = {Operations Research},
month = {jan},
number = {1},
pages = {150--168},
title = {{A Robust Optimization Approach to Inventory Theory}},
url = {http://or.journal.informs.org/cgi/doi/10.1287/opre.1050.0238},
volume = {54},
year = {2006}
}
@article{Drummond2003,
abstract = {Imbalanced data sets are becoming ubiquitous, as many applications have very few instances of the “interesting ” or “abnormal” class. Traditional machine learning algorithms can be biased towards majority class due to over-prevalence. It is desired that the interesting (minority) class prediction be improved, even if at the cost of additional majority class errors. In this paper, we study three issues, usually considered separately, concerning decision trees and imbalanced data sets — quality of probabilistic estimates, pruning, and effect of preprocessing the imbalanced data set by over or undersampling methods such that a fairly balanced training set is provided to the decision trees. We consider each issue independently and in conjunction with each other, highlighting the scenarios where one method might be preferred over another for learning decision trees from imbalanced data sets. 1.},
author = {Drummond, Chris and Holte, Robert C. and Chawla, Nitesh V. and Sheng, Victor S. and Gu, Bin and Fang, Wei and Wu, Jian},
doi = {10.1.1.126.1087},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drummond et al. - 2003 - Exploiting the cost (in)sensitivity of decision tree splitting criteria.pdf:pdf},
journal = {International Conference on Machine Learning},
keywords = {Cost-sensitive learning,Data mining,Defect escalation,Machine learning,Software defect escalation prediction},
number = {1},
pages = {239--246},
title = {{Exploiting the cost (in)sensitivity of decision tree splitting criteria}},
url = {http://www.site.uottawa.ca:4321/{~}nat/Workshop2003/chawla.pdf{\%}5Cnhttp://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-009.pdf},
volume = {66},
year = {2003}
}
@techreport{Defourny2008,
author = {Defourny, Boris and Ernst, Damien and Wehenkel, Louis},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Defourny, Ernst, Wehenkel - 2008 - Risk-Aware Decision Making and Dynamic Programming.pdf:pdf},
title = {{Risk-Aware Decision Making and Dynamic Programming}},
year = {2008}
}
@inproceedings{Zhou2010,
author = {Zhou, Zhi-Hua and Liu, Xu-Ying},
booktitle = {AAAI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Liu - 2006 - On Multi-Class Cost-Sensitive Learning.pdf:pdf},
keywords = {class-imbalance learning,cost-sensitive learning,data mining,machine learning,multi-class,problems,rescaling},
pages = {567--572},
title = {{On Multi-Class Cost-Sensitive Learning}},
year = {2006}
}
@book{Rasmussen2006,
author = {Rasmussen, Carl Edward and Williams, Chris},
publisher = {MIT Press},
title = {{Gaussian Processes for Machine Learning}},
year = {2006}
}
@book{Agresti2002,
abstract = {Amstat News asked three review editors to rate their top five favorite books in the September 2003 issue. Categorical Data Analysis was among those chosen. A valuable new edition of a standard reference "A 'must-have' book for anyone expecting to do research and/or applications in categorical data analysis." Statistics in Medicine on Categorical Data Analysis, First Edition The use of statistical methods for categorical data has increased dramatically, particularly for applications in the biomedical and social sciences. Responding to new developments in the field as well as to the needs of a new generation of professionals and students, this new edition of the classic Categorical Data Analysis offers a comprehensive introduction to the most important methods for categorical data analysis. Designed for statisticians and biostatisticians as well as scientists and graduate students practicing statistics, Categorical Data Analysis, Second Edition summarizes the latest methods for univariate and correlated multivariate categorical responses. Readers will find a unified generalized linear models approach that connects logistic regression and Poisson and negative binomial regression for discrete data with normal regression for continuous data. Adding to the value in the new edition is coverage of: Three new chapters on methods for repeated measurement and other forms of clustered categorical data, including marginal models and associated generalized estimating equations (GEE) methods, and mixed models with random effects Stronger emphasis on logistic regression modeling of binary and multicategory data An appendix showing the use of SAS for conducting nearly all analyses in the book Prescriptions for how ordinal variables should be treated differently than nominal variables Discussion of exact small-sample procedures More than 100 analyses of real data sets to illustrate application of the methods, and more than 600 exercises An Instructor's Manual presenting detailed solutions to all the problems in the book is available from the Wiley editorial department.},
author = {Agresti, Alan},
booktitle = {Wiley series in probability and statistics},
doi = {10.1198/tech.2003.s28},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agresti - 2002 - Categorical Data Analysis.pdf:pdf},
isbn = {0471360937},
issn = {00401706},
number = {1},
pages = {xv, 710 p. ST -- Categorical data analysis},
pmid = {20826130},
title = {{Categorical Data Analysis}},
url = {http://www.loc.gov/catdir/toc/wiley024/2002068982.html},
volume = {45},
year = {2002}
}
@article{Ben-Tal2005,
author = {Ben-Tal, Aharon and Teboulle, Marc},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ben‐Tal, Teboulle - 2007 - AN OLD‐NEW CONCEPT OF CONVEX RISK MEASURES THE OPTIMIZED CERTAINTY EQUIVALENT.pdf:pdf},
journal = {Mathematical Finance},
pages = {449--476},
title = {{An Old-New Concept of Convex Risk Measures: The Optimized Certainty Equivalent}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9965.2007.00311.x/full},
volume = {17},
year = {2007}
}
@phdthesis{Vahn2012,
author = {Vahn, GY},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vahn - 2012 - New approaches to robustness and learning in data-driven portfolio optimization.pdf:pdf},
title = {{New approaches to robustness and learning in data-driven portfolio optimization}},
url = {http://escholarship.org/uc/item/8x42f5pd.pdf},
year = {2012}
}
@inproceedings{Mahadevan2005,
author = {Mahadevan, Sridhar},
booktitle = {National Conference on Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahadevan - Unknown - Samuel meets Amarel Automating Value Function Approximation using Global State Space Analysis.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahadevan - 2005 - Value Function Approximation with Diffusion Wavelets and Laplacian Eigenfunctions.pdf:pdf},
keywords = {harmonic analysis,markov decision processes,ory,reinforcement learning,riemannian manifolds,spectral graph the-},
pages = {1--12},
title = {{Samuel meets Amarel: Automating value function approximation using global state space analysis}},
year = {2005}
}
@book{Abrol2014,
editor = {Abrol, Dharam P.},
file = {:home/marek/Downloads/book/book.pdf:pdf},
isbn = {978-0-12-398529-3},
publisher = {Academic Press},
title = {{Integrated Pest Management: Current Concepts and Ecological Perspective}},
year = {2014}
}
@article{Farias2003,
annote = {From Duplicate 2 ( The linear programming approach to approximate dynamic programming - de Farias, Daniela Pucci; Roy, Benjamin Van; Farias, Daniela Pucci De )

From Duplicate 1 ( On constraint sampling in the linear programming approach to approximate dynamic programming - de Farias, Daniela Pucci; Roy, Benjamin Van; Farias, Daniela Pucci De )

From Duplicate 1 ( On Constraint Sampling in the Linear Programming Approach to Approximate Dynamic Programming - Farias, Daniela Pucci De; Roy, Benjamin Van )





From Duplicate 3 ( On constraint sampling in the linear programming approach to approximate dynamic programming - de Farias, Daniela Pucci; Roy, Benjamin Van )
},
author = {de Farias, Daniela P. and {Van Roy}, Benjamin},
doi = {10.1287/moor.1040.0094},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Farias, Roy - 2002 - THE LINEAR PROGRAMMING APPROACH TO APPROXIMATE DYNAMIC PROGRAMMING.pdf:pdf},
journal = {Operations Research},
keywords = {2001,2002,2003,90c06,90c08,90c39,and july 28,basis functions,dynamic programming,finite state,history,markov,markov decision processes,ms subject classification,msc2000 subject classification,optimal control,or,policy,primary,received august 24,revised july 31,secondary,value function},
number = {6},
pages = {850--865},
title = {{The linear programming approach to approximate dynamic programming}},
volume = {51},
year = {2003}
}
@article{Jornsten1992,
author = {Jornsten, K and Leisten, R},
journal = {Optimization},
pages = {141--208},
title = {{Column aggregation and primal decomposition in linear programming: some observations}},
volume = {24},
year = {1992}
}
@article{Liu2004,
author = {Liu, Gin-rong and Liang, Chih-Kang and Kuo, Tsung-Hua and Lin, Tang-Huang and Shih-Jen-Huang},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2004 - Comparison of the NDVI, ARVI and AFRI vegetation index along with their relations with the AOD using SPOT 4 Vegetati.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Liang - Unknown - Comparison of the NDVI , ARVI and AFRI vegetation index , along with their relations with the AOD using SPOT 4 Ve.pdf:pdf},
journal = {TAO},
number = {1},
pages = {15--31},
title = {{Comparison of the NDVI, ARVI and AFRI vegetation index along with their relations with the AOD using SPOT 4 Vegetation data}},
url = {http://thesis.lib.ncu.edu.tw/ETD-db/ETD-search/view{\_}etd?URN=89621013},
volume = {15},
year = {2004}
}
@inproceedings{Viappiani2010,
author = {Viappiani, Paolo and Boutilier, Craig},
booktitle = {Neural Information Processing Systems (NIPS)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Viappiani, Boutilier - 2010 - Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets.pdf:pdf},
pages = {1--14},
title = {{Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets.}},
url = {https://papers.nips.cc/paper/3943-optimal-bayesian-recommendation-sets-and-myopically-optimal-choice-query-sets.pdf},
year = {2010}
}
@article{Shetty1987,
author = {Shetty, C M and Taylor, R W},
journal = {Computers and Operations Research},
pages = {385--393},
title = {{Solving large-scale linear programs by aggregation}},
volume = {14},
year = {1987}
}
@book{Oliver2004,
author = {Oliver, E and Porter, I},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oliver, Porter - 2004 - The Incomplete Guide to the Art of Discovery.pdf:pdf},
title = {{The Incomplete Guide to the Art of Discovery}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.115.2030},
year = {2004}
}
@article{Li1990,
abstract = {This paper studies one application of mutual information to symbolic sequences: the mutual information functionM(d). This function is compared with the more frequently used correlation functionG(d). An exact relation betweenM(d) andG(d) is derived for binary sequences. For sequences with more than two symbols, no such general relation exists; in particular,G(d)=0 may or may not lead toM(d)=0. This linear, but not general, independence between symbols separated by a distance is studied for ternary sequences. Also included is the estimation of the finite-size effect on calculating mutual information. Finally, the concept of symbolic noise is discussed.},
author = {Li, Wentian},
doi = {10.1007/BF01025996},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li - 1990 - Mutual information functions versus correlation functions.pdf:pdf},
issn = {00224715},
journal = {Journal of Statistical Physics},
keywords = {Mutual information function,correlation functions,linear and general dependence,symbolic noise},
number = {5-6},
pages = {823--837},
title = {{Mutual information functions versus correlation functions}},
volume = {60},
year = {1990}
}
@article{Shapiro2013,
author = {Shapiro, A. and Tekaya, W. and da Costa, J. P. and Soares, M. P.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shapiro et al. - 2013 - Risk-neutral and risk-averse stochastic dual dynamic programming method.pdf:pdf},
journal = {European Journal of Operational Research},
keywords = {average value-at-risk,case studies,dynamic equations,multistage stochastic programming,programming,risk averse,sample average approximation,stochastic dual dynamic},
number = {2},
pages = {375--391},
title = {{Risk-neutral and risk-averse stochastic dual dynamic programming method}},
volume = {224},
year = {2013}
}
@article{Xie2013,
annote = {The important contribution is that the state space of the bandit is finite when to cost is greater than 0},
author = {Xie, Jing and Frazier, PI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Frazier - 2013 - Sequential Bayes-Optimal Policies for Multiple Comparisons with a Known Standard.pdf:pdf},
journal = {Operations Research},
keywords = {bayesian statistics,control,dynamic programming,multiple comparisons with a,sequential experimental design,value of information},
title = {{Sequential Bayes-Optimal Policies for Multiple Comparisons with a Known Standard}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.2013.1207},
year = {2013}
}
@inproceedings{Davenport2000,
abstract = {The ability to detect metabolic changes in crop canopy before visible to the unaided human eye has the potential to improve the producer's ability to manage key inputs such as water, nutrients, and crop load. As model crops, we have chosen to work on the perennial crop grape (Vitis labrusca) and the annual crop potato (Solanum tuberosum). The early detection of stresses related to a range of physiological and/or environmental stress disorders in a perennial crop like grape can be used to make adjustments in water and/or canopy management. The effects of the disorders are multi-year and cumulative. In the annual crop, the early detection of water and nutrient (nitrogen) stress could be used to alter management practices to have fairly immediate but less long lasting impact relative to the perennial crop. We developed plant material with imposed stresses in both greenhouse and field conditions (Washington, USA, in 1998) and are developing full spectrum leaf reflectance libraries of the crop stress responses. The specific stress response wavelength can then be used to develop detection equipment in the bands specific to the stress response. To date, our research suggests wavelengths specific to the studied stresses of nutrient deficiency, water deficit, or chlorophyll loss, resulting in leaf discoloration unique and not consistent with wavelengths currently associated with remote sensing indices.},
author = {Davenport, J.R. and Lang, N.S. and Perry, E.M.},
booktitle = {Proceedings of the International Conference on Precision Agriculture},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davenport, Lang, Perry - 2000 - Leaf spectral reflectance for early detection of disorders in model annual and perennial crops.pdf:pdf},
pages = {1--14},
title = {{Leaf spectral reflectance for early detection of disorders in model annual and perennial crops}},
url = {http://www.psi.cz/ftp/publications/Remote Sensing Papers/Davenport-Lang-Perry-2000.pdf},
year = {2000}
}
@phdthesis{Madani2000,
author = {Madani, Omid},
school = {University of Washington},
title = {{Complexity results for infinite-horizon Markov decision processes}},
year = {2000}
}
@techreport{Edge,
author = {Edge, Red},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Edge - Unknown - The RapidEye Red Edge Band 2 The RapidEye Multispectral.pdf:pdf},
pages = {1--6},
title = {{The RapidEye Red Edge Band 2 The RapidEye Multispectral}}
}
@phdthesis{Delage2009a,
author = {Delage, Erick Hans},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Delage - 2009 - Distributionally robust optimization in context of data-driven problems.pdf:pdf},
school = {Stanford University},
title = {{Distributionally robust optimization in context of data-driven problems}},
url = {http://web.hec.ca/pages/erick.delage/DelageThesis.pdf},
year = {2009}
}
@article{Jones1998,
author = {Jones, Bruce L},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones - 1998 - Empirical Estimation of Risk Measures and Related Quantities.pdf:pdf},
title = {{Empirical Estimation of Risk Measures and Related Quantities}},
year = {1998}
}
@article{Shani2008,
abstract = {Recent scaling up of partially observable Markov decision process (POMDP) solvers toward realistic applications is largely due to point-based methods that quickly converge to an approximate solution for medium-sized domains. These algorithms compute a value function for a finite reachable set of belief points, using backup operations. Point-based algorithms differ on the selection of the set of belief points and on the order by which backup operations are executed on the selected belief points. We first show how current algorithms execute a large number of backups that can be removed without reducing the quality of the value function. We demonstrate that the ordering of backup operations on a predefined set of belief points is important. In the simpler domain of MDP solvers, prioritizing the order of equivalent backup operations on states is known to speed up convergence. We generalize the notion of prioritized backups to the POMDP framework, showing how existing algorithms can be improved by prioritizing backups. We also present a new algorithm, which is the prioritized value iteration, and show empirically that it outperforms current point-based algorithms. Finally, a new empirical evaluation measure (in addition to the standard runtime comparison), which is based on the number of atomic operations and the number of belief points, is proposed in order to provide more accurate benchmark comparisons.},
author = {Shani, Guy and Brafman, Ronen I and Shimony, Solomon Eyal},
doi = {10.1109/TSMCB.2008.928222},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shani, Brafman, Shimony - 2008 - Prioritizing point-based POMDP solvers.pdf:pdf},
issn = {1941-0492},
journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Decision Making,Decision Support Techniques,Markov Chains,Models, Theoretical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Problem Solving},
month = {dec},
number = {6},
pages = {1592--605},
pmid = {19022729},
title = {{Prioritizing point-based POMDP solvers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19022729},
volume = {38},
year = {2008}
}
@inproceedings{Azar2012,
author = {Azar, Mohammad Gheshlaghi and Munos, Remi and Kappen, Hilbert J},
booktitle = {International Conference of Machine Learning (ICML)},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azar, Munos, Kappen - 2012 - On the Sample Complexity of Reinforcement Learning with a Generative Model.pdf:pdf},
title = {{On the Sample Complexity of Reinforcement Learning with a Generative Model}},
year = {2012}
}
@article{Bowling2004,
author = {Bowling, Michael and Veloso, Manuela},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bowling, Veloso - 2004 - Existence of multiagent equilibria with limited agents.pdf:pdf},
journal = {Journal of {\{}A{\}}rtificial {\{}I{\}}ntelligence {\{}R{\}}esearch},
pages = {353�384},
title = {{Existence of multiagent equilibria with limited agents}},
volume = {22},
year = {2004}
}
@inproceedings{Manikonda2010,
author = {Manikonda, Lydia and Tuli, Annu and Pudi, Vikram},
booktitle = {SIGAI Workshop on Emerging Research Trends in AI},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Manikonda, Tuli, Pudi - 2010 - ProMax A Profit Maximizing Recommendation System for Market Baskets.pdf:pdf},
number = {April},
title = {{ProMax: A Profit Maximizing Recommendation System for Market Baskets}},
year = {2010}
}
@article{Ritter2003,
author = {Ritter, A and Hupet, F and Munoz-Carpena, R},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ritter, Hupet, Munoz-Carpena - 2003 - Using inverse methods for estimating soil hydraulic properties from field data as an alternative t.pdf:pdf},
journal = {Agricultural Water {\ldots}},
title = {{Using inverse methods for estimating soil hydraulic properties from field data as an alternative to direct methods}},
url = {http://www.sciencedirect.com/science/article/pii/S0378377402001609},
volume = {59},
year = {2003}
}
@article{Fereres2007,
abstract = {At present and more so in the future, irrigated agriculture will take place under water scarcity. Insufficient water supply for irrigation will be the norm rather than the exception, and irrigation management will shift from emphasizing production per unit area towards maximizing the production per unit of water consumed, the water productivity. To cope with scarce supplies, deficit irrigation, defined as the application of water below full crop-water requirements (evapotranspiration), is an important tool to achieve the goal of reducing irrigation water use. While deficit irrigation is widely practised over millions of hectares for a number of reasons - from inadequate network design to excessive irrigation expansion relative to catchment supplies - it has not received sufficient attention in research. Its use in reducing water consumption for biomass production, and for irrigation of annual and perennial crops is reviewed here. There is potential for improving water productivity in many field crops and there is sufficient information for defining the best deficit irrigation strategy for many situations. One conclusion is that the level of irrigation supply under deficit irrigation should be relatively high in most cases, one that permits achieving 60-100{\%} of full evapotranspiration. Several cases on the successful use of regulated deficit irrigation (RDI) in fruit trees and vines are reviewed, showing that RDI not only increases water productivity, but also farmers' profits. Research linking the physiological basis of these responses to the design of RDI strategies is likely to have a significant impact in increasing its adoption in water-limited areas.},
annote = {Some of the water losses are necessary to maintain soil salinity. Otherwise, the salts accumulate in the soil. Therefore, leaching is necessary!

Full irrigation meets the evapotranspiration losses

Two possible outcomes
- water is taken from the soil reserve
- water stress to the plan},
author = {Fereres, Elias and Soriano, Mar{\'{i}}a Auxiliadora},
doi = {10.1093/jxb/erl165},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fereres, Soriano - 2007 - Deficit irrigation for reducing agricultural water use.pdf:pdf},
issn = {0022-0957},
journal = {Journal of experimental botany},
keywords = {Agriculture,Agriculture: methods,Biomass,Crops, Agricultural,Disasters,Fruit,Trees,Water,Water Supply,Water: analysis,Water: metabolism},
month = {jan},
number = {2},
pages = {147--59},
pmid = {17088360},
title = {{Deficit irrigation for reducing agricultural water use.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17088360},
volume = {58},
year = {2007}
}
@article{Ward2009,
abstract = {In ecological modeling of the habitat of a species, it can be prohibitively expensive to determine species absence. Presence-only data consist of a sample of locations with observed presences and a separate group of locations sampled from the full landscape, with unknown presences. We propose an expectation-maximization algorithm to estimate the underlying presence-absence logistic model for presence-only data. This algorithm can be used with any off-the-shelf logistic model. For models with stepwise fitting procedures, such as boosted trees, the fitting process can be accelerated by interleaving expectation steps within the procedure. Preliminary analyses based on sampling from presence-absence records of fish in New Zealand rivers illustrate that this new procedure can reduce both deviance and the shrinkage of marginal effect estimates that occur in the naive model often used in practice. Finally, it is shown that the population prevalence of a species is only identifiable when there is some unrealistic constraint on the structure of the logistic model. In practice, it is strongly recommended that an estimate of population prevalence be provided.},
author = {Ward, G and Hastie, T and Barry, S and Elith, J and Leathwick, J R},
doi = {10.1111/j.1541-0420.2008.01116.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ward et al. - 2009 - Presence-Only Data and the EM Algorithm.pdf:pdf},
isbn = {0006-341X},
issn = {0006341X 15410420},
journal = {Biometrics},
keywords = {Boosted trees,EM algorithm,Logistic model,Presence-only data,Use-availability data,distributions,fish,habitat,new-zealand,regression},
number = {2},
pages = {554--563},
pmid = {18759851},
title = {{Presence-Only Data and the EM Algorithm}},
volume = {65},
year = {2009}
}
@article{Kaelbling1996,
author = {Kaelbling, LP and Littman, ML and Moore, AW},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kaelbling, Littman, Moore - 1996 - Reinforcement learning A survey.pdf:pdf},
journal = {arXiv preprint cs/9605103},
pages = {237--285},
title = {{Reinforcement learning: A survey}},
url = {http://arxiv.org/abs/cs/9605103},
year = {1996}
}
@inproceedings{Osogami2011,
author = {Osogami, Takayuki},
booktitle = {Uncertainty in Artificial Intelligence},
title = {{Iterated risk measures for risk-sensitive Markov decision processes with discounted}},
year = {2011}
}
@article{Bjorklund2007,
author = {Bj{\"{o}}rklund, H and Vorobyov, Sergei},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bj{\"{o}}rklund, Vorobyov - 2007 - A combinatorial strongly subexponential strategy improvement algorithm for mean payoff games.pdf:pdf},
journal = {Discrete Applied Mathematics},
title = {{A combinatorial strongly subexponential strategy improvement algorithm for mean payoff games}},
url = {http://www.sciencedirect.com/science/article/pii/S0166218X06002137},
year = {2007}
}
@inproceedings{Dean1997a,
author = {Dean, T and Givan, R and Leach, S},
booktitle = {Proceedings of the Thirteenth conference on {\ldots}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dean, Givan, Leach - 1997 - Model reduction techniques for computing approximately optimal solutions for Markov decision processes.pdf:pdf},
title = {{Model reduction techniques for computing approximately optimal solutions for Markov decision processes}},
url = {http://dl.acm.org/citation.cfm?id=2074241},
year = {1997}
}
@inproceedings{Petrik2008,
author = {Petrik, Marek and Zilberstein, Shlomo},
booktitle = {ISAIM},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik, Zilberstein - 2008 - A successive approximation algorithm for coordination problems.pdf:pdf},
title = {{A successive approximation algorithm for coordination problems}},
url = {http://isaim2008.unl.edu/PAPERS/TechnicalProgram/ISAIM2008{\_}0010{\_}bd3e886d5985e3a71bd4ba492e513685.pdf},
year = {2008}
}
@phdthesis{Petrik2010a,
author = {Petrik, Marek},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2010 - Optimization-based Approximate Dynamic Programming.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Presented, Petrik, Philosophy - 2010 - OPTIMIZATION-BASED APPROXIMATE DYNAMIC PROGRAMMING.pdf:pdf;:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Petrik - 2010 - Optimization-based approximate dynamic programming.pdf:pdf},
number = {September},
school = {University of Massachusetts Amherst},
title = {{Optimization-based Approximate Dynamic Programming}},
url = {http://scholarworks.umass.edu/open{\_}access{\_}dissertations/308/},
year = {2010}
}
@inproceedings{Poupart2002a,
author = {Poupart, Pascal and Boutilier, Craig},
booktitle = {Advances in Neural Information Processing Systems},
pages = {1547--1554},
title = {{Value-directed compression of POMDPs}},
year = {2002}
}
@article{Nino-Mora2011,
abstract = {This paper considers the efficient exact computation of the counterpart of the Gittins index for a finite-horizon discrete-state bandit, which measures for each initial state the average productivity, given by the maximum ratio of expected total discounted reward earned to expected total discounted time expended that can be achieved through a number of successive plays stopping by the given horizon. Besides characterizing optimal policies for the finite-horizon one-armed bandit problem, such an index provides a suboptimal heuristic index rule for the intractable finite-horizon multiarmed bandit problem, which represents the natural extension of the Gittins index rule (optimal in the infinite-horizon case). Although such a finite-horizon index was introduced in classic work in the 1950s, investigation of its efficient exact computation has received scant attention. This paper introduces a recursive adaptive-greedy algorithm using only arithmetic operations that computes the index in (pseudo-)polynomial time in the problem parameters (number of project states and time horizon length). In the special case of a project with limited transitions per state, the complexity is either reduced or depends only on the length of the time horizon. The proposed algorithm is benchmarked in a computational study against the conventional calibration method.},
author = {Ni{\~{n}}o-Mora, Jos{\'{e}}},
doi = {10.1287/ijoc.1100.0398},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ni{\~{n}}o-Mora - 2011 - Computing a classic index for finite-horizon bandits.pdf:pdf},
isbn = {1091-9856},
issn = {10919856},
journal = {INFORMS Journal on Computing},
keywords = {Analysis of algorithms,Bandits, finite-horizon,Computational complexity,Dynamic programming, Markov,Index policies},
number = {2},
pages = {254--267},
title = {{Computing a classic index for finite-horizon bandits}},
volume = {23},
year = {2011}
}
@misc{Trick1993,
author = {Trick, M and Stanley, E},
title = {{A Linear Programming Approach to Solving Stochastic Dynamic Programs}},
url = {citeseer.ist.psu.edu/trick93linear.html},
year = {1993}
}
@article{Prastacos1984,
author = {Prastacos, G. P.},
doi = {10.1287/mnsc.30.7.777},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Prastacos - 1984 - Blood Inventory Management An Overview of Theory and Practice.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
month = {jul},
number = {7},
pages = {777--800},
title = {{Blood Inventory Management: An Overview of Theory and Practice}},
url = {http://mansci.journal.informs.org/cgi/doi/10.1287/mnsc.30.7.777},
volume = {30},
year = {1984}
}
@article{Lehman2010,
abstract = {This document is a systematic reference manual for the biblatex package. Look at the sample documents which ship with this package to get a first impression. For a quick start guide, browse {\S}{\S} 1.1, 2.1, 2.2, 2.3, 3.1, 3.3, 3.5, 3.6, 3.10.},
author = {Lehman, Philipp},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lehman - 2010 - The biblatex Package.pdf:pdf},
journal = {English},
pages = {206},
title = {{The biblatex Package}},
year = {2010}
}
@article{Yang2008,
author = {Yang, Fan and Coulberson, Joseph and Holte, Robert and Zahavi, Uzi and Felner, Ariel},
journal = {Journal of Artificial Intelligence Research},
pages = {631--662},
title = {{A General Theory of Assitive State Space Abstraction}},
volume = {32},
year = {2008}
}
@inproceedings{Smith2004,
author = {Smith, Trey and Simmons, Reid},
booktitle = {Conference on Uncertainty in Artificial Intelligence},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith, Simmons - Unknown - Heuristic Search Value Iteration for POMDPs.pdf:pdf},
title = {{Heuristic search value iteration}},
year = {2004}
}
@article{Lake2015,
abstract = {People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation.We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world's alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches.We also present several “visual Turing tests” probing the model's creative generalization abilities, which in many cases are indistinguishable from human behavior.},
archivePrefix = {arXiv},
arxivId = {10.1126/science.aab3050},
author = {Lake, B. M. and Salakhutdinov, R. and Tenenbaum, J. B.},
doi = {10.1126/science.aab3050},
eprint = {science.aab3050},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lake, Salakhutdinov, Tenenbaum - 2015 - Human-level concept learning through probabilistic program induction.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
number = {6266},
pages = {1332--1338},
pmid = {26659050},
primaryClass = {10.1126},
title = {{Human-level concept learning through probabilistic program induction}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.aab3050},
volume = {350},
year = {2015}
}
@inproceedings{Jong2005,
author = {Jong, Nicholas K and Stone, Peter},
booktitle = {International Joint Conference on Artificial Intelligence},
title = {{State abstraction discovery from irrelevant state variables}},
year = {2005}
}
@article{Fithian2013,
abstract = {Statistical modeling of presence-only data has attracted much recent attention in the ecological literature, leading to a proliferation of meth- ods, including the inhomogeneous poisson process (IPP) model [15], maxi- mum entropy (Maxent) modeling of species distributions [12] [9] [10], and logistic regression models. Several recent articles have shown the close relationships between these methods [1] [15]. We explain why the IPP intensity function is a more natural object of inference in presence-only studies than occurrence probability (which is only defined with reference to quadrat size), and why presence-only data only allows estimation of relative, and not absolute intensities. All three of the above techniques amount to parametric density esti- mation under the same exponential family model. We show that the IPP and Maxent models give the exact same estimate for this density, but lo- gistic regression in general produces a different estimate in finite samples. When the model is misspecified, logistic regression and the IPP may have substantially different asymptotic limits with large data sets. We propose “infinitely weighted logistic regression,” which is exactly equivalent to the IPP in finite samples. Consequently, many already-implemented methods extending logistic regression can also extend the Maxent and IPP models in directly analogous ways using this technique. Finally, we address the issue of observer bias, modeling the presence- only data set as a thinned IPP.We discuss when the observer bias problem can solved by regression adjustment, and additionally propose a novel method for combining presence-only and presence-absence records from one or more species to account for it.},
archivePrefix = {arXiv},
arxivId = {arXiv:1207.6950v2},
author = {Fithian, William and Hastie, Trevor},
doi = {10.1214/13-AOAS667},
eprint = {arXiv:1207.6950v2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fithian, Hastie - 2013 - Finite-sample equivalence in statistical models for presence-only data.pdf:pdf},
isbn = {1932-6157},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Case-control sampling,Logistic regression,Maximum entropy,Poisson process models,Presence-only data,Species modeling},
number = {4},
pages = {1917--1939},
pmid = {25493106},
title = {{Finite-sample equivalence in statistical models for presence-only data}},
volume = {7},
year = {2013}
}
@article{Allen2016b,
abstract = {a b s t r a c t Available online xxxx Identifying invasion risk is critical for regional prioritization of management and monitoring, however, we cur-rently lack a comprehensive assessment of the invasion risk posed by plants for the United States. We aim to quantify geographic invasion risk for currently established terrestrial invasive plants in the continental U.S. under current and future climate. We assembled a comprehensive occurrence database for 896 terrestrial inva-sive plant species from 33 regional collections of field and museum data and projected species ranges using MaxEnt species distribution models based on current (1950–2000 average) and future (2040–2060 average) cli-mate. We quantified geographic invasion risk as differences in species richness, invasion debt, range infilling, and identification of hotspots. Potential invasive plant richness was higher than observed richness, particularly in eastern temperate forests, where as many as 83{\%} of species with suitable climate have not yet established. A small percentage (median = 0.22{\%}) of species' potential ranges are currently occupied by them. With climate change, potential invasive plant richness declined by a median of 7.3{\%} by 2050. About 80{\%} of invasive plant hotspots were geographically stable with climate change, with the remaining 20{\%} shifting northward. Invasion hotspots and current invasion debt reveal extensive, ongoing risk from existing invasive plants across the U.S., particularly in the Southeast. Climate change alters the spatial distributions of focal species for monitoring and is likely to reduce overall invasion risk in many areas. Early detection and rapid response programs could be most effective in stemming the spread of invasive plant species in areas with increased risk under climate change, while areas with persistent high risk are candidates for containment and control. The areas with reduced risk are prime locations for invasion of new imports from tropical and subtropical climates, highlighting the simultaneous need for prevention strategies.},
author = {Allen, Jenica M and Bradley, Bethany A},
doi = {10.1016/j.biocon.2016.09.015},
journal = {Biological Conservation},
keywords = {Biodiversity,Conservation biology,Invasion debt,Invasive plant management,Invasive species,Species richness},
pages = {306--312},
title = {{Out of the weeds? Reduced plant invasion risk with climate change in the continental United States}},
volume = {203},
year = {2016}
}
@article{Bradley2009,
author = {Bradley, BETHANY A. and Oppenheimer, MICHAEL and Wilcove, DAVID S.},
doi = {10.1111/j.1365-2486.2008.01824.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {conservation,invasives},
mendeley-tags = {conservation,invasives},
month = {jun},
number = {6},
pages = {1511--1521},
title = {{Climate change and plant invasions: restoration opportunities ahead?}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2008.01824.x},
volume = {15},
year = {2009}
}
@article{Fernandez2015,
abstract = {Species distribution modeling is widely applied to predict invasive species distributions and species range shifts under climate change. Accurate predictions depend upon meeting the assumption that ecological niches are conserved, i.e., spatially or temporally transferable. Here we present a multi-taxon comparative analysis of niche conservatism using biological invasion events well documented in natural history museum collections. Our goal is to assess spatial transferability of the climatic niche of a range of noxious terrestrial invasive species using two complementary approaches. First we compare species' native versus invasive ranges in environmental space using two distinct methods, Principal Components Analysis and Mahalanobis distance. Second we compare species' native versus invaded ranges in geographic space as estimated using the species distribution modeling technique Maxent and the comparative index Hellinger's I. We find that species exhibit a range of responses, from almost complete transferability, in which the invaded niches completely overlap with the native niches, to a complete dissociation between native and invaded ranges. Intermediate responses included expansion of dimension attributable to either temperature or precipitation derived variables, as well as niche expansion in multiple dimensions. We conclude that the ecological niche in the native range is generally a poor predictor of invaded range and, by analogy, the ecological niche may be a poor predictor of range shifts under climate change. We suggest that assessing dimensions of niche transferability prior to standard species distribution modeling may improve the understanding of species' dynamics in the invaded range.},
author = {Fern{\'{a}}ndez, Miguel and Hamilton, Healy},
doi = {10.1371/journal.pone.0119891},
issn = {1932-6203},
journal = {PloS one},
number = {3},
pmid = {25785858},
publisher = {Public Library of Science},
title = {{Ecological niche transferability using invasive species as a case study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25785858 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4364959},
volume = {10},
year = {2015}
}
@article{HIJMANS2006,
author = {Hijmans, ROBERT J. and Graham, CATHERINE H.},
doi = {10.1111/j.1365-2486.2006.01256.x},
issn = {1354-1013},
journal = {Global Change Biology},
keywords = {GAM,bioclim,climate change,domain,envelope models,maxent,species distributions},
month = {dec},
number = {12},
pages = {2272--2281},
publisher = {Blackwell Publishing Ltd},
title = {{The ability of climate envelope models to predict the effect of climate change on species distributions}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2006.01256.x},
volume = {12},
year = {2006}
}
@article{Taleghan2015,
abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Good- Turing estimate,MDP planning,Markov decision processes,invasive species management,reinforcement learning},
number = {1},
pages = {3877--3903},
title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
url = {http://jmlr.org/papers/v16/taleghan15a.html},
volume = {16},
year = {2015}
}
@article{Iyengar2005c,
abstract = {In this paper we propose a robust formulation for discrete time dynamic programming (DP). The objective of the robust formulation is to systematically mitigate the sensitivity of the DP optimal policy to ambiguity in the underlying transition probabilities. The ambiguity is modeled by associating a set of conditional measures with each state-action pair. Consequently, in the robust formulation each policy has a set of measures associated with it. We prove that when this set of measures has a certain “rectangularity” property, all of the main results for finite and infinite horizon DP extend to natural robust counterparts. We discuss techniques from Nilim and El Ghaoui [17] for constructing suitable sets of conditional measures that allow one to efficiently solve for the optimal robust policy. We also show that robust DP is equivalent to stochastic zero-sum games with perfect information.},
author = {Iyengar, Garud N.},
doi = {10.1287/moor.1040.0129},
isbn = {0364765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
number = {2},
pages = {257--280},
title = {{Robust Dynamic Programming}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1040.0129},
volume = {30},
year = {2005}
}
@article{Elith2011,
abstract = {Abstract MaxEnt is a program for modelling species distributions from presence-only species records. This paper is written for ecologists and describes the MaxEnt model from a statistical perspective, making explicit links between the structure of the model, decisions required in producing a modelled distribution, and knowledge about the species and the data that might affect those decisions. To begin we discuss the characteristics of presence-only data, highlighting implications for modelling distributions. We particularly focus on the problems of sample bias and lack of information on species prevalence. The keystone of the paper is a new statistical explanation of MaxEnt which shows that the model minimizes the relative entropy between two probability densities (one estimated from the presence data and one, from the landscape) defined in covariate space. For many users, this viewpoint is likely to be a more accessible way to understand the model than previous ones that rely on machine learning concepts. We then step through a detailed explanation of MaxEnt describing key components (e.g. covariates and features, and definition of the landscape extent), the mechanics of model fitting (e.g. feature selection, constraints and regularization) and outputs. Using case studies for a Banksia species native to south-west Australia and a riverine fish, we fit models and interpret them, exploring why certain choices affect the result and what this means. The fish example illustrates use of the model with vector data for linear river segments rather than raster (gridded) data. Appropriate treatments for survey bias, unprojected data, locally restricted species, and predicting to environments outside the range of the training data are demonstrated, and new capabilities discussed. Online appendices include additional details of the model and the mathematical links between previous explanations and this one, example code and data, and further information on the case studies.},
archivePrefix = {arXiv},
arxivId = {1132},
author = {Elith, Jane and Phillips, Steven J. and Hastie, Trevor and Dud{\'{i}}k, Miroslav and Chee, Yung En and Yates, Colin J.},
doi = {10.1111/j.1472-4642.2010.00725.x},
eprint = {1132},
isbn = {1472-4642},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Absence,Ecological niche,Entropy,Machine learning,Presence-only,Species distribution model},
number = {1},
pages = {43--57},
pmid = {15204886},
title = {{A statistical explanation of MaxEnt for ecologists}},
volume = {17},
year = {2011}
}
@inproceedings{Wu2016,
author = {Wu, Xiaojian and Kumar, Akshat and Sheldon, Daniel and Zilberstein, Shlomo},
booktitle = {AAAI Conference on Artificial Intelligence},
title = {{Robust Optimization for Tree-Structured Stochastic Network Design}},
year = {2016}
}
@article{Bradley2016,
abstract = {Context Understanding and predicting the spatial patterns of species abundance is a critical need in macroecology. But, widespread abundance data are rare, and habitat models based on species occurrences are typically poor predictors of abundance. Objectives I ask whether presence-only species distribution models based on locations of high species abundance can more effectively predict abundance than models based on occurrences. Methods I created climatic suitability models for fifteen problematic, non-native, invasive plants in the continental US using each of three datasets (1) occurrence data derived from herbarium records, (2) occurrence data derived from regional expert knowledge surveys, and (3) locations of high invasive plant abundance derived from regional expert knowledge surveys. Results Models based on occurrences from regional surveys were most effective for distinguishing presence from absence. Models based on locations of high abundance were most effective for characterizing both intermediate and high ranks of abundance. Occurrence data from herbarium records were poor predictors of both presence and abundance. Conclusions This analysis suggests that climate suitable for abundant populations is predictable with species distribution modeling, but not using distribution data alone. High probability of species occurrence does not equal high probability of species abundance, suggesting environmental factors differentially influence abundance and distribution. This difference highlights the need for a macrosystems approach to regional habitat modeling to consider how local-scale processes (e.g., biotic interactions) affect regional patterns. Moreover, as abundance is critical for understanding species roles and impacts on ecosystems, large-scale surveys of quantitative or qualitative species abundance are strongly needed.},
author = {Bradley, Bethany A.},
doi = {10.1007/s10980-015-0303-4},
isbn = {0921-2973},
issn = {15729761},
journal = {Landscape Ecology},
keywords = {Abundance,Abundant center,Bioclimatic envelope,Climatic suitability,Ecological niche,Habitat suitability,Invasion risk,Invasive plant,Maxent,Species distribution modeling},
number = {1},
pages = {19--30},
publisher = {Springer Netherlands},
title = {{Predicting abundance with presence-only models}},
volume = {31},
year = {2016}
}
@article{Hijmans2015,
author = {Hijmans, Robert J},
number = {2008},
pages = {1--27},
title = {{Introduction to the ' raster ' package ( version 2 . 5-2 )}},
year = {2015}
}
@article{Ren2002,
author = {Ren, Zhiyuan and Krogh, B.H.},
doi = {10.1109/CDC.2002.1184960},
isbn = {0-7803-7516-5},
issn = {01912216},
journal = {Proceedings of the 41st IEEE Conference on Decision and Control, 2002.},
keywords = {cesses,policy iterations,state},
number = {December},
pages = {3819--3824},
title = {{State aggregation in Markov decision processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1184960},
volume = {4},
year = {2002}
}
@article{Merow2016,
author = {Merow, Cory and Allen, Jenica M. and Aiello-Lammens, Matthew E. and {Silander Jr}, John. A.},
journal = {Global Ecology and Biogeography},
pages = {1022--1036},
title = {{Improving niche and range estimates with Maxent and point process models by integrating spatially explicit information}},
volume = {25},
year = {2016}
}
@article{Wiesemann2013a,
author = {Wiesemann, Wolfram},
journal = {{\ldots} of Operations Research},
keywords = {markov decision processes,robust optimization,semidefinite programming},
pages = {1--52},
title = {{Robust Markov decision processes}},
url = {http://mor.journal.informs.org/content/38/1/153.short},
year = {2013}
}
@article{Bocsi2016,
author = {Bocsi, Tierney and Allen, Jenica M. and Bellemare, Jesse and Kartesz, John and Nishino, Misako and Bradley, Bethany A.},
doi = {10.1111/ddi.12432},
issn = {13669516},
journal = {Diversity and Distributions},
title = {{Plants' native distributions do not reflect climatic tolerance}},
url = {http://doi.wiley.com/10.1111/ddi.12432},
volume = {Forthcomin},
year = {2016}
}
@article{Merow2013,
abstract = {The MaxEnt software package is one of the most popular tools for species distribution and environmental niche modeling, with over 1000 published applications since 2006. Its popularity is likely for two reasons: 1) MaxEnt typically outperforms other methods based on predictive accuracy and 2) the software is particularly easy to use. MaxEnt users must make a number of decisions about how they should select their input data and choose from a wide variety of settings in the software package to build models from these data. The underlying basis for making these decisions is unclear in many studies, and default settings are apparently chosen, even though alternative settings are often more appropriate. In this paper, we provide a detailed explanation of how MaxEnt works and a prospectus on modeling options to enable users to make informed decisions when preparing data, choosing settings and interpreting output. We explain how the choice of background samples reflects prior assumptions, how nonlinear functions of environmental variables (features) are created and selected, how to account for environmentally biased sampling, the interpretation of the various types of model output and the challenges for model evaluation. We demonstrate MaxEnt's calculations using both simplified simulated data and occurrence data from South Africa on species of the flowering plant family Proteaceae. Throughout, we show how MaxEnt's outputs vary in response to different settings to highlight the need for making biologically motivated modeling decisions.},
author = {Merow, Cory and Smith, Matthew J. and Silander, John A.},
doi = {10.1111/j.1600-0587.2013.07872.x},
isbn = {1600-0587},
issn = {09067590},
journal = {Ecography},
number = {10},
pages = {1058--1069},
pmid = {1921},
title = {{A practical guide to MaxEnt for modeling species' distributions: What it does, and why inputs and settings matter}},
volume = {36},
year = {2013}
}
@article{Allen2013,
author = {Allen, Jenica M. and Leininger, Thomas J. and Hurd, James D. and Civco, Daniel L. and Gelfand, Alan E. and Silander, John A.},
doi = {10.1007/s10980-013-9916-7},
issn = {0921-2973},
journal = {Landscape Ecology},
keywords = {LULC change},
mendeley-tags = {LULC change},
month = {jul},
number = {9},
pages = {1671--1686},
title = {{Socioeconomics drive woody invasive plant richness in New England, USA through forest fragmentation}},
url = {http://link.springer.com/10.1007/s10980-013-9916-7},
volume = {28},
year = {2013}
}
@article{Fithian2013,
abstract = {Statistical modeling of presence-only data has attracted much recent attention in the ecological literature, leading to a proliferation of meth- ods, including the inhomogeneous poisson process (IPP) model [15], maxi- mum entropy (Maxent) modeling of species distributions [12] [9] [10], and logistic regression models. Several recent articles have shown the close relationships between these methods [1] [15]. We explain why the IPP intensity function is a more natural object of inference in presence-only studies than occurrence probability (which is only defined with reference to quadrat size), and why presence-only data only allows estimation of relative, and not absolute intensities. All three of the above techniques amount to parametric density esti- mation under the same exponential family model. We show that the IPP and Maxent models give the exact same estimate for this density, but lo- gistic regression in general produces a different estimate in finite samples. When the model is misspecified, logistic regression and the IPP may have substantially different asymptotic limits with large data sets. We propose “infinitely weighted logistic regression,” which is exactly equivalent to the IPP in finite samples. Consequently, many already-implemented methods extending logistic regression can also extend the Maxent and IPP models in directly analogous ways using this technique. Finally, we address the issue of observer bias, modeling the presence- only data set as a thinned IPP.We discuss when the observer bias problem can solved by regression adjustment, and additionally propose a novel method for combining presence-only and presence-absence records from one or more species to account for it.},
archivePrefix = {arXiv},
arxivId = {arXiv:1207.6950v2},
author = {Fithian, William and Hastie, Trevor},
doi = {10.1214/13-AOAS667},
eprint = {arXiv:1207.6950v2},
isbn = {1932-6157},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Case-control sampling,Logistic regression,Maximum entropy,Poisson process models,Presence-only data,Species modeling},
number = {4},
pages = {1917--1939},
pmid = {25493106},
title = {{Finite-sample equivalence in statistical models for presence-only data}},
volume = {7},
year = {2013}
}
@article{McCullagh,
author = {McCullagh, Peter},
pages = {1--16},
title = {{QuotientSpacesAndStatisticalModels}}
}
@article{Renner2013a,
abstract = {Summary Modeling the spatial distribution of a species is a fundamental problem in ecology. A number of modeling methods have been developed, an extremely popular one being MAXENT, a maximum entropy modeling approach. In this article, we show that MAXENT is equivalent to a Poisson regression model and hence is related to a Poisson point process model, differing only in the intercept term, which is scale-dependent in MAXENT. We illustrate a number of improvements to MAXENT that follow from these relations. In particular, a point process model approach facilitates methods for choosing the appropriate spatial resolution, assessing model adequacy, and choosing the LASSO penalty parameter, all currently unavailable to MAXENT. The equivalence result represents a significant step in the unification of the species distribution modeling literature.},
author = {Renner, Ian W. and Warton, David I.},
doi = {10.1111/j.1541-0420.2012.01824.x},
isbn = {1541-0420},
issn = {0006341X},
journal = {Biometrics},
keywords = {Habitat modeling,Location-only,Maximum entropy,Poisson likelihood,Presence-only data,Use-availability},
number = {1},
pages = {274--281},
pmid = {23379623},
title = {{Equivalence of MAXENT and Poisson Point Process Models for Species Distribution Modeling in Ecology}},
volume = {69},
year = {2013}
}
@article{Bradley2015,
abstract = {Aim Our understanding of potential ranges for native and non-native species is often based on their current geographic distributions. Non-native species have had less time than co-occurring native species to expand their ranges following introduction, so non-native ranges may under-represent suitable conditions. Therefore it is often assumed that species distribution models will predict disproportionately smaller potential ranges for non-natives than natives. We compare the distributions of native, endemic, alien and invasive plants to determine how the different range attributes of these groups might influence ecological forecasting. Location Continental USA. Methods We compared the geographic ranges of 13,575 plant species (9402 native, 2397 endemic, 1201 alien and 755 invasive) using (1) US only and (2) global distribution data from herbarium records. We calculated US longitudinal and latitudinal range extents as potential indicators of range-limiting factors, modelled potential range based on climate using principal components analysis, and calculated occupancy of potential ranges (range infilling). Results Contrary to expectations, modelled potential ranges were significantly larger for non-natives than natives, even for species with few occurrences. Distributions of native species, not invasive species, appeared strongly limited longitudinally. However, invasive plants occupied substantially less area within their climatically suitable ranges than native plants (lower range infilling). Main conclusions Invasive plant distributions were consistently broader, both climatically and geographically, than comparable native species. This suggests that invasive plant distribution models at regional scales are not underpredicting potential ranges relative to models for native species. In contrast, the comparatively limited longitudinal ranges of native species suggest a high degree of non-climatic limitation, which is likely to cause distribution models to underpredict the potential ranges of native species. Invasive plants have not achieved the degree of range infilling expected relative to natives. Thus, plants introduced to the US still have plenty of space to invade.},
author = {Bradley, Bethany A. and Early, Regan and Sorte, Cascade J B},
doi = {10.1111/geb.12275},
isbn = {1466822X},
issn = {14668238},
journal = {Global Ecology and Biogeography},
keywords = {Alien,Bioclimatic envelope model,Dispersal,Ecological niche model,Equilibrium,Exotic,Introduced,Occupancy,Plant invasion},
month = {mar},
number = {3},
pages = {348--359},
title = {{Space to invade? Comparative range infilling and potential range of invasive and native plants}},
url = {http://doi.wiley.com/10.1111/geb.12275},
volume = {24},
year = {2015}
}
@article{Merow2011,
abstract = {Species distribution models are a fundamental tool in ecology, conservation biology, and biogeography and typically identify potential species distributions using static phenomenological models. We demonstrate the importance of complementing these popular models with spatially explicit, dynamic mechanistic models that link potential and realized distributions. We develop general grid-based, pattern-oriented spread models incorporating three mechanisms--plant population growth, local dispersal, and long-distance dispersal--to predict broadscale spread patterns in heterogeneous landscapes. We use the model to examine the spread of the invasive Celastrus orbiculatus (Oriental bittersweet) by Sturnus vulgaris (European starling) across northeastern North America. We find excellent quantitative agreement with historical spread records over the last century that are critically linked to the geometry of heterogeneous landscapes and each of the explanatory mechanisms considered. Spread of bittersweet before 1960 was primarily driven by high growth rates in developed and agricultural landscapes, while subsequent spread was mediated by expansion into deciduous and coniferous forests. Large, continuous patches of coniferous forests may substantially impede invasion. The success of C. orbiculatus and its potential mutualism with S. vulgaris suggest troubling predictions for the spread of other invasive, fleshy-fruited plant species across northeastern North America.},
author = {Merow, Cory and Lafleur, Nancy and {Silander Jr.}, John A. and Wilson, Adam M. and Rubega, Margaret and Silander, John a and Wilson, Adam M. and Rubega, Margaret},
doi = {10.1086/660295},
isbn = {1537-5323 (Electronic)$\backslash$n0003-0147 (Linking)},
issn = {1537-5323},
journal = {The American naturalist},
keywords = {Animals,Biological,Celastrus,Celastrus: physiology,Ecosystem,Introduced Species,Models,New England,Population Dynamics,Population Growth,Songbirds,Songbirds: physiology,Symbiosis},
month = {jul},
number = {1},
pages = {30--43},
pmid = {21670575},
title = {{Developing dynamic mechanistic species distribution models: predicting bird-mediated spread of invasive plants across northeastern North America.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21670575 http://www.journals.uchicago.edu/doi/10.1086/660295},
volume = {178},
year = {2011}
}
@article{Nilim2004a,
abstract = {Optimal solutions to Markov Decision Problems (MDPs) are very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of those probabilities is far from accurate. Hence, estimation errors are limiting factors in applying MDPs to realworld problems. We propose an algorithm for solving finite-state and finite-action MDPs, where the solution is guaranteed to be robust with respect to estimation errors on the state transition probabilities. Our algorithm involves a statistically accurate yet numerically efficient representation of uncertainty, via Kullback-Leibler divergence bounds. The worst-case complexity of the robust algorithm is the same as the original Bellman recursion. Hence, robustness can be added at practically no extra computing cost. 1},
author = {Nilim, Arnab and Ghaoui, Laurent El},
journal = {Operations Research},
number = {5},
pages = {780},
title = {{Robust solutions to Markov decision problems with uncertain transition matrices}},
volume = {53},
year = {2004}
}
@article{Frappier2004a,
abstract = {Abstract Effects of the non-indigenous shrub Rhamnus frangula L. (glossy buckthorn) on tree recruitment, herb cover, forest floor plant species richness, and R. frangula recruitment were tested in two southeastern New Hampshire Pinus forests using a randomized complete-block field experiment. The treatment, applied in January of 2000, was the presence of well-established R. frangula populations with three levels: R. frangula absent prior to experiment (“uninvaded”), {\textgreater} 90{\%} R. frangula cover (“Rhamnus present”), and removal of {\textgreater} 90{\%} R. frangula cover (“Rhamnus removed”). After 2 years of measurements, Rhamnus present had significantly lower first-year native tree seedling density than Rhamnus removed and uninvaded plots (0.11, 0.40, and 0.40 seedlings/m2 respectively). First-year native tree seedling density in the Rhamnus removed and uninvaded treatments were similar. Neither percent herb cover nor plant species richness were significantly affected by the removal of R. frangula in the two years following t...},
author = {Frappier, Brian and Eckert, Robert T. and Lee, Thomas D.},
doi = {10.1656/1092-6194(2004)011[0333:EROTNS]2.0.CO;2},
issn = {1092-6194},
journal = {Northeastern Naturalist},
number = {3},
pages = {333--342},
title = {{Experimental Removal of the Non-indigenous Shrub Rhamnus frangula (Glossy Buckthorn): Effects on Native Herbs and Woody Seedlings}},
url = {http://www.bioone.org/doi/abs/10.1656/1092-6194{\%}25282004{\%}2529011{\%}255B0333{\%}253AEROTNS{\%}255D2.0.CO{\%}253B2},
volume = {11},
year = {2004}
}
@article{Mastin2012,
abstract = {We analyze losses resulting from uncertain transition probabilities in Markov decision processes with bounded nonnegative rewards. We assume that policies are precomputed using exact dynamic programming with the estimated transition probabilities, but the system evolves according to different, true transition probabilities. Given a bound on the total variation error of estimated transition probability distributions, we derive upper bounds on the loss of expected total reward. The approach analyzes the growth of errors incurred by stepping backwards in time while precomputing value functions, which requires bounding a multilinear program. Loss bounds are given for the finite horizon undiscounted, finite horizon discounted, and infinite horizon discounted cases, and a tight example is shown.},
author = {Mastin, Andrew and Jaillet, Patrick},
doi = {10.1109/CDC.2012.6426504},
isbn = {978-1-4673-2066-5},
issn = {01912216},
journal = {Proceedings of the IEEE Conference on Decision and Control},
pages = {6708--6715},
title = {{Loss bounds for uncertain transition probabilities in Markov decision processes}},
year = {2012}
}
@article{Phillips2009,
abstract = {Most methods for modeling species distributions from occurrence records require additional data representing the range of environmental conditions in the modeled region. These data, called background or pseudo-absence data, are usually drawn at random from the entire region, whereas occurrence collection is often spatially biased toward easily accessed areas. Since the spatial bias generally results in environmental bias, the difference between occurrence collection and background sampling may lead to inaccurate models. To correct the estimation, we propose choosing background data with the same bias as occurrence data. We investigate theoretical and practical implications of this approach. Accurate information about spatial bias is usually lacking, so explicit biased sampling of background sites may not be possible. However, it is likely that an entire target group of species observed by similar methods will share similar bias. We therefore explore the use of all occurrences within a target group as bias...},
author = {Phillips, Steven J. and Dud{\'{i}}k, Miroslav and Elith, Jane and Graham, Catherine H. and Lehmann, Anthony and Leathwick, John and Ferrier, Simon},
doi = {10.1890/07-2153.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {MaxEnt,SDM,background data,niche modeling,presence-only distribution models,pseudo-absence,sample selection bias,sampling bias,species distribution modeling,target group},
language = {EN},
mendeley-tags = {MaxEnt,SDM,sampling bias},
month = {jan},
number = {1},
pages = {181--197},
publisher = {Ecological Society of America},
title = {{Sample selection bias and presence-only distribution models: implications for background and pseudo-absence data}},
url = {http://www.esajournals.org/doi/full/10.1890/07-2153.1},
volume = {19},
year = {2009}
}
@article{Hijmans2013,
abstract = {This document provides an introduction to species distribution modeling with R . Species distribution modeling (SDM) is also known under other names including climate envelope-modeling, habitat modeling, and (environmental or ecological) niche-modeling. The assumption of SDM is that you can predict the entire, or potential, spatial distribution of a phenomenon, by relating sites of known occurence (and perhaps non-occurrence) with predictor variables known for these sites and for all other sites. The common application of this method is to predict species ranges with climate data as predictors},
archivePrefix = {arXiv},
arxivId = {hep-th/0201144v2},
author = {Hijmans, Robert J and Elith, Jane},
doi = {10.1016/S0550-3213(02)00216-X},
eprint = {0201144v2},
isbn = {1574-9541},
issn = {05503213},
journal = {October},
pages = {71},
pmid = {25270536},
primaryClass = {hep-th},
title = {{Species distribution modeling with R Introduction}},
url = {ftp://cran.r-project.org/pub/R/web/packages/dismo/vignettes/sdm.pdf},
year = {2013}
}
@article{Elsner1995,
author = {Elsner, James B and Jagger, Thomas H},
pages = {1--32},
title = {{Use R for Climate Research}},
year = {1995}
}
@article{Vila2011,
abstract = {Biological invasions cause ecological and economic impacts across the globe. However, it is unclear whether there are strong patterns in terms of their major effects, how the vulnerability of different ecosystems varies and which ecosystem services are at greatest risk. We present a global meta-analysis of 199 articles reporting 1041 field studies that in total describe the impacts of 135 alien plant taxa on resident species, communities and ecosystems. Across studies, alien plants had a significant effect in 11 of 24 different types of impact assessed. The magnitude and direction of the impact varied both within and between different types of impact. On average, abundance and diversity of the resident species decreased in invaded sites, whereas primary production and several ecosystem processes were enhanced. While alien N-fixing species had greater impacts on N-cycling variables, they did not consistently affect other impact types. The magnitude of the impacts was not significantly different between island and mainland ecosystems. Overall, alien species impacts are heterogeneous and not unidirectional even within particular impact types. Our analysis also reveals that by the time changes in nutrient cycling are detected, major impacts on plant species and communities are likely to have already occurred.},
author = {Vil{\`{a}}, Montserrat and Espinar, Jos{\'{e}} L and Hejda, Martin and Hulme, Philip E and Jaro{\v{s}}{\'{i}}k, Vojt{\v{e}}ch and Maron, John L and Pergl, Jan and Schaffner, Urs and Sun, Yan and Py{\v{s}}ek, Petr},
doi = {10.1111/j.1461-0248.2011.01628.x},
issn = {1461-0248},
journal = {Ecology letters},
keywords = {Biodiversity,Ecosystem,Geography,Introduced Species,Plants,Population Density,Population Dynamics},
month = {jul},
number = {7},
pages = {702--8},
pmid = {21592274},
title = {{Ecological impacts of invasive alien plants: a meta-analysis of their effects on species, communities and ecosystems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21592274},
volume = {14},
year = {2011}
}
@book{Vrbik2013,
abstract = {A complete treatment of the theory of finite Markov chains,suitable as an undergraduate introduction to probability theory and as a reference. Examples from physics, economjcs and the life sciences. The central techniques (matrix operations forthe transition matrices representing the different chains) can be programmed easily. This is particularly important in the application of the theory.},
author = {Vrbik, Jan and Vrbik, Paul},
doi = {10.1007/978-1-4614-4057-4_2},
isbn = {0387901922},
pages = {5--38},
title = {{Finite Markov Chains}},
url = {http://link.springer.com/10.1007/978-1-4614-4057-4{\_}2},
volume = {40},
year = {2013}
}
@article{Ibanez2009,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and Silander, John A. and Wilson, Adam M. and LaFleur, Nancy and Tanaka, Nobuyuki and Tsuyama, Ikutaro},
doi = {10.1890/07-2095.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {SDM,climate change: bayes},
mendeley-tags = {SDM,climate change: bayes},
month = {mar},
number = {2},
pages = {359--375},
title = {{Multivariate forecasts of potential distributions of invasive plant species}},
url = {http://doi.wiley.com/10.1890/07-2095.1},
volume = {19},
year = {2009}
}
@article{Bagnell2001b,
abstract = {The authors consider the fundamental problem of nding good policies in uncertain models. It is demonstrated that although the general problem of nding the best policy with respect to the worst model is NP-hard, in the special case of a convex uncertainty set the problem is tractable. A stochastic dynamic game is proposed, and the security equilibrium solution of the game is shown to correspond to the value function under the worst model and the optimal controller. The authors demonstrate that the uncertain model approach can be used to solve a class of nearly Markovian Decision Problems, providing lower bounds on performance in stochastic models with higher-order interactions. The framework considered establishes connections between and generalizes paradigms of stochastic optimal, mini-max, and H1 /robust control. Applications are considered, including robustness in reinforcement learning, planning in nearly Markovian decision processes, and bounding error due to sensor discretization in noisy, continuous state-spaces.},
author = {Bagnell, J Andrew and Ng, Andrew Y and Schneider, Jeff G},
doi = {tech. report CMU-RI-TR-01-25},
journal = {Carnegie Mellon Research Showcase},
pages = {948--957},
title = {{Solving Uncertain Markov Decision Processes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.8550{\%}7B{\%}5C{\&}{\%}7Drep=rep1{\%}7B{\%}5C{\&}{\%}7Dtype=pdf{\%}7B{\%}5C{\%}25{\%}7D5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.8550},
year = {2001}
}
@article{ODonnell2012,
author = {O'Donnell, Jessica and Gallagher, Rachael V. and Wilson, Peter D. and Downey, Paul O. and Hughes, Lesley and Leishman, Michelle R.},
doi = {10.1111/j.1365-2486.2011.02537.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {SDMs,invasives},
mendeley-tags = {SDMs,invasives},
month = {feb},
number = {2},
pages = {617--629},
title = {{Invasion hotspots for non-native plants in Australia under current and future climates}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2011.02537.x},
volume = {18},
year = {2012}
}
@article{Kotani2011,
abstract = {The management programs for invasive species have been proposed and implemented in many regions of the world. However, practitioners and scientists have not reached a consensus on how to control them yet. One reason is the presence of various uncertainties associated with the management. To give some guidance on this issue, we characterize the optimal strategy by developing a dynamic model of invasive species management under uncertainties. In particular, focusing on (i) growth uncertainty and (ii) measurement uncertainty, we identify how these uncertainties affect optimal strategies and value functions. Our results suggest that a rise in growth uncertainty causes the optimal strategy to involve more restrained removals and the corresponding value function to shift up. Furthermore, we also find that a rise in measurement uncertainty affects optimal policies in a highly complex manner, but their corresponding value functions generally shift down as measurement uncertainty rises. Overall, a rise in growth uncertainty can be beneficial, while a rise in measurement uncertainty brings about an adverse effect, which implies the potential gain of precisely identifying the current stock size of invasive species. ?? 2011 Elsevier Inc.},
author = {Kotani, Koji and Kakinaka, Makoto and Matsuda, Hiroyuki},
doi = {10.1016/j.mbs.2011.06.002},
isbn = {0025-5564},
issn = {00255564},
journal = {Mathematical Biosciences},
keywords = {Bioeconomic model,Dynamic programming,Growth uncertainty,Invasive species management,Measurement uncertainty,Value functions},
number = {1},
pages = {32--46},
pmid = {21704642},
publisher = {Elsevier Inc.},
title = {{Optimal invasive species management under multiple uncertainties}},
url = {http://dx.doi.org/10.1016/j.mbs.2011.06.002},
volume = {233},
year = {2011}
}
@inproceedings{Kumar2014,
author = {Kumar, Akshat and Singh, Arambam James and Varakantham, Pradeep and Sheldon, Daniel},
booktitle = {AAAI Conference on Artificial Intelligence},
title = {{Robust Decision Making For Stochastic Network Design}},
year = {2014}
}
@article{Elith2009,
abstract = {Species distribution models (SDMs) are numerical tools that combine observations of species occurrence or abundance with environmental estimates. They are used to gain ecological and evolutionary insights and to predict distributions across landscapes, sometimes requiring extrapolation in space and time. SDMs are now widely used across terrestrial, freshwater, and marine realms. Differences in methods between disciplines reflect both differences in species mobility and in “established use.” Model realism and robustness is influenced by selection of relevant predictors and modeling method, consideration of scale, how the interplay between environmental and geographic factors is handled, and the extent of extrapolation. Current linkages between SDM practice and ecological theory are often weak, hindering progress. Remaining challenges include: improvement of methods for modeling presence-only data and for model selection and evaluation; accounting for biotic interactions; and assessing model uncertainty.},
author = {Elith, Jane and Leathwick, John R.},
doi = {10.1146/annurev.ecolsys.110308.120159},
issn = {1543-592X},
journal = {Annual Review of Ecology, Evolution, and Systematics},
keywords = {SDM,climate change,equilibrium,invasions,niche,predict,presence-only,spatial},
language = {en},
mendeley-tags = {SDM,equilibrium},
month = {dec},
number = {1},
pages = {677--697},
publisher = {Annual Reviews},
title = {{Species Distribution Models: Ecological Explanation and Prediction Across Space and Time}},
url = {http://www.annualreviews.org.silk.library.umass.edu/eprint/HWR4cusJrXYCSPZ9sUDj/full},
volume = {40},
year = {2009}
}
@article{Westphan2003,
author = {Westphan, Michael I and Pickett, Marcus and Getz, Wayne M and Possingham, Hugh P},
journal = {Ecological Applications},
number = {2},
pages = {543--555},
title = {{The Use of Stochastic Dynamic Programming in Optimal Landscape Reconstruction for Metapopulations}},
volume = {13},
year = {2003}
}
@article{Wilson2007a,
author = {Wilson, John R. U. and Richardson, David M. and Rouget, Mathieu and Procheş, Şerban and Amis, Mao A. and Henderson, Lesley and Thuiller, Wilfried},
doi = {10.1111/j.1366-9516.2006.00302.x},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Biological invasions,South Africa.,invasive species,range size,rates of spread,residence time},
month = {jan},
number = {1},
pages = {11--22},
publisher = {Blackwell Publishing Ltd},
title = {{Residence time and potential range: crucial considerations in modelling plant invasions}},
url = {http://doi.wiley.com/10.1111/j.1366-9516.2006.00302.x},
volume = {13},
year = {2007}
}
@article{Ehrenfeld2010,
abstract = {Exotic species affect the biogeochemical pools and fluxes of materials and energy, thereby altering the fundamental structure and function of their ecosystems. Rapidly accumulating evidence from many species of both an-imal and plant invaders suggests that invasive species often increase pool sizes, particularly of biomass, and promote accelerated flux rates, but many exceptions can be found. Ecosystem dynamics are altered through a variety of interacting, mutually reinforcing mechanistic pathways, including species' resource acquisition traits; population densities; ability to engineer changes to physical environmental conditions; effects on disturbance, especially fire; regimes; the ability to structure habitat for other species; and their impact on food webs. Local factors of landscape setting, history, and other sources of disturbance constrain ecosystem responses to invasions. New research directions are suggested, including the need for whole-system budgets, the quantification of abundance-impact relationships for particular ecosys-tem processes, and a better exploration of food web impacts on ecosystem processes.},
author = {Ehrenfeld, Joan G and Rodriguez, Diego},
doi = {10.1146/annurev-ecolsys-102209-144650},
journal = {Annu. Rev. Ecol. Evol. Syst},
keywords = {biogeochemistry,ecosystem engineers,functional traits,nutrients,transformers},
pages = {59--80},
title = {{Ecosystem Consequences of Biological Invasions}},
volume = {41},
year = {2010}
}
@article{Randin2006,
author = {Randin, Christophe F. and Dirnb{\"{o}}ck, Thomas and Dullinger, Stefan and Zimmermann, Niklaus E. and Zappa, Massimiliano and Guisan, Antoine},
doi = {10.1111/j.1365-2699.2006.01466.x},
issn = {0305-0270},
journal = {Journal of Biogeography},
keywords = {Austria,Switzerland,generality,generalized additive models (GAM),generalized linear models (GLM),geographical transferability,habitat distribution,model evaluation,predictions,spatial modelling},
month = {oct},
number = {10},
pages = {1689--1703},
publisher = {Blackwell Publishing Ltd},
title = {{Are niche-based species distribution models transferable in space?}},
url = {http://doi.wiley.com/10.1111/j.1365-2699.2006.01466.x},
volume = {33},
year = {2006}
}
@article{Jernigan2003,
abstract = {The chi-squared test of Markov chain lumpability is shown to operate reliably under a corrected derivation of the degrees of freedom. The test is used to screen out lumping schemes that corrupt the Markov property and give rise to higher order dependence. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Jernigan, Robert W. and Baran, Robert H.},
doi = {10.1016/S0167-7152(03)00126-3},
issn = {01677152},
journal = {Statistics and Probability Letters},
keywords = {Chi-squared tests,Lumpability,Markov chain,Time series},
number = {1},
pages = {17--23},
title = {{Testing lumpability in Markov chains}},
volume = {64},
year = {2003}
}
@article{Bradley2010,
author = {Bradley, Bethany A. and Wilcove, David S. and Oppenheimer, Michael},
doi = {10.1007/s10530-009-9597-y},
issn = {1387-3547},
journal = {Biological Invasions},
keywords = {SLDs,invasion risk,invasives},
mendeley-tags = {SLDs,invasion risk,invasives},
month = {oct},
number = {6},
pages = {1855--1872},
title = {{Climate change increases risk of plant invasion in the Eastern United States}},
url = {http://link.springer.com/10.1007/s10530-009-9597-y},
volume = {12},
year = {2010}
}
@article{Ibanez2009a,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and {Silander Jr}, John. A. and Allen, Jenica M. and Treanor, Sarah A. and Wilson, Adam},
doi = {10.1111/j.1365-2664.2009.01736.x},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {SDMs,abundance,climate change},
mendeley-tags = {SDMs,abundance,climate change},
month = {nov},
number = {6},
pages = {1219--1228},
title = {{Identifying hotspots for plant invasions and forecasting focal points of further spread}},
url = {http://doi.wiley.com/10.1111/j.1365-2664.2009.01736.x},
volume = {46},
year = {2009}
}
@misc{Eddmaps2016,
title = {{EDDMapS. 2016. Early Detection {\&} Distribution Mapping System. The University of Georgia - Center for Invasive Species and Ecosystem Health}},
urldate = {2011-06-20},
year = {2016}
}
@article{Moreno-Amat2015,
abstract = {Maximum entropy modeling (Maxent) is a widely used algorithm for predicting species distributions across space and time. Properly assessing the uncertainty in such predictions is non-trivial and requires validation with independent datasets. Notably, model complexity (number of model parameters) remains a major concern in relation to overfitting and, hence, transferability of Maxent models. An emerging approach is to validate the cross-temporal transferability of model predictions using paleoecological data. In this study, we assess the effect of model complexity on the performance of Maxent projections across time using two European plant species (Alnus glutinosa (L.) Gaertn. and Corylus avellana L.) with an extensive late Quaternary fossil record in Spain as a study case. We fit 110 models with different levels of complexity under present time and tested model performance using AUC (area under the receiver operating characteristic curve) and AICc (corrected Akaike Information Criterion) through the standard procedure of randomly partitioning current occurrence data. We then compared these results to an independent validation by projecting the models to mid-Holocene (6000 years before present) climatic conditions in Spain to assess their ability to predict fossil pollen presence–absence and abundance. We find that calibrating Maxent models with default settings result in the generation of overly complex models. While model performance increased with model complexity when predicting current distributions, it was higher with intermediate complexity when predicting mid-Holocene distributions. Hence, models of intermediate complexity resulted in the best trade-off to predict species distributions across time. Reliable temporal model transferability is especially relevant for forecasting species distributions under future climate change. Consequently, species-specific model tuning should be used to find the best modeling settings to control for complexity, notably with paleoecological data to independently validate model projections. For cross-temporal projections of species distributions for which paleoecological data is not available, models of intermediate complexity should be selected.},
author = {Moreno-Amat, Elena and Mateo, Rub{\'{e}}n G. and Nieto-Lugilde, Diego and Morueta-Holme, Naia and Svenning, Jens-Christian and Garc{\'{i}}a-Amorena, Ignacio},
doi = {10.1016/j.ecolmodel.2015.05.035},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Alnus glutinosa,Corylus avellana,Model validation,Pollen fossil,Species distribution model,$\beta$-Multiplier},
month = {sep},
pages = {308--317},
title = {{Impact of model complexity on cross-temporal transferability in Maxent species distribution models: An assessment using paleobotanical data}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380015002483},
volume = {312},
year = {2015}
}
@article{Wilcove1998,
abstract = {Habitat loss is the single greatest threat to biodiversity, followed by the spread of alien species},
author = {Wilcove, David S. and Rothstein, David and Dubow, Jason and Phillips, Ali and Losos, Elizabeth},
doi = {10.2307/1313420},
isbn = {0006-3568},
issn = {00063568},
journal = {BioScience},
number = {8},
pages = {607--615},
pmid = {3029},
title = {{Quantifying threats to imperiled species in the United States}},
volume = {48},
year = {1998}
}
@article{Webster2006,
abstract = {Invasive exotic species pose significant challenges for natural resource managers charged with the maintenance of biological diversity and the sustainable production of forest resources. In this article, we review what is known about the biology and control of some of the most serious woody invaders of eastern forests. Based on the parallels between these invasions, we propose a working framework for integrating invasive control into forestry practices. In general, early detection and rapid response to invasions are essential. However, given that consistently effective control strategies that are broadly applicable simply do not exist for many species, adaptive management strategies will be necessary.},
author = {Webster, Christopher R. and Jenkins, Michael A. and Jose, Shibu},
isbn = {0022-1201},
issn = {00221201},
journal = {Journal of Forestry},
keywords = {alien plants,invasive exotics,invasive species,perennial weeds},
number = {7},
pages = {366--374},
title = {{Woody invaders and the challenges they pose to forest ecosystems in the eastern United States}},
url = {http://www.ingentaconnect.com/content/saf/jof/2006/00000104/00000007/art00006},
volume = {104},
year = {2006}
}
@techreport{Michigan2012,
author = {{USDA Forest Service Forest Health Staff}},
pages = {1},
title = {{Glossy Buckthorn}},
volume = {2},
year = {2012}
}
@article{Hutter2014,
abstract = {We consider a Reinforcement Learning setup where an agent interacts with an environment in observation-reward-action cycles without any (esp.$\backslash$ MDP) assumptions on the environment. State aggregation and more generally feature reinforcement learning is concerned with mapping histories/raw-states to reduced/aggregated states. The idea behind both is that the resulting reduced process (approximately) forms a small stationary finite-state MDP, which can then be efficiently solved or learnt. We considerably generalize existing aggregation results by showing that even if the reduced process is not an MDP, the (q-)value functions and (optimal) policies of an associated MDP with same state-space size solve the original problem, as long as the solution can approximately be represented as a function of the reduced states. This implies an upper bound on the required state space size that holds uniformly for all RL problems. It may also explain why RL algorithms designed for MDPs sometimes perform well beyond MDPs.},
archivePrefix = {arXiv},
arxivId = {1407.3341},
author = {Hutter, Marcus},
eprint = {1407.3341},
keywords = {non-mdp,reinforcement learning,state aggregation},
title = {{Extreme State Aggregation Beyond MDPs}},
url = {http://arxiv.org/abs/1407.3341},
year = {2014}
}
@article{Dietterich2013,
author = {Dietterich, Thomas G. TG and Taleghan, Majid A. and Crowley, Mark},
journal = {National Conference on Artificial Intelligence (AAAI)},
title = {{PAC optimal planning for invasive species management: Improved exploration for reinforcement learning from simulator-defined MDPs.}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/download/6478/6850},
year = {2013}
}
@article{Phillips2006,
abstract = {The availability of detailed environmental data, together with inexpensive and powerful computers, has fueled a rapid increase in predictive modeling of species environmental requirements and geographic distributions. For some species, detailed presence/absence occurrence data are available, allowing the use of a variety of standard statistical techniques. However, absence data are not available for most species. In this paper, we introduce the use of the maximum entropy method (Maxent) for modeling species geographic distributions with presence-only data. Maxent is a general-purpose machine learning method with a simple and precise mathematical formulation, and it has a number of aspects that make it well-suited for species distribution modeling. In order to investigate the efficacy of the method, here we perform a continental-scale case study using two Neotropical mammals: a lowland species of sloth, Bradypus variegatus, and a small montane murid rodent, Microryzomys minutus. We compared Maxent predictions with those of a commonly used presence-only modeling method, the Genetic Algorithm for Rule-Set Prediction (GARP). We made predictions on 10 random subsets of the occurrence records for both species, and then used the remaining localities for testing. Both algorithms provided reasonable estimates of the species' range, far superior to the shaded outline maps available in field guides. All models were significantly better than random in both binomial tests of omission and receiver operating characteristic (ROC) analyses. The area under the ROC curve (AUC) was almost always higher for Maxent, indicating better discrimination of suitable versus unsuitable areas for the species. The Maxent modeling approach can be used in its present form for many applications with presence-only datasets, and merits further research and development.},
author = {Phillips, Steven J. and Anderson, Robert P. and Schapire, Robert E.},
doi = {10.1016/j.ecolmodel.2005.03.026},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Distribution,MaxEnt,Maximum entropy,Modeling,Niche,Range,SDMs},
mendeley-tags = {MaxEnt,SDMs},
month = {jan},
number = {3-4},
pages = {231--259},
title = {{Maximum entropy modeling of species geographic distributions}},
url = {http://www.sciencedirect.com/science/article/pii/S030438000500267X},
volume = {190},
year = {2006}
}
@article{Buyuktahtakn2011,
abstract = {A dynamic model of controlling invasive weeds is first developed which is a large scale, nonlinear 0-1 integer programming problem. This model is then applied for the case of control of the invasive grass, Pennisetum ciliare (buffelgrass), in the Arizona desert. The large size of the problem makes the application of direct optimization methods impossible, instead the most frequently suggested strategies were analyzed and their consequences compared. The model is more advanced and complex than those examined in earlier studies. ?? 2011 Elsevier Ltd. All rights reserved.},
author = {Buyuktahtakn, I. Esra and Feng, Zhuo and Frisvold, George and Szidarovszky, Ferenc and Olsson, Aaryn},
doi = {10.1016/j.camwa.2011.08.037},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {Biological invasion,Integer programming,Invasive species,Non-native species,Optimal control},
number = {9},
pages = {3326--3333},
publisher = {Elsevier Ltd},
title = {{A dynamic model of controlling invasive species}},
url = {http://dx.doi.org/10.1016/j.camwa.2011.08.037},
volume = {62},
year = {2011}
}
@inproceedings{Chades2007,
author = {Chades, I and Martin, T G and Curtis, J M R and Barreto, C},
booktitle = {International Congress on Modelling and Simulation},
keywords = {decision theory,predator-prey,reinforcement learning},
pages = {2209--2215},
title = {{Managing Interacting Species : A Reinforcement Learning Decision Theoretic Approach}},
year = {2007}
}
@article{LeTallec2007a,
abstract = {Markov Decision Processes (MDPs) model problems of sequential decision-making under uncertainty. They have been studied and applied extensively. Nonetheless, there are two major barriers that still hinder the applicability of MDPs to many more practical decision making problems: * The decision maker is often lacking a reliable MDP model. Since the results obtained by dynamic programming are sensitive to the assumed MDP model, their relevance is challenged by model uncertainty. * The structural and computational results of dynamic programming (which deals with expected performance) have been extended with only limited success to accommodate risk-sensitive decision makers. In this thesis, we investigate two ways of dealing with uncertain MDPs and we develop a new connection between robust control of uncertain MDPs and risk-sensitive control of dynamical systems. The first approach assumes a model of model uncertainty and formulates the control of uncertain MDPs as a problem of decision-making under (model) uncertainty. We establish that most formulations are at least NP-hard and thus suffer from the "'curse of uncertainty." The worst-case control of MDPs with rectangular uncertainty sets is equivalent to a zero-sum game between the controller and nature. The structural and computational results for such games make this formulation appealing. By adding a penalty for unlikely parameters, we extend the formulation of worst-case control of uncertain MDPs and mitigate its conservativeness. We show a duality between the penalized worst-case control of uncertain MDPs with rectangular uncertainty and the minimization of a Markovian dynamically consistent convex risk measure of the sample cost. This notion of risk has desirable properties for multi-period decision making, including a new Markovian property that we introduce and motivate. This Markovian property is critical in establishing the equivalence between minimizing some risk measure of the sample cost and solving a certain zero-sum Markov game between the decision maker and nature, and to tackling infinite-horizon problems. An alternative approach to dealing with uncertain MDPs, which avoids the curse of uncertainty, is to exploit directly observational data. Specifically, we estimate the expected performance of any given policy (and its gradient with respect to certain policy parameters) from a training set comprising observed trajectories sampled under a known policy. We propose new value (and value gradient) estimators that are unbiased and have low training set to training set variance. We expect our approach to outperform competing approaches when there are few system observations compared to the underlying MDP size, as indicated by numerical experiments.},
author = {{Le Tallec}, Yann},
journal = {Thesis},
pages = {211},
title = {{Robust, Risk-Sensitive, and Data-driven Control of Markov Decision Processes}},
url = {http://hdl.handle.net/1721.1/38598},
year = {2007}
}
@article{Mount2011a,
abstract = {As our colleague so aptly demonstrated ( http://www.win-vector.com/blog/2011/09/the-simpler- derivation-of-logistic-regression/ (link) ) there is one derivation of Logistic Regression that is particularly beautiful. It is not as general as that found in Agresti[Agresti, 1990] (which deals with generalized linear models in their full generality), but gets to the important balance equations very quickly. We will pursue this further to re-derive multi-category logistic regression in both its standard (sigmoid) phrasing and also in its equivalent maximum entropy clothing. It is well known that logistic regression and maximum entropy modeling are equivalent (for example see [Klein and Manning, 2003])- but we will show that the simpler derivation already given is a very good way to demonstrate the equivalence (and points out that logistic regression is actually special- not just one of many equivalent GLMs).},
author = {Mount, John},
number = {1},
pages = {1--8},
title = {{The equivalence of logistic regression and maximum entropy models}},
url = {http://www.win-vector.com/dfiles/LogisticRegressionMaxEnt.pdf},
year = {2011}
}
@article{Fern2014,
abstract = {This paper addresses adaptive conservation planning, where the objective is to maximize the population spread of a species by allocating limited resources over time to conserve land parcels. This problem is characterized by having highly stochastic exogenous events (population spread), a large action branching factor (number of allocation options) and state space, and the need to reason about numeric resources. Together these characteristics render most existing AI planning techniques ineffective. The main contribution of this paper is to design and evaluate an online planner for this problem based on Hindsight Optimization (HOP), a technique that has shown promise in other stochastic planning problems. Unfortunately, standard implementations of HOP scale linearly with the number of actions in a domain, which is not feasible for conservation problems such as ours. Thus, we develop a new approach for computing HOP policies based on mixed-integer programming and dual decomposition. Our experiments on synthetic and real-world scenarios show that this approach is effective and scalable compared to existing alternatives.},
author = {Fern, Alan and Sheldon, Daniel},
issn = {15337928},
journal = {Artificial Intelligence and Statistics (AISTATS)},
pages = {1033--1041},
title = {{Dynamic Resource Allocation for Optimizing Population Diffusion}},
volume = {33},
year = {2014}
}
@phdthesis{Aiello-Lammens2014,
abstract = {Ph.D. disertation},
author = {Aiello-Lammens, Matthew E.},
school = {Stony Brook University},
title = {{Patterns and Processes of the Invasion of Frangula alnus: An Integrated Model Framework}},
url = {http://www.soilinfo.psu.edu/},
year = {2014}
}
@article{Nilim2005a,
abstract = {Optimal solutions to Markov decision problems may be very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of these probabilities is far from accurate. Hence, estimation errors are limiting factors in applying Markov decision processes to real-world problems. We consider a robust control problem for a finite-state, finite-action Markov decision process, where uncertainty on the transition matrices is described in terms of possibly nonconvex sets. We show that perfect duality holds for this problem, and that as a consequence, it can be solved with a variant of the classical dynamic programming algorithm, the “robust dynamic programming” algorithm. We show that a particular choice of the uncertainty sets, involving likelihood regions or entropy bounds, leads to both a statistically accurate representation of uncertainty, and a complexity of the robust recursion that is almost the same as that of the classical recursion. Hence, robustness can be added at practically no extra computing cost. We derive similar results for other uncertainty sets, including one with a finite number of possible values for the transition matrices. We describe in a practical path planning example the benefits of using a robust strategy instead of the classical optimal strategy; even if the uncertainty level is only crudely guessed, the robust strategy yields a much better worst-case expected travel time.},
author = {Nilim, Arnab and {El Ghaoui}, Laurent},
doi = {10.1287/opre.1050.0216},
isbn = {0030364X},
issn = {0030-364X},
journal = {Mathematics of Operations Research},
number = {5},
pages = {780--798},
title = {{Robust Control of Markov Decision Processes with Uncertain Transition Matrices}},
url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1050.0216},
volume = {53},
year = {2005}
}
@article{Apr2017,
author = {Apr, No Mar and Bean, James C and Birge, John R and Smith, Robert L},
number = {2},
pages = {215--220},
title = {{Aggregation in Dynamic Programming Author ( s ): James C . Bean , John R . Birge and Robert L . Smith Published by : INFORMS Stable URL : http://www.jstor.org/stable/170693 REFERENCES Linked references are available on JSTOR for this article : You may nee}},
volume = {35},
year = {2017}
}
@article{VanRoy2006a,
abstract = {We consider approximate value iteration with a parameterized approximator in which the state space is partitioned and the optimal cost-to-go function over each partition is approximated by a constant. We establish performance loss bounds for policies derived from approximations associated with fixed points. These bounds identify benefits to using invariant distributions of appropriate policies as projection weights. Such projection weighting relates to what is done by temporal-difference learning. Our analysis also leads to the first performance loss bound for approximate value iteration with an average-cost objective.},
author = {{Van Roy}, Benjamin},
doi = {10.1287/moor.1060.0188},
isbn = {0364-765X},
issn = {0364-765X},
journal = {Mathematics of Operations Research},
keywords = {2004,2005,68t05,68t37,90c39,90c40,approximate value iteration,dynamic programming,finite state,history,markov,ms subject classification,msc2000 subject classification,optimal control,or,primary,received august 2,revised august 12,secondary,state aggregation,temporal-difference learning},
number = {2},
pages = {234--244},
title = {{Performance Loss Bounds for Approximate Value Iteration with State Aggregation}},
url = {http://dx.doi.org/10.1287/moor.1060.0188},
volume = {31},
year = {2006}
}
@article{Buyuktahtakin2014,
abstract = {Buffelgrass (Pennisetum ciliare) is a fire-prone, African bunchgrass spreading rapidly across the southern Arizona desert. This article introduces a model that simulates buffelgrass spread over a gridded landscape over time to evaluate strategies to control this invasive species. Weed-carrying capacity, treatment costs, and damages vary across grid cells. Damage from buffelgrass depends on its density and proximity to valued resources. Damages include negative effects on native species (through spatial competition) and increased fire risk to land and buildings. We evaluate recommended “rule of thumb” control strategies in terms of their ability to prevent weed establishment in newly infested areas and to reduce damage indices over time. Two such strategies—potential damage weighting and consecutive year treatment—used in combination, provided significant improvements in long-term control over no control and over a strategy of minimizing current damages in each year. Results suggest specific recommendations for deploying rapid-response teams to prevent establishment in new areas. The long-run population size and spatial distribution of buffelgrass is sensitive to the priority given to protecting different resources. Land managers with different priorities may pursue quite different control strategies, posing a challenge for coordinating control across jurisdictions.},
author = {Buyuktahtakin, I. Esra and Feng, Zhuo and Olsson, Aaryn D. and Frisvold, George and Szidarovszky, Ferenc},
doi = {10.1614/IPSM-D-13-00057.1},
issn = {1939-7291},
journal = {Invasive Plant Science and Management},
keywords = {biological invasion,buffelgrass,dynamic spatial processes,environmental studies,integer,invasive species,invasive weeds as a,land management,optimal control,programming,smith et al,spatial-dynamic problem,spread and management of,this study examines the},
number = {1},
pages = {132--146},
title = {{Invasive Species Control Optimization as a Dynamic Spatial Process: An Application to Buffelgrass ( Pennisetum ciliare ) in Arizona}},
url = {http://www.bioone.org/doi/abs/10.1614/IPSM-D-13-00057.1},
volume = {7},
year = {2014}
}
@article{Ibanez2009a,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and {Silander Jr}, John. A. and Allen, Jenica M. and Treanor, Sarah A. and Wilson, Adam},
doi = {10.1111/j.1365-2664.2009.01736.x},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {SDMs,abundance,climate change},
mendeley-tags = {SDMs,abundance,climate change},
month = {nov},
number = {6},
pages = {1219--1228},
title = {{Identifying hotspots for plant invasions and forecasting focal points of further spread}},
url = {http://doi.wiley.com/10.1111/j.1365-2664.2009.01736.x},
volume = {46},
year = {2009}
}
@article{Frappier2004,
abstract = {Abstract Effects of the non-indigenous shrub Rhamnus frangula L. (glossy buckthorn) on tree recruitment, herb cover, forest floor plant species richness, and R. frangula recruitment were tested in two southeastern New Hampshire Pinus forests using a randomized complete-block field experiment. The treatment, applied in January of 2000, was the presence of well-established R. frangula populations with three levels: R. frangula absent prior to experiment (“uninvaded”), {\textgreater} 90{\%} R. frangula cover (“Rhamnus present”), and removal of {\textgreater} 90{\%} R. frangula cover (“Rhamnus removed”). After 2 years of measurements, Rhamnus present had significantly lower first-year native tree seedling density than Rhamnus removed and uninvaded plots (0.11, 0.40, and 0.40 seedlings/m2 respectively). First-year native tree seedling density in the Rhamnus removed and uninvaded treatments were similar. Neither percent herb cover nor plant species richness were significantly affected by the removal of R. frangula in the two years following t...},
author = {Frappier, Brian and Eckert, Robert T. and Lee, Thomas D.},
doi = {10.1656/1092-6194(2004)011[0333:EROTNS]2.0.CO;2},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frappier, Eckert, Lee - 2004 - Experimental Removal of the Non-indigenous Shrub Rhamnus frangula (Glossy Buckthorn) Effects on Native He.pdf:pdf},
issn = {1092-6194},
journal = {Northeastern Naturalist},
month = {sep},
number = {3},
pages = {333--342},
title = {{Experimental Removal of the Non-indigenous Shrub Rhamnus frangula (Glossy Buckthorn): Effects on Native Herbs and Woody Seedlings}},
url = {http://www.bioone.org/doi/abs/10.1656/1092-6194{\%}282004{\%}29011{\%}5B0333{\%}3AEROTNS{\%}5D2.0.CO{\%}3B2},
volume = {11},
year = {2004}
}
@article{Fernandez2015,
abstract = {Species distribution modeling is widely applied to predict invasive species distributions and species range shifts under climate change. Accurate predictions depend upon meeting the assumption that ecological niches are conserved, i.e., spatially or temporally transferable. Here we present a multi-taxon comparative analysis of niche conservatism using biological invasion events well documented in natural history museum collections. Our goal is to assess spatial transferability of the climatic niche of a range of noxious terrestrial invasive species using two complementary approaches. First we compare species' native versus invasive ranges in environmental space using two distinct methods, Principal Components Analysis and Mahalanobis distance. Second we compare species' native versus invaded ranges in geographic space as estimated using the species distribution modeling technique Maxent and the comparative index Hellinger's I. We find that species exhibit a range of responses, from almost complete transferability, in which the invaded niches completely overlap with the native niches, to a complete dissociation between native and invaded ranges. Intermediate responses included expansion of dimension attributable to either temperature or precipitation derived variables, as well as niche expansion in multiple dimensions. We conclude that the ecological niche in the native range is generally a poor predictor of invaded range and, by analogy, the ecological niche may be a poor predictor of range shifts under climate change. We suggest that assessing dimensions of niche transferability prior to standard species distribution modeling may improve the understanding of species' dynamics in the invaded range.},
author = {Fern{\'{a}}ndez, Miguel and Hamilton, Healy},
doi = {10.1371/journal.pone.0119891},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern{\'{a}}ndez, Hamilton - 2015 - Ecological niche transferability using invasive species as a case study.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
number = {3},
pages = {e0119891},
pmid = {25785858},
publisher = {Public Library of Science},
title = {{Ecological niche transferability using invasive species as a case study.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25785858 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4364959},
volume = {10},
year = {2015}
}
@article{Ehrenfeld2010,
abstract = {Exotic species affect the biogeochemical pools and fluxes of materials and energy, thereby altering the fundamental structure and function of their ecosystems. Rapidly accumulating evidence from many species of both an-imal and plant invaders suggests that invasive species often increase pool sizes, particularly of biomass, and promote accelerated flux rates, but many exceptions can be found. Ecosystem dynamics are altered through a variety of interacting, mutually reinforcing mechanistic pathways, including species' resource acquisition traits; population densities; ability to engineer changes to physical environmental conditions; effects on disturbance, especially fire; regimes; the ability to structure habitat for other species; and their impact on food webs. Local factors of landscape setting, history, and other sources of disturbance constrain ecosystem responses to invasions. New research directions are suggested, including the need for whole-system budgets, the quantification of abundance-impact relationships for particular ecosys-tem processes, and a better exploration of food web impacts on ecosystem processes.},
author = {Ehrenfeld, Joan G and Rodriguez, Diego},
doi = {10.1146/annurev-ecolsys-102209-144650},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ehrenfeld, Rodriguez - 2010 - Ecosystem Consequences of Biological Invasions.pdf:pdf},
journal = {Annu. Rev. Ecol. Evol. Syst},
keywords = {biogeochemistry,ecosystem engineers,functional traits,nutrients,transformers},
pages = {59--80},
title = {{Ecosystem Consequences of Biological Invasions}},
volume = {41},
year = {2010}
}
@article{Merow2016,
author = {Merow, Cory and Allen, Jenica M. and Aiello-Lammens, Matthew E. and {Silander Jr}, John. A.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merow et al. - 2016 - Improving niche and range estimates with Maxent and point process models by integrating spatially explicit informa.pdf:pdf},
journal = {Global Ecology and Biogeography},
pages = {1022--1036},
title = {{Improving niche and range estimates with Maxent and point process models by integrating spatially explicit information}},
volume = {25},
year = {2016}
}
@article{Kotani2011,
abstract = {The management programs for invasive species have been proposed and implemented in many regions of the world. However, practitioners and scientists have not reached a consensus on how to control them yet. One reason is the presence of various uncertainties associated with the management. To give some guidance on this issue, we characterize the optimal strategy by developing a dynamic model of invasive species management under uncertainties. In particular, focusing on (i) growth uncertainty and (ii) measurement uncertainty, we identify how these uncertainties affect optimal strategies and value functions. Our results suggest that a rise in growth uncertainty causes the optimal strategy to involve more restrained removals and the corresponding value function to shift up. Furthermore, we also find that a rise in measurement uncertainty affects optimal policies in a highly complex manner, but their corresponding value functions generally shift down as measurement uncertainty rises. Overall, a rise in growth uncertainty can be beneficial, while a rise in measurement uncertainty brings about an adverse effect, which implies the potential gain of precisely identifying the current stock size of invasive species. ?? 2011 Elsevier Inc.},
author = {Kotani, Koji and Kakinaka, Makoto and Matsuda, Hiroyuki},
doi = {10.1016/j.mbs.2011.06.002},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kotani, Kakinaka, Matsuda - 2011 - Optimal invasive species management under multiple uncertainties.pdf:pdf},
isbn = {0025-5564},
issn = {00255564},
journal = {Mathematical Biosciences},
keywords = {Bioeconomic model,Dynamic programming,Growth uncertainty,Invasive species management,Measurement uncertainty,Value functions},
number = {1},
pages = {32--46},
pmid = {21704642},
publisher = {Elsevier Inc.},
title = {{Optimal invasive species management under multiple uncertainties}},
url = {http://dx.doi.org/10.1016/j.mbs.2011.06.002},
volume = {233},
year = {2011}
}
@article{Allen2016b,
abstract = {a b s t r a c t Available online xxxx Identifying invasion risk is critical for regional prioritization of management and monitoring, however, we cur-rently lack a comprehensive assessment of the invasion risk posed by plants for the United States. We aim to quantify geographic invasion risk for currently established terrestrial invasive plants in the continental U.S. under current and future climate. We assembled a comprehensive occurrence database for 896 terrestrial inva-sive plant species from 33 regional collections of field and museum data and projected species ranges using MaxEnt species distribution models based on current (1950–2000 average) and future (2040–2060 average) cli-mate. We quantified geographic invasion risk as differences in species richness, invasion debt, range infilling, and identification of hotspots. Potential invasive plant richness was higher than observed richness, particularly in eastern temperate forests, where as many as 83{\%} of species with suitable climate have not yet established. A small percentage (median = 0.22{\%}) of species' potential ranges are currently occupied by them. With climate change, potential invasive plant richness declined by a median of 7.3{\%} by 2050. About 80{\%} of invasive plant hotspots were geographically stable with climate change, with the remaining 20{\%} shifting northward. Invasion hotspots and current invasion debt reveal extensive, ongoing risk from existing invasive plants across the U.S., particularly in the Southeast. Climate change alters the spatial distributions of focal species for monitoring and is likely to reduce overall invasion risk in many areas. Early detection and rapid response programs could be most effective in stemming the spread of invasive plant species in areas with increased risk under climate change, while areas with persistent high risk are candidates for containment and control. The areas with reduced risk are prime locations for invasion of new imports from tropical and subtropical climates, highlighting the simultaneous need for prevention strategies.},
author = {Allen, Jenica M and Bradley, Bethany A},
doi = {10.1016/j.biocon.2016.09.015},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Bradley - 2016 - Out of the weeds Reduced plant invasion risk with climate change in the continental United States.pdf:pdf},
journal = {Biological Conservation},
keywords = {Biodiversity,Conservation biology,Invasion debt,Invasive plant management,Invasive species,Species richness},
pages = {306--312},
title = {{Out of the weeds? Reduced plant invasion risk with climate change in the continental United States}},
volume = {203},
year = {2016}
}
@article{ODonnell2012,
author = {O'Donnell, Jessica and Gallagher, Rachael V. and Wilson, Peter D. and Downey, Paul O. and Hughes, Lesley and Leishman, Michelle R.},
doi = {10.1111/j.1365-2486.2011.02537.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {SDMs,invasives},
mendeley-tags = {SDMs,invasives},
month = {feb},
number = {2},
pages = {617--629},
title = {{Invasion hotspots for non-native plants in Australia under current and future climates}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2011.02537.x},
volume = {18},
year = {2012}
}
@article{Bradley2015,
abstract = {Aim Our understanding of potential ranges for native and non-native species is often based on their current geographic distributions. Non-native species have had less time than co-occurring native species to expand their ranges following introduction, so non-native ranges may under-represent suitable conditions. Therefore it is often assumed that species distribution models will predict disproportionately smaller potential ranges for non-natives than natives. We compare the distributions of native, endemic, alien and invasive plants to determine how the different range attributes of these groups might influence ecological forecasting. Location Continental USA. Methods We compared the geographic ranges of 13,575 plant species (9402 native, 2397 endemic, 1201 alien and 755 invasive) using (1) US only and (2) global distribution data from herbarium records. We calculated US longitudinal and latitudinal range extents as potential indicators of range-limiting factors, modelled potential range based on climate using principal components analysis, and calculated occupancy of potential ranges (range infilling). Results Contrary to expectations, modelled potential ranges were significantly larger for non-natives than natives, even for species with few occurrences. Distributions of native species, not invasive species, appeared strongly limited longitudinally. However, invasive plants occupied substantially less area within their climatically suitable ranges than native plants (lower range infilling). Main conclusions Invasive plant distributions were consistently broader, both climatically and geographically, than comparable native species. This suggests that invasive plant distribution models at regional scales are not underpredicting potential ranges relative to models for native species. In contrast, the comparatively limited longitudinal ranges of native species suggest a high degree of non-climatic limitation, which is likely to cause distribution models to underpredict the potential ranges of native species. Invasive plants have not achieved the degree of range infilling expected relative to natives. Thus, plants introduced to the US still have plenty of space to invade.},
author = {Bradley, Bethany A. and Early, Regan and Sorte, Cascade J B},
doi = {10.1111/geb.12275},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bradley, Early, Sorte - 2015 - Space to invade Comparative range infilling and potential range of invasive and native plants.pdf:pdf},
isbn = {1466822X},
issn = {14668238},
journal = {Global Ecology and Biogeography},
keywords = {Alien,Bioclimatic envelope model,Dispersal,Ecological niche model,Equilibrium,Exotic,Introduced,Occupancy,Plant invasion},
month = {mar},
number = {3},
pages = {348--359},
title = {{Space to invade? Comparative range infilling and potential range of invasive and native plants}},
url = {http://doi.wiley.com/10.1111/geb.12275},
volume = {24},
year = {2015}
}
@article{Allen2016a,
abstract = {a b s t r a c t Available online xxxx Identifying invasion risk is critical for regional prioritization of management and monitoring, however, we cur-rently lack a comprehensive assessment of the invasion risk posed by plants for the United States. We aim to quantify geographic invasion risk for currently established terrestrial invasive plants in the continental U.S. under current and future climate. We assembled a comprehensive occurrence database for 896 terrestrial inva-sive plant species from 33 regional collections of field and museum data and projected species ranges using MaxEnt species distribution models based on current (1950–2000 average) and future (2040–2060 average) cli-mate. We quantified geographic invasion risk as differences in species richness, invasion debt, range infilling, and identification of hotspots. Potential invasive plant richness was higher than observed richness, particularly in eastern temperate forests, where as many as 83{\%} of species with suitable climate have not yet established. A small percentage (median = 0.22{\%}) of species' potential ranges are currently occupied by them. With climate change, potential invasive plant richness declined by a median of 7.3{\%} by 2050. About 80{\%} of invasive plant hotspots were geographically stable with climate change, with the remaining 20{\%} shifting northward. Invasion hotspots and current invasion debt reveal extensive, ongoing risk from existing invasive plants across the U.S., particularly in the Southeast. Climate change alters the spatial distributions of focal species for monitoring and is likely to reduce overall invasion risk in many areas. Early detection and rapid response programs could be most effective in stemming the spread of invasive plant species in areas with increased risk under climate change, while areas with persistent high risk are candidates for containment and control. The areas with reduced risk are prime locations for invasion of new imports from tropical and subtropical climates, highlighting the simultaneous need for prevention strategies.},
author = {Allen, Jenica M and Bradley, Bethany A},
doi = {10.1016/j.biocon.2016.09.015},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Allen, Bradley - 2016 - Out of the weeds Reduced plant invasion risk with climate change in the continental United States.pdf:pdf},
journal = {Biological Conservation},
keywords = {Biodiversity,Conservation biology,Invasion debt,Invasive plant management,Invasive species,Species richness},
pages = {306--312},
title = {{Out of the weeds? Reduced plant invasion risk with climate change in the continental United States}},
volume = {203},
year = {2016}
}
@article{Aiello-Lammens2014,
abstract = {Ph.D. disertation},
author = {Aiello-Lammens, Matthew E.},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aiello-Lammens - 2014 - Patterns and Processes of the Invasion of Frangula alnus An Integrated Model Framework.pdf:pdf},
keywords = {p2-fral},
number = {May},
pages = {201},
title = {{Patterns and Processes of the Invasion of Frangula alnus: An Integrated Model Framework}},
url = {http://www.soilinfo.psu.edu/},
year = {2014}
}
@article{Sanford2003,
abstract = {Although plant invasion is often facilitated by disturbance, several non-native trees and shrubs have successfully invaded intact forest habitats in northeastern North America. To better understand invasive plant performance in intact versus disturbed forest habitats, we compared survival, relative height growth rate, aboveground biomass allocation, and leaf area of alien and native woody seedlings. In replicated understory versus open treatment plots at two sites we planted three pairs of native and alien species that appear ecologically similar: sugar maple (Acer saccharum) and Norway maple (Acer platanoides), arrow-wood (Viburnum dentatum) and glossy buckthorn (Rhamnus frangula), and silky dogwood (Cornus amomum) and autumn olive (Eleagnus umbellata). Seedlings were protected from deer browsing by open-topped cages made of chicken wire. Norway maple survival in open and understory environments was greater than that of sugar maple, and autumn olive survival in understory environments was greater than that of silky dogwood. The species differed in their responses to open versus understory environments in height growth, aboveground biomass and leaf area. The four shrub species grew faster in the open, with glossy buckthorn growing faster than the others, while the two tree species did not differ in growth between the environments. Leaf mass per unit leaf area was greater in the open than in the understory for all six species, but the difference did not vary among species. Arrow-wood, silky dogwood, and autumn olive decreased leaf area per unit biomass in the understory, but variation in survival among species was not related to maintenance of leaf area ratio. Among the six species, the increase in biomass from understory to open environments was negatively correlated with growing season survival in the understory. This apparent trade-off relationship applied equally to native and alien species, indicating that release from physiological constraints does not explain the success of the invasive species.},
author = {Sanford, Nicole L. and Harrington, Robin A. and Fownes, James H.},
doi = {10.1016/S0378-1127(03)00141-5},
issn = {03781127},
journal = {Forest Ecology and Management},
number = {1},
pages = {377--385},
title = {{Survival and growth of native and alien woody seedlings in open and understory environments}},
volume = {183},
year = {2003}
}
@article{Buyuktahtakin2014,
abstract = {Buffelgrass (Pennisetum ciliare) is a fire-prone, African bunchgrass spreading rapidly across the southern Arizona desert. This article introduces a model that simulates buffelgrass spread over a gridded landscape over time to evaluate strategies to control this invasive species. Weed-carrying capacity, treatment costs, and damages vary across grid cells. Damage from buffelgrass depends on its density and proximity to valued resources. Damages include negative effects on native species (through spatial competition) and increased fire risk to land and buildings. We evaluate recommended “rule of thumb” control strategies in terms of their ability to prevent weed establishment in newly infested areas and to reduce damage indices over time. Two such strategies—potential damage weighting and consecutive year treatment—used in combination, provided significant improvements in long-term control over no control and over a strategy of minimizing current damages in each year. Results suggest specific recommendations for deploying rapid-response teams to prevent establishment in new areas. The long-run population size and spatial distribution of buffelgrass is sensitive to the priority given to protecting different resources. Land managers with different priorities may pursue quite different control strategies, posing a challenge for coordinating control across jurisdictions.},
author = {Buyuktahtakin, I. Esra and Feng, Zhuo and Olsson, Aaryn D. and Frisvold, George and Szidarovszky, Ferenc},
doi = {10.1614/IPSM-D-13-00057.1},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buyuktahtakin et al. - 2014 - Invasive Species Control Optimization as a Dynamic Spatial Process An Application to Buffelgrass ( Pennise.pdf:pdf},
issn = {1939-7291},
journal = {Invasive Plant Science and Management},
keywords = {biological invasion,buffelgrass,dynamic spatial processes,environmental studies,integer,invasive species,invasive weeds as a,land management,optimal control,programming,smith et al,spatial-dynamic problem,spread and management of,this study examines the},
number = {1},
pages = {132--146},
title = {{Invasive Species Control Optimization as a Dynamic Spatial Process: An Application to Buffelgrass ( Pennisetum ciliare ) in Arizona}},
url = {http://www.bioone.org/doi/abs/10.1614/IPSM-D-13-00057.1},
volume = {7},
year = {2014}
}
@article{Merow2011,
author = {Merow, Cory and LaFleur, Nancy and {Silander Jr.}, John A. and Wilson, Adam M. and Rubega, Margaret},
doi = {10.1086/660295},
issn = {0003-0147},
journal = {The American Naturalist},
month = {jul},
number = {1},
pages = {30--43},
title = {{Developing Dynamic Mechanistic Species Distribution Models: Predicting Bird-Mediated Spread of Invasive Plants across Northeastern North America}},
url = {http://www.journals.uchicago.edu/doi/10.1086/660295},
volume = {178},
year = {2011}
}
@article{Buyuktahtakn2011,
abstract = {A dynamic model of controlling invasive weeds is first developed which is a large scale, nonlinear 0-1 integer programming problem. This model is then applied for the case of control of the invasive grass, Pennisetum ciliare (buffelgrass), in the Arizona desert. The large size of the problem makes the application of direct optimization methods impossible, instead the most frequently suggested strategies were analyzed and their consequences compared. The model is more advanced and complex than those examined in earlier studies. ?? 2011 Elsevier Ltd. All rights reserved.},
author = {Buyuktahtakn, I. Esra and Feng, Zhuo and Frisvold, George and Szidarovszky, Ferenc and Olsson, Aaryn},
doi = {10.1016/j.camwa.2011.08.037},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buyuktahtakn et al. - 2011 - A dynamic model of controlling invasive species.pdf:pdf},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {Biological invasion,Integer programming,Invasive species,Non-native species,Optimal control},
number = {9},
pages = {3326--3333},
publisher = {Elsevier Ltd},
title = {{A dynamic model of controlling invasive species}},
url = {http://dx.doi.org/10.1016/j.camwa.2011.08.037},
volume = {62},
year = {2011}
}
@article{Ibanez2009d,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and {Silander Jr}, John. A. and Allen, Jenica M. and Treanor, Sarah A. and Wilson, Adam},
doi = {10.1111/j.1365-2664.2009.01736.x},
issn = {00218901},
journal = {Journal of Applied Ecology},
keywords = {SDMs,abundance,climate change},
mendeley-tags = {SDMs,abundance,climate change},
month = {nov},
number = {6},
pages = {1219--1228},
title = {{Identifying hotspots for plant invasions and forecasting focal points of further spread}},
url = {http://doi.wiley.com/10.1111/j.1365-2664.2009.01736.x},
volume = {46},
year = {2009}
}
@article{Reinartz2002,
abstract = {Common buckthorn (Rhamnus cathartica), glossy buckthorn (R. frangula), Tartarian honeysuckle (Lonicera tatarica), and Morrow honeysuckle (L. morrowii) are invasive, non-native shrub species that have become serious threats to the ecological integrity of many natural areas in the northeastern and midwestern United States. The " cut-stump method " (cutting stems near the ground and applying herbicide to the freshly cut stumps) is an effective control method for all four of these species when applied during the growing season, especially in late summer and fall (Heidorn 1991, Hoffman and Kearns 1997). I sought a winter control method for these species for several reasons: 1) work crews are often available in winter; 2) the task of locating and cutting shrubs is less arduous on a nice winter day than during the growing season, when heat and biting insects are a factor; 3) all of these shrubs are easily identifiable during winter; 4) the frozen ground provides easier access to glossy buckthorn, a species found primarily in wetlands; and 5) most species in this area are deciduous or dormant in the winter, so herbicide application is very selective and does not damage non-target plants. I have also found that winter (December through March) can be an ideal time for applying the cut-stump method with glyphosate to all four of these species in southeastern Wisconsin. In an earlier study (Reinartz 1997), I successfully tested this method on glossy buckthorn at Cedarburg Bog in Ozaukee County, Wisconsin during winter 1989-90. That experiment resulted in an average kill rate of 98 percent when I applied glyphosate (10.25-percent active ingredient) to 150 stumps cut 2-6 inches (5-15 cm) from the ground. This herbicide concentration was obtained by mixing 3 parts water with 1 part Roundup{\textregistered} herbicide that was purchased as a 41-percent active ingredient solution. Following my success with glossy buckthorn, I expanded this study to include common buckthorn and the two honeysuckle species. All treatment sites were located within 10 miles (16.1km) of the University of Wisconsin-Milwaukee Field Station, Ozaukee County, Wisconsin. At various times during the winters of 1992 through 2000 (Table 1), I cut shrubs with stems greater than 0.6 inches (15mm) in diameter to 2-6 inches (5-15cm) above the ground. Since I had already found the winter cut-stump method to be effective on glossy buckthorn, I collected data less frequently on that species than on the others. Within five minutes of stem cutting, I covered at least 50 percent (usually 100 percent) of the surface area of each cut stump with Roundup™ (about 10 percent concentration of glyphosate) using a squirt bottle. I took care to treat every stem of multiple-stemmed plants. Temperatures were generally between 20°F (–7°C) and 45°F (7°C) at the time of each treatment, and the ground was frozen. On some treatment days there was a snow cover. Although observations during the growing seasons showed that both Tartarian and Morrow honeysuckle occurred at some of the sites where these trials were conducted, I did not distinguish between the two species either during the winter treatment periods or when evaluating the stumps for effectiveness of the treatment},
author = {Reinartz, James A},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reinartz - Unknown - Winter Season Offers Many Advantages for Treating Invasive Buckthorns and Honeysuckles (Wisconsin).pdf:pdf},
journal = {Ecological Restoration Notes},
pages = {237},
title = {{Winter Season Offers Many Advantages for Treating Invasive Buckthorns and Honeysuckles (Wisconsin)}},
volume = {20},
year = {2002}
}
@article{Lee2012,
abstract = {The extent to which forests can be invaded by exotic plants and the role of tree harvest in facilitating such invasions are important issues in invasion biology. Our objective was to determine: (a) whether a widespread exotic shrub, glossy buckthorn (Frangula alnus), can invade a common northeastern US forest type, (b) the extent to which logging facilitates buckthorn invasion, (c) whether buckthorn invades gaps through pre-disturbance (‘advance') regeneration, (d) whether or not it forms uneven-aged populations in invaded stands. We selected nine eastern white pine – hardwoods stands in Durham, NH. Three were undisturbed, three were clear-cut, and three were partially cut. Cutting occurred ⩾6years prior to sampling. Glossy buckthorn (⩾0.5m tall) was present in all stands at the time of sampling and most buckthorn populations were all-aged, suggesting that recruitment by seed continued after initial establishment and that long-term persistence in these stands is possible. Buckthorn was present in four of six cut stands prior to cutting, indicating some advance regeneration. The results support the view that forests are not inherently resistant to invasion by exotic plants. Compared to uncut stands, however, buckthorn had higher densities in clear-cut and partially cut stands. In partially cut stands, buckthorn density was greater in canopy gaps than in adjacent uncut areas. Thus, logging facilitated buckthorn invasion. Given this result and the known negative effects of buckthorn on tree regeneration, control measures should be considered when logging stands where buckthorn invasion is likely.},
author = {Lee, Thomas D. and Thompson, Jennifer H.},
doi = {10.1016/j.foreco.2011.10.035},
issn = {03781127},
journal = {Forest Ecology and Management},
pages = {201--210},
title = {{Effects of logging history on invasion of eastern white pine forests by exotic glossy buckthorn (Frangula alnus P. Mill.)}},
volume = {265},
year = {2012}
}
@article{Elith2011,
abstract = {Abstract MaxEnt is a program for modelling species distributions from presence-only species records. This paper is written for ecologists and describes the MaxEnt model from a statistical perspective, making explicit links between the structure of the model, decisions required in producing a modelled distribution, and knowledge about the species and the data that might affect those decisions. To begin we discuss the characteristics of presence-only data, highlighting implications for modelling distributions. We particularly focus on the problems of sample bias and lack of information on species prevalence. The keystone of the paper is a new statistical explanation of MaxEnt which shows that the model minimizes the relative entropy between two probability densities (one estimated from the presence data and one, from the landscape) defined in covariate space. For many users, this viewpoint is likely to be a more accessible way to understand the model than previous ones that rely on machine learning concepts. We then step through a detailed explanation of MaxEnt describing key components (e.g. covariates and features, and definition of the landscape extent), the mechanics of model fitting (e.g. feature selection, constraints and regularization) and outputs. Using case studies for a Banksia species native to south-west Australia and a riverine fish, we fit models and interpret them, exploring why certain choices affect the result and what this means. The fish example illustrates use of the model with vector data for linear river segments rather than raster (gridded) data. Appropriate treatments for survey bias, unprojected data, locally restricted species, and predicting to environments outside the range of the training data are demonstrated, and new capabilities discussed. Online appendices include additional details of the model and the mathematical links between previous explanations and this one, example code and data, and further information on the case studies.},
archivePrefix = {arXiv},
arxivId = {1132},
author = {Elith, Jane and Phillips, Steven J. and Hastie, Trevor and Dud{\'{i}}k, Miroslav and Chee, Yung En and Yates, Colin J.},
doi = {10.1111/j.1472-4642.2010.00725.x},
eprint = {1132},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elith et al. - 2011 - A statistical explanation of MaxEnt for ecologists.pdf:pdf},
isbn = {1472-4642},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Absence,Ecological niche,Entropy,Machine learning,Presence-only,Species distribution model},
number = {1},
pages = {43--57},
pmid = {15204886},
title = {{A statistical explanation of MaxEnt for ecologists}},
volume = {17},
year = {2011}
}
@article{HIJMANS2006,
author = {Hijmans, ROBERT J. and Graham, CATHERINE H.},
doi = {10.1111/j.1365-2486.2006.01256.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hijmans, Graham - 2006 - The ability of climate envelope models to predict the effect of climate change on species distributions.pdf:pdf},
issn = {1354-1013},
journal = {Global Change Biology},
keywords = {GAM,bioclim,climate change,domain,envelope models,maxent,species distributions},
month = {dec},
number = {12},
pages = {2272--2281},
publisher = {Blackwell Publishing Ltd},
title = {{The ability of climate envelope models to predict the effect of climate change on species distributions}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2006.01256.x},
volume = {12},
year = {2006}
}
@article{Pimentel2005,
abstract = {Invading alien species in the United States cause major environmental damages and losses adding up to almost {\$}120 billion per year. There are approximately 50,000 foreign species and the number is increasing. About 42{\%} of the species on the Threatened or Endangered species lists are at risk primarily because of alien-invasive species.},
author = {Pimentel, David and Zuniga, Rodolfo and Morrison, Doug},
doi = {10.1016/j.ecolecon.2004.10.002},
file = {::},
issn = {09218009},
journal = {Ecological Economics},
keywords = {Alien-invasive species,Environmental and economic cost,Threatened or endangered species},
month = {feb},
number = {3},
pages = {273--288},
title = {{Update on the environmental and economic costs associated with alien-invasive species in the United States}},
url = {http://www.sciencedirect.com/science/article/pii/S0921800904003027},
volume = {52},
year = {2005}
}
@article{Bradshaw2016,
author = {Bradshaw, Corey J. A. and Leroy, Boris and Bellard, C{\'{e}}line and Roiz, David and Albert, C{\'{e}}line and Fournier, Alice and Barbet-Massin, Morgane and Salles, Jean-Michel and Simard, Fr{\'{e}}d{\'{e}}ric and Courchamp, Franck and Mellor, P. S. and Boorman, J. and Baylis, M. and Oerke, E.-C. and Aukema, J. E. and Su, N. Y. and Kenis, M. and Mora, C. and Tittensor, D. P. and Adl, S. and Simpson, A. G. B. and Worm, B. and Bebber, D. P. and Ramotowski, M. A. T. and Gurr, S. J. and Paini, D. R. and Kurz, W. A. and Gubler, D. J. and Zalucki, M. P. and Widmer, L. L. and Blank, P. R. and Herck, K. Van and Hatz, C. and Schlagenhauf, P. and Bellard, C. and Jeschke, J. M. and Costanza, R. and Nunes, P. A. L. D. and van den Bergh, J. C. J. M. and Rodriguez, L. F. and Li, D.-Z. and Pritchard, H. W. and Sanguinetti, A. and Singer, R. B. and Aizen, M. A. and Py{\v{s}}ek, P. and Butchart, S. H. M. and Bellard, C. and Holmes, T. P. and Aukema, J. E. and Holle, B. Von and Liebhold, A. and Sills, E. and Vazquez-Prokopec, G. M. and Chaves, L. F. and Ritchie, S. A. and Davis, J. and Kitron, U. and Olson, L. J. and Roy, S. and Jenkins, P. T. and Xu, K. and Gopalan, S. Saraswathy and Das, A. and Juliano, S. A. and Lounibos, L. Philip and Dosdall, L. M. and Colautti, R. I. and Bailey, S. a. and van Overdijk, C. D. A. and Amundsen, K. and MacIsaac, H. J. and Aukema, J. E. and Haack, R. A. and H{\'{e}}rard, F. and Herard, F. and Sun, J. and Turgeon, J. J.},
doi = {10.1038/ncomms12986},
file = {::},
issn = {2041-1723},
journal = {Nature Communications},
month = {oct},
pages = {12986},
publisher = {Nature Publishing Group},
title = {{Massive yet grossly underestimated global costs of invasive insects}},
url = {http://www.nature.com/doifinder/10.1038/ncomms12986},
volume = {7},
year = {2016}
}
@article{Bois2011,
author = {Bois, Sarah T. and Silander, John A. and Mehrhoff, Leslie J.},
doi = {10.1525/bio.2011.61.10.6},
issn = {00063568},
journal = {BioScience},
keywords = {IPANE},
language = {en},
mendeley-tags = {IPANE},
month = {oct},
number = {10},
pages = {763--770},
publisher = {Oxford University Press},
title = {{Invasive Plant Atlas of New England: The role of citizens in the science of invasive alien species detection}},
url = {http://bioscience.oxfordjournals.org.silk.library.umass.edu/content/61/10/763.full},
volume = {61},
year = {2011}
}
@article{Cunard2009,
author = {Cunard, Chelsea and Lee, Thomas D.},
doi = {10.1007/s10530-008-9272-8},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cunard, Lee - 2009 - Is patience a virtue Succession, light, and the death of invasive glossy buckthorn (Frangula alnus).pdf:pdf},
issn = {1387-3547},
journal = {Biological Invasions},
month = {mar},
number = {3},
pages = {577--586},
publisher = {Springer Netherlands},
title = {{Is patience a virtue? Succession, light, and the death of invasive glossy buckthorn (Frangula alnus)}},
url = {http://link.springer.com/10.1007/s10530-008-9272-8},
volume = {11},
year = {2009}
}
@book{Stohlgren2007a,
author = {Stohlgren, Thomas J.},
publisher = {Oxford University Press},
title = {{Measuring Plant Diversity: Lessons from the Field - Thomas J. Stohlgren - Google Books}},
url = {https://books.google.com/books/about/Measuring{\_}Plant{\_}Diversity.html?id=yPmvSrj9pBMC{\&}printsec=frontcover{\&}source=kp{\_}read{\_}button{\#}v=onepage{\&}q{\&}f=false},
year = {2007}
}
@article{Fagan2004,
abstract = {The invasion of forests in the northeastern USA by glossy buckthorn (Rhamnus frangula L.) has resulted in a dense, non-native shrub layer that frequently dominates the understory. We investigated the effects of buckthorn on the survival and growth of juvenile canopy trees spanning a wide range of shade tolerance (sugar maple, Acer saccharum Marsh.; red maple, Acer rubrum L.; white ash, Fraxinus americana L.; and white pine, Pinus strobus L.), in a stand dominated by white pine. First, we measured the effect of buckthorn on sapling growth in a field study. Second, we inferred effects on sapling survivorship from age data and from published relationships between radial growth and mortality rate. Third, we evaluated the effects of buckthorn on seedling growth and survival in canopy openings, by felling trees to create experimental gaps. Buckthorn reduced the growth and survival of saplings of all species, and altered the relative abundance of seedlings in favor of shade-tolerant species. Estimates of sapling survival implied that {\textless}10{\%} of tree saplings can survive to grow through high density buckthorn under closed canopies. This reduces the probability that understory saplings will survive to recruit into all newly formed canopy gaps. The experimental results suggest that tree seedlings are most likely to recruit in canopy gaps, despite the generally high buckthorn cover in gaps. Thus, recruitment of tree seedlings in gaps (even under buckthorn) may become the main source of canopy recruits. The increasing dominance of glossy buckthorn in New England pine forests is likely to change the relative abundance of tree species in the forest canopy, and may delay the filling of canopy gaps.},
author = {Fagan, M.E and Peart, D.R},
doi = {10.1016/j.foreco.2004.02.015},
issn = {03781127},
journal = {Forest Ecology and Management},
number = {1},
pages = {95--107},
title = {{Impact of the invasive shrub glossy buckthorn (Rhamnus frangula L.) on juvenile recruitment by canopy trees}},
volume = {194},
year = {2004}
}
@article{Reinartz1997,
author = {Reinartz, James A},
journal = {Natural Areas Journal},
pages = {38--41},
title = {{Controlling glossy buckthorn (Rhamnus frangula L.) with winter herbicide treatments of cut stumps.}},
volume = {17},
year = {1997}
}
@article{Harrington1989,
author = {Harrington, Robin A. and Brown, Becky J. and Reich, Peter B. and Fownes, James H.},
journal = {Oecologia},
pages = {368--373},
title = {{Ecophysiology of Exotic and Native Shrubs in Southern Wisconsin. II. Annual Growth and Carbon Gain on JSTOR}},
url = {http://www.jstor.org/stable/4219059?seq=1{\#}page{\_}scan{\_}tab{\_}contents},
volume = {80},
year = {1989}
}
@article{Phillips2009,
abstract = {Most methods for modeling species distributions from occurrence records require additional data representing the range of environmental conditions in the modeled region. These data, called background or pseudo-absence data, are usually drawn at random from the entire region, whereas occurrence collection is often spatially biased toward easily accessed areas. Since the spatial bias generally results in environmental bias, the difference between occurrence collection and background sampling may lead to inaccurate models. To correct the estimation, we propose choosing background data with the same bias as occurrence data. We investigate theoretical and practical implications of this approach. Accurate information about spatial bias is usually lacking, so explicit biased sampling of background sites may not be possible. However, it is likely that an entire target group of species observed by similar methods will share similar bias. We therefore explore the use of all occurrences within a target group as bias...},
author = {Phillips, Steven J. and Dud{\'{i}}k, Miroslav and Elith, Jane and Graham, Catherine H. and Lehmann, Anthony and Leathwick, John and Ferrier, Simon},
doi = {10.1890/07-2153.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {MaxEnt,SDM,background data,niche modeling,presence-only distribution models,pseudo-absence,sample selection bias,sampling bias,species distribution modeling,target group},
language = {EN},
mendeley-tags = {MaxEnt,SDM,sampling bias},
month = {jan},
number = {1},
pages = {181--197},
publisher = {Ecological Society of America},
title = {{Sample selection bias and presence-only distribution models: implications for background and pseudo-absence data}},
url = {http://www.esajournals.org/doi/full/10.1890/07-2153.1},
volume = {19},
year = {2009}
}
@article{Hijmanns2006,
author = {Hijmanns, Robert J. and Graham, Catherine H.},
doi = {10.1111/j.1365-2486.2006.01256.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hijmans, Graham - 2006 - The ability of climate envelope models to predict the effect of climate change on species distributions.pdf:pdf},
issn = {1354-1013},
journal = {Global Change Biology},
keywords = {GAM,bioclim,climate change,domain,envelope models,maxent,species distributions},
month = {dec},
number = {12},
pages = {2272--2281},
publisher = {Blackwell Publishing Ltd},
title = {{The ability of climate envelope models to predict the effect of climate change on species distributions}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2006.01256.x},
volume = {12},
year = {2006}
}
@article{Godwin1943,
author = {Godwin, H.},
doi = {10.2307/2256791},
issn = {00220477},
journal = {The Journal of Ecology},
month = {may},
number = {1},
pages = {66},
title = {{Rhamnaceae}},
url = {http://www.jstor.org/stable/2256791?origin=crossref},
volume = {31},
year = {1943}
}
@article{Vila2011,
abstract = {Biological invasions cause ecological and economic impacts across the globe. However, it is unclear whether there are strong patterns in terms of their major effects, how the vulnerability of different ecosystems varies and which ecosystem services are at greatest risk. We present a global meta-analysis of 199 articles reporting 1041 field studies that in total describe the impacts of 135 alien plant taxa on resident species, communities and ecosystems. Across studies, alien plants had a significant effect in 11 of 24 different types of impact assessed. The magnitude and direction of the impact varied both within and between different types of impact. On average, abundance and diversity of the resident species decreased in invaded sites, whereas primary production and several ecosystem processes were enhanced. While alien N-fixing species had greater impacts on N-cycling variables, they did not consistently affect other impact types. The magnitude of the impacts was not significantly different between island and mainland ecosystems. Overall, alien species impacts are heterogeneous and not unidirectional even within particular impact types. Our analysis also reveals that by the time changes in nutrient cycling are detected, major impacts on plant species and communities are likely to have already occurred.},
author = {Vil{\`{a}}, Montserrat and Espinar, Jos{\'{e}} L and Hejda, Martin and Hulme, Philip E and Jaro{\v{s}}{\'{i}}k, Vojt{\v{e}}ch and Maron, John L and Pergl, Jan and Schaffner, Urs and Sun, Yan and Py{\v{s}}ek, Petr},
doi = {10.1111/j.1461-0248.2011.01628.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vil{\`{a}} et al. - 2011 - Ecological impacts of invasive alien plants a meta-analysis of their effects on species, communities and ecosystem.pdf:pdf},
issn = {1461-0248},
journal = {Ecology letters},
keywords = {Biodiversity,Ecosystem,Geography,Introduced Species,Plants,Population Density,Population Dynamics},
month = {jul},
number = {7},
pages = {702--8},
pmid = {21592274},
title = {{Ecological impacts of invasive alien plants: a meta-analysis of their effects on species, communities and ecosystems.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21592274},
volume = {14},
year = {2011}
}
@article{Taleghan2015,
abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taleghan et al. - 2015 - PAC Optimal MDP Planning with Application to Invasive Species Management.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Good- Turing estimate,MDP planning,Markov decision processes,invasive species management,reinforcement learning},
pages = {3877--3903},
title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
url = {http://jmlr.org/papers/v16/taleghan15a.html},
volume = {16},
year = {2015}
}
@article{Allen2013,
author = {Allen, Jenica M. and Leininger, Thomas J. and Hurd, James D. and Civco, Daniel L. and Gelfand, Alan E. and Silander, John A.},
doi = {10.1007/s10980-013-9916-7},
issn = {0921-2973},
journal = {Landscape Ecology},
keywords = {LULC change},
mendeley-tags = {LULC change},
month = {jul},
number = {9},
pages = {1671--1686},
title = {{Socioeconomics drive woody invasive plant richness in New England, USA through forest fragmentation}},
url = {http://link.springer.com/10.1007/s10980-013-9916-7},
volume = {28},
year = {2013}
}
@article{Elith2009,
abstract = {Species distribution models (SDMs) are numerical tools that combine observations of species occurrence or abundance with environmental estimates. They are used to gain ecological and evolutionary insights and to predict distributions across landscapes, sometimes requiring extrapolation in space and time. SDMs are now widely used across terrestrial, freshwater, and marine realms. Differences in methods between disciplines reflect both differences in species mobility and in “established use.” Model realism and robustness is influenced by selection of relevant predictors and modeling method, consideration of scale, how the interplay between environmental and geographic factors is handled, and the extent of extrapolation. Current linkages between SDM practice and ecological theory are often weak, hindering progress. Remaining challenges include: improvement of methods for modeling presence-only data and for model selection and evaluation; accounting for biotic interactions; and assessing model uncertainty.},
author = {Elith, Jane and Leathwick, John R.},
doi = {10.1146/annurev.ecolsys.110308.120159},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elith, Leathwick - 2009 - Species Distribution Models Ecological Explanation and Prediction Across Space and Time.pdf:pdf;::},
issn = {1543-592X},
journal = {Annual Review of Ecology, Evolution, and Systematics},
keywords = {SDM,climate change,equilibrium,invasions,niche,predict,presence-only,spatial},
language = {en},
mendeley-tags = {SDM,equilibrium},
month = {dec},
number = {1},
pages = {677--697},
publisher = {Annual Reviews},
title = {{Species Distribution Models: Ecological Explanation and Prediction Across Space and Time}},
url = {http://www.annualreviews.org.silk.library.umass.edu/eprint/HWR4cusJrXYCSPZ9sUDj/full},
volume = {40},
year = {2009}
}
@book{Stohlgren2007,
address = {New York},
author = {Stohlgren, Thomas J.},
publisher = {Oxford University Press},
title = {{Measuring Plant Diversity: Lessons from the Field}},
url = {https://books.google.com/books/about/Measuring{\_}Plant{\_}Diversity.html?id=yPmvSrj9pBMC{\&}printsec=frontcover{\&}source=kp{\_}read{\_}button{\#}v=onepage{\&}q{\&}f=false},
year = {2007}
}
@techreport{Michigan2012,
author = {{USDA Forest Service Forest Health Staff}},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/USDA Forest Service Forest Health Staff - 2012 - Glossy Buckthorn.pdf:pdf},
pages = {1},
title = {{Glossy Buckthorn}},
volume = {2},
year = {2012}
}
@misc{USDA,
author = {USDA},
keywords = {NRCS,PLANTS,Plant identification,Plant taxonomy,USDA},
title = {{USDA PLANTS Database}},
url = {http://plants.usda.gov/java/},
urldate = {2014-10-17}
}
@article{Early2016,
author = {Early, Regan and Bradley, Bethany A. and Dukes, Jeffrey S. and Lawler, Joshua J. and Olden, Julian D. and Blumenthal, Dana M. and Gonzalez, Patrick and Grosholz, Edwin D. and Iba{\~{n}}ez, Ines and Miller, Luke P. and Sorte, Cascade J. B. and Tatem, Andrew J. and Levine, J. M. and D'Antonio, C. M. and Theoharides, K. A. and Dukes, J. S. and McGeoch, M. A. and Py{\v{s}}ek, P. and Seebens, H. and Tatem, A. J. and Tittensor, D. P. and Hulme, P. E. and Bradley, B. A. and Reichard, S. H. and White, P. and Smith, K. F. and McCullough, D. G. and Work, T. T. and Cavey, J. F. and Liebhold, A. M. and Marshall, D. and Essl, F. and Bellard, C. and Leroy, B. and Thuiller, W. and Rysman, J. F. and Courchamp, F. and Chytr{\'{y}}, M. and Diez, J. M. and Mack, R. N. and Roy, H. E. and Garc{\'{i}}a-de-Lomas, J. and Vil{\`{a}}, M. and Bacon, S. J. and Bacher, S. and Aebi, A. and Westbrooks, R. G. and Hulme, P. E. and McGeoch, M. A. and Pheloung, P. C. and Williams, P. A. and Halloy, S. R. and McGeoch, M. A. and Spear, D. and Kleynhans, E. J. and Marais, E. and Keller, R. P. and Perrings, C. and Bradley, B. A. and Early, R. and Sorte, C. J. B. and Catford, J. A. and Gallardo, B. and Aldridge, D. C. and Bogoch, I. I. and Banks, N. C. and Paini, D. R. and Bayliss, K. L. and Hodda, M. and Tollington, S. and Blackburn, T. M. and Lockwood, J. L. and Cassey, P. and Blackburn, T. and Essl, F. and Mack, R. N. and Erneberg, M. and Skarpaas, O. and {\O}kland, B. and McNeill, M. and Koch, F. H. and Yemshanov, D. and Colunga-Garcia, M. and Magarey, R. D. and Smith, W. D. and Spear, D. and Foxcroft, L. C. and Bezuidenhout, H. and McGeoch, M. A. and Work, T. T. and McCullough, D. G. and Cavey, J. F. and Komsa, R. and Gray, D. R. and Richardson, D. M. and Py{\v{s}}ek, P. and Hobbs, R. J. and Huenneke, L. F. and Chytr{\'{y}}, M. and Vicente, J. and Alves, P. and Randin, C. and Guisan, A. and Honrado, J. and Levine, J. M. and Adler, P. B. and Yelenik, S. G. and Moritz, M. A. and Alba, C. and Sk{\'{a}}lov{\'{a}}, H. and McGregor, K. F. and D'Antonio, C. and Py{\v{s}}ek, P. and Kelley, A. L. and Walther, G. R. and Pereira, H. M. and Balvanera, P. and Fargione, J. and Brown, C. S. and Tilman, D. and Diez, J. M. and Pulliam, H. R. and DeSantis, R. D. and Hallgren, S. W. and Stahle, D. W. and Py{\v{s}}ek, P. and Aikio, S. and Duncan, R. P. and Hulme, P. E. and Aagaard, K. and Lockwood, J. and Huang, Z. and Das, A. and Qiu, Y. and Tatem, A. and Mueller, J. M. and Hellmann, J. J. and Ricciardi, A. and Halpern, B. S. and Gonzalez, P. and Neilson, R. P. and Lenihan, J. M. and Drapek, R. J. and Mouillot, F. and Field, C. B. and Dobrovolski, R. and Diniz-Filho, J. and Loyola, R. and J{\'{u}}nior, P. De Marco},
doi = {10.1038/ncomms12485},
issn = {2041-1723},
journal = {Nature Communications},
month = {aug},
pages = {12485},
publisher = {Nature Publishing Group},
title = {{Global threats from invasive alien species in the twenty-first century and national response capacities}},
url = {http://www.nature.com/doifinder/10.1038/ncomms12485},
volume = {7},
year = {2016}
}
@article{Moreno-Amat2015,
abstract = {Maximum entropy modeling (Maxent) is a widely used algorithm for predicting species distributions across space and time. Properly assessing the uncertainty in such predictions is non-trivial and requires validation with independent datasets. Notably, model complexity (number of model parameters) remains a major concern in relation to overfitting and, hence, transferability of Maxent models. An emerging approach is to validate the cross-temporal transferability of model predictions using paleoecological data. In this study, we assess the effect of model complexity on the performance of Maxent projections across time using two European plant species (Alnus glutinosa (L.) Gaertn. and Corylus avellana L.) with an extensive late Quaternary fossil record in Spain as a study case. We fit 110 models with different levels of complexity under present time and tested model performance using AUC (area under the receiver operating characteristic curve) and AICc (corrected Akaike Information Criterion) through the standard procedure of randomly partitioning current occurrence data. We then compared these results to an independent validation by projecting the models to mid-Holocene (6000 years before present) climatic conditions in Spain to assess their ability to predict fossil pollen presence–absence and abundance. We find that calibrating Maxent models with default settings result in the generation of overly complex models. While model performance increased with model complexity when predicting current distributions, it was higher with intermediate complexity when predicting mid-Holocene distributions. Hence, models of intermediate complexity resulted in the best trade-off to predict species distributions across time. Reliable temporal model transferability is especially relevant for forecasting species distributions under future climate change. Consequently, species-specific model tuning should be used to find the best modeling settings to control for complexity, notably with paleoecological data to independently validate model projections. For cross-temporal projections of species distributions for which paleoecological data is not available, models of intermediate complexity should be selected.},
author = {Moreno-Amat, Elena and Mateo, Rub{\'{e}}n G. and Nieto-Lugilde, Diego and Morueta-Holme, Naia and Svenning, Jens-Christian and Garc{\'{i}}a-Amorena, Ignacio},
doi = {10.1016/j.ecolmodel.2015.05.035},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moreno-Amat et al. - 2015 - Impact of model complexity on cross-temporal transferability in Maxent species distribution models An assess.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Alnus glutinosa,Corylus avellana,Model validation,Pollen fossil,Species distribution model,$\beta$-Multiplier},
month = {sep},
pages = {308--317},
title = {{Impact of model complexity on cross-temporal transferability in Maxent species distribution models: An assessment using paleobotanical data}},
url = {http://www.sciencedirect.com/science/article/pii/S0304380015002483},
volume = {312},
year = {2015}
}
@article{Webster2006,
abstract = {Invasive exotic species pose significant challenges for natural resource managers charged with the maintenance of biological diversity and the sustainable production of forest resources. In this article, we review what is known about the biology and control of some of the most serious woody invaders of eastern forests. Based on the parallels between these invasions, we propose a working framework for integrating invasive control into forestry practices. In general, early detection and rapid response to invasions are essential. However, given that consistently effective control strategies that are broadly applicable simply do not exist for many species, adaptive management strategies will be necessary.},
author = {Webster, Christopher R. and Jenkins, Michael A. and Jose, Shibu},
isbn = {0022-1201},
issn = {00221201},
journal = {Journal of Forestry},
keywords = {alien plants,invasive exotics,invasive species,perennial weeds},
number = {7},
pages = {366--374},
title = {{Woody invaders and the challenges they pose to forest ecosystems in the eastern United States}},
url = {http://www.ingentaconnect.com/content/saf/jof/2006/00000104/00000007/art00006},
volume = {104},
year = {2006}
}
@article{Koning2013,
abstract = {ABSTRACT To investigate the hypothesis that Frangula alnus, glossy buckthorn, is causing a decrease in native plant diversity in forested plant communities of southwest New Hampshire, thirty nine 20-m × 20-m plots were established in five different forest types, and all buckthorn saplings and seedlings were removed from 15 of the plots. A nested plot design was used to sample shrubs and herbs. Treatment plots were kept free of buckthorn for five years. There was a positive relationship between pre-treatment buckthorn density and percent openness of the forest canopy, and with basal area of white pine (Pinus strobus), but not with soil wetness indicators. No significant changes in overall plant diversity or stem density were detected after buckthorn was removed, although stem density of woody plants, and seedlings of Acer rubrum did show significant increases in the treatment plots when compared to controls, but these effects were only seen in areas with the highest densities of buckthorn. No effects of bu...},
author = {Koning, Catherine Owen and Singleton, Rhine},
doi = {10.3375/043.033.0304},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koning, Singleton - 2013 - Effects of Moderate Densities of Glossy Buckthorn on Forested Plant Communities in Southwest New Hampshire, U.pdf:pdf},
issn = {0885-8608},
journal = {Natural Areas Journal},
keywords = {Frangula alnus,forest management,glossy buckthorn,invasive species},
month = {jul},
number = {3},
pages = {256--263},
publisher = { Natural Areas Association },
title = {{Effects of Moderate Densities of Glossy Buckthorn on Forested Plant Communities in Southwest New Hampshire, USA}},
url = {http://www.bioone.org/doi/abs/10.3375/043.033.0304},
volume = {33},
year = {2013}
}
@article{Dietterich2013,
author = {Dietterich, TG and Taleghan, MA and Crowley, Mark},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich, Taleghan, Crowley - 2013 - PAC optimal planning for invasive species management Improved exploration for reinforcement learn.pdf:pdf},
journal = {National Conference on Artificial Intelligence (AAAI)},
title = {{PAC optimal planning for invasive species management: Improved exploration for reinforcement learning from simulator-defined MDPs.}},
url = {http://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/download/6478/6850},
year = {2013}
}
@article{Allen2013a,
author = {Allen, Jenica M. and Leininger, Thomas J. and Hurd, James D. and Civco, Daniel L. and Gelfand, Alan E. and Silander, John A.},
doi = {10.1007/s10980-013-9916-7},
issn = {0921-2973},
journal = {Landscape Ecology},
keywords = {LULC change},
mendeley-tags = {LULC change},
month = {jul},
number = {9},
pages = {1671--1686},
title = {{Socioeconomics drive woody invasive plant richness in New England, USA through forest fragmentation}},
url = {http://link.springer.com/10.1007/s10980-013-9916-7},
volume = {28},
year = {2013}
}
@article{Bradley2010,
author = {Bradley, Bethany A. and Wilcove, David S. and Oppenheimer, Michael},
doi = {10.1007/s10530-009-9597-y},
issn = {1387-3547},
journal = {Biological Invasions},
keywords = {SLDs,invasion risk,invasives},
mendeley-tags = {SLDs,invasion risk,invasives},
month = {oct},
number = {6},
pages = {1855--1872},
title = {{Climate change increases risk of plant invasion in the Eastern United States}},
url = {http://link.springer.com/10.1007/s10530-009-9597-y},
volume = {12},
year = {2010}
}
@article{Westphan2003,
author = {Westphan, Michael I and Pickett, Marcus and Getz, Wayne M and Possingham, Hugh P},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Westphan et al. - 2003 - The Use of Stochastic Dynamic Programming in Optimal Landscape Reconstruction for Metapopulations.pdf:pdf},
journal = {Ecological Applications},
number = {2},
pages = {543--555},
title = {{The Use of Stochastic Dynamic Programming in Optimal Landscape Reconstruction for Metapopulations}},
volume = {13},
year = {2003}
}
@article{Wilcove1998,
abstract = {Habitat loss is the single greatest threat to biodiversity, followed by the spread of alien species},
author = {Wilcove, David S. and Rothstein, David and Dubow, Jason and Phillips, Ali and Losos, Elizabeth},
doi = {10.2307/1313420},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcove et al. - 1998 - Quantifying threats to imperiled species in the United States.pdf:pdf},
isbn = {0006-3568},
issn = {00063568},
journal = {BioScience},
number = {8},
pages = {607--615},
pmid = {3029},
title = {{Quantifying threats to imperiled species in the United States}},
volume = {48},
year = {1998}
}
@article{Ibanez2009,
author = {Ib{\'{a}}{\~{n}}ez, In{\'{e}}s and Silander, John A. and Wilson, Adam M. and LaFleur, Nancy and Tanaka, Nobuyuki and Tsuyama, Ikutaro},
doi = {10.1890/07-2095.1},
issn = {1051-0761},
journal = {Ecological Applications},
keywords = {SDM,climate change: bayes},
mendeley-tags = {SDM,climate change: bayes},
month = {mar},
number = {2},
pages = {359--375},
title = {{Multivariate forecasts of potential distributions of invasive plant species}},
url = {http://doi.wiley.com/10.1890/07-2095.1},
volume = {19},
year = {2009}
}
@article{Randin2006,
author = {Randin, Christophe F. and Dirnb{\"{o}}ck, Thomas and Dullinger, Stefan and Zimmermann, Niklaus E. and Zappa, Massimiliano and Guisan, Antoine},
doi = {10.1111/j.1365-2699.2006.01466.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Randin et al. - 2006 - Are niche-based species distribution models transferable in space.pdf:pdf},
issn = {0305-0270},
journal = {Journal of Biogeography},
keywords = {Austria,Switzerland,generality,generalized additive models (GAM),generalized linear models (GLM),geographical transferability,habitat distribution,model evaluation,predictions,spatial modelling},
month = {oct},
number = {10},
pages = {1689--1703},
publisher = {Blackwell Publishing Ltd},
title = {{Are niche-based species distribution models transferable in space?}},
url = {http://doi.wiley.com/10.1111/j.1365-2699.2006.01466.x},
volume = {33},
year = {2006}
}
@article{Bosci2016a,
author = {Bosci, Tierney and Allen, Jenica M. and Bellemare, Jesse and Kartesz, John and Nishino, Misako and Bradley, Bethany A.},
doi = {10.1111/ddi.12432},
journal = {Diversity and Distributions},
pages = {615--624},
title = {{Plants' native distributions do not reflect climatic tolerance}},
volume = {22},
year = {2016}
}
@article{Phillips2006,
abstract = {The availability of detailed environmental data, together with inexpensive and powerful computers, has fueled a rapid increase in predictive modeling of species environmental requirements and geographic distributions. For some species, detailed presence/absence occurrence data are available, allowing the use of a variety of standard statistical techniques. However, absence data are not available for most species. In this paper, we introduce the use of the maximum entropy method (Maxent) for modeling species geographic distributions with presence-only data. Maxent is a general-purpose machine learning method with a simple and precise mathematical formulation, and it has a number of aspects that make it well-suited for species distribution modeling. In order to investigate the efficacy of the method, here we perform a continental-scale case study using two Neotropical mammals: a lowland species of sloth, Bradypus variegatus, and a small montane murid rodent, Microryzomys minutus. We compared Maxent predictions with those of a commonly used presence-only modeling method, the Genetic Algorithm for Rule-Set Prediction (GARP). We made predictions on 10 random subsets of the occurrence records for both species, and then used the remaining localities for testing. Both algorithms provided reasonable estimates of the species' range, far superior to the shaded outline maps available in field guides. All models were significantly better than random in both binomial tests of omission and receiver operating characteristic (ROC) analyses. The area under the ROC curve (AUC) was almost always higher for Maxent, indicating better discrimination of suitable versus unsuitable areas for the species. The Maxent modeling approach can be used in its present form for many applications with presence-only datasets, and merits further research and development.},
author = {Phillips, Steven J. and Anderson, Robert P. and Schapire, Robert E.},
doi = {10.1016/j.ecolmodel.2005.03.026},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Anderson, Schapire - 2006 - Maximum entropy modeling of species geographic distributions.pdf:pdf},
issn = {03043800},
journal = {Ecological Modelling},
keywords = {Distribution,MaxEnt,Maximum entropy,Modeling,Niche,Range,SDMs},
mendeley-tags = {MaxEnt,SDMs},
month = {jan},
number = {3-4},
pages = {231--259},
title = {{Maximum entropy modeling of species geographic distributions}},
url = {http://www.sciencedirect.com/science/article/pii/S030438000500267X},
volume = {190},
year = {2006}
}
@article{Catling1994,
author = {Catling, Paul M. and Porebski, S. Z.},
journal = {The Canadian Field Naturalist},
pages = {305--310},
title = {{The history of invasion and current status of g...}},
url = {https://archive.org/stream/cbarchive{\_}108881{\_}thehistoryofinvasionandcurrent1919/thehistoryofinvasionandcurrent1919{\#}page/n3/mode/2up},
volume = {108},
year = {1994}
}
@article{Bradley2009,
author = {Bradley, BETHANY A. and Oppenheimer, MICHAEL and Wilcove, DAVID S.},
doi = {10.1111/j.1365-2486.2008.01824.x},
issn = {13541013},
journal = {Global Change Biology},
keywords = {conservation,invasives},
mendeley-tags = {conservation,invasives},
month = {jun},
number = {6},
pages = {1511--1521},
title = {{Climate change and plant invasions: restoration opportunities ahead?}},
url = {http://doi.wiley.com/10.1111/j.1365-2486.2008.01824.x},
volume = {15},
year = {2009}
}
@article{Wilson2007a,
author = {Wilson, John R. U. and Richardson, David M. and Rouget, Mathieu and Procheş, Şerban and Amis, Mao A. and Henderson, Lesley and Thuiller, Wilfried},
doi = {10.1111/j.1366-9516.2006.00302.x},
file = {:home/marek/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson et al. - 2007 - Residence time and potential range crucial considerations in modelling plant invasions.pdf:pdf},
issn = {13669516},
journal = {Diversity and Distributions},
keywords = {Biological invasions,South Africa.,invasive species,range size,rates of spread,residence time},
month = {jan},
number = {1},
pages = {11--22},
publisher = {Blackwell Publishing Ltd},
title = {{Residence time and potential range: crucial considerations in modelling plant invasions}},
url = {http://doi.wiley.com/10.1111/j.1366-9516.2006.00302.x},
volume = {13},
year = {2007}
}
@book{Ghavamzadeh2015,
	abstract = {Bayesian Reinforcement Learning: A Survey},
	archivePrefix = {arXiv},
	arxivId = {1405.4980},
	author = {Ghavamzadeh, Mohammed and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
	booktitle = {Foundations and Trends{\textregistered} in Machine Learning},
	doi = {10.1561/2200000049},
	eprint = {1405.4980},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1609.04436.pdf:pdf},
	isbn = {2200000049},
	issn = {1935-8237},
	number = {5-6},
	pages = {359--483},
	pmid = {18255791},
	title = {{Convex Optimization: Algorithms and Complexity}},
	url = {http://www.nowpublishers.com/article/Details/MAL-049},
	volume = {8},
	year = {2015}
}
@article{Satisfaction2013,
	author = {Zukui Li, Christodoulos A. Floudas},
	doi = {10.1021/ie201651s.A},
	file = {:E$\backslash$:/ML-Research/Papers/nihms372641.pdf:pdf},
	keywords = {conservatism,probability bounds,probability distribution,robust optimization,tightness},
	number = {19},
	pages = {6769--6788},
	title = {{A Comparative Theoretical and Computational Study on Robust Counterpart Optimization: II. Probabilistic Guarantees on Constraint Satisfaction}},
	volume = {51},
	year = {2013}
}
@article{Engineering2008,
	author = {Katrien R., Gerrit K.},
	doi = {10.1504/EJIE.2008.018441},
	file = {:E$\backslash$:/ML-Research/Papers/EJIE{\_}R-021-06.pdf:pdf},
	number = {May 2014},
	title = {{On the choice of a demand distribution for inventory management models}},
	year = {2008}
}
@book{Puterman2005,
	author = {Puterman, Martin L},
	file = {:C$\backslash$:/Users/Reazul Hasan Russel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman - 2005 - Markov decision processes Discrete stochastic dynamic programming.pdf:pdf},
	publisher = {John Wiley {\&} Sons, Inc.},
	title = {{Markov decision processes: Discrete stochastic dynamic programming}},
	year = {2005}
}
@book{Eugene2002,
	author = {Eugene A. Feinberg, Adam Shwartz},
	file = {:C$\backslash$:/Users/Reazul Hasan Russel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman - 2005 - Markov decision processes Discrete stochastic dynamic programming.pdf:pdf},
	publisher = {Springer US},
	title = {{Handbook of Markov Decision Processes}},
	year = {2002}
}
@article{Kalyanasundaram2002,
	author = {Kalyanasundaram, Suresh and Shroff, Ness B},
	file = {:E$\backslash$:/ML-Research/Papers/Markov Decision Processes with Uncertain Transition Rates Sensitivity and robust control.pdf:pdf},
	isbn = {0780375165},
	number = {December},
	pages = {3799--3804},
	title = {{Markov Decision Processes with Uncertain Transition Rates : Sensitivity and Robust Control}},
	year = {2002}
}
@article{Ding2004,
	author = {Ding, Chris},
	file = {:E$\backslash$:/ML-Research/Papers/KmeansCluesteringViaPCA.pdf:pdf},
	title = {{K -means Clustering via Principal Component Analysis}},
	year = {2004}
}
@article{Carlier2016,
	abstract = {We propose a notion of conditional vector quantile function and a vector quantile regression. A $\backslash$emph{\{}conditional vector quantile function{\}} (CVQF) of a random vector {\$}Y{\$}, taking values in {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$} given covariates {\$}Z=z{\$}, taking values in {\$}\backslashmathbb{\{}R{\}}{\%} {\^{}}k{\$}, is a map {\$}u \backslashlongmapsto Q{\_}{\{}Y\backslashmid Z{\}}(u,z){\$}, which is monotone, in the sense of being a gradient of a convex function, and such that given that vector {\$}U{\$} follows a reference non-atomic distribution {\$}F{\_}U{\$}, for instance uniform distribution on a unit cube in {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$}, the random vector {\$}Q{\_}{\{}Y\backslashmid Z{\}}(U,z){\$} has the distribution of {\$}Y{\$} conditional on {\$}Z=z{\$}. Moreover, we have a strong representation, {\$}Y = Q{\_}{\{}Y\backslashmid Z{\}}(U,Z){\$} almost surely, for some version of {\$}U{\$}. The $\backslash$emph{\{}vector quantile regression{\}} (VQR) is a linear model for CVQF of {\$}Y{\$} given {\$}Z{\$}. Under correct specification, the notion produces strong representation, {\$}Y=\backslashbeta \backslashleft(U\backslashright) {\^{}}\backslashtop f(Z){\$}, for {\$}f(Z){\$} denoting a known set of transformations of {\$}Z{\$}, where {\$}u \backslashlongmapsto \backslashbeta(u){\^{}}\backslashtop f(Z){\$} is a monotone map, the gradient of a convex function, and the quantile regression coefficients {\$}u \backslashlongmapsto \backslashbeta(u){\$} have the interpretations analogous to that of the standard scalar quantile regression. As {\$}f(Z){\$} becomes a richer class of transformations of {\$}Z{\$}, the model becomes nonparametric, as in series modelling. A key property of VQR is the embedding of the classical Monge-Kantorovich's optimal transportation problem at its core as a special case. In the classical case, where {\$}Y{\$} is scalar, VQR reduces to a version of the classical QR, and CVQF reduces to the scalar conditional quantile function. An application to multiple Engel curve estimation is considered.},
	archivePrefix = {arXiv},
	arxivId = {1406.4643},
	author = {Carlier, Guillaume and Chernozhukov, Victor and Galichon, Alfred},
	doi = {10.1214/15-AOS1401},
	eprint = {1406.4643},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/euclid.aos.1460381690.pdf:pdf},
	issn = {00905364},
	journal = {Annals of Statistics},
	keywords = {Monge-Kantorovich-Brenier,Vector conditional quantile function,Vector quantile regression},
	number = {3},
	pages = {1165--1192},
	title = {{Vector quantile regression: An optimal transport approach}},
	volume = {44},
	year = {2016}
}
@article{Taleghan2015,
	abstract = {In a simulator-defined MDP, the Markovian dynamics and rewards are provided in the form of a simulator from which samples can be drawn. This paper studies MDP planning algorithms that attempt to minimize the number of simulator calls before terminating and outputting a policy that is approximately optimal with high probability. The paper introduces two heuristics for efficient exploration and an improved confidence interval that enables earlier termination with probabilis- tic guarantees. We prove that the heuristics and the confidence interval are sound and produce with high probability an approximately optimal policy in polynomial time. Experiments on two benchmark problems and two instances of an invasive species management problem show that the improved confidence intervals and the new search heuristics yield reductions of between 8{\%} and 47{\%} in the number of simulator calls required to reach near-optimal policies.},
	author = {Taleghan, Majid Alkaee and Dietterich, Thomas G. and Crowley, Mark and Hall, Kim and Albers, H. Jo},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/taleghan15a.pdf:pdf},
	issn = {15337928},
	journal = {Journal of Machine Learning Research},
	keywords = {Good- Turing estimate,MDP planning,Markov decision processes,invasive species management,reinforcement learning},
	pages = {3877--3903},
	title = {{PAC Optimal MDP Planning with Application to Invasive Species Management}},
	url = {http://jmlr.org/papers/v16/taleghan15a.html},
	volume = {16},
	year = {2015}
}
@article{Kong2012,
	abstract = {The use of quantiles to obtain insights about multivariate data is addressed. It is argued that incisive insights can be obtained by considering directional quantiles, the quantiles of projections. Directional quantile envelopes are proposed as a way to condense this kind of information; it is demonstrated that they are essentially halfspace (Tukey) depth levels sets, coinciding for elliptic distributions (in particular multivariate normal) with density contours. Relevant questions concerning their indexing, the possibility of the reverse retrieval of directional quantile information, invariance with respect to affine transformations, and approximation/asymptotic properties are studied. It is argued that the analysis in terms of directional quantiles and their envelopes offers a straightforward probabilistic interpretation and thus conveys a concrete quantitative meaning; the directional definition can be adapted to elaborate frameworks, like estimation of extreme quantiles and directional quantile regression, the regression of depth contours on covariates. The latter facilitates the construction of multivariate growth charts---the question that motivated all the development.},
	archivePrefix = {arXiv},
	arxivId = {0805.0056},
	author = {Kong, Linglong and Mizera, Ivan},
	doi = {10.5705/ss.2010.224},
	eprint = {0805.0056},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/0805.0056.pdf:pdf},
	issn = {10170405},
	journal = {Statistica Sinica},
	keywords = {and phrases,data depth,growth charts,quantile regression,quantiles},
	number = {2000},
	pages = {1--23},
	title = {{Quantile tomography: using quantiles with multivariate data}},
	url = {http://www3.stat.sinica.edu.tw/statistica/j22n4/J22N410/J22N410.html},
	year = {2012}
}
@article{Bertsimas2007,
	author = {Bertsimas, Dimitris and Brown, David B},
	keywords = {coherent risk measures,robust optimization,spectral risk measures,uncertainty sets},
	pages = {1--25},
	title = {{Constructing uncertainty sets for robust linear optimization}},
	year = {2007}
}
@article{Xu2008,
	abstract = {One of the central issues in learning to rank for information retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in information retrieval such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG). Several such algorithms including SVMmap and AdaRank have been proposed and their effectiveness has been verified. However, the relationships between the algorithms are not clear, and furthermore no comparisons have been conducted between them. In this paper, we conduct a study on the approach of directly optimizing evaluation measures in learning to rank for Information Retrieval (IR). We focus on the methods that minimize loss functions upper bounding the basic loss function defined on the IR measures. We first provide a general framework for the study and analyze the existing algorithms of SVMmap and AdaRank within the framework. The framework is based on upper bound analysis and two types of upper bounds are discussed. Moreover, we show that we can derive new algorithms on the basis of this analysis and create one example algorithm called PermuRank. We have also conducted comparisons between SVMmap, AdaRank, PermuRank, and conventional methods of Ranking SVM and RankBoost, using benchmark datasets. Experimental results show that the methods based on direct optimization of evaluation measures can always outperform conventional methods of Ranking SVM and RankBoost. However, no significant difference exists among the performances of the direct optimization methods themselves.},
	author = {Xu, Jun and Liu, T Y and Lu, Min and Xu, Jun and Lu, Min and Ma, Wei-Ying and Li, Hang and Li, Hang and Ma, W Y and Liu, Tie-Yan},
	doi = {10.1145/1390334.1390355},
	isbn = {978-1-60558-164-4},
	journal = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
	keywords = {all or part of,evaluation measure,information retrieval,is granted without fee,learning to rank,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
	number = {49},
	pages = {107--114},
	title = {{Directly optimizing evaluation measures in learning to rank}},
	url = {http://portal.acm.org/citation.cfm?id=1390334.1390355},
	year = {2008}
}
@article{Ball1997,
	author = {Ball, Keith},
	pages = {1--58},
	title = {{An Elementary Introduction to Modern Convex Geometry}},
	volume = {31},
	year = {1997}
}
@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	doi = {10.1038/nature14236},
	issn = {0028-0836},
	journal = {Nature},
	number = {7540},
	pages = {529--533},
	publisher = {Nature Publishing Group},
	title = {learning},
	url = {http://dx.doi.org/10.1038/nature14236},
	volume = {518},
	year = {2015}
}
@book{Chains,
	author = {Chains, Finite Markov},
	isbn = {3540901922},
	title = {{Finite Markov Chains}},
	volume = {40}
}
@misc{,
	title = {lrt{\{}{\_}{\}}framework}
}
@article{Sahni2007,
	author = {Sahni, Saurabh},
	journal = {Information Retrieval},
	title = {{Information Retrieval in Resource Constrained Environments}},
	year = {2007}
}
@article{Lovsjo,
	author = {Lovsj{\"{o}}, Niclas},
	title = {{From Markov chains to Markov decision processes Matematiska institutionen}}
}
@book{Optimization,
	author = {Optimization, Robust},
	isbn = {9780691143682},
	title = {{Robust Optimization}}
}
@article{Kuo2009,
	abstract = {Ranking is a key problem in many information retrieval (IR) applications, such as document retrieval and collaborative filtering. In this paper, we address the issue of learning to rank in document retrieval. Learning-based methods, such as RankNet, RankSVM, and RankBoost, try to create ranking functions automatically by using some training data. Recently, several learning to rank methods have been proposed to directly optimize the performance of IR applications in terms of various evaluation measures. They undoubtedly provide statistically significant improvements over conventional methods; however, from the viewpoint of decision-making, most of them do not minimize the Bayes risk of the IR system. In an attempt to fill this research gap, we propose a novel framework that directly optimizes the Bayes risk related to the ranking accuracy in terms of the IR evaluation measures. The results of experiments on the LETOR collections demonstrate that the framework outperforms several existing methods in most cases. Copyright 2009 ACM.},
	author = {Kuo, Jen-Wei and Cheng, Pu-Jen and Wang, Hsin-Min},
	doi = {10.1145/1645953.1646058},
	isbn = {9781605585123},
	issn = {1605585122},
	journal = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
	keywords = {learning to rank,ranking function},
	pages = {827},
	title = {{Learning to rank from Bayesian decision inference}},
	url = {http://portal.acm.org/citation.cfm?doid=1645953.1646058},
	year = {2009}
}
@article{He2008,
	abstract = {Ranking is the key problem for information retrieval and other text applications. Recently, the ranking methods based on machine learning approaches, called learning to rank, become the focus for researchers and practitioners. The main idea of these methods is to apply the various existing and effective algorithms on machine learning to ranking. However, as a learning problem, ranking is different from other classical ones such as classification and regression. In this paper, we investigate the important papers in this direction; the cons and pros of the recent-proposed framework and algorithms for ranking are analyzed, and the relationships among them are discussed. Finally, the promising directions in practice are also pointed out.},
	author = {He, Chuan and Wanq, Cong and Zhonq, Yi Xin and Li, Rui Fan},
	doi = {10.1109/ICMLC.2008.4620685},
	isbn = {9781424420964},
	journal = {Proceedings of the 7th International Conference on Machine Learning and Cybernetics, ICMLC},
	keywords = {Evaluation,Information retrieval support vector machine,Learning to rank,Ordinal regression,Ranking},
	number = {July},
	pages = {1734--1739},
	title = {{A survey on learning to rank}},
	volume = {3},
	year = {2008}
}
@article{Sutton2016,
	author = {Sutton, Richard S and Barto, Andrew G},
	title = {{Reinforcement Learning : An Introduction **** Draft ****}},
	year = {2016}
}
@article{,
	number = {1},
	pages = {1--7},
	title = {{Solution Structure for L 1 Uncertainty}}
}
@article{Phophalia2011a,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	number = {December 2011},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Ferns,
	author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
	keywords = {1,60j05,68t37,7,90c40,93e20,ams subject classifications,bisimulation,continuous,formalism for describ-,introduction,markov decision process,markov decision processes,mdps,metrics,offer a popular mathematical,planning and learning in,reinforcement learning,the presence of uncertainty,they are a standard,tool for},
	number = {1999},
	pages = {258--273},
	title = {{BISIMULATION METRICS FOR CONTINUOUS MARKOV DECISION}}
}
@article{Jernigan2003,
	abstract = {The chi-squared test of Markov chain lumpability is shown to operate reliably under a corrected derivation of the degrees of freedom. The test is used to screen out lumping schemes that corrupt the Markov property and give rise to higher order dependence. ?? 2003 Elsevier B.V. All rights reserved.},
	author = {Jernigan, Robert W and Baran, Robert H},
	doi = {10.1016/S0167-7152(03)00126-3},
	issn = {01677152},
	journal = {Statistics and Probability Letters},
	keywords = {Chi-squared tests,Lumpability,Markov chain,Time series},
	number = {1},
	pages = {17--23},
	title = {{Testing lumpability in Markov chains}},
	volume = {64},
	year = {2003}
}
@article{Jernigan2003,
	abstract = {The chi-squared test of Markov chain lumpability is shown to operate reliably under a corrected derivation of the degrees of freedom. The test is used to screen out lumping schemes that corrupt the Markov property and give rise to higher order dependence. ?? 2003 Elsevier B.V. All rights reserved.},
	author = {Jernigan, Robert W and Baran, Robert H},
	doi = {10.1016/S0167-7152(03)00126-3},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1-s2.0-S0167715203001263-main.pdf:pdf},
	issn = {01677152},
	journal = {Statistics and Probability Letters},
	keywords = {Chi-squared tests,Lumpability,Markov chain,Time series},
	number = {1},
	pages = {17--23},
	title = {{Testing lumpability in Markov chains}},
	volume = {64},
	year = {2003}
}
@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	doi = {10.1038/nature14236},
	issn = {0028-0836},
	journal = {Nature},
	number = {7540},
	pages = {529--533},
	publisher = {Nature Publishing Group},
	title = {learning},
	url = {http://dx.doi.org/10.1038/nature14236},
	volume = {518},
	year = {2015}
}
@article{Petrik2016,
	author = {Petrik, Marek},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Petrik2016b.pdf:pdf},
	number = {Nips},
	title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
	year = {2016}
}
@article{Doran2009,
	author = {Doran, Christine},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doran - 2009 - ACL-IJCNLP 2009 Handbook.pdf:pdf},
	journal = {Presentations},
	title = {{ACL-IJCNLP 2009 Handbook}},
	year = {2009}
}
@article{Gorissen2014,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1501.02634v1},
	author = {Gorissen, Bram L and Yanıkoğlu, Ihsan and Hertog, Dick Den},
	doi = {10.1016/j.omega.2014.12.006.)},
	eprint = {arXiv:1501.02634v1},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1501.02634.pdf:pdf},
	number = {Soyster 1973},
	title = {{A Practical Guide to Robust Optimization}},
	year = {2014}
}
@article{Lu2010,
	author = {Lu, Tyler and P{\'{a}}l, D{\'{a}}vid and P{\'{a}}l, Martin},
	issn = {15324435},
	journal = {International Conference on Artificial Intelligence and Statistics},
	pages = {485--492},
	title = {{Contextual multi-armed bandits}},
	volume = {9},
	year = {2010}
}
@article{Ball1997,
	author = {Ball, Keith},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/ball.pdf:pdf},
	pages = {1--58},
	title = {{An Elementary Introduction to Modern Convex Geometry}},
	volume = {31},
	year = {1997}
}
@article{Ferns,
	author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/siamFP11.pdf:pdf},
	keywords = {1,60j05,68t37,7,90c40,93e20,ams subject classifications,bisimulation,continuous,formalism for describ-,introduction,markov decision process,markov decision processes,mdps,metrics,offer a popular mathematical,planning and learning in,reinforcement learning,the presence of uncertainty,they are a standard,tool for},
	number = {1999},
	pages = {258--273},
	title = {{BISIMULATION METRICS FOR CONTINUOUS MARKOV DECISION}}
}
@article{Gorissen2014,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1501.02634v1},
	author = {Gorissen, Bram L and Yanıkoğlu, Ihsan and Hertog, Dick Den},
	doi = {10.1016/j.omega.2014.12.006.)},
	eprint = {arXiv:1501.02634v1},
	number = {Soyster 1973},
	title = {{A Practical Guide to Robust Optimization}},
	year = {2014}
}
@article{Petrik2016,
	author = {Petrik, Marek},
	number = {Nips},
	title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
	year = {2016}
}
@article{Instructor2009,
	author = {Instructor, Combinatorial Optimization and Lecture, Chandra Chekuri and Im, Sungjin},
	title = {{1 Polyhedra and Linear Programming}},
	year = {2009}
}
@book{Optimizationa,
	author = {Optimization, Convex},
	isbn = {9780521833783},
	title = {{Convex Optimization}}
}
@article{Phillips2006,
	abstract = {The availability of detailed environmental data, together with inexpensive and powerful computers, has fueled a rapid increase in predictive modeling of species environmental requirements and geographic distributions. For some species, detailed presence/absence occurrence data are available, allowing the use of a variety of standard statistical techniques. However, absence data are not available for most species. In this paper, we introduce the use of the maximum entropy method (Maxent) for modeling species geographic distributions with presence-only data. Maxent is a general-purpose machine learning method with a simple and precise mathematical formulation, and it has a number of aspects that make it well-suited for species distribution modeling. In order to investigate the efficacy of the method, here we perform a continental-scale case study using two Neotropical mammals: a lowland species of sloth, Bradypus variegatus, and a small montane murid rodent, Microryzomys minutus. We compared Maxent predictions with those of a commonly used presence-only modeling method, the Genetic Algorithm for Rule-Set Prediction (GARP). We made predictions on 10 random subsets of the occurrence records for both species, and then used the remaining localities for testing. Both algorithms provided reasonable estimates of the species' range, far superior to the shaded outline maps available in field guides. All models were significantly better than random in both binomial tests of omission and receiver operating characteristic (ROC) analyses. The area under the ROC curve (AUC) was almost always higher for Maxent, indicating better discrimination of suitable versus unsuitable areas for the species. The Maxent modeling approach can be used in its present form for many applications with presence-only datasets, and merits further research and development.},
	author = {Phillips, Steven J. and Anderson, Robert P. and Schapire, Robert E.},
	doi = {10.1016/j.ecolmodel.2005.03.026},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Anderson, Schapire - 2006 - Maximum entropy modeling of species geographic distributions.pdf:pdf},
	issn = {03043800},
	journal = {Ecological Modelling},
	keywords = {Distribution,MaxEnt,Maximum entropy,Modeling,Niche,Range,SDMs},
	mendeley-tags = {MaxEnt,SDMs},
	month = {jan},
	number = {3-4},
	pages = {231--259},
	title = {{Maximum entropy modeling of species geographic distributions}},
	url = {http://www.sciencedirect.com/science/article/pii/S030438000500267X},
	volume = {190},
	year = {2006}
}
@article{Doran2009,
	author = {Doran, Christine},
	journal = {Presentations},
	title = {{ACL-IJCNLP 2009 Handbook}},
	year = {2009}
}
@article{Hasselt,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1509.06461v3},
	author = {Hasselt, Hado Van and Guez, Arthur and Silver, David},
	eprint = {arXiv:1509.06461v3},
	title = {{Deep Reinforcement Learning with Double Q-learning}}
}
@article{Hanasusanto,
	author = {Hanasusanto, Grani A and Kuhn, Daniel},
	pages = {1--9},
	title = {{Robust Data-Driven Dynamic Programming}}
}
@book{Chains,
	author = {Chains, Finite Markov},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Kemeny-Snell1976.pdf:pdf},
	isbn = {3540901922},
	title = {{Finite Markov Chains}},
	volume = {40}
}
@article{,
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/robustrectangular{\_}l1.pdf:pdf},
	number = {1},
	pages = {1--7},
	title = {{Solution Structure for L 1 Uncertainty}}
}
@article{,
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/AIMMS3OM{\_}LinearProgrammingTricks.pdf:pdf},
	journal = {Technology},
	title = {{AIMMS Modeling Guide - Integer Programming Tricks This file contains only one chapter of the book . For a free download of the complete book in pdf format , please visit www.aimms.com or order your hard-}}
}
@article{Hasselt,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1509.06461v3},
	author = {Hasselt, Hado Van and Guez, Arthur and Silver, David},
	eprint = {arXiv:1509.06461v3},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1509.06461.pdf:pdf},
	title = {{Deep Reinforcement Learning with Double Q-learning}}
}
@article{Sutton2016,
	author = {Sutton, Richard S and Barto, Andrew G},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Sutton, Barto - 2016 - Reinforcement Learning An Introduction.pdf:pdf},
	title = {{Reinforcement Learning : An Introduction **** Draft ****}},
	year = {2016}
}
@article{Lovsjo,
	author = {Lovsj{\"{o}}, Niclas},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/2015{\_}05{\_}report.pdf:pdf},
	title = {{From Markov chains to Markov decision processes Matematiska institutionen}}
}
@article{Bertsimas2007,
	author = {Bertsimas, Dimitris and Brown, David B},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/5d83b565b9351cdc36b248cde6730dfeaaaf.pdf:pdf},
	keywords = {coherent risk measures,robust optimization,spectral risk measures,uncertainty sets},
	pages = {1--25},
	title = {{Constructing uncertainty sets for robust linear optimization}},
	year = {2007}
}
@article{Sahni2007,
	author = {Sahni, Saurabh},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahni - 2007 - Information Retrieval in Resource Constrained Environments.pdf:pdf},
	journal = {Information Retrieval},
	title = {{Information Retrieval in Resource Constrained Environments}},
	year = {2007}
}
@book{Optimization,
	author = {Optimization, Robust},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/FullBookDec11.pdf:pdf},
	isbn = {9780691143682},
	title = {{Robust Optimization}}
}
@article{Jarvelin2000,
	abstract = {This paper proposes evaluation methods based on the use of non-dichotomous relevance judgements in IR experiments. It is argued that evaluation methods should credit IR methods for their ability to retrieve highly relevant documents. This is de- sirable from the user point of view in modem large IR envi- ronments. The proposed methods are (1) a novel application of P-R curves and average precision computations based on sepa- rate recall bases for documents of different degrees of rele- vance, and (2) two novel measures computing the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. We then demonstrate the use of these evaluation methods in a case study on the effectiveness of query types, based on combinations of query structures and expansion, in retrieving documents of various degrees of rele- vance. The test was run with a best match retrieval system (In- Query I) in a text database consisting of newspaper articles. The results indicate that the tested strong query structures are most effective in retrieving highly relevant documents. The differ- ences between the query types are practically essential and statistically significant. More generally, the novel evaluation methods and the case demonstrate that non-dichotomous rele- vance assessments are applicable in IR experiments, may reveal interesting phenomena, and allow harder testing of IR methods.},
	author = {J{\"{a}}rvelin, Kalervo and Kek{\"{a}}l{\"{a}}inen, Jaana},
	doi = {10.1145/345508.345545},
	isbn = {1581132263},
	issn = {01635840 (ISSN)},
	journal = {Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval - SIGIR '00},
	pages = {41--48},
	title = {{IR evaluation methods for retrieving highly relevant documents}},
	url = {http://dl.acm.org/citation.cfm?id=345508.345545},
	year = {2000}
}
@article{Instructor2009,
	author = {Instructor, Combinatorial Optimization and Lecture, Chandra Chekuri and Im, Sungjin},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Polyhedra and Linear Programming.pdf:pdf},
	title = {{1 Polyhedra and Linear Programming}},
	year = {2009}
}
@article{Xu2008,
	abstract = {One of the central issues in learning to rank for information retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in information retrieval such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG). Several such algorithms including SVMmap and AdaRank have been proposed and their effectiveness has been verified. However, the relationships between the algorithms are not clear, and furthermore no comparisons have been conducted between them. In this paper, we conduct a study on the approach of directly optimizing evaluation measures in learning to rank for Information Retrieval (IR). We focus on the methods that minimize loss functions upper bounding the basic loss function defined on the IR measures. We first provide a general framework for the study and analyze the existing algorithms of SVMmap and AdaRank within the framework. The framework is based on upper bound analysis and two types of upper bounds are discussed. Moreover, we show that we can derive new algorithms on the basis of this analysis and create one example algorithm called PermuRank. We have also conducted comparisons between SVMmap, AdaRank, PermuRank, and conventional methods of Ranking SVM and RankBoost, using benchmark datasets. Experimental results show that the methods based on direct optimization of evaluation measures can always outperform conventional methods of Ranking SVM and RankBoost. However, no significant difference exists among the performances of the direct optimization methods themselves.},
	author = {Xu, Jun and Liu, T Y and Lu, Min and Xu, Jun and Lu, Min and Ma, Wei-Ying and Li, Hang and Li, Hang and Ma, W Y and Liu, Tie-Yan},
	doi = {10.1145/1390334.1390355},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2008 - Directly optimizing evaluation measures in learning to rank.pdf:pdf},
	isbn = {978-1-60558-164-4},
	journal = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
	keywords = {all or part of,evaluation measure,information retrieval,is granted without fee,learning to rank,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
	number = {49},
	pages = {107--114},
	title = {{Directly optimizing evaluation measures in learning to rank}},
	url = {http://portal.acm.org/citation.cfm?id=1390334.1390355},
	year = {2008}
}
@article{Hanasusanto,
	author = {Hanasusanto, Grani A and Kuhn, Daniel},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/NIPS2013{\_}5123.pdf:pdf},
	pages = {1--9},
	title = {{Robust Data-Driven Dynamic Programming}}
}
@book{Optimizationa,
	author = {Optimization, Convex},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/bv{\_}cvxbook.pdf:pdf},
	isbn = {9780521833783},
	title = {{Convex Optimization}}
}
@article{Kuo2009,
	abstract = {Ranking is a key problem in many information retrieval (IR) applications, such as document retrieval and collaborative filtering. In this paper, we address the issue of learning to rank in document retrieval. Learning-based methods, such as RankNet, RankSVM, and RankBoost, try to create ranking functions automatically by using some training data. Recently, several learning to rank methods have been proposed to directly optimize the performance of IR applications in terms of various evaluation measures. They undoubtedly provide statistically significant improvements over conventional methods; however, from the viewpoint of decision-making, most of them do not minimize the Bayes risk of the IR system. In an attempt to fill this research gap, we propose a novel framework that directly optimizes the Bayes risk related to the ranking accuracy in terms of the IR evaluation measures. The results of experiments on the LETOR collections demonstrate that the framework outperforms several existing methods in most cases. Copyright 2009 ACM.},
	author = {Kuo, Jen-Wei and Cheng, Pu-Jen and Wang, Hsin-Min},
	doi = {10.1145/1645953.1646058},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo, Cheng, Wang - 2009 - Learning to rank from Bayesian decision inference.pdf:pdf},
	isbn = {9781605585123},
	issn = {1605585122},
	journal = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
	keywords = {learning to rank,ranking function},
	pages = {827},
	title = {{Learning to rank from Bayesian decision inference}},
	url = {http://portal.acm.org/citation.cfm?doid=1645953.1646058},
	year = {2009}
}
@article{GurobiOptimization2014,
	author = {{Gurobi Optimization}, Inc.},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Gurobi{\_}quickstart{\_}windows.pdf:pdf},
	title = {{Gurobi optimizer quick start guide}},
	url = {http://www.gurobi.com/documentation/5.6/quick-start-guide/quickstart.pdf},
	year = {2014}
}
@misc{,
	title = {lrt{\{}{\_}{\}}framework}
}
@article{Phophalia2011,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	pages = {8--10},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Candes2007,
	abstract = {It is now well understood that (1) it is possible to reconstruct sparse signals exactly from what appear to be highly incomplete sets of linear measurements and (2) that this can be done by constrained L1 minimization. In this paper, we study a novel method for sparse signal recovery that in many situations outperforms L1 minimization in the sense that substantially fewer measurements are needed for exact recovery. The algorithm consists of solving a sequence of weighted L1-minimization problems where the weights used for the next iteration are computed from the value of the current solution. We present a series of experiments demonstrating the remarkable performance and broad applicability of this algorithm in the areas of sparse signal recovery, statistical estimation, error correction and image processing. Interestingly, superior gains are also achieved when our method is applied to recover signals with assumed near-sparsity in overcomplete representations--not by reweighting the L1 norm of the coefficient sequence as is common, but by reweighting the L1 norm of the transformed object. An immediate consequence is the possibility of highly efficient data acquisition protocols by improving on a technique known as compressed sensing.},
	archivePrefix = {arXiv},
	arxivId = {0711.1612},
	author = {Candes, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
	doi = {10.1007/s00041-008-9045-x},
	eprint = {0711.1612},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/s00041-008-9045-x.pdf:pdf},
	isbn = {1069-5869},
	issn = {1069-5869},
	keywords = {1 -minimization,compressive sensing,dantzig selector,focuss,iterative reweighting,linear equations,sparsity,underdetermined systems of},
	pages = {877--905},
	pmid = {19110489},
	title = {{Enhancing Sparsity by Reweighted L1 Minimization}},
	url = {http://arxiv.org/abs/0711.1612},
	year = {2007}
}
@article{Gross2016,
	archivePrefix = {arXiv},
	arxivId = {15334406},
	author = {Gross, James J},
	doi = {10.1177/0963721414541462.Self-Control},
	eprint = {15334406},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/nihms537830.pdf:pdf},
	isbn = {0000000000000},
	issn = {1527-5418},
	keywords = {achievement,another is,but even people who,grit,have comparable levels of,more successful than others,motivation,one obvious answer is,opportunity,self-control,talent,talent and opportunity often,volition,why are some people},
	number = {5},
	pages = {352--359},
	pmid = {24655651},
	title = {{HHS Public Access}},
	volume = {34},
	year = {2016}
}
@article{Szepesvari2010,
	abstract = {Reinforcement learning is a learning paradigm concerned with learning to control a system so as to maximize a numerical performance measure that expresses a long-term objective.What distin- guishes reinforcement learning from supervised learning is that only partial feedback is given to the learner about the learner's predictions. Further, the predictions may have long term effects through influencing the future state of the controlled system. Thus, time plays a special role. The goal in reinforcement learning is to develop efficient learning algorithms, as well as to understand the al- gorithms' merits and limitations. Reinforcement learning is of great interest because of the large number of practical applications that it can be used to address, ranging from problems in artificial intelligence to operations research or control engineering. In this book,we focus on those algorithms of reinforcement learning that build on the powerful theory of dynamic programming.We give a fairly comprehensive catalog of learning problems, describe the core ideas, note a large number of state of the art algorithms, followed by the discussion of their theoretical properties and limitations.},
	author = {Szepesv{\'{a}}ri, Csaba and Bartok, Gabor},
	doi = {10.2200/S00268ED1V01Y201005AIM009},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/RLAlgsInMDPs.pdf:pdf},
	isbn = {9781608454921},
	issn = {1939-4608},
	journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	number = {x},
	pages = {1--103},
	title = {{Algorithms for Reinforcement Learning (Errata)}},
	volume = {4},
	year = {2010}
}
@article{Ahmed2017,
	author = {Ahmed, Asrar and Jaillet, Patrick},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/SamplingBasedApproachesForMinimizingRegretInUncertainMDP.pdf:pdf},
	pages = {229--264},
	title = {{Sampling Based Approaches for Minimizing Regret in Uncertain Markov Decision Processes ( MDPs )}},
	volume = {59},
	year = {2017}
}
@misc{Berthomieu1983,
	abstract = {This paper is concerned with specifying and proving correct systems in which time appears as a parameter. We model such systems via Merlin's Time Petri Nets. An enumerative analysis technique is introduced for these nets based on the computation of a set of state classes and a reachability relation on the set. State classes are de ned in the text and an algorithm is provided for their enumeration. This enumerative approach allows us to derive a nite representation of their behavior for a large family of Time Petri Nets. The analysis method is illustrated by the analysis of a communication protocol},
	archivePrefix = {arXiv},
	arxivId = {arXiv:0912.0827v5},
	author = {Berthomieu, B. and Menasche, M.},
	booktitle = {Proceedings IFIP},
	doi = {10.1007/3-540-45014-9},
	eprint = {arXiv:0912.0827v5},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/10.1.1.470.9161.pdf:pdf},
	isbn = {0-9695338-5-3},
	issn = {0010-4485},
	pages = {41--46},
	pmid = {12185262},
	title = {{An enumerative approach for analyzing time Petri nets}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.4063},
	year = {1983}
}
@article{Antonov2013,
	author = {Antonov, Anton},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Quantile regression through linear programming.pdf:pdf},
	pages = {1--21},
	title = {{Quantile regression through linear programming}},
	year = {2013}
}
@article{MaxJaderbergVolodymyrMnihWojciechMarianCzarneckiTomSchaulJoelZLeibo2016,
	abstract = {Deep reinforcement learning agents have achieved state-of-the-art results by directly maximising cumulative reward. However, environments contain a much wider variety of possible training signals. In this paper, we introduce an agent that also maximises many other pseudo-reward functions simultaneously by reinforcement learning. All of these tasks share a common representation that, like unsupervised learning, continues to develop in the absence of extrinsic rewards. We also introduce a novel mechanism for focusing this representation upon extrinsic rewards, so that learning can rapidly adapt to the most relevant aspects of the actual task. Our agent significantly outperforms the previous state-of-the- art on Atari, averaging 880{\%} expert human performance, and a challenging suite of first-person, three-dimensional Labyrinth tasks leading to a mean speedup in learning of 10× and averaging 87{\%} expert human performance on Labyrinth.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1509.03044v2},
	author = {{Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki Tom Schaul, Joel Z Leibo}, David Silver {\&} Koray Kavukcuoglu},
	doi = {10.1051/0004-6361/201527329},
	eprint = {arXiv:1509.03044v2},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1611.05397.pdf:pdf},
	isbn = {2004012439},
	issn = {0004-6361},
	journal = {arXiv},
	pages = {1--11},
	pmid = {23459267},
	title = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},
	year = {2016}
}
@book{Optimization,
	author = {Optimization, Robust},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/FullBookDec11.pdf:pdf},
	isbn = {9780691143682},
	title = {{Robust Optimization}}
}
@article{Instructor2009,
	author = {Instructor, Combinatorial Optimization and Lecture, Chandra Chekuri and Im, Sungjin},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Polyhedra and Linear Programming.pdf:pdf},
	title = {{1 Polyhedra and Linear Programming}},
	year = {2009}
}
@article{Lovsjo,
	author = {Lovsj{\"{o}}, Niclas},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/2015{\_}05{\_}report.pdf:pdf},
	title = {{From Markov chains to Markov decision processes Matematiska institutionen}}
}
@book{Optimizationa,
	author = {Optimization, Convex},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/bv{\_}cvxbook.pdf:pdf},
	isbn = {9780521833783},
	title = {{Convex Optimization}}
}
@article{Jernigan2003,
	abstract = {The chi-squared test of Markov chain lumpability is shown to operate reliably under a corrected derivation of the degrees of freedom. The test is used to screen out lumping schemes that corrupt the Markov property and give rise to higher order dependence. ?? 2003 Elsevier B.V. All rights reserved.},
	author = {Jernigan, Robert W. and Baran, Robert H.},
	doi = {10.1016/S0167-7152(03)00126-3},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1-s2.0-S0167715203001263-main.pdf:pdf},
	issn = {01677152},
	journal = {Statistics and Probability Letters},
	keywords = {Chi-squared tests,Lumpability,Markov chain,Time series},
	number = {1},
	pages = {17--23},
	title = {{Testing lumpability in Markov chains}},
	volume = {64},
	year = {2003}
}
@article{Bertsimas2007,
	author = {Bertsimas, Dimitris and Brown, David B},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/5d83b565b9351cdc36b248cde6730dfeaaaf.pdf:pdf},
	keywords = {coherent risk measures,robust optimization,spectral risk measures,uncertainty sets},
	pages = {1--25},
	title = {{Constructing uncertainty sets for robust linear optimization}},
	year = {2007}
}
@article{Sutton2016,
	author = {Sutton, Richard S and Barto, Andrew G},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Sutton, Barto - 2016 - Reinforcement Learning An Introduction.pdf:pdf},
	title = {{Reinforcement Learning : An Introduction **** Draft ****}},
	year = {2016}
}
@article{Ball1997,
	author = {Ball, Keith},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/ball.pdf:pdf},
	pages = {1--58},
	title = {{An Elementary Introduction to Modern Convex Geometry}},
	volume = {31},
	year = {1997}
}
@article{Petrik2016,
	author = {Petrik, Marek},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Petrik2016b.pdf:pdf},
	number = {Nips},
	title = {{Safe Policy Improvement by Minimizing Robust Baseline Regret}},
	year = {2016}
}
@article{Hanasusanto,
	author = {Hanasusanto, Grani A and Kuhn, Daniel},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/NIPS2013{\_}5123.pdf:pdf},
	pages = {1--9},
	title = {{Robust Data-Driven Dynamic Programming}}
}
@article{Hasselt,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1509.06461v3},
	author = {Hasselt, Hado Van and Guez, Arthur and Silver, David},
	eprint = {arXiv:1509.06461v3},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1509.06461.pdf:pdf},
	title = {{Deep Reinforcement Learning with Double Q-learning}}
}
@article{Ferns,
	author = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/siamFP11.pdf:pdf},
	keywords = {1,60j05,68t37,7,90c40,93e20,ams subject classifications,bisimulation,continuous,formalism for describ-,introduction,markov decision process,markov decision processes,mdps,metrics,offer a popular mathematical,planning and learning in,reinforcement learning,the presence of uncertainty,they are a standard,tool for},
	number = {1999},
	pages = {258--273},
	title = {{BISIMULATION METRICS FOR CONTINUOUS MARKOV DECISION}}
}
@article{Gorissen2014,
	archivePrefix = {arXiv},
	arxivId = {arXiv:1501.02634v1},
	author = {Gorissen, Bram L and Yanıkoğlu, Ihsan and Hertog, Dick Den},
	doi = {10.1016/j.omega.2014.12.006.)},
	eprint = {arXiv:1501.02634v1},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/1501.02634.pdf:pdf},
	number = {Soyster 1973},
	title = {{A Practical Guide to Robust Optimization}},
	year = {2014}
}
@book{Chains,
	author = {Chains, Finite Markov},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/Kemeny-Snell1976.pdf:pdf},
	isbn = {3540901922},
	title = {{Finite Markov Chains}},
	volume = {40}
}
@article{,
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/robustrectangular{\_}l1.pdf:pdf},
	number = {1},
	pages = {1--7},
	title = {{Solution Structure for L 1 Uncertainty}}
}
@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	doi = {10.1038/nature14236},
	file = {:home/reazul/Summer-2017/ML+Summer/Summer-2017/Robust{\_}Papers{\_}Summer{\_}17/DQN.pdf:pdf},
	issn = {0028-0836},
	journal = {Nature},
	number = {7540},
	pages = {529--533},
	publisher = {Nature Publishing Group},
	title = {learning},
	url = {http://dx.doi.org/10.1038/nature14236},
	volume = {518},
	year = {2015}
}
@article{Apr2017,
	author = {Apr, No Mar and Bean, James C and Birge, John R and Smith, Robert L},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Apr et al. - 2017 - Aggregation in Dynamic Programming Author ( s ) James C . Bean , John R . Birge and Robert L . Smith Published by I.pdf:pdf},
	number = {2},
	pages = {215--220},
	title = {{Aggregation in Dynamic Programming Author ( s ): James C . Bean , John R . Birge and Robert L . Smith Published by : INFORMS Stable URL : http://www.jstor.org/stable/170693 REFERENCES Linked references are available on JSTOR for this article : You may nee}},
	volume = {35},
	year = {2017}
}
@article{VanRoy2006,
	abstract = {We consider approximate value iteration with a parameterized approximator in which the state space is partitioned and the optimal cost-to-go function over each partition is approximated by a constant. We establish performance loss bounds for policies derived from approximations associated with fixed points. These bounds identify benefits to using invariant distributions of appropriate policies as projection weights. Such projection weighting relates to what is done by temporal-difference learning. Our analysis also leads to the first performance loss bound for approximate value iteration with an average-cost objective.},
	author = {{Van Roy}, Benjamin},
	doi = {10.1287/moor.1060.0188},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Roy - 2006 - Performance Loss Bounds for Approximate Value Iteration with State Aggregation.pdf:pdf},
	isbn = {0364-765X},
	issn = {0364-765X},
	journal = {Mathematics of Operations Research},
	keywords = {2004,2005,68t05,68t37,90c39,90c40,approximate value iteration,dynamic programming,finite state,history,markov,ms subject classification,msc2000 subject classification,optimal control,or,primary,received august 2,revised august 12,secondary,state aggregation,temporal-difference learning},
	number = {2},
	pages = {234--244},
	title = {{Performance Loss Bounds for Approximate Value Iteration with State Aggregation}},
	url = {http://dx.doi.org/10.1287/moor.1060.0188},
	volume = {31},
	year = {2006}
}
@article{Hutter2014,
	abstract = {We consider a Reinforcement Learning setup where an agent interacts with an environment in observation-reward-action cycles without any (esp.$\backslash$ MDP) assumptions on the environment. State aggregation and more generally feature reinforcement learning is concerned with mapping histories/raw-states to reduced/aggregated states. The idea behind both is that the resulting reduced process (approximately) forms a small stationary finite-state MDP, which can then be efficiently solved or learnt. We considerably generalize existing aggregation results by showing that even if the reduced process is not an MDP, the (q-)value functions and (optimal) policies of an associated MDP with same state-space size solve the original problem, as long as the solution can approximately be represented as a function of the reduced states. This implies an upper bound on the required state space size that holds uniformly for all RL problems. It may also explain why RL algorithms designed for MDPs sometimes perform well beyond MDPs.},
	archivePrefix = {arXiv},
	arxivId = {1407.3341},
	author = {Hutter, Marcus},
	eprint = {1407.3341},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hutter - 2014 - Extreme State Aggregation Beyond MDPs.pdf:pdf},
	keywords = {non-mdp,reinforcement learning,state aggregation},
	title = {{Extreme State Aggregation Beyond MDPs}},
	url = {http://arxiv.org/abs/1407.3341},
	year = {2014}
}
@article{Mastin2012,
	abstract = {We analyze losses resulting from uncertain transition probabilities in Markov decision processes with bounded nonnegative rewards. We assume that policies are precomputed using exact dynamic programming with the estimated transition probabilities, but the system evolves according to different, true transition probabilities. Given a bound on the total variation error of estimated transition probability distributions, we derive upper bounds on the loss of expected total reward. The approach analyzes the growth of errors incurred by stepping backwards in time while precomputing value functions, which requires bounding a multilinear program. Loss bounds are given for the finite horizon undiscounted, finite horizon discounted, and infinite horizon discounted cases, and a tight example is shown.},
	author = {Mastin, Andrew and Jaillet, Patrick},
	doi = {10.1109/CDC.2012.6426504},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mastin, Jaillet - 2012 - Loss bounds for uncertain transition probabilities in Markov decision processes.pdf:pdf},
	isbn = {978-1-4673-2066-5},
	issn = {01912216},
	journal = {Proceedings of the IEEE Conference on Decision and Control},
	pages = {6708--6715},
	title = {{Loss bounds for uncertain transition probabilities in Markov decision processes}},
	year = {2012}
}
@article{Wiesemann2013,
	author = {Wiesemann, Wolfram},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiesemann - 2013 - Robust Markov decision processes.pdf:pdf},
	journal = {{\ldots} of Operations Research},
	keywords = {markov decision processes,robust optimization,semidefinite programming},
	pages = {1--52},
	title = {{Robust Markov decision processes}},
	url = {http://mor.journal.informs.org/content/38/1/153.short},
	year = {2013}
}
@article{Nilim2005,
	abstract = {Optimal solutions to Markov decision problems may be very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of these probabilities is far from accurate. Hence, estimation errors are limiting factors in applying Markov decision processes to real-world problems. We consider a robust control problem for a finite-state, finite-action Markov decision process, where uncertainty on the transition matrices is described in terms of possibly nonconvex sets. We show that perfect duality holds for this problem, and that as a consequence, it can be solved with a variant of the classical dynamic programming algorithm, the “robust dynamic programming” algorithm. We show that a particular choice of the uncertainty sets, involving likelihood regions or entropy bounds, leads to both a statistically accurate representation of uncertainty, and a complexity of the robust recursion that is almost the same as that of the classical recursion. Hence, robustness can be added at practically no extra computing cost. We derive similar results for other uncertainty sets, including one with a finite number of possible values for the transition matrices. We describe in a practical path planning example the benefits of using a robust strategy instead of the classical optimal strategy; even if the uncertainty level is only crudely guessed, the robust strategy yields a much better worst-case expected travel time.},
	author = {Nilim, Arnab and {El Ghaoui}, Laurent},
	doi = {10.1287/opre.1050.0216},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nilim, El Ghaoui - 2005 - Robust Control of Markov Decision Processes with Uncertain Transition Matrices.pdf:pdf},
	isbn = {0030364X},
	issn = {0030-364X},
	journal = {Mathematics of Operations Research},
	number = {5},
	pages = {780--798},
	title = {{Robust Control of Markov Decision Processes with Uncertain Transition Matrices}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/opre.1050.0216},
	volume = {53},
	year = {2005}
}
@article{Bagnell2001,
	abstract = {The authors consider the fundamental problem of nding good policies in uncertain models. It is demonstrated that although the general problem of nding the best policy with respect to the worst model is NP-hard, in the special case of a convex uncertainty set the problem is tractable. A stochastic dynamic game is proposed, and the security equilibrium solution of the game is shown to correspond to the value function under the worst model and the optimal controller. The authors demonstrate that the uncertain model approach can be used to solve a class of nearly Markovian Decision Problems, providing lower bounds on performance in stochastic models with higher-order interactions. The framework considered establishes connections between and generalizes paradigms of stochastic optimal, mini-max, and H1 /robust control. Applications are considered, including robustness in reinforcement learning, planning in nearly Markovian decision processes, and bounding error due to sensor discretization in noisy, continuous state-spaces.},
	author = {Bagnell, J Andrew and Ng, Andrew Y and Schneider, Jeff G},
	doi = {tech. report CMU-RI-TR-01-25},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bagnell, Ng, Schneider - 2001 - Solving Uncertain Markov Decision Processes.pdf:pdf},
	journal = {Carnegie Mellon Research Showcase},
	pages = {948--957},
	title = {{Solving Uncertain Markov Decision Processes}},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.57.8550{\%}7B{\%}5C{\&}{\%}7Drep=rep1{\%}7B{\%}5C{\&}{\%}7Dtype=pdf{\%}7B{\%}5C{\%}25{\%}7D5Cnhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.8550},
	year = {2001}
}
@article{Nilim2004,
	abstract = {Optimal solutions to Markov Decision Problems (MDPs) are very sensitive with respect to the state transition probabilities. In many practical problems, the estimation of those probabilities is far from accurate. Hence, estimation errors are limiting factors in applying MDPs to realworld problems. We propose an algorithm for solving finite-state and finite-action MDPs, where the solution is guaranteed to be robust with respect to estimation errors on the state transition probabilities. Our algorithm involves a statistically accurate yet numerically efficient representation of uncertainty, via Kullback-Leibler divergence bounds. The worst-case complexity of the robust algorithm is the same as the original Bellman recursion. Hence, robustness can be added at practically no extra computing cost. 1},
	author = {Nilim, Arnab and Ghaoui, Laurent El},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nilim, Ghaoui - 2004 - Robust solutions to Markov decision problems with uncertain transition matrices.pdf:pdf},
	journal = {Mathematics of Operations Research},
	number = {5},
	pages = {780-788},
	title = {{Robust solutions to Markov decision problems with uncertain transition matrices}},
	volume = {53},
	year = {2004}
}
@article{Ren2002,
	author = {Ren, Zhiyuan and Krogh, B.H.},
	doi = {10.1109/CDC.2002.1184960},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren, Krogh - 2002 - State aggregation in Markov decision processes.pdf:pdf},
	isbn = {0-7803-7516-5},
	issn = {01912216},
	journal = {Proceedings of the 41st IEEE Conference on Decision and Control, 2002.},
	keywords = {cesses,policy iterations,state},
	number = {December},
	pages = {3819--3824},
	title = {{State aggregation in Markov decision processes}},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1184960},
	volume = {4},
	year = {2002}
}
@article{LeTallec2007,
	abstract = {Markov Decision Processes (MDPs) model problems of sequential decision-making under uncertainty. They have been studied and applied extensively. Nonetheless, there are two major barriers that still hinder the applicability of MDPs to many more practical decision making problems: * The decision maker is often lacking a reliable MDP model. Since the results obtained by dynamic programming are sensitive to the assumed MDP model, their relevance is challenged by model uncertainty. * The structural and computational results of dynamic programming (which deals with expected performance) have been extended with only limited success to accommodate risk-sensitive decision makers. In this thesis, we investigate two ways of dealing with uncertain MDPs and we develop a new connection between robust control of uncertain MDPs and risk-sensitive control of dynamical systems. The first approach assumes a model of model uncertainty and formulates the control of uncertain MDPs as a problem of decision-making under (model) uncertainty. We establish that most formulations are at least NP-hard and thus suffer from the "'curse of uncertainty." The worst-case control of MDPs with rectangular uncertainty sets is equivalent to a zero-sum game between the controller and nature. The structural and computational results for such games make this formulation appealing. By adding a penalty for unlikely parameters, we extend the formulation of worst-case control of uncertain MDPs and mitigate its conservativeness. We show a duality between the penalized worst-case control of uncertain MDPs with rectangular uncertainty and the minimization of a Markovian dynamically consistent convex risk measure of the sample cost. This notion of risk has desirable properties for multi-period decision making, including a new Markovian property that we introduce and motivate. This Markovian property is critical in establishing the equivalence between minimizing some risk measure of the sample cost and solving a certain zero-sum Markov game between the decision maker and nature, and to tackling infinite-horizon problems. An alternative approach to dealing with uncertain MDPs, which avoids the curse of uncertainty, is to exploit directly observational data. Specifically, we estimate the expected performance of any given policy (and its gradient with respect to certain policy parameters) from a training set comprising observed trajectories sampled under a known policy. We propose new value (and value gradient) estimators that are unbiased and have low training set to training set variance. We expect our approach to outperform competing approaches when there are few system observations compared to the underlying MDP size, as indicated by numerical experiments.},
	author = {{Le Tallec}, Yann},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Tallec - 2007 - Robust, Risk-Sensitive, and Data-driven Control of Markov Decision Processes.pdf:pdf},
	journal = {Thesis},
	pages = {211},
	title = {{Robust, Risk-Sensitive, and Data-driven Control of Markov Decision Processes}},
	url = {http://hdl.handle.net/1721.1/38598},
	year = {2007}
}
@article{Iyengar2005,
	abstract = {In this paper we propose a robust formulation for discrete time dynamic programming (DP). The objective of the robust formulation is to systematically mitigate the sensitivity of the DP optimal policy to ambiguity in the underlying transition probabilities. The ambiguity is modeled by associating a set of conditional measures with each state-action pair. Consequently, in the robust formulation each policy has a set of measures associated with it. We prove that when this set of measures has a certain “rectangularity” property, all of the main results for finite and infinite horizon DP extend to natural robust counterparts. We discuss techniques from Nilim and El Ghaoui [17] for constructing suitable sets of conditional measures that allow one to efficiently solve for the optimal robust policy. We also show that robust DP is equivalent to stochastic zero-sum games with perfect information.},
	author = {Iyengar, Garud N.},
	doi = {10.1287/moor.1040.0129},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iyengar - 2005 - Robust Dynamic Programming.pdf:pdf},
	isbn = {0364765X},
	issn = {0364-765X},
	journal = {Mathematics of Operations Research},
	number = {2},
	pages = {257--280},
	title = {{Robust Dynamic Programming}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/moor.1040.0129},
	volume = {30},
	year = {2005}
}
@article{Freund2003,
	abstract = {We study the problem of learning to accurately rank a set of objects by combining a given collec-tion of ranking or preference functions. This problem of combining preferences arises in several applications, such as that of combining the results of different search engines, or the " collaborative-filtering " problem of ranking movies for a user based on the movie rankings provided by other users. In this work, we begin by presenting a formal framework for this general problem. We then describe and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine learning. We give theoretical results describing the algorithm's behavior both on the training data, and on new test data not seen during training. We also describe an efficient implementation of the algorithm for a particular restricted but common case. We next discuss two experiments we carried out to assess the performance of RankBoost. In the first exper-iment, we used the algorithm to combine different web search strategies, each of which is a query expansion for a given domain. The second experiment is a collaborative-filtering task for making movie recommendations.},
	author = {Freund, Yoav and Iyer, Raj and Schapire, Robert E and Singer, Yoram},
	doi = {10.1162/jmlr.2003.4.6.933},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freund et al. - 2003 - An Efficient Boosting Algorithm for Combining Preferences.pdf:pdf},
	isbn = {1581134924},
	issn = {15324435},
	journal = {Journal of Machine Learning Research},
	pages = {933--969},
	pmid = {345},
	title = {{An Efficient Boosting Algorithm for Combining Preferences}},
	volume = {4},
	year = {2003}
}
@article{Burges2005,
	abstract = {We investigate using gradient descent methods for learning ranking functions; we propose a simple probabilistic cost function, and we introduce RankNet, an implementation of these ideas using a neural network to model the underlying ranking function. We present test results on toy data and on data from a commercial internet search engine.},
	author = {Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
	doi = {10.1145/1102351.1102363},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Burges et al. - 2005 - Learning to rank using gradient descent.pdf:pdf},
	isbn = {1595931805},
	issn = {00243205},
	journal = {Proceedings of the 22nd international conference on Machine learning - ICML '05},
	keywords = {gradient descent,internet search,neural networks,probabilistic cost functions,ranking},
	pages = {89--96},
	pmid = {16483612},
	title = {{Learning to rank using gradient descent}},
	url = {http://dl.acm.org/citation.cfm?id=1102351.1102363{\%}5Cnhttp://portal.acm.org/citation.cfm?doid=1102351.1102363},
	year = {2005}
}
@article{Sahni2007,
	author = {Sahni, Saurabh},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahni - 2007 - Information Retrieval in Resource Constrained Environments.pdf:pdf},
	journal = {Information Retrieval},
	title = {{Information Retrieval in Resource Constrained Environments}},
	year = {2007}
}
@article{Doran2009,
	author = {Doran, Christine},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doran - 2009 - ACL-IJCNLP 2009 Handbook.pdf:pdf},
	journal = {Presentations},
	title = {{ACL-IJCNLP 2009 Handbook}},
	year = {2009}
}
@article{Joachims2002,
	abstract = {This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.},
	author = {Joachims, Thorsten},
	doi = {10.1145/775047.775067},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joachims - 2002 - Optimizing search engines using clickthrough data.pdf:pdf},
	isbn = {158113567X},
	issn = {10468188},
	journal = {Kdd '02},
	keywords = {analysis,information,learning,log,rank,retrieval},
	pages = {133--142},
	pmid = {21474660},
	title = {{Optimizing search engines using clickthrough data}},
	url = {http://www.cs.cornell.edu/People/tj/publications/joachims{\_}02c.pdf},
	year = {2002}
}
@misc{,
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - herbrich-ordinal-00.gz:gz},
	title = {herbrich-ordinal-00}
}
@misc{,
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - lrt{\_}framework.png:png},
	title = {lrt{\_}framework}
}
@article{Kuo2009,
	abstract = {Ranking is a key problem in many information retrieval (IR) applications, such as document retrieval and collaborative filtering. In this paper, we address the issue of learning to rank in document retrieval. Learning-based methods, such as RankNet, RankSVM, and RankBoost, try to create ranking functions automatically by using some training data. Recently, several learning to rank methods have been proposed to directly optimize the performance of IR applications in terms of various evaluation measures. They undoubtedly provide statistically significant improvements over conventional methods; however, from the viewpoint of decision-making, most of them do not minimize the Bayes risk of the IR system. In an attempt to fill this research gap, we propose a novel framework that directly optimizes the Bayes risk related to the ranking accuracy in terms of the IR evaluation measures. The results of experiments on the LETOR collections demonstrate that the framework outperforms several existing methods in most cases. Copyright 2009 ACM.},
	author = {Kuo, Jen-Wei and Cheng, Pu-Jen and Wang, Hsin-Min},
	doi = {10.1145/1645953.1646058},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo, Cheng, Wang - 2009 - Learning to rank from Bayesian decision inference.pdf:pdf},
	isbn = {9781605585123},
	issn = {1605585122},
	journal = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
	keywords = {learning to rank,ranking function},
	pages = {827},
	title = {{Learning to rank from Bayesian decision inference}},
	url = {http://portal.acm.org/citation.cfm?doid=1645953.1646058},
	year = {2009}
}
@article{Transformation,
	author = {Transformation, The},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Transformation - Unknown - Retrieval of Information by Computer.pdf:pdf},
	title = {{Retrieval of Information by Computer}}
}
@article{Kuo2009,
	abstract = {Ranking is a key problem in many information retrieval (IR) applications, such as document retrieval and collaborative filtering. In this paper, we address the issue of learning to rank in document retrieval. Learning-based methods, such as RankNet, RankSVM, and RankBoost, try to create ranking functions automatically by using some training data. Recently, several learning to rank methods have been proposed to directly optimize the performance of IR applications in terms of various evaluation measures. They undoubtedly provide statistically significant improvements over conventional methods; however, from the viewpoint of decision-making, most of them do not minimize the Bayes risk of the IR system. In an attempt to fill this research gap, we propose a novel framework that directly optimizes the Bayes risk related to the ranking accuracy in terms of the IR evaluation measures. The results of experiments on the LETOR collections demonstrate that the framework outperforms several existing methods in most cases. Copyright 2009 ACM.},
	author = {Kuo, Jen-Wei and Cheng, Pu-Jen and Wang, Hsin-Min},
	doi = {10.1145/1645953.1646058},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo, Cheng, Wang - 2009 - Learning to rank from Bayesian decision inference.pdf:pdf},
	isbn = {9781605585123},
	issn = {1605585122},
	journal = {Proceeding of the 18th ACM conference on Information and knowledge management - CIKM '09},
	keywords = {learning to rank,ranking function},
	pages = {827},
	title = {{Learning to rank from Bayesian decision inference}},
	url = {http://portal.acm.org/citation.cfm?doid=1645953.1646058},
	year = {2009}
}
@article{Xu2008,
	abstract = {One of the central issues in learning to rank for information retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in information retrieval such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG). Several such algorithms including SVMmap and AdaRank have been proposed and their effectiveness has been verified. However, the relationships between the algorithms are not clear, and furthermore no comparisons have been conducted between them. In this paper, we conduct a study on the approach of directly optimizing evaluation measures in learning to rank for Information Retrieval (IR). We focus on the methods that minimize loss functions upper bounding the basic loss function defined on the IR measures. We first provide a general framework for the study and analyze the existing algorithms of SVMmap and AdaRank within the framework. The framework is based on upper bound analysis and two types of upper bounds are discussed. Moreover, we show that we can derive new algorithms on the basis of this analysis and create one example algorithm called PermuRank. We have also conducted comparisons between SVMmap, AdaRank, PermuRank, and conventional methods of Ranking SVM and RankBoost, using benchmark datasets. Experimental results show that the methods based on direct optimization of evaluation measures can always outperform conventional methods of Ranking SVM and RankBoost. However, no significant difference exists among the performances of the direct optimization methods themselves.},
	author = {Xu, Jun and Liu, T.Y. and Lu, Min and Xu, Jun and Lu, Min and Ma, Wei-Ying and Li, Hang and Li, Hang and Ma, W.Y. and Liu, Tie-Yan},
	doi = {10.1145/1390334.1390355},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2008 - Directly optimizing evaluation measures in learning to rank.pdf:pdf},
	isbn = {978-1-60558-164-4},
	journal = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
	keywords = {all or part of,evaluation measure,information retrieval,is granted without fee,learning to rank,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
	number = {49},
	pages = {107--114},
	title = {{Directly optimizing evaluation measures in learning to rank}},
	url = {http://portal.acm.org/citation.cfm?id=1390334.1390355},
	year = {2008}
}
@article{He2008,
	abstract = {Ranking is the key problem for information retrieval and other text applications. Recently, the ranking methods based on machine learning approaches, called learning to rank, become the focus for researchers and practitioners. The main idea of these methods is to apply the various existing and effective algorithms on machine learning to ranking. However, as a learning problem, ranking is different from other classical ones such as classification and regression. In this paper, we investigate the important papers in this direction; the cons and pros of the recent-proposed framework and algorithms for ranking are analyzed, and the relationships among them are discussed. Finally, the promising directions in practice are also pointed out.},
	author = {He, Chuan and Wanq, Cong and Zhonq, Yi Xin and Li, Rui Fan},
	doi = {10.1109/ICMLC.2008.4620685},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2008 - A survey on learning to rank.pdf:pdf},
	isbn = {9781424420964},
	journal = {Proceedings of the 7th International Conference on Machine Learning and Cybernetics, ICMLC},
	keywords = {Evaluation,Information retrieval support vector machine,Learning to rank,Ordinal regression,Ranking},
	number = {July},
	pages = {1734--1739},
	title = {{A survey on learning to rank}},
	volume = {3},
	year = {2008}
}
@article{Phophalia2011a,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phophalia - 2011 - A survey on Learning to Rank (LETOR) approaches in information retrieval(2).pdf:pdf},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	number = {December 2011},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Doran2009,
	author = {Doran, Christine},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doran - 2009 - ACL-IJCNLP 2009 Handbook.pdf:pdf},
	journal = {Presentations},
	title = {{ACL-IJCNLP 2009 Handbook}},
	year = {2009}
}
@article{Xu2008,
	abstract = {One of the central issues in learning to rank for information retrieval is to develop algorithms that construct ranking models by directly optimizing evaluation measures used in information retrieval such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG). Several such algorithms including SVMmap and AdaRank have been proposed and their effectiveness has been verified. However, the relationships between the algorithms are not clear, and furthermore no comparisons have been conducted between them. In this paper, we conduct a study on the approach of directly optimizing evaluation measures in learning to rank for Information Retrieval (IR). We focus on the methods that minimize loss functions upper bounding the basic loss function defined on the IR measures. We first provide a general framework for the study and analyze the existing algorithms of SVMmap and AdaRank within the framework. The framework is based on upper bound analysis and two types of upper bounds are discussed. Moreover, we show that we can derive new algorithms on the basis of this analysis and create one example algorithm called PermuRank. We have also conducted comparisons between SVMmap, AdaRank, PermuRank, and conventional methods of Ranking SVM and RankBoost, using benchmark datasets. Experimental results show that the methods based on direct optimization of evaluation measures can always outperform conventional methods of Ranking SVM and RankBoost. However, no significant difference exists among the performances of the direct optimization methods themselves.},
	author = {Xu, Jun and Liu, T Y and Lu, Min and Xu, Jun and Lu, Min and Ma, Wei-Ying and Li, Hang and Li, Hang and Ma, W Y and Liu, Tie-Yan},
	doi = {10.1145/1390334.1390355},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2008 - Directly optimizing evaluation measures in learning to rank.pdf:pdf},
	isbn = {978-1-60558-164-4},
	journal = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
	keywords = {all or part of,evaluation measure,information retrieval,is granted without fee,learning to rank,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,this work for},
	number = {49},
	pages = {107--114},
	title = {{Directly optimizing evaluation measures in learning to rank}},
	url = {http://portal.acm.org/citation.cfm?id=1390334.1390355},
	year = {2008}
}
@article{Jarvelin2000,
	abstract = {This paper proposes evaluation methods based on the use of non-dichotomous relevance judgements in IR experiments. It is argued that evaluation methods should credit IR methods for their ability to retrieve highly relevant documents. This is de- sirable from the user point of view in modem large IR envi- ronments. The proposed methods are (1) a novel application of P-R curves and average precision computations based on sepa- rate recall bases for documents of different degrees of rele- vance, and (2) two novel measures computing the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. We then demonstrate the use of these evaluation methods in a case study on the effectiveness of query types, based on combinations of query structures and expansion, in retrieving documents of various degrees of rele- vance. The test was run with a best match retrieval system (In- Query I) in a text database consisting of newspaper articles. The results indicate that the tested strong query structures are most effective in retrieving highly relevant documents. The differ- ences between the query types are practically essential and statistically significant. More generally, the novel evaluation methods and the case demonstrate that non-dichotomous rele- vance assessments are applicable in IR experiments, may reveal interesting phenomena, and allow harder testing of IR methods.},
	author = {J{\"{a}}rvelin, Kalervo and Kek{\"{a}}l{\"{a}}inen, Jaana},
	doi = {10.1145/345508.345545},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/J{\"{a}}rvelin, Kek{\"{a}}l{\"{a}}inen - 2000 - IR evaluation methods for retrieving highly relevant documents.pdf:pdf},
	isbn = {1581132263},
	issn = {01635840 (ISSN)},
	journal = {Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval - SIGIR '00},
	pages = {41--48},
	title = {{IR evaluation methods for retrieving highly relevant documents}},
	url = {http://dl.acm.org/citation.cfm?id=345508.345545},
	year = {2000}
}
@article{Phophalia2011,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phophalia - 2011 - A survey on Learning to Rank (LETOR) approaches in information retrieval(2).pdf:pdf},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	pages = {8--10},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Ding,
	author = {Ding, Ruoyao},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding - Unknown - Literature survey for Learning to rank.pdf:pdf},
	title = {{Literature survey for Learning to rank}}
}
@article{Sahni2007,
	author = {Sahni, Saurabh},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahni - 2007 - Information Retrieval in Resource Constrained Environments.pdf:pdf},
	journal = {Information Retrieval},
	title = {{Information Retrieval in Resource Constrained Environments}},
	year = {2007}
}
@misc{Robertson1976,
	abstract = {Abstract 10.1002/asi.4630270302.abs This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections.},
	author = {Robertson, SE and Jones, KS},
	booktitle = {Journal of American Society of Information Science},
	doi = {10.1002/asi.4630270302},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertson, Jones - 1976 - Relevance weighting of search terms.pdf:pdf},
	isbn = {0-947568-21-2},
	issn = {1097-4571},
	number = {3},
	pages = {129--146},
	pmid = {3048012021851954321},
	title = {{Relevance weighting of search terms}},
	url = {http://www.marilia.unesp.br/Home/Instituicao/Docentes/EdbertoFerneda/MRI 01 - Robertson SE; Jones KS - 1976.pdf{\%}5Cnhttp://dx.doi.org/10.1002/asi.4630270302{\%}5Cnhttp://onlinelibrary.wiley.com/doi/10.1002/asi.4630270302/abstract?systemMessage=Wiley+Online+Li},
	volume = {27},
	year = {1976}
}
@article{Ponte2014,
	abstract = {Mycotoxins are small (MW approximately 700), toxic chemical products formed as secondary metabolites by a few fungal species that readily colonise crops and contaminate them with toxins in the field or after harvest. Ochratoxins and Aflatoxins are mycotoxins of major significance and hence there has been significant research on broad range of analytical and detection techniques that could be useful and practical. Due to the variety of structures of these toxins, it is impossible to use one standard technique for analysis and/or detection. Practical requirements for high-sensitivity analysis and the need for a specialist laboratory setting create challenges for routine analysis. Several existing analytical techniques, which offer flexible and broad-based methods of analysis and in some cases detection, have been discussed in this manuscript. There are a number of methods used, of which many are lab-based, but to our knowledge there seems to be no single technique that stands out above the rest, although analytical liquid chromatography, commonly linked with mass spectroscopy is likely to be popular. This review manuscript discusses (a) sample pre-treatment methods such as liquid-liquid extraction (LLE), supercritical fluid extraction (SFE), solid phase extraction (SPE), (b) separation methods such as (TLC), high performance liquid chromatography (HPLC), gas chromatography (GC), and capillary electrophoresis (CE) and (c) others such as ELISA. Further currents trends, advantages and disadvantages and future prospects of these methods have been discussed.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Ponte, Jay M. and Croft, W. Bruce},
	doi = {10.1007/s13398-014-0173-7.2},
	eprint = {arXiv:1011.1669v3},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponte, Croft - 2014 - A Language Modeling Approach to Information Retrieval.pdf:pdf},
	isbn = {9780874216561},
	issn = {0717-6163},
	journal = {Igarss 2014},
	keywords = {Bott},
	number = {1},
	pages = {1--5},
	pmid = {15003161},
	title = {{A Language Modeling Approach to Information Retrieval}},
	year = {2014}
}
@article{He2008,
	abstract = {Ranking is the key problem for information retrieval and other text applications. Recently, the ranking methods based on machine learning approaches, called learning to rank, become the focus for researchers and practitioners. The main idea of these methods is to apply the various existing and effective algorithms on machine learning to ranking. However, as a learning problem, ranking is different from other classical ones such as classification and regression. In this paper, we investigate the important papers in this direction; the cons and pros of the recent-proposed framework and algorithms for ranking are analyzed, and the relationships among them are discussed. Finally, the promising directions in practice are also pointed out.},
	author = {He, Chuan and Wanq, Cong and Zhonq, Yi Xin and Li, Rui Fan},
	doi = {10.1109/ICMLC.2008.4620685},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2008 - A survey on learning to rank.pdf:pdf},
	isbn = {9781424420964},
	journal = {Proceedings of the 7th International Conference on Machine Learning and Cybernetics, ICMLC},
	keywords = {Evaluation,Information retrieval support vector machine,Learning to rank,Ordinal regression,Ranking},
	number = {July},
	pages = {1734--1739},
	title = {{A survey on learning to rank}},
	volume = {3},
	year = {2008}
}
@article{Phophalia2011,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phophalia - 2011 - A survey on Learning to Rank (LETOR) approaches in information retrieval(2).pdf:pdf},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	pages = {8--10},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Phophalia2011a,
	abstract = {In Recent years, the application of machine learning approaches to conventional IR system evolve a new dimension in the field. The emphasis is now shifted from simply retrieving a set of documents to rank them also for a given query in terms of user's need. The researcher's task is not only to retrieve the documents from the corpus but also to rank them in order of their relevance to the user's requirement. To improve the system's performance is now the hot area of research. In this paper, an attempt has been made to put some of most commonly used algorithms in the community. It presents a survey on the approaches used to rank the retrieved documents and their evaluation strategies.},
	author = {Phophalia, Ashish},
	doi = {10.1109/NUiConE.2011.6153228},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phophalia - 2011 - A survey on Learning to Rank (LETOR) approaches in information retrieval.pdf:pdf},
	isbn = {9781457721694},
	journal = {2011 Nirma University International Conference on Engineering: Current Trends in Technology, NUiCONE 2011 - Conference Proceedings},
	keywords = {Information Retrieval,Learning to Rank (LETOR),Machine Learning},
	number = {December 2011},
	title = {{A survey on Learning to Rank (LETOR) approaches in information retrieval}},
	year = {2011}
}
@article{Heumann2011,
	author = {Heumann, Benjamin W. and Walsh, Stephen J. and McDaniel, Phillip M.},
	doi = {10.1016/j.ecoinf.2011.04.004.Assessing},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heumann, Walsh, McDaniel - 2011 - Assessing the Aplicatinon of a Geographic Presence-Only Model for Land Suitability Mapping.pdf:pdf},
	journal = {Ecological Informatics},
	keywords = {2011 elsevier b,agriculture,all rights reserved,land suitability,maxent,presence-only,thailand,v},
	number = {5},
	pages = {257--269},
	title = {{Assessing the Aplicatinon of a Geographic Presence-Only Model for Land Suitability Mapping}},
	volume = {6},
	year = {2011}
}
@article{Hijmans2013,
	abstract = {This document provides an introduction to species distribution modeling with R . Species distribution modeling (SDM) is also known under other names including climate envelope-modeling, habitat modeling, and (environmental or ecological) niche-modeling. The assumption of SDM is that you can predict the entire, or potential, spatial distribution of a phenomenon, by relating sites of known occurence (and perhaps non-occurrence) with predictor variables known for these sites and for all other sites. The common application of this method is to predict species ranges with climate data as predictors},
	archivePrefix = {arXiv},
	arxivId = {hep-th/0201144v2},
	author = {Hijmans, Robert J and Elith, Jane},
	doi = {10.1016/S0550-3213(02)00216-X},
	eprint = {0201144v2},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hijmans, Elith - 2013 - Species distribution modeling with R Introduction.pdf:pdf},
	isbn = {1574-9541},
	issn = {05503213},
	journal = {October},
	pages = {71},
	pmid = {25270536},
	primaryClass = {hep-th},
	title = {{Species distribution modeling with R Introduction}},
	url = {ftp://cran.r-project.org/pub/R/web/packages/dismo/vignettes/sdm.pdf},
	year = {2013}
}
@article{Choi1995,
	author = {Choi, S P M and Yeung, D.-Y.},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choi, Yeung - 1995 - Predictive Q-Routing A Memory-based Reinforcement Learning Approach to Adaptive Traffic Control.pdf:pdf},
	journal = {Advances in Neural Information Processing Systems 8},
	title = {{Predictive Q-Routing: A Memory-based Reinforcement Learning Approach to Adaptive Traffic Control}},
	year = {1995}
}
@article{Safran1995,
	abstract = {Clinical data repositories represent a potential gold mine of information and knowledge. Rapid access to such information can help bridge the gap between clinical care and research, support clinical and executive decision making, and improve the quality of care. A clinical database can be used in four ways: to display information about an individual patient (results reporting); to find data on a patient with similarities to one being seen (case finding); to describe a group of patients with at least one attribute in common (cohort description); and to analyze data patterns in terms of trends or relationships (predictive modeling). It seems unlikely that many important clinical questions will be subject to randomized clinical trials because of the ethics, logistics, and expense that would be involved. Evolving statistical and epidemiological methods allow us to approach these clinical data repositories with the purpose of building predictive models, but a clear understanding of the limitations of routinely collected clinical data and the inherent biases is necessary. The largest barrier to using routinely collected clinical data is not the limitations of the data themselves, but rather the lack of a data paradigm for the decision-maker. We present some of the problems and pitfalls in obtaining and using routinely collected data, based upon the use of ClinQuery at Boston's Beth Israel Hospital and the resources and traditions at the Mayo Clinic. ?? 1995.},
	archivePrefix = {arXiv},
	arxivId = {z0009},
	author = {Safran, Charles and Chute, Christopher G.},
	doi = {10.1016/0020-7101(94)01094-H},
	eprint = {z0009},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Safran, Chute - 1995 - Exploration and exploitation of clinical databases.pdf:pdf},
	isbn = {0020-7101 (Print)$\backslash$r0020-7101 (Linking)},
	issn = {00207101},
	journal = {International Journal of Bio-Medical Computing},
	keywords = {Clinical data repositories,Clinical information systems,Clinical research,Computer-based patient records,Exploratory data analysis},
	number = {1},
	pages = {151--156},
	pmid = {7601529},
	title = {{Exploration and exploitation of clinical databases}},
	volume = {39},
	year = {1995}
}
@article{He2017,
	author = {He, Author Zi-lin and Wong, Poh-kam and He, Zi-lin},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Wong, He - 2017 - Exploration vs . Exploitation An Empirical Test of the Ambidexterity Hypothesis.pdf:pdf},
	keywords = {ambidextrous organization,innovation strategy,technological innovation},
	number = {4},
	pages = {481--494},
	title = {{Exploration vs . Exploitation : An Empirical Test of the Ambidexterity Hypothesis}},
	volume = {15},
	year = {2017}
}
@article{Kane2017,
	author = {Kane, Gerald C and Alavi, Maryam and Science, Source Organization and Technology, Information and Kane, Gerald C},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kane et al. - 2017 - Exploitation Processes Linked references are available on JSTOR for this article Organization Science infnunM Info.pdf:pdf},
	keywords = {electronic communities of practice,exploitation,exploration,grant 1996,groupware,knowledge,knowledge management,knowledge portals,many organizations allocate dedicated,organizational learning,repositories,simulation,the ability of organizations,to learn and acquire},
	number = {5},
	pages = {796--812},
	title = {{Exploitation Processes Linked references are available on JSTOR for this article : Organization Science infnunM Information Technology and Organizational Learning : An Investigation of Exploration and Exploitation Processes}},
	volume = {18},
	year = {2017}
}
@article{Elith2011,
	author = {Elith, Jane and Phillips, Steven J and Hastie, Trevor and Dudı, Miroslav},
	doi = {10.1111/j.1472-4642.2010.00725.x},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elith et al. - 2011 - A statistical explanation of MaxEnt for.pdf:pdf},
	keywords = {absence,ecological niche,entropy,machine learning,presence-only,species},
	pages = {43--57},
	title = {{A statistical explanation of MaxEnt for}},
	year = {2011}
}
@article{Gupta2017,
	author = {Gupta, Anil K and Smith, Ken G and Shalley, Christina E and Smith, K E N G and Shalley, Christina E},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2017 - The Interplay between Exploration and Exploitation Linked references are available on JSTOR for this article THE.pdf:pdf},
	number = {4},
	pages = {693--706},
	title = {{The Interplay between Exploration and Exploitation Linked references are available on JSTOR for this article : THE INTERPLAY BETWEEN EXPLORATION AND EXPLOITATION}},
	volume = {49},
	year = {2017}
}
@article{Zhang2001,
	abstract = {One of the most important features of current state-of-the-art SAT solvers is the use of conflict based backtracking and learning techniques. In this paper, we generalize various conflict driven learning strategies in terms of different partitioning schemes of the implication graph. We re-examine the learning techniques used in various SAT solvers and propose an array of new learning schemes. Extensive experiments with real world examples show that the best performing new learning scheme has at least a 2X speedup compared with learning schemes employed in state-of-the-art SAT solvers.},
	author = {Zhang, Lintao and Madigan, Conor F and Moskewicz, Matthew H and Malik, Sharad},
	doi = {10.1109/ICCAD.2001.968634},
	isbn = {0-7803-7249-2},
	issn = {1092-3152},
	journal = {Proceedings of the 2001 IEEE/ACM International Conference on Computer-aided Design},
	keywords = {CDCL,Clause Learning,Learning,SAT,UIP First UIP},
	pages = {279--285},
	title = {{Efficient Conflict Driven Learning in a Boolean Satisfiability Solver}},
	url = {http://dl.acm.org/citation.cfm?id=603095.603153},
	year = {2001}
}
@article{Phillips2004,
	author = {Phillips, Steven J and Avenue, Park and Park, Florham},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Avenue, Park - 2004 - A Maximum Entropy Approach to Species Distribution Modeling.pdf:pdf},
	pages = {655--662},
	title = {{A Maximum Entropy Approach to Species Distribution Modeling}},
	year = {2004}
}
@article{Phillips2006,
	author = {Phillips, Steven J and Anderson, Robert P and Schapire, Robert E},
	doi = {10.1016/j.ecolmodel.2005.03.026},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Phillips, Anderson, Schapire - 2006 - Maximum entropy modeling of species geographic distributions.pdf:pdf},
	keywords = {distribution,maximum entropy,modeling,niche,range},
	pages = {231--259},
	title = {{Maximum entropy modeling of species geographic distributions}},
	volume = {190},
	year = {2006}
}
@article{Trust2017,
	author = {Trust, Biometrika},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trust - 2017 - Biometrika Trust A Dynamic Allocation Index for the Discounted Multiarmed Bandit Problem Author ( s ) J . C . Gittins and.pdf:pdf},
	number = {3},
	pages = {561--565},
	title = {{Biometrika Trust A Dynamic Allocation Index for the Discounted Multiarmed Bandit Problem Author ( s ): J . C . Gittins and D . M . Jones Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : http://www.jstor.org/stable/2335176 }},
	volume = {66},
	year = {2017}
}
@article{,
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2017 - Exploration and Exploitation in Organizational Learning Author ( s ) James G . March Source Organization Science , Vol.pdf:pdf},
	number = {1},
	pages = {71--87},
	title = {{Exploration and Exploitation in Organizational Learning Author ( s ): James G . March Source : Organization Science , Vol . 2 , No . 1 , Special Issue : Organizational Learning : Papers in Honor of ( and by ) James G . March ( 1991 ), pp . 71-87 Published}},
	volume = {2},
	year = {2017}
}
@article{Gilsing2006,
	author = {Gilsing, Victor and Nooteboom, Bart},
	doi = {10.1016/j.respol.2005.06.007},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gilsing, Nooteboom - 2006 - Exploration and exploitation in innovation systems The case of pharmaceutical biotechnology.pdf:pdf},
	keywords = {exploitation,exploration,pharmaceutical biotechnology,sectoral systems},
	pages = {1--23},
	title = {{Exploration and exploitation in innovation systems : The case of pharmaceutical biotechnology}},
	volume = {35},
	year = {2006}
}
@article{Rothaermel2017,
	author = {Rothaermel, Frank T and Deeds, David L and Strategic, Source and Journal, Management and Mar, No},
	doi = {10.1002/smj.376},
	file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rothaermel et al. - 2017 - Development BIOTECHNOLOGY A SYSTEM OF NEW PRODUCT.pdf:pdf},
	number = {3},
	pages = {201--221},
	title = {{Development BIOTECHNOLOGY : A SYSTEM OF NEW PRODUCT}},
	volume = {25},
	year = {2017}
}
@article{Pelikan2012,
	abstract = {Estimation of distribution algorithms (EDAs) guide the search for the optimum by building and sampling explicit probabilistic models of promising candidate solutions. However, EDAs are not only optimization techniques; besides the optimum or its approximation, EDAs provide practitioners with a series of probabilistic models that reveal a lot of information about the problem being solved. This information can in turn be used to design problem-specific neighborhood operators for local search, to bias future runs of EDAs on a similar problem, or to create an efficient computational model of the problem. This chapter provides an introduction to EDAs as well as a number of pointers for obtaining more information about this class of algorithms.},
	author = {Pelikan, Martin and Hauschild, Mark W. and Lobo, Fernando G.},
	keywords = {Estimation of distribution algorithms,evolutionary computation,graphical models,stochastic optimization},
	number = {2012003},
	pages = {42},
	title = {{Introduction to Estimation of Distribution Algorithms}},
	year = {2012}
}
@article{Pipatsrisawat2010,
	author = {Pipatsrisawat, Knot and Darwiche, Adnan},
	doi = {10.1007/s10817-009-9156-3},
	issn = {15730670},
	journal = {Journal of Automated Reasoning},
	keywords = {Clause learning,Phase selection heuristic,Satisfiability,Satisfiability solver},
	number = {3},
	pages = {277--301},
	title = {{On modern clause-learning satisfiability solvers}},
	volume = {44},
	year = {2010}
}
@article{Madera2006,
	abstract = {Training Artificial Neural Networks (ANNs) is a very complex task with a high practical relevance in the field of supervised learning. In this chapter, the problem of training ANNs is faced with several Estimation of Distribution Algorithms (EDAs) with different features, exploring both continuous and discrete search spaces. These EDAs have been tested on a benchmark taken from the medicine field. The results have been carefully analyzed, and compared versus those of other algorithms in the literature for the considered problem. Our conclusions are both that our EDAs are competitive with the other compared algorithms, and also that the use of continuous EDAs is advantageous, in general, versus discretizing the search space for the studied problems.},
	author = {Madera, Julio and Dorronsoro, Bernab{\'{e}}},
	doi = {10.1007/0-387-33416-5_5},
	isbn = {9781461515395},
	journal = {Metaheuristic Procedures for Training Neutral Networks},
	number = {December},
	pages = {87--108},
	title = {{Estimation of Distribution Algorithms}},
	year = {2006}
}
@article{Cai2013,
	author = {Cai, Shaowei},
	keywords = {algorithm implementation,local search,walksat},
	title = {{Faster Implementation for WalkSAT}},
	year = {2013}
}
@article{Pipatsrisawat2011,
	abstract = {In this work, we improve on existing results on the relationship between proof systems obtained from conflict-driven clause-learning SAT solvers and general resolution. Previous contributions such as those by Beame et al. (2004), Hertel et al. (2008), and Buss et al. (2008) demonstrated that variations on conflict-driven clause-learning SAT solvers corresponded to proof systems as powerful as general resolution. However, the models used in these studies required either an extra degree of non-determinism or a preprocessing step that is not utilized by state-of-the-art SAT solvers in practice. In this paper, we prove that conflict-driven clause-learning SAT solvers yield proof systems that indeed p-simulate general resolution without the need for any additional techniques. Moreover, we show that our result can be generalized to certain other practical variations of the solvers, which are based on different learning schemes and restart policies. ?? 2010 Elsevier B.V. All rights reserved.},
	author = {Pipatsrisawat, Knot and Darwiche, Adnan},
	doi = {10.1016/j.artint.2010.10.002},
	isbn = {3642042430},
	issn = {00043702},
	journal = {Artificial Intelligence},
	keywords = {Boolean satisfiability,Clause-learning SAT solvers,DPLL,Proof complexity,Resolution proof},
	number = {2},
	pages = {512--525},
	title = {{On the power of clause-learning SAT solvers as resolution engines}},
	volume = {175},
	year = {2011}
}
@article{Hcbr,
	author = {Hcbr, X D},
	title = {{HG1t {\&} t ( p vu w ! xu dy ip  {\&}  x  {\pounds} s  d   v eq HG1G I ¨ {\textcopyright} P dc @ e fX YX a ` wxxzyg {\{} w | kTl nmok qpdr {\textcopyright} sut xlDv ( j Dwxxzy {\}}{\{} w | {\~{}} C  y {\#} wxxzy {\}}{\{} w | D  yg  1  yzx  B w    d ¡ B  ( ¢ {\pounds}¢ g ¤ {\&}  i g s ¥ {\S} ¦¨¤  x {\textcopyright}  H}}}
}
@article{Boese1994,
abstract = {We analyze relationships among local minima for the traveling salesman and graph bisection problems under standard neighborhood structures. Our work reveals surprising correlations that suggest a globally convex, or "big valley" structure in these optimization cost surfaces. In conjunction with combinatorial results that sharpen previous analyses, our analysis directly motivates a new adaptive multi-start paradigm for heuristic global optimization, wherein starting points for greedy descent are adaptively derived from the best previously found local minima. We test a simple instance of this method for the traveling salesman problem and obtain very significant speedups over previous multi-start implementations. ?? 1994.},
author = {Boese, Kenneth D. and Kahng, Andrew B. and Muddu, Sudhakar},
doi = {10.1016/0167-6377(94)90065-5},
issn = {01676377},
journal = {Operations Research Letters},
keywords = {Global optimization,Graph bisection,Heuristic search,Multi-start,Stochastic hill-climbing,Traveling salesman problem},
number = {2},
pages = {101--113},
title = {{A new adaptive multi-start technique for combinatorial global optimizations}},
volume = {16},
year = {1994}
}
@article{Adsit2014,
author = {Adsit, Connor and Bradley, Kevin and Heinrich, Christian},
pages = {1--17},
title = {{WalkSAT : Solving Boolean Satisfiability via Stochastic Search}},
year = {2014}
}
@article{Armananzas2008,
abstract = {Evolutionary search algorithms have become an essential asset in the algorithmic toolbox for solving high-dimensional optimization problems in across a broad range of bioinformatics problems. Genetic algorithms, the most well-known and representative evolutionary search technique, have been the subject of the major part of such applications. Estimation of distribution algorithms (EDAs) offer a novel evolutionary paradigm that constitutes a natural and attractive alternative to genetic algorithms. They make use of a probabilistic model, learnt from the promising solutions, to guide the search process. In this paper, we set out a basic taxonomy of EDA techniques, underlining the nature and complexity of the probabilistic model of each EDA variant. We review a set of innovative works that make use of EDA techniques to solve challenging bioinformatics problems, emphasizing the EDA paradigm's potential for further research in this domain.},
author = {Arma{\~{n}}anzas, Rub{\'{e}}n and Inza, I{\~{n}}aki and Santana, Roberto and Saeys, Yvan and Flores, Jose Luis and Lozano, Jose Antonio and {Van de Peer}, Yves and Blanco, Rosa and Robles, V{\'{i}}ctor and Bielza, Concha and Larra{\~{n}}aga, Pedro},
doi = {10.1186/1756-0381-1-6},
isbn = {1756-0381},
issn = {1756-0381},
journal = {BioData mining},
keywords = {Algorithms,Bioinformatics,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Data Mining and Knowledge Discovery},
number = {1},
pages = {6},
pmid = {18822112},
title = {{A review of estimation of distribution algorithms in bioinformatics.}},
url = {http://biodatamining.biomedcentral.com/articles/10.1186/1756-0381-1-6},
volume = {1},
year = {2008}
}
@article{Tabassum2014,
author = {Tabassum, Mujahid},
doi = {10.17781/P001091},
issn = {2225-658X},
journal = {International Journal of Digital Information and Wireless Communications},
number = {1},
pages = {124--142},
title = {{a Genetic Algorithm Analysis Towards Optimization Solutions}},
url = {http://sdiwc.net/digital-library/a-genetic-algorithm-analysis-towards-optimization-solutions.html},
volume = {4},
year = {2014}
}
@article{Selman1995,
abstract = {It has recently been shown that local search is surprisingly good at nding satisfying assignments for certain classes of CNF formulas In this paper we demonstrate that the power of local search for satissability testing can be further enhanced by employinga new strategy, called $\backslash$mixed random walk", for escaping from local minima. We present experimental results showing how this strategy allows us to handle formulas that are substantially larger than those that can be solved with basic local search. We also present a detailed comparison of our random walk strategy with simulated annealing. Our results show that mixed random walk is the superior strategy on several classes of computationally diicult problem instances. Finally, we present results demonstrating the eeectiveness of local search with walk for solving circuit synthesis and diagnosis problems.},
author = {Selman, Bart and Kautz, Henry and Cohen, Bram},
journal = {DIMACS Series in Discrete Mathematics and Theoretical Computer Science},
title = {{Local Search Strategies for Satissability Testing}},
volume = {00},
year = {1995}
}
@article{Trust2016,
author = {Trust, Biometrika},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trust - 2016 - Biometrika Trust On the Regression Analysis of Multivariate Failure Time Data Author ( s ) R . L . Prentice , B . J . Wil.pdf:pdf},
number = {2},
pages = {373--379},
title = {{Biometrika Trust On the Regression Analysis of Multivariate Failure Time Data Author ( s ): R . L . Prentice , B . J . Williams and A . V . Peterson Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : http://www.jstor.org/sta}},
volume = {68},
year = {2016}
}
@article{Bousquet2004,
abstract = {The goal of statistical learning theory is to study, in a statistical framework, the properties of learning algorithms. In particular, most results take the form of so-called error bounds. This tutorial introduces the techniques that are used to obtain such results.},
author = {Bousquet, Olivier},
doi = {10.1007/978-3-540-28650-9_8},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bousquet - 2004 - Introduction to Statistical Learning Theory.pdf:pdf},
isbn = {9783540231226},
issn = {03029743},
journal = {Biological Cybernetics},
number = {1},
pages = {169--207},
title = {{Introduction to Statistical Learning Theory}},
url = {http://www.springerlink.com/index/CGW0K6W5W1W1WR9B.pdf},
volume = {3176},
year = {2004}
}
@article{Lu2010,
author = {Lu, Tyler and P{\'{a}}l, D{\'{a}}vid and P{\'{a}}l, Martin},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu, P{\'{a}}l, P{\'{a}}l - 2010 - Contextual multi-armed bandits.pdf:pdf},
issn = {15324435},
journal = {International Conference on Artificial Intelligence and Statistics},
pages = {485--492},
title = {{Contextual multi-armed bandits}},
volume = {9},
year = {2010}
}
@article{Miller2012,
author = {Miller, G. and Weatherwax, M. and Gardinier, T. and Abe, N. and Melville, P. and Pendus, C. and Jensen, D. and Reddy, C. K. and Thomas, V. and Bennett, J. and Anderson, G. and Cooley, B.},
doi = {10.1287/inte.1110.0618},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller et al. - 2012 - Tax Collections Optimization for New York State.pdf:pdf},
issn = {0092-2102},
journal = {Interfaces},
keywords = {data analysis,decision support systems,dynamic programming,tax policy},
number = {1},
pages = {74--84},
title = {{Tax Collections Optimization for New York State}},
volume = {42},
year = {2012}
}
@article{Problem2016,
author = {Problem, Two-armed Bandit},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Problem - 2016 - Online planning for Multi-armed Bandit Problems.pdf:pdf},
number = {1},
pages = {2--4},
title = {{Online planning for Multi-armed Bandit Problems}},
year = {2016}
}
@article{Jiang2015,
abstract = {For Markov decision processes with long horizons (i.e., dis-count factors close to one), it is common in practice to use reduced horizons during planning to speed computation. However, perhaps surprisingly, when the model available to the agent is estimated from data, as will be the case in most real-world problems, the policy found using a shorter planning horizon can actually be better than a policy learned with the true horizon. In this paper we provide a precise explanation for this phenomenon based on principles of learn-ing theory. We show formally that the planning horizon is a complexity control parameter for the class of policies to be learned. In particular, it has an intuitive, monotonic rela-tionship with a simple counting measure of complexity, and that a similar relationship can be observed empirically with a more general and data-dependent Rademacher complexity measure. Each complexity measure gives rise to a bound on the planning loss predicting that a planning horizon shorter than the true horizon can reduce overfitting and improve test performance, and we confirm these predictions empirically.},
author = {Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang et al. - 2015 - The Dependence of Effective Planning Horizon on Model Accuracy.pdf:pdf},
isbn = {9781450337700},
issn = {15582914},
journal = {Proceedings of the 14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
keywords = {discount factor,over-fitting,reinforcement learning},
pages = {1181--1189},
title = {{The Dependence of Effective Planning Horizon on Model Accuracy}},
year = {2015}
}
@article{Cabras2007,
abstract = {Threshold selection is a key aspect in extreme values analysis, especially$\backslash$nwhen the sample size is small. The main idea underpinning this work$\backslash$nis that extreme observations are assumed to be outliers of a specified$\backslash$nparametric model. We propose a threshold selection method based on$\backslash$noutlier detection using a suitable measure of surprise. Copyright$\backslash$n(c) 2006 John Wiley {\&} Sons, Ltd.},
author = {Cabras, S and Morales, J},
doi = {10.1002/asmb},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cabras, Morales - 2007 - Extreme Value Analysis within a Parametric Outlier Detection Framework.pdf:pdf},
isbn = {15241904},
issn = {1524-1904},
journal = {Applied Stochastic Models in Business and Industry},
keywords = {generalized pareto distribution,partial posterior predictive distribution,threshold selection},
number = {January},
pages = {157--164},
pmid = {35395390},
title = {{Extreme Value Analysis within a Parametric Outlier Detection Framework}},
volume = {23},
year = {2007}
}
@incollection{Mahajan2008,
abstract = {Multi-armed bandit (MAB) problems are a class of sequential resource allo- cation problems concerned with allocating one or more resources among several alternative (competing) projects. Such problems are paradigms of a fun- damental conflict between making decisions (allocating resources) that yield high current rewards, versus making decisions that sacrifice current gains with the prospect of better future rewards. The MAB formulation models resource allocation problems arising in several technological and scientific disciplines such as sensor management, manufacturing systems, economics, queueing and communication networks, clinical trials, control theory, search theory, etc. (see 88 and references therein).},
author = {Mahajan, Aditya},
booktitle = {Foundations and Applications of Sensor Management},
doi = {10.1007/978-0-387-49819-5_6},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahajan - 2008 - Multi-Armed BAndit Problems.pdf:pdf},
isbn = {978-0-387-27892-6},
issn = {10959203},
pages = {121-- 151},
pmid = {16917057},
title = {{Multi-Armed BAndit Problems}},
url = {http://www.springerlink.com/index/RX4L35L04K022G37.pdf},
year = {2008}
}
@article{Kim2015,
abstract = {The multiarmed bandit problem is a popular framework for studying the exploration versus exploitation trade-off. Recent applications include dynamic assortment design, Internet advertising, dynamic pricing, and the control of queues. The standard mathematical formulation for a bandit problem makes the strong assumption that the decision maker has a full characterization of the joint distribution of the rewards, and that “arms” under this distribution are independent. These assumptions are not satisfied in many applications, and the out-of-sample performance of policies that optimize a misspecified model can be poor. Motivated by these concerns, we formulate a robust bandit problem in which a decision maker accounts for distrust in the nominal model by solving a worst-case problem against an adversary (“nature”) who has the ability to alter the underlying reward distribution and does so to minimize the decision maker's expected total profit. Structural properties of the optimal worst-case policy are charac...},
author = {Kim, Michael Jong and Lim, Andrew E.B.},
doi = {10.1287/mnsc.2015.2153},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Lim - 2015 - Robust Multiarmed Bandit Problems.pdf:pdf},
issn = {0025-1909},
journal = {Management Science},
keywords = {bandit problems,games against nature,model uncertainty,relative entropy,robust control},
number = {April},
pages = {150805104205004},
title = {{Robust Multiarmed Bandit Problems}},
year = {2015}
}
@book{Vanderbei2001,
author = {Vanderbei, Robert J},
edition = {2nd},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vanderbei - 2001 - Linear Programming Foundations and Extensions.pdf:pdf},
publisher = {Springer},
title = {{Linear Programming: Foundations and Extensions}},
year = {2001}
}
@book{Puterman2005,
author = {Puterman, Martin L},
file = {:home/reazul/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Puterman - 2005 - Markov decision processes Discrete stochastic dynamic programming.pdf:pdf},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Markov decision processes: Discrete stochastic dynamic programming}},
year = {2005}
}
@misc{openai,
	Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
	Title = {OpenAI Gym},
	Year = {2016},
	Eprint = {arXiv:1606.01540},
}
