\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Agrawal and Goyal}{2012a}]{Agrawal2012}
S.~Agrawal and N.~Goyal.
\newblock {Thompson Sampling for contextual bandits with linear payoffs}.
\newblock {\em Proceedings of the 30th International Conference on Machine
  Learning (ICML)}, 28:127--135, 2012.

\bibitem[\protect\citeauthoryear{Agrawal and Goyal}{2012b}]{Agrawal2011}
Shipra Agrawal and N~Goyal.
\newblock {Analysis of Thompson sampling for the multi-armed bandit problem}.
\newblock In {\em Annual Conference on Learning Theory (COLT)}, pages
  39.1--39.26, 2012.

\bibitem[\protect\citeauthoryear{Auer \bgroup \em et al.\egroup
  }{2009}]{Auer2009}
Peter Auer, Thomas Jaksch, and Ronald Ortner.
\newblock {Near-optimal Regret Bounds for Reinforcement Learning}.
\newblock In D~Koller, D~Schuurmans, Y~Bengio, and L~Bottou, editors, {\em
  Advances in Neural Information Processing Systems 21}. 2009.

\bibitem[\protect\citeauthoryear{Auer \bgroup \em et al.\egroup
  }{2010}]{Auer2010a}
P~Auer, Thomas Jaksch, and R~Ortner.
\newblock {Near-optimal regret bounds for reinforcement learning}.
\newblock {\em Journal of Machine Learning Research}, 11(1):1563--1600, 2010.

\bibitem[\protect\citeauthoryear{Auer}{2006}]{Auer2006}
Peter Auer.
\newblock {Logarithmic Online Regret Bounds for Undiscounted Reinforcement
  Learning}.
\newblock {\em Advances in Neural Information Processing Systems (NIPS)}, 2006.

\bibitem[\protect\citeauthoryear{Bertsekas and
  Tsitsiklis}{1996}]{Bertsekas1996}
Dimitri~P Bertsekas and John~N Tsitsiklis.
\newblock {\em {Neuro-dynamic programming}}.
\newblock 1996.

\bibitem[\protect\citeauthoryear{Brafman and Tennenholtz}{2001}]{Brafman2001}
Ronen~I. Brafman and Moshe Tennenholtz.
\newblock {R-MAX - A general polynomial time algorithm for near-optimal
  reinforcement learning}.
\newblock {\em International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2001.

\bibitem[\protect\citeauthoryear{Gelman \bgroup \em et al.\egroup
  }{2014}]{Gelman2004}
Andrew Gelman, John~B Carlin, Hal~S Stern, and Donald~B Rubin.
\newblock {\em {Bayesian Data Analysis}}.
\newblock 3rd edition, 2014.

\bibitem[\protect\citeauthoryear{Gupta}{2015}]{Gupta2015}
Vishal Gupta.
\newblock {Near-Optimal Bayesian Ambiguity Sets for Distributionally Robust
  Optimization}.
\newblock 2015.

\bibitem[\protect\citeauthoryear{Jaksch \bgroup \em et al.\egroup
  }{2010}]{Jaksch2010}
Thomas Jaksch, Ronald Ortner, and Peter Auer.
\newblock {Near-optimal Regret Bounds for Reinforcement Learning}.
\newblock {\em Journal of Machine Learning Research}, 11(1):1563--1600, 2010.

\bibitem[\protect\citeauthoryear{Kearns and Singh}{1998}]{Kearns1998a}
Michael Kearns and Satinder Singh.
\newblock {Near-optimal reinforcement learning in polynomial time}.
\newblock In {\em International Conference on Machine Learning}, volume~49,
  pages 260--268. Morgan Kaufmann, 1998.

\bibitem[\protect\citeauthoryear{Osband and {Van Roy}}{2017}]{Osband2016}
Ian Osband and Benjamin {Van Roy}.
\newblock {Why is Posterior Sampling Better than Optimism for Reinforcement
  Learning?}
\newblock {\em International Conference on Machine Learning (ICML)}, 2017.

\bibitem[\protect\citeauthoryear{Osband \bgroup \em et al.\egroup
  }{2013}]{Osband2013}
Ian Osband, Daniel Russo, and Benjamin {Van Roy}.
\newblock {(More) Efficient Reinforcement Learning via Posterior Sampling?}
\newblock {\em Advances in Neural Information Processing Systems (NIPS)}, 2013.

\bibitem[\protect\citeauthoryear{Petrik and Luss}{2016}]{Petrik2016}
Marek Petrik and Ronny Luss.
\newblock {Interpretable Policies for Dynamic Product Recommendations}.
\newblock In {\em Uncertainty in Artificial Intelligence (UAI)}, 2016.

\bibitem[\protect\citeauthoryear{Puterman}{2005}]{Puterman2005}
Martin~L Puterman.
\newblock {\em {Markov decision processes: Discrete stochastic dynamic
  programming}}.
\newblock John Wiley {\&} Sons, Inc., 2005.

\bibitem[\protect\citeauthoryear{Shapiro \bgroup \em et al.\egroup
  }{2014}]{Shapiro2014}
A.~Shapiro, D.~Dentcheva, and A.~Ruszczynski.
\newblock {\em {Lectures on stochastic programming: Modeling and theory}}.
\newblock 2014.

\bibitem[\protect\citeauthoryear{Strehl and Littman}{2004}]{Strehl2004}
a.~L. Strehl and M.~L. Littman.
\newblock {An empirical evaluation of interval estimation for markov decision
  processes}.
\newblock (April 2007):128--135, 2004.

\bibitem[\protect\citeauthoryear{Strehl and Littman}{2008}]{Strehl2008}
Alexander~L Strehl and Michael~L Littman.
\newblock {\em Journal of Computer and System Sciences}, 74:1309--1331, 2008.

\bibitem[\protect\citeauthoryear{Strens}{2000}]{Strens2002}
Malcolm Strens.
\newblock {A Bayesian Framework for Reinforcement Learning}.
\newblock {\em International Conference on Machine Learning (ICML)}, 2000.

\bibitem[\protect\citeauthoryear{Sutton and Barto}{1998}]{Sutton1998}
Richard~S Sutton and Andrew Barto.
\newblock {\em {Reinforcement learning}}.
\newblock 1998.

\bibitem[\protect\citeauthoryear{Thompson}{1933}]{Thompson1933}
W.R. Thompson.
\newblock {On the Likelihood that One Unknown Probability Exceeds Another in
  View of the Evidence of Two Samples}.
\newblock {\em Oxford University Press}, 25(3):285--294, 1933.

\bibitem[\protect\citeauthoryear{Wiering and Schmidhuber}{1998}]{Wiering1998}
Marco Wiering and Jurgen Schmidhuber.
\newblock {\em International Conference on Simulation of Adaptive Behavior
  (SAB)}, pages 223--228, 1998.

\bibitem[\protect\citeauthoryear{Wiesemann}{2013}]{Wiesemann2013a}
Wolfram Wiesemann.
\newblock {Robust Markov decision processes}.
\newblock {\em {\ldots} of Operations Research}, pages 1--52, 2013.

\end{thebibliography}
